{"text": "Convert the coordinate to text: [ 4.8857 -4.9441]: The authors introduce a general solution named ALT, a method that works alongside most existing GNNs to handle graphs with either low or high homophily effectively. ALT decomposes a graph into two components, extracts complementary signals, and merges them adaptively for node classification.", "target": "The authors introduce a general solution named ALT, a method that works alongside most existing GNNs to handle graphs with either low or high homophily effectively. ALT decomposes a graph into two components, extracts complementary signals, and merges them adaptively for node classification.", "example": "Convert the coordinate to text: [ 4.8857 -4.9441]:"}
{"text": "Convert the coordinate to text: [-6.0596 11.2176]: The authors conduct a systematic evaluation of toxicity in chatbot language models, specifically in ChatGPT. They examine the impact of assigning a persona to the model on the toxicity in its generations.", "target": "The authors conduct a systematic evaluation of toxicity in chatbot language models, specifically in ChatGPT. They examine the impact of assigning a persona to the model on the toxicity in its generations.", "example": "Convert the coordinate to text: [-6.0596 11.2176]:"}
{"text": "Convert the coordinate to text: [-3.8331 -3.6357]: The team PAI proposes a universal Named Entity Recognition (NER) system that integrates external entity information to improve performance. This system retrieves entities with properties from a knowledge base for a given text, then concatenates this entity information with the input sentence and feeds it into Transformer-based models.", "target": "The team PAI proposes a universal Named Entity Recognition (NER) system that integrates external entity information to improve performance. This system retrieves entities with properties from a knowledge base for a given text, then concatenates this entity information with the input sentence and feeds it into Transformer-based models.", "example": "Convert the coordinate to text: [-3.8331 -3.6357]:"}
{"text": "Convert the coordinate to text: [ 3.3341 -6.386 ]: We propose a Hierarchical Attention model for HKG Embedding (HAHE), including global-level and local-level attention. The global-level attention models the graphical structure of HKG using hypergraph dual-attention layers, while the local-level attention learns the sequential structure inside H-Facts via heterogeneous self-attention layers.", "target": "We propose a Hierarchical Attention model for HKG Embedding (HAHE), including global-level and local-level attention. The global-level attention models the graphical structure of HKG using hypergraph dual-attention layers, while the local-level attention learns the sequential structure inside H-Facts via heterogeneous self-attention layers.", "example": "Convert the coordinate to text: [ 3.3341 -6.386 ]:"}
{"text": "Convert the coordinate to text: [-2.6053 -6.7169]: The authors created four language models for Ancient Greek, varying by model type (RoBERTa and T5) and language composition (monolingual Ancient Greek or multilingual including Latin and English), providing a wide-ranging study on their applicability for Classical philology tasks.", "target": "The authors created four language models for Ancient Greek, varying by model type (RoBERTa and T5) and language composition (monolingual Ancient Greek or multilingual including Latin and English), providing a wide-ranging study on their applicability for Classical philology tasks.", "example": "Convert the coordinate to text: [-2.6053 -6.7169]:"}
{"text": "Convert the coordinate to text: [ 9.5253 -2.3824]: In this paper, the authors propose a method of re-parameterizing and fine-tuning PLMs by discovering intrinsic task-specific subspaces. This is done by exploiting the dynamics of the fine-tuning process for a given task and learning the parameter optimization trajectory.", "target": "In this paper, the authors propose a method of re-parameterizing and fine-tuning PLMs by discovering intrinsic task-specific subspaces. This is done by exploiting the dynamics of the fine-tuning process for a given task and learning the parameter optimization trajectory.", "example": "Convert the coordinate to text: [ 9.5253 -2.3824]:"}
{"text": "Convert the coordinate to text: [-0.8183 -0.2393]: The authors present a new task setting for attribute mining on e-commerce products, which extracts open-world attributes with minimal human intervention using a seed attribute set. They also propose a method, Amacer, designed specifically to handle this limited supervision.", "target": "The authors present a new task setting for attribute mining on e-commerce products, which extracts open-world attributes with minimal human intervention using a seed attribute set. They also propose a method, Amacer, designed specifically to handle this limited supervision.", "example": "Convert the coordinate to text: [-0.8183 -0.2393]:"}
{"text": "Convert the coordinate to text: [-5.8213 10.4242]: The paper proposes a method for building personalized open-domain dialogue systems that solve the WWH problem using tools such as weighted dataset blending, negative persona information augmentation, and personalized conversation datasets.", "target": "The paper proposes a method for building personalized open-domain dialogue systems that solve the WWH problem using tools such as weighted dataset blending, negative persona information augmentation, and personalized conversation datasets.", "example": "Convert the coordinate to text: [-5.8213 10.4242]:"}
{"text": "Convert the coordinate to text: [-9.7277 -5.143 ]: The authors propose the RST Continuity Corpus (RST-CC), a corpus of discourse relations annotated for continuity dimensions using operationalised versions of Giv\u00f3n\u2019s (1993) continuity dimensions.", "target": "The authors propose the RST Continuity Corpus (RST-CC), a corpus of discourse relations annotated for continuity dimensions using operationalised versions of Giv\u00f3n\u2019s (1993) continuity dimensions.", "example": "Convert the coordinate to text: [-9.7277 -5.143 ]:"}
{"text": "Convert the coordinate to text: [ 3.0266 -5.8095]: The paper introduces a new quantum machine learning model, Variational Quantum Network Embedding (VQNE), that uses quantum walk to extract structure information from two aligning networks and also adopts a quantum embedding ansatz for learning each node's latent representation, avoiding high quantum gate cost and the need for classic-quantum communication.", "target": "The paper introduces a new quantum machine learning model, Variational Quantum Network Embedding (VQNE), that uses quantum walk to extract structure information from two aligning networks and also adopts a quantum embedding ansatz for learning each node's latent representation, avoiding high quantum gate cost and the need for classic-quantum communication.", "example": "Convert the coordinate to text: [ 3.0266 -5.8095]:"}
{"text": "Convert the coordinate to text: [13.4156 -4.7012]: The authors propose GCBA, the first backdoor attack specifically designed for graph contrastive learning. This includes three types of attacks: poisoning, crafting, and natural backdoor, each targetting a different stage of the GCL pipeline.", "target": "The authors propose GCBA, the first backdoor attack specifically designed for graph contrastive learning. This includes three types of attacks: poisoning, crafting, and natural backdoor, each targetting a different stage of the GCL pipeline.", "example": "Convert the coordinate to text: [13.4156 -4.7012]:"}
{"text": "Convert the coordinate to text: [  5.2415 -12.7985]: The authors propose a novel method for generating general foreground-background segmentation models from simple textual descriptions, eliminating the need for segmentation labels. This method uses pre-trained latent diffusion models to create weak segmentation masks for concepts and objects, which are then used to fine-tune the diffusion model on an inpainting task.", "target": "The authors propose a novel method for generating general foreground-background segmentation models from simple textual descriptions, eliminating the need for segmentation labels. This method uses pre-trained latent diffusion models to create weak segmentation masks for concepts and objects, which are then used to fine-tune the diffusion model on an inpainting task.", "example": "Convert the coordinate to text: [  5.2415 -12.7985]:"}
{"text": "Convert the coordinate to text: [10.2324 -3.9504]: The authors propose the Tiny Updater - a novel training methodology that allows a fraction (10%~20%) of the parameters to update neural network-based software, building upon previous model compression research.", "target": "The authors propose the Tiny Updater - a novel training methodology that allows a fraction (10%~20%) of the parameters to update neural network-based software, building upon previous model compression research.", "example": "Convert the coordinate to text: [10.2324 -3.9504]:"}
{"text": "Convert the coordinate to text: [10.453   3.1582]: The authors propose the GRAND-SLAMIN framework for learning GAMs with interactions under sparsity and additional structural constraints. This tool offers flexibility, scalability, and accuracy across differentiable loss functions and is implemented using first-order gradient-based optimization and sparse backpropagation.", "target": "The authors propose the GRAND-SLAMIN framework for learning GAMs with interactions under sparsity and additional structural constraints. This tool offers flexibility, scalability, and accuracy across differentiable loss functions and is implemented using first-order gradient-based optimization and sparse backpropagation.", "example": "Convert the coordinate to text: [10.453   3.1582]:"}
{"text": "Convert the coordinate to text: [  5.1712 -14.5991]: This paper introduces PaintSeg, a novel unsupervised method for segmenting objects without any training. It uses an adversarial masked contrastive painting (AMCP) process which creates a contrast between the original image and a painted image.", "target": "This paper introduces PaintSeg, a novel unsupervised method for segmenting objects without any training. It uses an adversarial masked contrastive painting (AMCP) process which creates a contrast between the original image and a painted image.", "example": "Convert the coordinate to text: [  5.1712 -14.5991]:"}
{"text": "Convert the coordinate to text: [1.3058 7.9908]: A new algorithm is proposed for evaluating conjunctive queries with both short and long comparisons, and an acyclic condition is identified under which linear time can be achieved.", "target": "A new algorithm is proposed for evaluating conjunctive queries with both short and long comparisons, and an acyclic condition is identified under which linear time can be achieved.", "example": "Convert the coordinate to text: [1.3058 7.9908]:"}
{"text": "Convert the coordinate to text: [  7.8481 -12.6125]: The paper proposes that detectors be designed to reach tradeoffs between energy and performance. The authors propose a balanced detector driven by energy using discovered low-energy components named FemtoDet. A new instance boundary enhancement (IBE) module and a recursive warm-restart (RecWR) for optimizing training strategy are introduced.", "target": "The paper proposes that detectors be designed to reach tradeoffs between energy and performance. The authors propose a balanced detector driven by energy using discovered low-energy components named FemtoDet. A new instance boundary enhancement (IBE) module and a recursive warm-restart (RecWR) for optimizing training strategy are introduced.", "example": "Convert the coordinate to text: [  7.8481 -12.6125]:"}
{"text": "Convert the coordinate to text: [-1.0513 -8.2057]: The authors argue based on information-theoretic reasoning that perfect modality alignment can actually be sub-optimal for downstream tasks. They propose that the key to better performance lies in constructing meaningful latent modality structures.", "target": "The authors argue based on information-theoretic reasoning that perfect modality alignment can actually be sub-optimal for downstream tasks. They propose that the key to better performance lies in constructing meaningful latent modality structures.", "example": "Convert the coordinate to text: [-1.0513 -8.2057]:"}
{"text": "Convert the coordinate to text: [-1.2236 -8.2893]: The authors argue that the modality gap between speech and text data in E2E ST doesn't vastly impact final performance and that the capacity gap plays a crucial part to sub-optimal results. They propose focusing on regularization rather than modality adaption.", "target": "The authors argue that the modality gap between speech and text data in E2E ST doesn't vastly impact final performance and that the capacity gap plays a crucial part to sub-optimal results. They propose focusing on regularization rather than modality adaption.", "example": "Convert the coordinate to text: [-1.2236 -8.2893]:"}
{"text": "Convert the coordinate to text: [11.6122 -5.4833]: The authors proposed a novel adversarial training framework for spatiotemporal traffic forecasting tasks. The framework incorporates a reinforcement learning-based method for optimal node selection, alongside a self-knowledge distillation regularization module to address issues caused by changing adversarial nodes during training.", "target": "The authors proposed a novel adversarial training framework for spatiotemporal traffic forecasting tasks. The framework incorporates a reinforcement learning-based method for optimal node selection, alongside a self-knowledge distillation regularization module to address issues caused by changing adversarial nodes during training.", "example": "Convert the coordinate to text: [11.6122 -5.4833]:"}
{"text": "Convert the coordinate to text: [-11.1119  -2.0936]: To systematically study the robustness of Table QA models, the authors propose a benchmark called RobuT. It includes human-annotated adversarial perturbations in terms of table header, table content, and question, building upon existing Table QA datasets like WTQ, WikiSQL-Weak, and SQA.", "target": "To systematically study the robustness of Table QA models, the authors propose a benchmark called RobuT. It includes human-annotated adversarial perturbations in terms of table header, table content, and question, building upon existing Table QA datasets like WTQ, WikiSQL-Weak, and SQA.", "example": "Convert the coordinate to text: [-11.1119  -2.0936]:"}
{"text": "Convert the coordinate to text: [-1.5391 -3.1612]: The authors propose Concept2Box, a novel approach that embeds both the ontological view and the instance view of a knowledge graph using dual geometric representations; concepts are modeled using box embeddings, capturing their hierarchy and relationships like overlap and disjoint, and entities are modeled as vectors.", "target": "The authors propose Concept2Box, a novel approach that embeds both the ontological view and the instance view of a knowledge graph using dual geometric representations; concepts are modeled using box embeddings, capturing their hierarchy and relationships like overlap and disjoint, and entities are modeled as vectors.", "example": "Convert the coordinate to text: [-1.5391 -3.1612]:"}
{"text": "Convert the coordinate to text: [ 1.6964 -4.4905]: The paper proposes a model-agnostic framework named MoCL, based on contrastive learning, to refine original representations for cross-domain NER.", "target": "The paper proposes a model-agnostic framework named MoCL, based on contrastive learning, to refine original representations for cross-domain NER.", "example": "Convert the coordinate to text: [ 1.6964 -4.4905]:"}
{"text": "Convert the coordinate to text: [-2.6458  0.0878]: The authors propose a fine-tuned transformer-based model for problematic webpage classification and a novel webpage data collection strategy leveraging short-text hate speech datasets. They also introduce a custom GPT-4 few-shot prompt annotation scheme for webpage annotation.", "target": "The authors propose a fine-tuned transformer-based model for problematic webpage classification and a novel webpage data collection strategy leveraging short-text hate speech datasets. They also introduce a custom GPT-4 few-shot prompt annotation scheme for webpage annotation.", "example": "Convert the coordinate to text: [-2.6458  0.0878]:"}
{"text": "Convert the coordinate to text: [ 4.7954 -7.1927]: The authors present a new neural network architecture that incorporates document embeddings from a fine-tuned transformer-based model into a stacked long short-term memory (LSTM) and a fully connected linear (FCL) layer.", "target": "The authors present a new neural network architecture that incorporates document embeddings from a fine-tuned transformer-based model into a stacked long short-term memory (LSTM) and a fully connected linear (FCL) layer.", "example": "Convert the coordinate to text: [ 4.7954 -7.1927]:"}
{"text": "Convert the coordinate to text: [-3.2176  1.422 ]: This paper presents a novel approach, known as Joint Constrained Learning framework with Boundary-adjusting for Emotion-Cause Pair Extraction (JCB), which uses constrained learning to include the prior rules present in the data into the model optimization process. Furthermore, it adjusts the decision boundary of classifiers based on the relations between subtasks.", "target": "This paper presents a novel approach, known as Joint Constrained Learning framework with Boundary-adjusting for Emotion-Cause Pair Extraction (JCB), which uses constrained learning to include the prior rules present in the data into the model optimization process. Furthermore, it adjusts the decision boundary of classifiers based on the relations between subtasks.", "example": "Convert the coordinate to text: [-3.2176  1.422 ]:"}
{"text": "Convert the coordinate to text: [ 0.2766 -9.259 ]: To address the issue of semantic misalignment, a new framework named Concept Curation (CoCu) is introduced. This uses CLIP to compensate for missing semantics in image-text pairs by maintaining a concept archive with potential visually-matched concepts.", "target": "To address the issue of semantic misalignment, a new framework named Concept Curation (CoCu) is introduced. This uses CLIP to compensate for missing semantics in image-text pairs by maintaining a concept archive with potential visually-matched concepts.", "example": "Convert the coordinate to text: [ 0.2766 -9.259 ]:"}
{"text": "Convert the coordinate to text: [14.2688 -1.6056]: The authors propose a spike sorting-free decoding method that directly models the distribution of extracted spike features using a mixture of Gaussians (MoG) to encode the uncertainty of spike assignments.", "target": "The authors propose a spike sorting-free decoding method that directly models the distribution of extracted spike features using a mixture of Gaussians (MoG) to encode the uncertainty of spike assignments.", "example": "Convert the coordinate to text: [14.2688 -1.6056]:"}
{"text": "Convert the coordinate to text: [-5.3385  6.2463]: The authors aim to analyze the relationship between relevance and conflict in online social link recommendations using the Friedkin-Johnsen model of opinion dynamics.", "target": "The authors aim to analyze the relationship between relevance and conflict in online social link recommendations using the Friedkin-Johnsen model of opinion dynamics.", "example": "Convert the coordinate to text: [-5.3385  6.2463]:"}
{"text": "Convert the coordinate to text: [ 3.3724 14.463 ]: The paper introduces the self-play and adversarial Generalized Eluder Coefficient (GEC) as new complexity measures for function approximation in MGs. They also propose two novel model-based posterior sampling methods for learning Nash equilibrium and adversarial MGs.", "target": "The paper introduces the self-play and adversarial Generalized Eluder Coefficient (GEC) as new complexity measures for function approximation in MGs. They also propose two novel model-based posterior sampling methods for learning Nash equilibrium and adversarial MGs.", "example": "Convert the coordinate to text: [ 3.3724 14.463 ]:"}
{"text": "Convert the coordinate to text: [ 3.3708 -3.2777]: The authors propose handling continual learning tasks with neural processes (NPs), a class of meta-learners that encode different tasks into probabilistic distributions over functions which can also provide reliable uncertainty estimates. More specifically, they present a novel NP-based CL approach (NPCL) with task-specific modules organized in a hierarchical latent variable model.", "target": "The authors propose handling continual learning tasks with neural processes (NPs), a class of meta-learners that encode different tasks into probabilistic distributions over functions which can also provide reliable uncertainty estimates. More specifically, they present a novel NP-based CL approach (NPCL) with task-specific modules organized in a hierarchical latent variable model.", "example": "Convert the coordinate to text: [ 3.3708 -3.2777]:"}
{"text": "Convert the coordinate to text: [  9.2628 -11.3025]: This study presents D$^2$CSG, a neural model with dual and complementary network branches and dropouts for the unsupervised learning of compact CSG representations. The novelty lies in the dedicated residual branch to assemble the potentially complex shape complement which is subtracted from an overall shape modeled by the cover branch.", "target": "This study presents D$^2$CSG, a neural model with dual and complementary network branches and dropouts for the unsupervised learning of compact CSG representations. The novelty lies in the dedicated residual branch to assemble the potentially complex shape complement which is subtracted from an overall shape modeled by the cover branch.", "example": "Convert the coordinate to text: [  9.2628 -11.3025]:"}
{"text": "Convert the coordinate to text: [ 6.2637 -6.4822]: The paper proposes Metis, a novel framework which transforms REs to affordable models for network devices by leveraging the expert knowledge of REs and learning capability of NNs. Metis involves converting REs to byte-level recurrent neural networks (BRNNs) without training, with the option to improve their performance via training when rich labeled data is accessible.", "target": "The paper proposes Metis, a novel framework which transforms REs to affordable models for network devices by leveraging the expert knowledge of REs and learning capability of NNs. Metis involves converting REs to byte-level recurrent neural networks (BRNNs) without training, with the option to improve their performance via training when rich labeled data is accessible.", "example": "Convert the coordinate to text: [ 6.2637 -6.4822]:"}
{"text": "Convert the coordinate to text: [-1.2103 -4.1702]: The authors propose an efficient algorithm for latent variable modeling to leverage large amounts of dialogue data, avoiding the need for intermediate labels. This is achieved by adapting a query generator with an off-the-shelf knowledge retriever and simultaneously training the query and response generators over the query's latent variable.", "target": "The authors propose an efficient algorithm for latent variable modeling to leverage large amounts of dialogue data, avoiding the need for intermediate labels. This is achieved by adapting a query generator with an off-the-shelf knowledge retriever and simultaneously training the query and response generators over the query's latent variable.", "example": "Convert the coordinate to text: [-1.2103 -4.1702]:"}
{"text": "Convert the coordinate to text: [ -0.8667 -12.5162]: The authors propose an efficient masked autoencoder for trajectory prediction (Traj-MAE) that better encapsulates the complex behaviors of agents in a driving context. Traj-MAE employs different masking strategies to pre-train the trajectory encoder and map encoder which captures social and temporal data among agents while leveraging effects of the environment at multiple levels.", "target": "The authors propose an efficient masked autoencoder for trajectory prediction (Traj-MAE) that better encapsulates the complex behaviors of agents in a driving context. Traj-MAE employs different masking strategies to pre-train the trajectory encoder and map encoder which captures social and temporal data among agents while leveraging effects of the environment at multiple levels.", "example": "Convert the coordinate to text: [ -0.8667 -12.5162]:"}
{"text": "Convert the coordinate to text: [16.141   1.7849]: A new feature-space OOD detection score is proposed that simultaneously considers both class-specific and class-agnostic information. The method utilizes Whitened Linear Discriminant Analysis to project features into two subspaces, the discriminative and residual subspaces, which maximally separate and closely cluster ID classes, respectively.", "target": "A new feature-space OOD detection score is proposed that simultaneously considers both class-specific and class-agnostic information. The method utilizes Whitened Linear Discriminant Analysis to project features into two subspaces, the discriminative and residual subspaces, which maximally separate and closely cluster ID classes, respectively.", "example": "Convert the coordinate to text: [16.141   1.7849]:"}
{"text": "Convert the coordinate to text: [-14.6961  10.9101]: The authors propose to critically discuss whether hardware is inherently 'harder' and whether its innovation is a worthwhile endeavor for the HCI community.", "target": "The authors propose to critically discuss whether hardware is inherently 'harder' and whether its innovation is a worthwhile endeavor for the HCI community.", "example": "Convert the coordinate to text: [-14.6961  10.9101]:"}
{"text": "Convert the coordinate to text: [-1.464  -3.1789]: The paper proposes an unsupervised method for constructing Contextualized Commonsense Knowledge Graphs (CCKGs) that selects contextually relevant knowledge from large knowledge graphs (KGs). It computes semantic similarity between KG triplets and textual arguments, using these similarities as weights to extract contextualized knowledge paths connecting a conclusion to its premise.", "target": "The paper proposes an unsupervised method for constructing Contextualized Commonsense Knowledge Graphs (CCKGs) that selects contextually relevant knowledge from large knowledge graphs (KGs). It computes semantic similarity between KG triplets and textual arguments, using these similarities as weights to extract contextualized knowledge paths connecting a conclusion to its premise.", "example": "Convert the coordinate to text: [-1.464  -3.1789]:"}
{"text": "Convert the coordinate to text: [-9.3016  2.8262]: The authors propose to establish connections between shopping interests and product types by extracting product types from web pages containing hand-crafted product type recommendations for shopping interests. The extraction task is formulated as binary HTML node classification and they introduce TrENC for this task, a model that improves inter-node dependency modeling and injects shopping interest into node features for better semantic representation.", "target": "The authors propose to establish connections between shopping interests and product types by extracting product types from web pages containing hand-crafted product type recommendations for shopping interests. The extraction task is formulated as binary HTML node classification and they introduce TrENC for this task, a model that improves inter-node dependency modeling and injects shopping interest into node features for better semantic representation.", "example": "Convert the coordinate to text: [-9.3016  2.8262]:"}
{"text": "Convert the coordinate to text: [-1.5405 -5.2438]: The paper conducts a broad evaluation of methods for extracting confidence scores from language models fine-tuned with RLHF, and highlights the importance of the right prompting strategy in producing well-calibrated predictions.", "target": "The paper conducts a broad evaluation of methods for extracting confidence scores from language models fine-tuned with RLHF, and highlights the importance of the right prompting strategy in producing well-calibrated predictions.", "example": "Convert the coordinate to text: [-1.5405 -5.2438]:"}
{"text": "Convert the coordinate to text: [-2.223  -7.1515]: The authors investigate outlier dimensions and their relation to anisotropy in multiple pre-trained multilingual language models. The focus is on cross-lingual semantic similarity tasks, where sentence representations are particularly examined.", "target": "The authors investigate outlier dimensions and their relation to anisotropy in multiple pre-trained multilingual language models. The focus is on cross-lingual semantic similarity tasks, where sentence representations are particularly examined.", "example": "Convert the coordinate to text: [-2.223  -7.1515]:"}
{"text": "Convert the coordinate to text: [-4.058   9.8165]: The authors devised three novel text-based tasks for situational reasoning in the traffic domain (BDD-QA, TV-QA, HDT-QA), aiming to evaluate the ability of Language Models (LMs) to perform situational decision-making, reason about complex event causality and answer human driving exams, respectively.", "target": "The authors devised three novel text-based tasks for situational reasoning in the traffic domain (BDD-QA, TV-QA, HDT-QA), aiming to evaluate the ability of Language Models (LMs) to perform situational decision-making, reason about complex event causality and answer human driving exams, respectively.", "example": "Convert the coordinate to text: [-4.058   9.8165]:"}
{"text": "Convert the coordinate to text: [ 4.9106 11.7264]: A new model, Dual Period-Varying Preference modeling (DPVP), is proposed to tackle these challenges. The model includes a dual interaction-aware module that captures users' dual preferences based on their interactions with stores and foods, and a time-based decomposition module with a time-aware gating mechanism to account for varying preferences throughout the day.", "target": "A new model, Dual Period-Varying Preference modeling (DPVP), is proposed to tackle these challenges. The model includes a dual interaction-aware module that captures users' dual preferences based on their interactions with stores and foods, and a time-based decomposition module with a time-aware gating mechanism to account for varying preferences throughout the day.", "example": "Convert the coordinate to text: [ 4.9106 11.7264]:"}
{"text": "Convert the coordinate to text: [ 3.5255 -2.3592]: To tackle the problem of negative transfer, the authors propose a new algorithm that clusters tasks into groups based on a higher-order task affinity measure. A multitask model is then fit on each task group in a boosting procedure.", "target": "To tackle the problem of negative transfer, the authors propose a new algorithm that clusters tasks into groups based on a higher-order task affinity measure. A multitask model is then fit on each task group in a boosting procedure.", "example": "Convert the coordinate to text: [ 3.5255 -2.3592]:"}
{"text": "Convert the coordinate to text: [12.1986 -5.1745]: This study validates that adversarial samples created by attack algorithms correlate strongly with a specific vector in high-dimensional inputs called Universal Adversarial Perturbations (UAPs) that can be computed without original training data. A data-agnostic adversarial detection framework is proposed based on this discovery.", "target": "This study validates that adversarial samples created by attack algorithms correlate strongly with a specific vector in high-dimensional inputs called Universal Adversarial Perturbations (UAPs) that can be computed without original training data. A data-agnostic adversarial detection framework is proposed based on this discovery.", "example": "Convert the coordinate to text: [12.1986 -5.1745]:"}
{"text": "Convert the coordinate to text: [18.5249 -3.2038]: This study explores the use of transformer-based text classification, specifically fine-tuned RoBERTa transformer models, for clickbait spoiling and spoiler type classification, while also investigating an initial model for spoiler creation.", "target": "This study explores the use of transformer-based text classification, specifically fine-tuned RoBERTa transformer models, for clickbait spoiling and spoiler type classification, while also investigating an initial model for spoiler creation.", "example": "Convert the coordinate to text: [18.5249 -3.2038]:"}
{"text": "Convert the coordinate to text: [12.043  -5.2918]: The authors propose a simple and effective sharpness-based detector to distinct adversarial samples by maximizing the loss increment within the region where the inference sample is located.", "target": "The authors propose a simple and effective sharpness-based detector to distinct adversarial samples by maximizing the loss increment within the region where the inference sample is located.", "example": "Convert the coordinate to text: [12.043  -5.2918]:"}
{"text": "Convert the coordinate to text: [ 2.3648 -3.9456]: The paper proposes Contrastive Novelty-Augmented Learning (CoNAL), a two-step method that generates Out-Of-Distribution (OOD) examples representative of novel classes and trains to decrease confidence on them.", "target": "The paper proposes Contrastive Novelty-Augmented Learning (CoNAL), a two-step method that generates Out-Of-Distribution (OOD) examples representative of novel classes and trains to decrease confidence on them.", "example": "Convert the coordinate to text: [ 2.3648 -3.9456]:"}
{"text": "Convert the coordinate to text: [  4.0805 -12.4518]: EgoObjects is introduced, which is a large-scale egocentric dataset for fine-grained object understanding. It includes instance-level identifiers for each object and captures the same object under varied conditions like background complexities, surrounding objects, distances, lighting, and camera motion.", "target": "EgoObjects is introduced, which is a large-scale egocentric dataset for fine-grained object understanding. It includes instance-level identifiers for each object and captures the same object under varied conditions like background complexities, surrounding objects, distances, lighting, and camera motion.", "example": "Convert the coordinate to text: [  4.0805 -12.4518]:"}
{"text": "Convert the coordinate to text: [ 8.7784 10.6604]: The authors introduce Quantum-Gaussian Process-Upper Confidence Bound (Q-GP-UCB), the first Bayesian optimization algorithm capable of achieving an upper bound of O(polylog T), which is considerably smaller than the regret lower bound of Omega(sqrt(T)) in a classical framework.", "target": "The authors introduce Quantum-Gaussian Process-Upper Confidence Bound (Q-GP-UCB), the first Bayesian optimization algorithm capable of achieving an upper bound of O(polylog T), which is considerably smaller than the regret lower bound of Omega(sqrt(T)) in a classical framework.", "example": "Convert the coordinate to text: [ 8.7784 10.6604]:"}
{"text": "Convert the coordinate to text: [9.4684 0.8702]: The authors propose a new estimator called Rand-Proj-Spatial, which improves encoding by projecting the client vectors onto a random $k$-dimensional subspace using Subsampled Randomized Hadamard Transform (SRHT). The authors also propose a practical variant of Rand-Proj-Spatial for scenarios where correlation information is not available to the server.", "target": "The authors propose a new estimator called Rand-Proj-Spatial, which improves encoding by projecting the client vectors onto a random $k$-dimensional subspace using Subsampled Randomized Hadamard Transform (SRHT). The authors also propose a practical variant of Rand-Proj-Spatial for scenarios where correlation information is not available to the server.", "example": "Convert the coordinate to text: [9.4684 0.8702]:"}
{"text": "Convert the coordinate to text: [-2.1625 -6.3459]: The authors propose EconBERTa, a large language model pretrained on scientific publications in economics, and they also introduce ECON-IE, a new dataset of economics abstracts for Named Entity Recognition (NER).", "target": "The authors propose EconBERTa, a large language model pretrained on scientific publications in economics, and they also introduce ECON-IE, a new dataset of economics abstracts for Named Entity Recognition (NER).", "example": "Convert the coordinate to text: [-2.1625 -6.3459]:"}
{"text": "Convert the coordinate to text: [  4.6901 -14.287 ]: The authors propose using Normalized Mutual Information (NMI) for abstract segmentation, assuming that conclusions are strongly semantically linked with preceding premises, and introduce an unsupervised approach called GreedyCAS that places two segmentation boundaries by optimizing the NMI score.", "target": "The authors propose using Normalized Mutual Information (NMI) for abstract segmentation, assuming that conclusions are strongly semantically linked with preceding premises, and introduce an unsupervised approach called GreedyCAS that places two segmentation boundaries by optimizing the NMI score.", "example": "Convert the coordinate to text: [  4.6901 -14.287 ]:"}
{"text": "Convert the coordinate to text: [-7.2301 -8.8321]: The authors propose TopWORDS-Poetry, an unsupervised method to simultaneously perform reliable text segmentation and word discovery for classical Chinese poetry without a pre-given vocabulary or training corpus.", "target": "The authors propose TopWORDS-Poetry, an unsupervised method to simultaneously perform reliable text segmentation and word discovery for classical Chinese poetry without a pre-given vocabulary or training corpus.", "example": "Convert the coordinate to text: [-7.2301 -8.8321]:"}
{"text": "Convert the coordinate to text: [-2.4189  4.2393]: The authors propose a neural-network-based system that scores and extracts insights from a marketing content design. This system includes a multimodal neural network that predicts the attractiveness of marketing contents, and a post-hoc attribution method that generates actionable insights to improve content in specific marketing locations.", "target": "The authors propose a neural-network-based system that scores and extracts insights from a marketing content design. This system includes a multimodal neural network that predicts the attractiveness of marketing contents, and a post-hoc attribution method that generates actionable insights to improve content in specific marketing locations.", "example": "Convert the coordinate to text: [-2.4189  4.2393]:"}
{"text": "Convert the coordinate to text: [  8.0835 -20.0253]: The authors propose a new approach termed as 'ray conditioning' which is a geometry-free alternative that relaxes the photo-consistency constraint. It generates multi-view images by conditioning a 2D GAN on a light field prior.", "target": "The authors propose a new approach termed as 'ray conditioning' which is a geometry-free alternative that relaxes the photo-consistency constraint. It generates multi-view images by conditioning a 2D GAN on a light field prior.", "example": "Convert the coordinate to text: [  8.0835 -20.0253]:"}
{"text": "Convert the coordinate to text: [13.2594 -4.6972]: The authors propose AttDef, an efficient attribution-based pipeline to defend against two insertion-based poisoning attacks, BadNL and InSent. The method relies on identifying tokens with larger attribution scores as potential triggers since they contribute more to the false prediction results and are more likely to be poison triggers.", "target": "The authors propose AttDef, an efficient attribution-based pipeline to defend against two insertion-based poisoning attacks, BadNL and InSent. The method relies on identifying tokens with larger attribution scores as potential triggers since they contribute more to the false prediction results and are more likely to be poison triggers.", "example": "Convert the coordinate to text: [13.2594 -4.6972]:"}
{"text": "Convert the coordinate to text: [-1.7064 -1.7431]: This paper aims to assess the utility of machine-generated rationales for human users and proposes a new score, GEN-U, to evaluate the human utility of these rationales.", "target": "This paper aims to assess the utility of machine-generated rationales for human users and proposes a new score, GEN-U, to evaluate the human utility of these rationales.", "example": "Convert the coordinate to text: [-1.7064 -1.7431]:"}
{"text": "Convert the coordinate to text: [ 0.6435 -3.4857]: The authors investigate the impact of compositionality on imitation learning in language emergence and explore the relationship between the learning algorithm and the nature of language produced.", "target": "The authors investigate the impact of compositionality on imitation learning in language emergence and explore the relationship between the learning algorithm and the nature of language produced.", "example": "Convert the coordinate to text: [ 0.6435 -3.4857]:"}
{"text": "Convert the coordinate to text: [-1.0912  2.9069]: The authors propose Ranger, a task-agnostic toolkit that combines the effect of a treatment on multiple tasks into one statistical evaluation, making it possible to compare different metrics and compute a summary effect.", "target": "The authors propose Ranger, a task-agnostic toolkit that combines the effect of a treatment on multiple tasks into one statistical evaluation, making it possible to compare different metrics and compute a summary effect.", "example": "Convert the coordinate to text: [-1.0912  2.9069]:"}
{"text": "Convert the coordinate to text: [-6.121  -7.4842]: The paper introduces AlignScore, a unified, holistic metric based on a general function of information alignment between any two given text pieces. This metric is meant to assess a variety of factual inconsistency scenarios.", "target": "The paper introduces AlignScore, a unified, holistic metric based on a general function of information alignment between any two given text pieces. This metric is meant to assess a variety of factual inconsistency scenarios.", "example": "Convert the coordinate to text: [-6.121  -7.4842]:"}
{"text": "Convert the coordinate to text: [-1.324  -5.7693]: The authors propose to conduct a fairer comparison of the generalization performance of few-shot fine-tuning and in-context learning by controlling for the model size, number of examples and number of parameters.", "target": "The authors propose to conduct a fairer comparison of the generalization performance of few-shot fine-tuning and in-context learning by controlling for the model size, number of examples and number of parameters.", "example": "Convert the coordinate to text: [-1.324  -5.7693]:"}
{"text": "Convert the coordinate to text: [11.4199 -2.6545]: In this paper, both strengths and weaknesses of attention layers are examined in terms of representational power, focusing on intrinsic parameters such as width, depth, and embedding dimension.", "target": "In this paper, both strengths and weaknesses of attention layers are examined in terms of representational power, focusing on intrinsic parameters such as width, depth, and embedding dimension.", "example": "Convert the coordinate to text: [11.4199 -2.6545]:"}
{"text": "Convert the coordinate to text: [-2.4256 11.3866]: The paper proposes NESTA (NEuro-Symbolic Textual Agent), a modular system that combines a generic semantic parser with a rule induction system to learn abstract, interpretable rules as policies.", "target": "The paper proposes NESTA (NEuro-Symbolic Textual Agent), a modular system that combines a generic semantic parser with a rule induction system to learn abstract, interpretable rules as policies.", "example": "Convert the coordinate to text: [-2.4256 11.3866]:"}
{"text": "Convert the coordinate to text: [-7.5723 -5.0716]: This research aims to develop methods for identifying animate entities visually in comics using annotation experiments.", "target": "This research aims to develop methods for identifying animate entities visually in comics using annotation experiments.", "example": "Convert the coordinate to text: [-7.5723 -5.0716]:"}
{"text": "Convert the coordinate to text: [ 5.3762 -0.9142]: The authors propose WeLT, a cost-sensitive fine-tuning approach to deal with class imbalance in biomedical NER tasks. This approach introduces re-scaled class weights to improve the fine-tuning of BioPLMs.", "target": "The authors propose WeLT, a cost-sensitive fine-tuning approach to deal with class imbalance in biomedical NER tasks. This approach introduces re-scaled class weights to improve the fine-tuning of BioPLMs.", "example": "Convert the coordinate to text: [ 5.3762 -0.9142]:"}
{"text": "Convert the coordinate to text: [ 0.4131 -4.7657]: A unified generative model called UniCOQE is proposed to solve the COQE task in one shot. A generative template is designed where all the comparative tuples are concatenated as the target output sequence and a new 'predict-and-assign' training paradigm is introduced to alleviate order bias.", "target": "A unified generative model called UniCOQE is proposed to solve the COQE task in one shot. A generative template is designed where all the comparative tuples are concatenated as the target output sequence and a new 'predict-and-assign' training paradigm is introduced to alleviate order bias.", "example": "Convert the coordinate to text: [ 0.4131 -4.7657]:"}
{"text": "Convert the coordinate to text: [-6.6391  4.7366]: The authors propose Geo-Seq2seq, a sequence-to-sequence model for Twitter user geolocation that rewrites noisy, multilingual user-provided location strings into structured English location names.", "target": "The authors propose Geo-Seq2seq, a sequence-to-sequence model for Twitter user geolocation that rewrites noisy, multilingual user-provided location strings into structured English location names.", "example": "Convert the coordinate to text: [-6.6391  4.7366]:"}
{"text": "Convert the coordinate to text: [11.4321 -8.909 ]: The authors introduce a new sketch-photo correspondence benchmark (PSC6k) and propose a self-supervised method for learning dense correspondences between sketch-photo pairs, leveraging a spatial transformer network to estimate the warp flow between the latent representations of a sketch and photo.", "target": "The authors introduce a new sketch-photo correspondence benchmark (PSC6k) and propose a self-supervised method for learning dense correspondences between sketch-photo pairs, leveraging a spatial transformer network to estimate the warp flow between the latent representations of a sketch and photo.", "example": "Convert the coordinate to text: [11.4321 -8.909 ]:"}
{"text": "Convert the coordinate to text: [ 3.9756 -3.7569]: The authors propose a solution, TechCD, exploiting a pedagogical knowledge concept graph (KCG) as a mediator connecting various domains to transfer student cognitive signals from established domains to the zero-shot cold-start domain.", "target": "The authors propose a solution, TechCD, exploiting a pedagogical knowledge concept graph (KCG) as a mediator connecting various domains to transfer student cognitive signals from established domains to the zero-shot cold-start domain.", "example": "Convert the coordinate to text: [ 3.9756 -3.7569]:"}
{"text": "Convert the coordinate to text: [ 7.4932 -4.5232]: In this paper, the authors propose the first Unsupervised Domain Generalization framework for Face Anti-Spoofing (UDG-FAS) which exploits large amounts of easily accessible unlabeled data to learn generalizable features for enhancing the low-data regime of FAS. The authors propose a novel Split-Rotation-Merge module and search cross-domain neighbors method.", "target": "In this paper, the authors propose the first Unsupervised Domain Generalization framework for Face Anti-Spoofing (UDG-FAS) which exploits large amounts of easily accessible unlabeled data to learn generalizable features for enhancing the low-data regime of FAS. The authors propose a novel Split-Rotation-Merge module and search cross-domain neighbors method.", "example": "Convert the coordinate to text: [ 7.4932 -4.5232]:"}
{"text": "Convert the coordinate to text: [ 12.9469 -10.8598]: The authors present a face editing framework that merges a 3D face model with StyleGAN vector-quantization to help learn multi-level semantic facial control. This strategy allows more semantic facial representations, for instance, teeth and pupils, to be modeled beyond what can be achieved with 3D tracking priors.", "target": "The authors present a face editing framework that merges a 3D face model with StyleGAN vector-quantization to help learn multi-level semantic facial control. This strategy allows more semantic facial representations, for instance, teeth and pupils, to be modeled beyond what can be achieved with 3D tracking priors.", "example": "Convert the coordinate to text: [ 12.9469 -10.8598]:"}
{"text": "Convert the coordinate to text: [ 13.2722 -11.1549]: The authors propose a face recognition distillation method, ICD-Face, that introduces intra-class compactness distillation into the existing distillation framework.", "target": "The authors propose a face recognition distillation method, ICD-Face, that introduces intra-class compactness distillation into the existing distillation framework.", "example": "Convert the coordinate to text: [ 13.2722 -11.1549]:"}
{"text": "Convert the coordinate to text: [  8.7343 -11.2955]: The study proposes a weakly supervised method for point cloud segmentation, called Multimodal Interlaced Transformer (MIT), that uses two encoders and one decoder for jointly considering 2D and 3D data. The two encoders compute self-attended features for 3D point clouds and 2D multi-view images, while the decoder implements interlaced 2D-3D cross-attention and carries out implicit feature fusion.", "target": "The study proposes a weakly supervised method for point cloud segmentation, called Multimodal Interlaced Transformer (MIT), that uses two encoders and one decoder for jointly considering 2D and 3D data. The two encoders compute self-attended features for 3D point clouds and 2D multi-view images, while the decoder implements interlaced 2D-3D cross-attention and carries out implicit feature fusion.", "example": "Convert the coordinate to text: [  8.7343 -11.2955]:"}
{"text": "Convert the coordinate to text: [ 1.9949 -6.0673]: The key idea is the initiation of a new contrastive learning framework, FOCAL, which extracts comprehensive features from multimodal time-series sensing signals through self-supervised training. It encodes each modality into a factorized latent space of shared features and private features, and applies a temporal structural constraint for modality features.", "target": "The key idea is the initiation of a new contrastive learning framework, FOCAL, which extracts comprehensive features from multimodal time-series sensing signals through self-supervised training. It encodes each modality into a factorized latent space of shared features and private features, and applies a temporal structural constraint for modality features.", "example": "Convert the coordinate to text: [ 1.9949 -6.0673]:"}
{"text": "Convert the coordinate to text: [ 7.2218 12.5056]: To address these issues, the authors introduce an optimal stopping policy gradient algorithm (OSPG) that leverages recurrent neural networks (RNNs) effectively in non-Markovian settings. This is achieved by implicitly optimizing value functions without recursion, which helps in mitigating the issue of the curse of non-Markovianity.", "target": "To address these issues, the authors introduce an optimal stopping policy gradient algorithm (OSPG) that leverages recurrent neural networks (RNNs) effectively in non-Markovian settings. This is achieved by implicitly optimizing value functions without recursion, which helps in mitigating the issue of the curse of non-Markovianity.", "example": "Convert the coordinate to text: [ 7.2218 12.5056]:"}
{"text": "Convert the coordinate to text: [ 2.5492 14.1353]: The paper expands upon previous works by designing new algorithms, along with lower bounds, to provide a comprehensive parameterized complexity picture for calculating Nash and individually stable outcomes, without necessarily restricting the number of colors to two.", "target": "The paper expands upon previous works by designing new algorithms, along with lower bounds, to provide a comprehensive parameterized complexity picture for calculating Nash and individually stable outcomes, without necessarily restricting the number of colors to two.", "example": "Convert the coordinate to text: [ 2.5492 14.1353]:"}
{"text": "Convert the coordinate to text: [ 7.4116 -2.1455]: The paper introduces a novel approach called iFedCrowd (incentive-boosted Federated Crowdsourcing) which allows participants to locally process sensitive data, only uploading encrypted training models. This approach is designed to manage both the privacy and quality of crowdsourcing projects. An incentive mechanism is also introduced to encourage workers to constantly collect fresh data for training accurate client models and boosting global model training.", "target": "The paper introduces a novel approach called iFedCrowd (incentive-boosted Federated Crowdsourcing) which allows participants to locally process sensitive data, only uploading encrypted training models. This approach is designed to manage both the privacy and quality of crowdsourcing projects. An incentive mechanism is also introduced to encourage workers to constantly collect fresh data for training accurate client models and boosting global model training.", "example": "Convert the coordinate to text: [ 7.4116 -2.1455]:"}
{"text": "Convert the coordinate to text: [-7.9183 -1.4889]: The authors find that all Information Extraction tasks can be interpreted as extracting spans and span relations. They propose a Unified Token-pair Classification architecture for Information Extraction (UTC-IE) to unify all these tasks under the same token-pair classification formulation.", "target": "The authors find that all Information Extraction tasks can be interpreted as extracting spans and span relations. They propose a Unified Token-pair Classification architecture for Information Extraction (UTC-IE) to unify all these tasks under the same token-pair classification formulation.", "example": "Convert the coordinate to text: [-7.9183 -1.4889]:"}
{"text": "Convert the coordinate to text: [-2.4455  7.3863]: A generate-and-edit approach is proposed which utilizes the execution results of the generated code from LLMs to improve the code quality on a competitive programming task, and a fault-aware code editor is used to correct errors in the generated code.", "target": "A generate-and-edit approach is proposed which utilizes the execution results of the generated code from LLMs to improve the code quality on a competitive programming task, and a fault-aware code editor is used to correct errors in the generated code.", "example": "Convert the coordinate to text: [-2.4455  7.3863]:"}
{"text": "Convert the coordinate to text: [ 8.511 -5.285]: The authors introduce a flexible framework relying on stochastic frame-averaging (SFA) to make any model E(3)-equivariant or invariant through data transformations, and a new GNN named FAENet, optimized for SFA, that processes geometric information without any symmetry-preserving design constraints.", "target": "The authors introduce a flexible framework relying on stochastic frame-averaging (SFA) to make any model E(3)-equivariant or invariant through data transformations, and a new GNN named FAENet, optimized for SFA, that processes geometric information without any symmetry-preserving design constraints.", "example": "Convert the coordinate to text: [ 8.511 -5.285]:"}
{"text": "Convert the coordinate to text: [-5.6874 -6.4164]: The paper proposes a new approach to generate substitute candidates from a paraphraser, owing to the paraphraser's ability to contain variations in word choice and preserve the sentence's meaning. Two simple decoding strategies that focus on variations of the target word during decoding are introduced.", "target": "The paper proposes a new approach to generate substitute candidates from a paraphraser, owing to the paraphraser's ability to contain variations in word choice and preserve the sentence's meaning. Two simple decoding strategies that focus on variations of the target word during decoding are introduced.", "example": "Convert the coordinate to text: [-5.6874 -6.4164]:"}
{"text": "Convert the coordinate to text: [-0.4315 -2.1591]: The authors propose MolXPT, a unified language model of text and molecules pre-trained on SMILES sequences wrapped by text. In this approach, molecule names in text are detected and replaced with their corresponding SMILES representation, which could leverage the surrounding text information and vice versa.", "target": "The authors propose MolXPT, a unified language model of text and molecules pre-trained on SMILES sequences wrapped by text. In this approach, molecule names in text are detected and replaced with their corresponding SMILES representation, which could leverage the surrounding text information and vice versa.", "example": "Convert the coordinate to text: [-0.4315 -2.1591]:"}
{"text": "Convert the coordinate to text: [0.1093 0.7924]: The authors propose REsidual Attention Debiasing (READ), an end-to-end debiasing method specifically designed to mitigate unintended biases from attention in language understanding tasks.", "target": "The authors propose REsidual Attention Debiasing (READ), an end-to-end debiasing method specifically designed to mitigate unintended biases from attention in language understanding tasks.", "example": "Convert the coordinate to text: [0.1093 0.7924]:"}
{"text": "Convert the coordinate to text: [ 7.2224 -3.4196]: The authors recast controlled generation under distribution shift as an invariant learning problem, implying the most effective predictor should be invariant across different text environments.", "target": "The authors recast controlled generation under distribution shift as an invariant learning problem, implying the most effective predictor should be invariant across different text environments.", "example": "Convert the coordinate to text: [ 7.2224 -3.4196]:"}
{"text": "Convert the coordinate to text: [-0.8611 -8.5211]: This paper introduces an observation-guided radiology report generation framework (ORGAN) which first creates an observation plan and then uses this plan along with the radiographs to generate the report. An observation graph and a tree reasoning mechanism are utilized to enhance the plan information by capturing the multi-formats of each observation.", "target": "This paper introduces an observation-guided radiology report generation framework (ORGAN) which first creates an observation plan and then uses this plan along with the radiographs to generate the report. An observation graph and a tree reasoning mechanism are utilized to enhance the plan information by capturing the multi-formats of each observation.", "example": "Convert the coordinate to text: [-0.8611 -8.5211]:"}
{"text": "Convert the coordinate to text: [-9.2997 -6.6051]: The authors propose a syntax-guided text generation schema that generates the sequence guided by a constituency parse tree in a top-down direction, leading to a more natural language texts generation.", "target": "The authors propose a syntax-guided text generation schema that generates the sequence guided by a constituency parse tree in a top-down direction, leading to a more natural language texts generation.", "example": "Convert the coordinate to text: [-9.2997 -6.6051]:"}
{"text": "Convert the coordinate to text: [-4.2349 -5.3486]: The proposed system leverages language model representations using hand-crafted tag descriptors and explores how integrating the contextualized representations of tag descriptors with a language model can improve performance.", "target": "The proposed system leverages language model representations using hand-crafted tag descriptors and explores how integrating the contextualized representations of tag descriptors with a language model can improve performance.", "example": "Convert the coordinate to text: [-4.2349 -5.3486]:"}
{"text": "Convert the coordinate to text: [-1.4192  0.0874]: The paper presents the System of Ensembling Fine-tuning Models (SEFM) for the SemEval-2023 Task 10: Explainable Detection of Online Sexism. The approach uses task-adaptive pre-trained language models, addresses data imbalance through over-sampling and adjusting the loss function, and incorporates indicators and feedback modules to boost performance.", "target": "The paper presents the System of Ensembling Fine-tuning Models (SEFM) for the SemEval-2023 Task 10: Explainable Detection of Online Sexism. The approach uses task-adaptive pre-trained language models, addresses data imbalance through over-sampling and adjusting the loss function, and incorporates indicators and feedback modules to boost performance.", "example": "Convert the coordinate to text: [-1.4192  0.0874]:"}
{"text": "Convert the coordinate to text: [-2.64   -6.4932]: This paper proposes a system to achieve high generalization in sentiment analysis by further pre-training of the AfroXLM Pre-trained Language Model (PLM), combining AfroXLM and MARBERT PLMs using a residual layer, and studying the impact of metric learning and two out-of-distribution generalization training objectives.", "target": "This paper proposes a system to achieve high generalization in sentiment analysis by further pre-training of the AfroXLM Pre-trained Language Model (PLM), combining AfroXLM and MARBERT PLMs using a residual layer, and studying the impact of metric learning and two out-of-distribution generalization training objectives.", "example": "Convert the coordinate to text: [-2.64   -6.4932]:"}
{"text": "Convert the coordinate to text: [-8.1449 10.8257]: The authors propose a conceptual design of a task-based, user-adaptive dashboard for an intelligent language tutoring system that not only displays the learning progress and performance, but also supports navigation through the learning content.", "target": "The authors propose a conceptual design of a task-based, user-adaptive dashboard for an intelligent language tutoring system that not only displays the learning progress and performance, but also supports navigation through the learning content.", "example": "Convert the coordinate to text: [-8.1449 10.8257]:"}
{"text": "Convert the coordinate to text: [-2.2525 -7.3757]: The authors suggest a different pre-training method called Masked Latent Semantic Modeling (MLSM), which shifts the objective from reconstructing the exact masked subwords to predicting their latent semantic characteristics.", "target": "The authors suggest a different pre-training method called Masked Latent Semantic Modeling (MLSM), which shifts the objective from reconstructing the exact masked subwords to predicting their latent semantic characteristics.", "example": "Convert the coordinate to text: [-2.2525 -7.3757]:"}
{"text": "Convert the coordinate to text: [4.4249 0.0315]: The authors explore five different parameter-efficient weight ensembling methods to achieve transferability between tasks. These methods leverage information from datasets and trained lightweight parameters to determine task similarity, then use comparability weighting to adapt parameters for new task initializations.", "target": "The authors explore five different parameter-efficient weight ensembling methods to achieve transferability between tasks. These methods leverage information from datasets and trained lightweight parameters to determine task similarity, then use comparability weighting to adapt parameters for new task initializations.", "example": "Convert the coordinate to text: [4.4249 0.0315]:"}
{"text": "Convert the coordinate to text: [ 1.9494 -2.5004]: The paper explores for the first time whether the beneficial aspect of in-context instruction learning can be extended to a setting where tasks are sequentially fed to the target PLM for lifelong in-context instruction learning aimed at improving the target PLM's instance- and task-level generalization performance as it observes more tasks.", "target": "The paper explores for the first time whether the beneficial aspect of in-context instruction learning can be extended to a setting where tasks are sequentially fed to the target PLM for lifelong in-context instruction learning aimed at improving the target PLM's instance- and task-level generalization performance as it observes more tasks.", "example": "Convert the coordinate to text: [ 1.9494 -2.5004]:"}
{"text": "Convert the coordinate to text: [11.8859 -2.3806]: This study proposes a novel way to interpret neural networks through a linear decomposition method, considering the ReLU-activated Transformer as a linear model on a single input.", "target": "This study proposes a novel way to interpret neural networks through a linear decomposition method, considering the ReLU-activated Transformer as a linear model on a single input.", "example": "Convert the coordinate to text: [11.8859 -2.3806]:"}
{"text": "Convert the coordinate to text: [ 6.7251 13.2475]: The authors propose the versatile safe RL problem formulation incorporating two primary requirements: training efficiency and zero-shot adaptation capability. They introduce the Conditioned Constrained Policy Optimization (CCPO) framework consisting of two modules, the Versatile Value Estimation (VVE) and the Conditioned Variational Inference (CVI).", "target": "The authors propose the versatile safe RL problem formulation incorporating two primary requirements: training efficiency and zero-shot adaptation capability. They introduce the Conditioned Constrained Policy Optimization (CCPO) framework consisting of two modules, the Versatile Value Estimation (VVE) and the Conditioned Variational Inference (CVI).", "example": "Convert the coordinate to text: [ 6.7251 13.2475]:"}
{"text": "Convert the coordinate to text: [3.8241 8.8058]: In this work, the authors introduce a theoretical framework for analyzing the effectiveness of using generative models in optimizing combinatorial problems. The models should be expressive enough to generate approximately optimal solutions, have a tractable number of parameters, and their optimization landscape should not contain sub-optimal stationary points.", "target": "In this work, the authors introduce a theoretical framework for analyzing the effectiveness of using generative models in optimizing combinatorial problems. The models should be expressive enough to generate approximately optimal solutions, have a tractable number of parameters, and their optimization landscape should not contain sub-optimal stationary points.", "example": "Convert the coordinate to text: [3.8241 8.8058]:"}
{"text": "Convert the coordinate to text: [ 9.994 -8.414]: This study proposes a method for reconstructing complex images with high resolutions and large batch sizes in federated learning systems by constructing an over-parameterized convolutional network, allowing images to be generated before fitting to the gradient matching requirement.", "target": "This study proposes a method for reconstructing complex images with high resolutions and large batch sizes in federated learning systems by constructing an over-parameterized convolutional network, allowing images to be generated before fitting to the gradient matching requirement.", "example": "Convert the coordinate to text: [ 9.994 -8.414]:"}
{"text": "Convert the coordinate to text: [12.172  -5.5535]: The authors propose the Adversarial Visual Information Hiding (AVIH) method, which generates obfuscating adversarial perturbations to obscure visual data's visual information while ensuring hidden objectives are correctly predicted by models. Importantly, this method does not alter the parameters of the applied model, thereby ensuring its applicability in various scenarios.", "target": "The authors propose the Adversarial Visual Information Hiding (AVIH) method, which generates obfuscating adversarial perturbations to obscure visual data's visual information while ensuring hidden objectives are correctly predicted by models. Importantly, this method does not alter the parameters of the applied model, thereby ensuring its applicability in various scenarios.", "example": "Convert the coordinate to text: [12.172  -5.5535]:"}
{"text": "Convert the coordinate to text: [-2.342  11.9158]: A novel framework named 'Reflexion' is proposed that reinforces language agents not by updating weights, but through linguistic feedback, with agents verbally reflecting on task feedback signals, and maintaining their own reflective text in an episodic memory buffer to induce better decision-making in subsequent trials.", "target": "A novel framework named 'Reflexion' is proposed that reinforces language agents not by updating weights, but through linguistic feedback, with agents verbally reflecting on task feedback signals, and maintaining their own reflective text in an episodic memory buffer to induce better decision-making in subsequent trials.", "example": "Convert the coordinate to text: [-2.342  11.9158]:"}
{"text": "Convert the coordinate to text: [13.4297 -4.7303]: This paper introduces a robust and stealthy backdoor attack design: BITE. BITE poisons training data to establish strong correlations between a target label and certain 'trigger words' by naturally and iteratively injecting them into target-label instances.", "target": "This paper introduces a robust and stealthy backdoor attack design: BITE. BITE poisons training data to establish strong correlations between a target label and certain 'trigger words' by naturally and iteratively injecting them into target-label instances.", "example": "Convert the coordinate to text: [13.4297 -4.7303]:"}
{"text": "Convert the coordinate to text: [-4.1973 16.2116]: The authors propose a new approach, Unified Autonomous Driving (UniAD), a comprehensive framework that includes all full-stack driving tasks within one network. Instead of treating tasks separately, all tasks are designed to contribute specifically to planning, the ultimate goal of autonomous driving.", "target": "The authors propose a new approach, Unified Autonomous Driving (UniAD), a comprehensive framework that includes all full-stack driving tasks within one network. Instead of treating tasks separately, all tasks are designed to contribute specifically to planning, the ultimate goal of autonomous driving.", "example": "Convert the coordinate to text: [-4.1973 16.2116]:"}
{"text": "Convert the coordinate to text: [-2.52   -5.1154]: This study is concerned with evaluating PLMs in the medical domain, with specific reference to the French language. The authors make the first comparison of performance of PLMs trained on both public data from the web and private data from healthcare establishments in French medical domain.", "target": "This study is concerned with evaluating PLMs in the medical domain, with specific reference to the French language. The authors make the first comparison of performance of PLMs trained on both public data from the web and private data from healthcare establishments in French medical domain.", "example": "Convert the coordinate to text: [-2.52   -5.1154]:"}
{"text": "Convert the coordinate to text: [-5.4933 -4.4316]: SemEval-2023 Task 2 is a fine-grained multilingual NER task, calling for methods to identify complex fine-grained named entities in 12 languages, in both monolingual and multilingual scenarios, as well as noisy settings, using the MultiCoNER V2 dataset.", "target": "SemEval-2023 Task 2 is a fine-grained multilingual NER task, calling for methods to identify complex fine-grained named entities in 12 languages, in both monolingual and multilingual scenarios, as well as noisy settings, using the MultiCoNER V2 dataset.", "example": "Convert the coordinate to text: [-5.4933 -4.4316]:"}
{"text": "Convert the coordinate to text: [10.3282 -3.8389]: The authors propose representing the optimal pruning decision as an equality-constrained 0-1 Integer Linear Programming problem and propose a self-regularization scheme where model prediction is regularized by the latest checkpoint with increasing sparsity throughout pruning.", "target": "The authors propose representing the optimal pruning decision as an equality-constrained 0-1 Integer Linear Programming problem and propose a self-regularization scheme where model prediction is regularized by the latest checkpoint with increasing sparsity throughout pruning.", "example": "Convert the coordinate to text: [10.3282 -3.8389]:"}
{"text": "Convert the coordinate to text: [-7.3912  6.9898]: The authors propose a new annotated dataset with human-labelled explanations and classification of Interpersonal Risk Factors (IRF) affecting mental disturbance on social media, namely Thwarted Belongingness (TBe) and Perceived Burdensomeness (PBu).", "target": "The authors propose a new annotated dataset with human-labelled explanations and classification of Interpersonal Risk Factors (IRF) affecting mental disturbance on social media, namely Thwarted Belongingness (TBe) and Perceived Burdensomeness (PBu).", "example": "Convert the coordinate to text: [-7.3912  6.9898]:"}
{"text": "Convert the coordinate to text: [-2.0532 -5.5541]: The study examines and compares the learning trajectories of deep language models, specifically GPT-2, to those of children. The aim is to determine whether stages of language acquisition in GPT-2 during training are comparable to those observed in children aged 18 months to 6 years.", "target": "The study examines and compares the learning trajectories of deep language models, specifically GPT-2, to those of children. The aim is to determine whether stages of language acquisition in GPT-2 during training are comparable to those observed in children aged 18 months to 6 years.", "example": "Convert the coordinate to text: [-2.0532 -5.5541]:"}
{"text": "Convert the coordinate to text: [-2.7553 -3.7383]: The paper proposes using a probing technique to elicit relational semantic knowledge from large-scale pre-trained language models. It also introduces a graph decomposition method to decompose the probing graph into four sub-graphs from intra- and inter-passage perspectives.", "target": "The paper proposes using a probing technique to elicit relational semantic knowledge from large-scale pre-trained language models. It also introduces a graph decomposition method to decompose the probing graph into four sub-graphs from intra- and inter-passage perspectives.", "example": "Convert the coordinate to text: [-2.7553 -3.7383]:"}
{"text": "Convert the coordinate to text: [18.5388 -3.1898]: The authors propose using DeBERTaV3 models and introduce an approach that takes into account the information-placement described within the webpages markup for classifying spoiler types in clickbait web articles.", "target": "The authors propose using DeBERTaV3 models and introduce an approach that takes into account the information-placement described within the webpages markup for classifying spoiler types in clickbait web articles.", "example": "Convert the coordinate to text: [18.5388 -3.1898]:"}
{"text": "Convert the coordinate to text: [-1.2696  0.0865]: The authors conduct a comparison of pre-trained encoder-only and decoder-only language models with continued pre-training for detecting online sexism and put a focus on enhancing the interpretability of such systems.", "target": "The authors conduct a comparison of pre-trained encoder-only and decoder-only language models with continued pre-training for detecting online sexism and put a focus on enhancing the interpretability of such systems.", "example": "Convert the coordinate to text: [-1.2696  0.0865]:"}
{"text": "Convert the coordinate to text: [-1.8824 -6.1049]: The authors propose a model using the LinkBERT transformer in the biomedical domain, denoted as BioLinkBERT. The model uses sentences from clinical trial reports as evidence in premise-statement inference to determine inference relations, and applies a soft voting ensemble mechanism to enhance system performance.", "target": "The authors propose a model using the LinkBERT transformer in the biomedical domain, denoted as BioLinkBERT. The model uses sentences from clinical trial reports as evidence in premise-statement inference to determine inference relations, and applies a soft voting ensemble mechanism to enhance system performance.", "example": "Convert the coordinate to text: [-1.8824 -6.1049]:"}
{"text": "Convert the coordinate to text: [-5.6068 -9.488 ]: The authors present an imitation learning approach where a teacher NMT system corrects the errors of an AST student without relying on manual transcripts.", "target": "The authors present an imitation learning approach where a teacher NMT system corrects the errors of an AST student without relying on manual transcripts.", "example": "Convert the coordinate to text: [-5.6068 -9.488 ]:"}
{"text": "Convert the coordinate to text: [-9.8431 -2.2364]: The authors propose to rely on dynamic learning analytics for automatic and dynamic generation and adaptation of distractors in Single Choice exercises, as well as informing exercise generation in terms of relevant learning goals and reasonable chunking in Jumbled Sentences exercises.", "target": "The authors propose to rely on dynamic learning analytics for automatic and dynamic generation and adaptation of distractors in Single Choice exercises, as well as informing exercise generation in terms of relevant learning goals and reasonable chunking in Jumbled Sentences exercises.", "example": "Convert the coordinate to text: [-9.8431 -2.2364]:"}
{"text": "Convert the coordinate to text: [-1.7281 -5.0318]: The authors propose a solution to the identified problem: a training algorithm called LM-TOAST, which makes PLMs both task-solvers and self-calibrators. This addresses the challenges of limited training samples, data imbalance, and distribution shifts.", "target": "The authors propose a solution to the identified problem: a training algorithm called LM-TOAST, which makes PLMs both task-solvers and self-calibrators. This addresses the challenges of limited training samples, data imbalance, and distribution shifts.", "example": "Convert the coordinate to text: [-1.7281 -5.0318]:"}
{"text": "Convert the coordinate to text: [-3.7026 -8.5809]: The paper proposes a two-stage translation prototype called hybrid-regressive translation (HRT) that combines the robustness of AT with the speed of NAT by first generating discontinuous sequences via autoregression and then filling in all previously skipped tokens at once in a non-autoregressive manner.", "target": "The paper proposes a two-stage translation prototype called hybrid-regressive translation (HRT) that combines the robustness of AT with the speed of NAT by first generating discontinuous sequences via autoregression and then filling in all previously skipped tokens at once in a non-autoregressive manner.", "example": "Convert the coordinate to text: [-3.7026 -8.5809]:"}
{"text": "Convert the coordinate to text: [ 5.4128 -5.1698]: The authors question the necessity of MP in KGC tasks, finding that simple MLP models can achieve comparable performance to MPNNs. They also highlight the impact of careful scoring function and loss function design on the KGC model's performance.", "target": "The authors question the necessity of MP in KGC tasks, finding that simple MLP models can achieve comparable performance to MPNNs. They also highlight the impact of careful scoring function and loss function design on the KGC model's performance.", "example": "Convert the coordinate to text: [ 5.4128 -5.1698]:"}
{"text": "Convert the coordinate to text: [-1.5545 -8.2215]: The paper introduces a novel fine-tuning method known as DEER that allows a single pre-trained model to perform Dynamic and Efficient infERence. The main concept involves utilizing non-autoregressive (NAR) generation and dynamic parameter pruning techniques to control the model's decoding iteration steps and sizes according to memory limitations and latency.", "target": "The paper introduces a novel fine-tuning method known as DEER that allows a single pre-trained model to perform Dynamic and Efficient infERence. The main concept involves utilizing non-autoregressive (NAR) generation and dynamic parameter pruning techniques to control the model's decoding iteration steps and sizes according to memory limitations and latency.", "example": "Convert the coordinate to text: [-1.5545 -8.2215]:"}
{"text": "Convert the coordinate to text: [ 1.4252 -6.6575]: The authors propose a fine-grained attention alignment approach that jointly optimizes a cascade document ranking model. The approach uses the attention activations from the document ranker as feedback to optimize the selector and fuses the relevance scores from the selector into the ranker.", "target": "The authors propose a fine-grained attention alignment approach that jointly optimizes a cascade document ranking model. The approach uses the attention activations from the document ranker as feedback to optimize the selector and fuses the relevance scores from the selector into the ranker.", "example": "Convert the coordinate to text: [ 1.4252 -6.6575]:"}
{"text": "Convert the coordinate to text: [2.3772 6.999 ]: The authors aim to answer the question raised by Zhang et al., regarding the capability of probabilistic generating circuits to efficiently represent all strongly Rayleigh distributions.", "target": "The authors aim to answer the question raised by Zhang et al., regarding the capability of probabilistic generating circuits to efficiently represent all strongly Rayleigh distributions.", "example": "Convert the coordinate to text: [2.3772 6.999 ]:"}
{"text": "Convert the coordinate to text: [-0.6102 -6.0719]: The authors propose Dynamic Prompt Learning (DPL) to refine cross-attention maps which forces more attention on correct noun words in the text prompt. This addresses the issue of unintended changes in off-target areas during text-based image editing.", "target": "The authors propose Dynamic Prompt Learning (DPL) to refine cross-attention maps which forces more attention on correct noun words in the text prompt. This addresses the issue of unintended changes in off-target areas during text-based image editing.", "example": "Convert the coordinate to text: [-0.6102 -6.0719]:"}
{"text": "Convert the coordinate to text: [-5.6363 -0.6741]: The authors propose a novel approach named DisCal to enhance the level of abstractiveness (measured by n-gram overlap) without sacrificing the informativeness (measured by ROUGE) of generated summaries. DisCal exposes diverse pseudo summaries with two supervision to the student model.", "target": "The authors propose a novel approach named DisCal to enhance the level of abstractiveness (measured by n-gram overlap) without sacrificing the informativeness (measured by ROUGE) of generated summaries. DisCal exposes diverse pseudo summaries with two supervision to the student model.", "example": "Convert the coordinate to text: [-5.6363 -0.6741]:"}
{"text": "Convert the coordinate to text: [11.8252  6.9564]: A theoretical examination is conducted to comprehend chaotic and non-smooth optimizations in model-based RP PGMs. The smoothness of function approximators is identified as a major factor affecting gradient estimation quality in these situations.", "target": "A theoretical examination is conducted to comprehend chaotic and non-smooth optimizations in model-based RP PGMs. The smoothness of function approximators is identified as a major factor affecting gradient estimation quality in these situations.", "example": "Convert the coordinate to text: [11.8252  6.9564]:"}
{"text": "Convert the coordinate to text: [9.3365 0.565 ]: The authors propose a decorrelation-enhanced GCF objective that promotes feature diversity by leveraging the principle of redundancy reduction in embeddings, using non-Euclidean geometry to maintain the range space of the matrix and obtain a small condition number, thereby preventing the embedding space degradation.", "target": "The authors propose a decorrelation-enhanced GCF objective that promotes feature diversity by leveraging the principle of redundancy reduction in embeddings, using non-Euclidean geometry to maintain the range space of the matrix and obtain a small condition number, thereby preventing the embedding space degradation.", "example": "Convert the coordinate to text: [9.3365 0.565 ]:"}
{"text": "Convert the coordinate to text: [16.2454  1.8064]: The authors provide a systematic and in-depth analysis on OOD detection for document understanding models, studying the effects of model modality, pre-training, and fine-tuning across various types of OOD inputs. They also propose a spatial-aware adapter to better exploit spatial information in documents for OOD detection.", "target": "The authors provide a systematic and in-depth analysis on OOD detection for document understanding models, studying the effects of model modality, pre-training, and fine-tuning across various types of OOD inputs. They also propose a spatial-aware adapter to better exploit spatial information in documents for OOD detection.", "example": "Convert the coordinate to text: [16.2454  1.8064]:"}
{"text": "Convert the coordinate to text: [-15.1681  10.2672]: The paper proposes a workshop aiming to gather seasoned scholars and early career researchers to explore the intersection of generative AI and Human Computer Interaction (HCI). They will scrutinize the interaction of humans with generative AI, ethical controls, and collaborative patterns.", "target": "The paper proposes a workshop aiming to gather seasoned scholars and early career researchers to explore the intersection of generative AI and Human Computer Interaction (HCI). They will scrutinize the interaction of humans with generative AI, ethical controls, and collaborative patterns.", "example": "Convert the coordinate to text: [-15.1681  10.2672]:"}
{"text": "Convert the coordinate to text: [ 5.0858 -4.6535]: This work presents GeneticFlow (GF), a suite of graph-based scholar profiles that fulfill three requirements: structured-context, scholar-centric, and evolution-rich. The authors propose a framework to compute GF over large-scale academic data sources.", "target": "This work presents GeneticFlow (GF), a suite of graph-based scholar profiles that fulfill three requirements: structured-context, scholar-centric, and evolution-rich. The authors propose a framework to compute GF over large-scale academic data sources.", "example": "Convert the coordinate to text: [ 5.0858 -4.6535]:"}
{"text": "Convert the coordinate to text: [-11.99   -11.1566]: This study proposes to improve the RDW experience by mitigating visual-vestibular inconsistencies using four types of vestibular stimulations: noisy and directional galvanic vestibular stimulation, bone-conduction vibration, and caloric vestibular stimulation.", "target": "This study proposes to improve the RDW experience by mitigating visual-vestibular inconsistencies using four types of vestibular stimulations: noisy and directional galvanic vestibular stimulation, bone-conduction vibration, and caloric vestibular stimulation.", "example": "Convert the coordinate to text: [-11.99   -11.1566]:"}
{"text": "Convert the coordinate to text: [-11.8801   8.7285]: The authors present a free and open web-based study planning toolkit for researchers, which contains multiple interactive research applications aimed at assisting with the selection of research methods, planning of experimental studies, informed consent generation, calendar booking for studies in shared labs, and automated participation confirmation.", "target": "The authors present a free and open web-based study planning toolkit for researchers, which contains multiple interactive research applications aimed at assisting with the selection of research methods, planning of experimental studies, informed consent generation, calendar booking for studies in shared labs, and automated participation confirmation.", "example": "Convert the coordinate to text: [-11.8801   8.7285]:"}
{"text": "Convert the coordinate to text: [14.2252  5.3974]: This work seeks to address the limitations in scoring functions by employing the unbalanced optimal transport theory and hence investigating the local and global trade-off. Specifically, a new embedding method, Wasserstein-Fisher-Rao Embedding (WFRE), is proposed that embeds sets as bounded measures in \u211d with a scoring function based on the Wasserstein-Fisher-Rao metric, thus facilitating closed-form set operators in the embedding space.", "target": "This work seeks to address the limitations in scoring functions by employing the unbalanced optimal transport theory and hence investigating the local and global trade-off. Specifically, a new embedding method, Wasserstein-Fisher-Rao Embedding (WFRE), is proposed that embeds sets as bounded measures in \u211d with a scoring function based on the Wasserstein-Fisher-Rao metric, thus facilitating closed-form set operators in the embedding space.", "example": "Convert the coordinate to text: [14.2252  5.3974]:"}
{"text": "Convert the coordinate to text: [-10.4266  -1.5896]: This paper proposes a 5W framework (who, what, when, where, and why) for question-answer-based fact explainability and introduces the FACTIFY-5WQA dataset. This dataset is comprised of facts along with relevant 5W questions and answers. The authors also develop a robust fact verification system that can validate paraphrased claims automatically.", "target": "This paper proposes a 5W framework (who, what, when, where, and why) for question-answer-based fact explainability and introduces the FACTIFY-5WQA dataset. This dataset is comprised of facts along with relevant 5W questions and answers. The authors also develop a robust fact verification system that can validate paraphrased claims automatically.", "example": "Convert the coordinate to text: [-10.4266  -1.5896]:"}
{"text": "Convert the coordinate to text: [-5.5696 -6.9425]: The authors propose taking a step back from the technical component and focus on how linguistic aspects such as mutual intelligibility or degree of language relatedness can improve ARA in a low-resource setting.", "target": "The authors propose taking a step back from the technical component and focus on how linguistic aspects such as mutual intelligibility or degree of language relatedness can improve ARA in a low-resource setting.", "example": "Convert the coordinate to text: [-5.5696 -6.9425]:"}
{"text": "Convert the coordinate to text: [-0.4674  0.4277]: This study unveils and addresses the social bias problem within pretrained code generation models. An innovative framework is proposed for constructing code prompts that reveal social biases in these models.", "target": "This study unveils and addresses the social bias problem within pretrained code generation models. An innovative framework is proposed for constructing code prompts that reveal social biases in these models.", "example": "Convert the coordinate to text: [-0.4674  0.4277]:"}
{"text": "Convert the coordinate to text: [-0.1767 -4.479 ]: The authors propose Diable, a new task formalisation for dialogue state tracking, which simplifies the design and implementation of DST systems. It represents the dialogue state as a table and formalises DST as a table manipulation task, updating the state by generating table operations based on the dialogue context.", "target": "The authors propose Diable, a new task formalisation for dialogue state tracking, which simplifies the design and implementation of DST systems. It represents the dialogue state as a table and formalises DST as a table manipulation task, updating the state by generating table operations based on the dialogue context.", "example": "Convert the coordinate to text: [-0.1767 -4.479 ]:"}
{"text": "Convert the coordinate to text: [ 5.0941 13.9516]: This paper proposes Fine-Grained RLHF, a framework that leverages fine-grained human feedback, such as pinpointing where a sentence is false, and uses it as an explicit training signal. This feedback is fine-grained in two respects: density, providing a reward after every segment is generated, and incorporating multiple reward models associated with different feedback types.", "target": "This paper proposes Fine-Grained RLHF, a framework that leverages fine-grained human feedback, such as pinpointing where a sentence is false, and uses it as an explicit training signal. This feedback is fine-grained in two respects: density, providing a reward after every segment is generated, and incorporating multiple reward models associated with different feedback types.", "example": "Convert the coordinate to text: [ 5.0941 13.9516]:"}
{"text": "Convert the coordinate to text: [-2.7063 -6.9646]: The paper introduces XLM-P, a system that contextually retrieves prompts as flexible guidance for encoding instances conditionally, enabling lightweight modeling of language-invariant and language-specific knowledge across languages and easy integration with other multilingual pre-training methods.", "target": "The paper introduces XLM-P, a system that contextually retrieves prompts as flexible guidance for encoding instances conditionally, enabling lightweight modeling of language-invariant and language-specific knowledge across languages and easy integration with other multilingual pre-training methods.", "example": "Convert the coordinate to text: [-2.7063 -6.9646]:"}
{"text": "Convert the coordinate to text: [-9.8102 -5.9538]: The authors address these challenges by proposing an opinion tree parsing model that can parse all sentiment elements from an opinion tree. This model normalizes the tree structure using a novel context-free opinion grammar, and uses a neural chart-based opinion tree parser to fully explore correlations among sentiment elements.", "target": "The authors address these challenges by proposing an opinion tree parsing model that can parse all sentiment elements from an opinion tree. This model normalizes the tree structure using a novel context-free opinion grammar, and uses a neural chart-based opinion tree parser to fully explore correlations among sentiment elements.", "example": "Convert the coordinate to text: [-9.8102 -5.9538]:"}
{"text": "Convert the coordinate to text: [-0.8541 -2.889 ]: The authors introduce KGRec, a self-supervised rationalization method for knowledge-aware recommender systems that uses an attentive rationalization mechanism to generate scores for knowledge triplets and integrates generative and contrastive self-supervised tasks for recommendation via rational masking.", "target": "The authors introduce KGRec, a self-supervised rationalization method for knowledge-aware recommender systems that uses an attentive rationalization mechanism to generate scores for knowledge triplets and integrates generative and contrastive self-supervised tasks for recommendation via rational masking.", "example": "Convert the coordinate to text: [-0.8541 -2.889 ]:"}
{"text": "Convert the coordinate to text: [-5.7093 -0.6058]: The authors propose a two-step summary generation method designed to retain source-summary faithfulness. Their method utilizes a graph representation to rank sentence saliency in each chapter, distributing summary segments in distinct regions of the chapter.", "target": "The authors propose a two-step summary generation method designed to retain source-summary faithfulness. Their method utilizes a graph representation to rank sentence saliency in each chapter, distributing summary segments in distinct regions of the chapter.", "example": "Convert the coordinate to text: [-5.7093 -0.6058]:"}
{"text": "Convert the coordinate to text: [-2.1184  0.4511]: The authors used two different embedding techniques to interpret the data, and explored a variety of models including an XGBoost model, an unsupervised learning model, and two Ensemble learning models, with an ensemble model employing a soft voting technique.", "target": "The authors used two different embedding techniques to interpret the data, and explored a variety of models including an XGBoost model, an unsupervised learning model, and two Ensemble learning models, with an ensemble model employing a soft voting technique.", "example": "Convert the coordinate to text: [-2.1184  0.4511]:"}
{"text": "Convert the coordinate to text: [-1.902 -6.408]: The key idea is to use BERT embedding to represent each character in the original sentence and train a CRF-Rdrop to predict named entity categories using the dataset provided by the organizer.", "target": "The key idea is to use BERT embedding to represent each character in the original sentence and train a CRF-Rdrop to predict named entity categories using the dataset provided by the organizer.", "example": "Convert the coordinate to text: [-1.902 -6.408]:"}
{"text": "Convert the coordinate to text: [-9.6834 -6.0709]: The authors propose a new approach for sentiment analysis, called the 'semantic tree'. This is a tree form derived from a context-free grammar (CFG) that describes specific composition rules based on different semantic roles.", "target": "The authors propose a new approach for sentiment analysis, called the 'semantic tree'. This is a tree form derived from a context-free grammar (CFG) that describes specific composition rules based on different semantic roles.", "example": "Convert the coordinate to text: [-9.6834 -6.0709]:"}
{"text": "Convert the coordinate to text: [-3.4472 -5.5245]: The authors present DefBERT, a simple method that integrates pretrained models with word semantics in dictionaries, aiming to better model the meaning of words through their definitions.", "target": "The authors present DefBERT, a simple method that integrates pretrained models with word semantics in dictionaries, aiming to better model the meaning of words through their definitions.", "example": "Convert the coordinate to text: [-3.4472 -5.5245]:"}
{"text": "Convert the coordinate to text: [2.2692 2.9676]: The authors focus on identifying if a sample is affected by selection bias, under different conditions, for both parametric and non-parametric families of distributions.", "target": "The authors focus on identifying if a sample is affected by selection bias, under different conditions, for both parametric and non-parametric families of distributions.", "example": "Convert the coordinate to text: [2.2692 2.9676]:"}
{"text": "Convert the coordinate to text: [ 6.5615 11.5816]: The authors propose a new complexity measure called the 'spanning capacity', which depends only on the policy class set $\\Pi$ and is independent of the MDP dynamics. Additionally, they explore a sunflower structure, which together with bounded spanning capacity, facilitates efficient online RL.", "target": "The authors propose a new complexity measure called the 'spanning capacity', which depends only on the policy class set $\\Pi$ and is independent of the MDP dynamics. Additionally, they explore a sunflower structure, which together with bounded spanning capacity, facilitates efficient online RL.", "example": "Convert the coordinate to text: [ 6.5615 11.5816]:"}
{"text": "Convert the coordinate to text: [12.4318 -3.961 ]: The study concentrates on GNNs derived from diverse neural flows and argues that Lyapunov stability is insufficient for ensuring adversarial robustness. Conservative Hamiltonian neural flows, inspired by physics principles, are proposed for constructing robust GNNs.", "target": "The study concentrates on GNNs derived from diverse neural flows and argues that Lyapunov stability is insufficient for ensuring adversarial robustness. Conservative Hamiltonian neural flows, inspired by physics principles, are proposed for constructing robust GNNs.", "example": "Convert the coordinate to text: [12.4318 -3.961 ]:"}
{"text": "Convert the coordinate to text: [10.1966 -8.3514]: The authors propose a Degradation-Resistant Unfolding Network (DeRUN) for the HIF task, which is designed to generate high-quality images even under degradation scenarios. A novel HIF model for degradation resistance is also introduced.", "target": "The authors propose a Degradation-Resistant Unfolding Network (DeRUN) for the HIF task, which is designed to generate high-quality images even under degradation scenarios. A novel HIF model for degradation resistance is also introduced.", "example": "Convert the coordinate to text: [10.1966 -8.3514]:"}
{"text": "Convert the coordinate to text: [ 2.9832 -3.0893]: The paper introduces a Few-shot Continual Infomax Learning (FCIL) framework which enables a deep model to incrementally learn new concepts from few labeled samples, thereby mitigating catastrophic forgetting. This is achieved through feature embedding infomax based on the theoretical definition of transfer entropy, and continual structure infomax learning.", "target": "The paper introduces a Few-shot Continual Infomax Learning (FCIL) framework which enables a deep model to incrementally learn new concepts from few labeled samples, thereby mitigating catastrophic forgetting. This is achieved through feature embedding infomax based on the theoretical definition of transfer entropy, and continual structure infomax learning.", "example": "Convert the coordinate to text: [ 2.9832 -3.0893]:"}
{"text": "Convert the coordinate to text: [ 4.5615 -1.2323]: The study proposes RankMatch, an LNL framework that leverages dimensions of confidence and consistency to mitigate the effects of noisy labels. It introduces a confidence-based sample selection strategy and uses rank of principal features as a robust indicator for measuring consistency of inner-class samples.", "target": "The study proposes RankMatch, an LNL framework that leverages dimensions of confidence and consistency to mitigate the effects of noisy labels. It introduces a confidence-based sample selection strategy and uses rank of principal features as a robust indicator for measuring consistency of inner-class samples.", "example": "Convert the coordinate to text: [ 4.5615 -1.2323]:"}
{"text": "Convert the coordinate to text: [12.8498 -8.103 ]: The paper presents a self-supervised encoder-decoder model that decomposes entangled GAN space into a conceptual and hierarchical latent space. This model leverages outputs of 3D morphable face models to independently control image synthesis parameters like pose, expression, and illumination.", "target": "The paper presents a self-supervised encoder-decoder model that decomposes entangled GAN space into a conceptual and hierarchical latent space. This model leverages outputs of 3D morphable face models to independently control image synthesis parameters like pose, expression, and illumination.", "example": "Convert the coordinate to text: [12.8498 -8.103 ]:"}
{"text": "Convert the coordinate to text: [ 9.6475 -7.9139]: Authors proposed a Hybrid Spectral Denoising Transformer (HSDT) with three novel components: Spatial-Spectral Separable Convolution (S3Conv), Guided Spectral Self-Attention (GSSA), and Self-Modulated Feed-Forward Network (SM-FFN) that combine the advantages of both models.", "target": "Authors proposed a Hybrid Spectral Denoising Transformer (HSDT) with three novel components: Spatial-Spectral Separable Convolution (S3Conv), Guided Spectral Self-Attention (GSSA), and Self-Modulated Feed-Forward Network (SM-FFN) that combine the advantages of both models.", "example": "Convert the coordinate to text: [ 9.6475 -7.9139]:"}
{"text": "Convert the coordinate to text: [11.5433  5.9076]: The authors propose a new method for differentiating through optimal trajectories by directly evaluating matrix equations that arise from applying variable elimination on the Lagrange multipliers in the differential Karush-Kuhn-Tucker (KKT) system. This approach scales linearly with the number of timesteps and allows easy parallelization, improved scalability with model size, direct computation of vector-Jacobian products, and improved numerical stability.", "target": "The authors propose a new method for differentiating through optimal trajectories by directly evaluating matrix equations that arise from applying variable elimination on the Lagrange multipliers in the differential Karush-Kuhn-Tucker (KKT) system. This approach scales linearly with the number of timesteps and allows easy parallelization, improved scalability with model size, direct computation of vector-Jacobian products, and improved numerical stability.", "example": "Convert the coordinate to text: [11.5433  5.9076]:"}
{"text": "Convert the coordinate to text: [  8.0389 -10.9489]: The authors introduce Vision-Centric Multi-modal Distillation (VCD), a framework to improve the apprentices by using a multi-modal expert that mainly relies on camera features and includes strategies for proficient temporal fusion. The expert VCD-E model uses the same structure as the camera-only apprentice model to reduce feature disparity and uses LiDAR input as a depth prior for 3D scene reconstruction.", "target": "The authors introduce Vision-Centric Multi-modal Distillation (VCD), a framework to improve the apprentices by using a multi-modal expert that mainly relies on camera features and includes strategies for proficient temporal fusion. The expert VCD-E model uses the same structure as the camera-only apprentice model to reduce feature disparity and uses LiDAR input as a depth prior for 3D scene reconstruction.", "example": "Convert the coordinate to text: [  8.0389 -10.9489]:"}
{"text": "Convert the coordinate to text: [9.4188 3.2044]: The authors critically assess the previous practice, showing that the smoothness of a mixture of Mat\u00e9rn kernels is determined by the least smooth component and that a GP with such a kernel is effectively equivalent to the least smooth kernel component. Furthermore, they found that none of the mixing weights or parameters within individual kernel components are identifiable.", "target": "The authors critically assess the previous practice, showing that the smoothness of a mixture of Mat\u00e9rn kernels is determined by the least smooth component and that a GP with such a kernel is effectively equivalent to the least smooth kernel component. Furthermore, they found that none of the mixing weights or parameters within individual kernel components are identifiable.", "example": "Convert the coordinate to text: [9.4188 3.2044]:"}
{"text": "Convert the coordinate to text: [11.864   5.7978]: The authors developed a framework for finding approximately optimal preconditioners and solving linear systems. This includes a new algorithm that computes an optimal diagonal preconditioner, and another one that solves linear systems in time, given conditions.", "target": "The authors developed a framework for finding approximately optimal preconditioners and solving linear systems. This includes a new algorithm that computes an optimal diagonal preconditioner, and another one that solves linear systems in time, given conditions.", "example": "Convert the coordinate to text: [11.864   5.7978]:"}
{"text": "Convert the coordinate to text: [ 8.884  -7.5854]: A fully convolutional masked autoencoder and a new Global Response Normalization (GRN) layer are proposed, which can be incorporated into the ConvNeXt architecture to enhance inter-channel feature competition, leading to the creation of ConvNeXt V2.", "target": "A fully convolutional masked autoencoder and a new Global Response Normalization (GRN) layer are proposed, which can be incorporated into the ConvNeXt architecture to enhance inter-channel feature competition, leading to the creation of ConvNeXt V2.", "example": "Convert the coordinate to text: [ 8.884  -7.5854]:"}
{"text": "Convert the coordinate to text: [-3.4829 -7.5519]: This paper introduces a cross-lingual consistency regularization, CrossConST, to bridge the representation gap among different languages and enhance zero-shot translation performance.", "target": "This paper introduces a cross-lingual consistency regularization, CrossConST, to bridge the representation gap among different languages and enhance zero-shot translation performance.", "example": "Convert the coordinate to text: [-3.4829 -7.5519]:"}
{"text": "Convert the coordinate to text: [-2.6097 11.8585]: The authors propose a model of a visually grounded referential game, endowing the speaker with the ability to adapt its utterances using a simulation module that evaluates its effectiveness from the listener's perspective, and this adaptation mechanism is based on plug-and-play approaches without modifying the underlying language model.", "target": "The authors propose a model of a visually grounded referential game, endowing the speaker with the ability to adapt its utterances using a simulation module that evaluates its effectiveness from the listener's perspective, and this adaptation mechanism is based on plug-and-play approaches without modifying the underlying language model.", "example": "Convert the coordinate to text: [-2.6097 11.8585]:"}
{"text": "Convert the coordinate to text: [-1.274  -3.8967]: The paper introduces the 'joint pre-training and local re-training' framework for learning multi-source KG embeddings. It trains a large teacher KG embedding model over linked multi-source KGs and then distills knowledge to train a more specific student model. This process involves creating a linked subgraph through entity alignment across different KGs and three-tiered knowledge distillation - feature, network, and prediction levels. The pre-trained teacher model can be reused for different KGs and tasks.", "target": "The paper introduces the 'joint pre-training and local re-training' framework for learning multi-source KG embeddings. It trains a large teacher KG embedding model over linked multi-source KGs and then distills knowledge to train a more specific student model. This process involves creating a linked subgraph through entity alignment across different KGs and three-tiered knowledge distillation - feature, network, and prediction levels. The pre-trained teacher model can be reused for different KGs and tasks.", "example": "Convert the coordinate to text: [-1.274  -3.8967]:"}
{"text": "Convert the coordinate to text: [3.363  5.9181]: The paper introduces the study of improving graph cohesiveness through the merging of nodes, using the size of the k-truss as the objective in a mathematical formulation of the problem.", "target": "The paper introduces the study of improving graph cohesiveness through the merging of nodes, using the size of the k-truss as the objective in a mathematical formulation of the problem.", "example": "Convert the coordinate to text: [3.363  5.9181]:"}
{"text": "Convert the coordinate to text: [-3.6023 -3.6008]: The paper proposes a new approach that simplifies NLQ on structured data into several standard NLP tasks: domain classification, multi-head slot/entity extraction, and slot value disambiguation.", "target": "The paper proposes a new approach that simplifies NLQ on structured data into several standard NLP tasks: domain classification, multi-head slot/entity extraction, and slot value disambiguation.", "example": "Convert the coordinate to text: [-3.6023 -3.6008]:"}
{"text": "Convert the coordinate to text: [-2.7781 -6.7779]: The authors propose a solution that combines attention and memory mechanisms for the Multilingual Tweet Intimacy Analysis task. Their model inputs preprocessed tweets to the XLM-T layer to get sentence embeddings, and subsequently processes it with a bidirectional GRU layer to obtain intimacy ratings.", "target": "The authors propose a solution that combines attention and memory mechanisms for the Multilingual Tweet Intimacy Analysis task. Their model inputs preprocessed tweets to the XLM-T layer to get sentence embeddings, and subsequently processes it with a bidirectional GRU layer to obtain intimacy ratings.", "example": "Convert the coordinate to text: [-2.7781 -6.7779]:"}
{"text": "Convert the coordinate to text: [ 0.1234 -9.1688]: A prompt-based and multimodal retrieval enhanced VWSD system is proposed, which leverages large-scale pre-trained models and additional text-image information from knowledge bases and open datasets.", "target": "A prompt-based and multimodal retrieval enhanced VWSD system is proposed, which leverages large-scale pre-trained models and additional text-image information from knowledge bases and open datasets.", "example": "Convert the coordinate to text: [ 0.1234 -9.1688]:"}
{"text": "Convert the coordinate to text: [-2.5816 -6.8575]: The paper proposes a method that fine-tunes the XLM-RoBERTa pre-trained model for this multilingual regression task and uses data augmentation and a focal mean square error (MSE) loss to mitigate the impact of class imbalance.", "target": "The paper proposes a method that fine-tunes the XLM-RoBERTa pre-trained model for this multilingual regression task and uses data augmentation and a focal mean square error (MSE) loss to mitigate the impact of class imbalance.", "example": "Convert the coordinate to text: [-2.5816 -6.8575]:"}
{"text": "Convert the coordinate to text: [-0.8107  6.1124]: The authors introduce Rule By Example (RBE), a new contrastive learning approach which leverages logical rules for textual content moderation. RBE provides rule-grounded predictions, increasing explainability and customization.", "target": "The authors introduce Rule By Example (RBE), a new contrastive learning approach which leverages logical rules for textual content moderation. RBE provides rule-grounded predictions, increasing explainability and customization.", "example": "Convert the coordinate to text: [-0.8107  6.1124]:"}
{"text": "Convert the coordinate to text: [-14.9528   1.6988]: The authors develop a visual analytical system DHive to visualize and analyze the query execution progress via dataflow analysis at multiple levels.", "target": "The authors develop a visual analytical system DHive to visualize and analyze the query execution progress via dataflow analysis at multiple levels.", "example": "Convert the coordinate to text: [-14.9528   1.6988]:"}
{"text": "Convert the coordinate to text: [10.3455 -8.1191]: The paper proposes a physically explainable and generative diffusion model called Diff-Retinex for low-light image enhancement, which capitalizes on the strengths of a physical model and a generative network to supplement or deduce missing information in low-light images.", "target": "The paper proposes a physically explainable and generative diffusion model called Diff-Retinex for low-light image enhancement, which capitalizes on the strengths of a physical model and a generative network to supplement or deduce missing information in low-light images.", "example": "Convert the coordinate to text: [10.3455 -8.1191]:"}
{"text": "Convert the coordinate to text: [ 12.5655 -16.6198]: This paper introduces a new fusion model, RPEFlow, that combines RGB images, point clouds and event data to jointly estimate optical and scene flow, offering a solution to the limitations in existing methods.", "target": "This paper introduces a new fusion model, RPEFlow, that combines RGB images, point clouds and event data to jointly estimate optical and scene flow, offering a solution to the limitations in existing methods.", "example": "Convert the coordinate to text: [ 12.5655 -16.6198]:"}
{"text": "Convert the coordinate to text: [14.7839 -9.5311]: The authors propose a Saliency-Guided Features Decorrelation (SGFD) model to eliminate these correlations through sample reweighting. It consists of two techniques: Random Fourier Functions (RFF) to estimate the complex non-linear correlations in high-dimensional images, and a saliency map to identify the changed features.", "target": "The authors propose a Saliency-Guided Features Decorrelation (SGFD) model to eliminate these correlations through sample reweighting. It consists of two techniques: Random Fourier Functions (RFF) to estimate the complex non-linear correlations in high-dimensional images, and a saliency map to identify the changed features.", "example": "Convert the coordinate to text: [14.7839 -9.5311]:"}
{"text": "Convert the coordinate to text: [ 1.1625 -9.4948]: The authors present a new task for in-depth traffic scene understanding called Visual Traffic Knowledge Graph Generation (VTKGG) that attempts to extract multiple kinds of information and integrate them into a knowledge graph, and propose a novel traffic scene parsing architecture containing a Hierarchical Graph ATtention network (HGAT).", "target": "The authors present a new task for in-depth traffic scene understanding called Visual Traffic Knowledge Graph Generation (VTKGG) that attempts to extract multiple kinds of information and integrate them into a knowledge graph, and propose a novel traffic scene parsing architecture containing a Hierarchical Graph ATtention network (HGAT).", "example": "Convert the coordinate to text: [ 1.1625 -9.4948]:"}
{"text": "Convert the coordinate to text: [ 3.016  -8.7722]: This paper proposes Rank-DETR, an object detector based on DETR but incorporating rank-oriented designs for improved accuracy. These designs include an architecture that prompts positive predictions and suppresses negatives, and a loss function that prioritizes predictions of more accurate localization accuracy during ranking.", "target": "This paper proposes Rank-DETR, an object detector based on DETR but incorporating rank-oriented designs for improved accuracy. These designs include an architecture that prompts positive predictions and suppresses negatives, and a loss function that prioritizes predictions of more accurate localization accuracy during ranking.", "example": "Convert the coordinate to text: [ 3.016  -8.7722]:"}
{"text": "Convert the coordinate to text: [ 9.1841 -4.1477]: The authors propose to use the intra-class correlation coefficient (ICC) to evaluate the repeatability of embeddings and then introduce a novel ICC regularizer as a complementary component for contrastive losses to guide deep neural networks to create embeddings with higher repeatability.", "target": "The authors propose to use the intra-class correlation coefficient (ICC) to evaluate the repeatability of embeddings and then introduce a novel ICC regularizer as a complementary component for contrastive losses to guide deep neural networks to create embeddings with higher repeatability.", "example": "Convert the coordinate to text: [ 9.1841 -4.1477]:"}
{"text": "Convert the coordinate to text: [ 6.9955 -1.2775]: The authors propose the use of mutual information (MI) as a metric to measure the shared information between synthetic and real datasets. The newly proposed method, MIM4DD, works by maximizing mutual information through an optimizable objective within a contrastive learning framework.", "target": "The authors propose the use of mutual information (MI) as a metric to measure the shared information between synthetic and real datasets. The newly proposed method, MIM4DD, works by maximizing mutual information through an optimizable objective within a contrastive learning framework.", "example": "Convert the coordinate to text: [ 6.9955 -1.2775]:"}
{"text": "Convert the coordinate to text: [13.4635 -4.5271]: The authors seek to investigate whether datasets can be inherently robust to indiscriminate poisoning attacks for linear learners.", "target": "The authors seek to investigate whether datasets can be inherently robust to indiscriminate poisoning attacks for linear learners.", "example": "Convert the coordinate to text: [13.4635 -4.5271]:"}
{"text": "Convert the coordinate to text: [11.7484  7.7401]: The authors propose the doubly smoothed gradient descent ascent method (DS-GDA), a novel universally applicable single-loop algorithm that balances the primal and dual updates to solve nonconvex-concave, convex-nonconcave, and nonconvex-nonconcave problems with one-sided K\u0141 properties.", "target": "The authors propose the doubly smoothed gradient descent ascent method (DS-GDA), a novel universally applicable single-loop algorithm that balances the primal and dual updates to solve nonconvex-concave, convex-nonconcave, and nonconvex-nonconcave problems with one-sided K\u0141 properties.", "example": "Convert the coordinate to text: [11.7484  7.7401]:"}
{"text": "Convert the coordinate to text: [ 4.7239 -1.8779]: The authors propose a novel self-training framework, DesERT, which identifies and handles two types of previously overlooked biases in distant supervision. The first is the structural (not fully randomized) nature of noise in distant labels, and the second is an inherent bias in the self-training framework that affects sample selection and prediction.", "target": "The authors propose a novel self-training framework, DesERT, which identifies and handles two types of previously overlooked biases in distant supervision. The first is the structural (not fully randomized) nature of noise in distant labels, and the second is an inherent bias in the self-training framework that affects sample selection and prediction.", "example": "Convert the coordinate to text: [ 4.7239 -1.8779]:"}
{"text": "Convert the coordinate to text: [ 10.7741 -10.9768]: The authors propose a new AI task 'Re-identify Any Animal in the Wild' (ReID-AW) for developing re-identification models that can be expanded to any unseen wildlife category and introduce a universal re-identification model, UniReID, for this task.", "target": "The authors propose a new AI task 'Re-identify Any Animal in the Wild' (ReID-AW) for developing re-identification models that can be expanded to any unseen wildlife category and introduce a universal re-identification model, UniReID, for this task.", "example": "Convert the coordinate to text: [ 10.7741 -10.9768]:"}
{"text": "Convert the coordinate to text: [ 7.1097 12.6112]: The authors propose a new policy learning method that incorporates analytical gradients within the Proximal Policy Optimization (PPO) algorithm, by introducing an \u03b1-policy as a locally superior policy. Management of the influence of analytical policy gradients during learning is achieved through adaptive modification of the \u03b1 value.", "target": "The authors propose a new policy learning method that incorporates analytical gradients within the Proximal Policy Optimization (PPO) algorithm, by introducing an \u03b1-policy as a locally superior policy. Management of the influence of analytical policy gradients during learning is achieved through adaptive modification of the \u03b1 value.", "example": "Convert the coordinate to text: [ 7.1097 12.6112]:"}
{"text": "Convert the coordinate to text: [ 3.8579 -6.0074]: A novel tree-based graph neural network called SyncTREE is proposed in this paper; it incorporates both structural and physical properties of electronic circuits to accelerate timing analysis. Major innovations include a two-pass message-passing, a tree contrastive loss to guide learning, and a closed formula-based approach for fast timing.", "target": "A novel tree-based graph neural network called SyncTREE is proposed in this paper; it incorporates both structural and physical properties of electronic circuits to accelerate timing analysis. Major innovations include a two-pass message-passing, a tree contrastive loss to guide learning, and a closed formula-based approach for fast timing.", "example": "Convert the coordinate to text: [ 3.8579 -6.0074]:"}
{"text": "Convert the coordinate to text: [12.053  -4.8072]: This study examines the influence of the quality rather than the quantity of the training data on the generalization of a model, particularly focusing on two types of data: human-adversarial (h-adversarial), sample pairs with small differences but different ground-truth labels, and human-affable (h-affable), sample pairs with minor differences but the same ground-truth labels.", "target": "This study examines the influence of the quality rather than the quantity of the training data on the generalization of a model, particularly focusing on two types of data: human-adversarial (h-adversarial), sample pairs with small differences but different ground-truth labels, and human-affable (h-affable), sample pairs with minor differences but the same ground-truth labels.", "example": "Convert the coordinate to text: [12.053  -4.8072]:"}
{"text": "Convert the coordinate to text: [12.385  -1.2052]: The authors investigate the cross-over between the regimes of over-parametrized networks and narrow networks in a high-dimensional setting, especially the connection between the mean-field/hydrodynamic regime and Saad & Solla's approach.", "target": "The authors investigate the cross-over between the regimes of over-parametrized networks and narrow networks in a high-dimensional setting, especially the connection between the mean-field/hydrodynamic regime and Saad & Solla's approach.", "example": "Convert the coordinate to text: [12.385  -1.2052]:"}
{"text": "Convert the coordinate to text: [12.482  -0.9883]: The authors work on deriving exact solutions to the dynamics of learning with rich prior knowledge in deep linear networks by generalizing Fukumizu's matrix Riccati solution.", "target": "The authors work on deriving exact solutions to the dynamics of learning with rich prior knowledge in deep linear networks by generalizing Fukumizu's matrix Riccati solution.", "example": "Convert the coordinate to text: [12.482  -0.9883]:"}
{"text": "Convert the coordinate to text: [11.9853 -8.5971]: The paper introduces UniST, a Unified Style Transfer framework for both images and videos that includes a domain interaction transformer (DIT). This DIT explores context information within the specific domain first and then interacts contextualized domain information for joint learning. The DIT also enables exploration of temporal information from videos for the image style transfer task and allows rich appearance texture from images for video style transfer.", "target": "The paper introduces UniST, a Unified Style Transfer framework for both images and videos that includes a domain interaction transformer (DIT). This DIT explores context information within the specific domain first and then interacts contextualized domain information for joint learning. The DIT also enables exploration of temporal information from videos for the image style transfer task and allows rich appearance texture from images for video style transfer.", "example": "Convert the coordinate to text: [11.9853 -8.5971]:"}
{"text": "Convert the coordinate to text: [ 4.9911 -6.2027]: The work proposes a byte-level traffic graph construction approach based on point-wise mutual information (PMI) and a model named Temporal Fusion Encoder using Graph Neural Networks (TFE-GNN) for feature extraction.", "target": "The work proposes a byte-level traffic graph construction approach based on point-wise mutual information (PMI) and a model named Temporal Fusion Encoder using Graph Neural Networks (TFE-GNN) for feature extraction.", "example": "Convert the coordinate to text: [ 4.9911 -6.2027]:"}
{"text": "Convert the coordinate to text: [  1.627  -12.7081]: The study proposes the design and creation of a machine-learning-based system, ScannerScope, that aims to detect web vulnerability scanners using fingerprinting techniques. ScannerScope works like a transparent reverse proxy injecting fingerprinting modules without the knowledge of protected web applications.", "target": "The study proposes the design and creation of a machine-learning-based system, ScannerScope, that aims to detect web vulnerability scanners using fingerprinting techniques. ScannerScope works like a transparent reverse proxy injecting fingerprinting modules without the knowledge of protected web applications.", "example": "Convert the coordinate to text: [  1.627  -12.7081]:"}
{"text": "Convert the coordinate to text: [-10.6178  -1.9016]: The authors propose SG-CQG, a two-stage CQG framework. It uses a semantic graph to select a sentence as the rationale and extract the answer span from it for the what-to-ask stage, and for the how-to-ask stage, it uses a classifier with explicit control signals to determine the target answer type of the question.", "target": "The authors propose SG-CQG, a two-stage CQG framework. It uses a semantic graph to select a sentence as the rationale and extract the answer span from it for the what-to-ask stage, and for the how-to-ask stage, it uses a classifier with explicit control signals to determine the target answer type of the question.", "example": "Convert the coordinate to text: [-10.6178  -1.9016]:"}
{"text": "Convert the coordinate to text: [ 3.759  -3.9038]: This paper introduces the concept of distillation influence to gauge the impact of each training sample's distillation on the student model's generalization ability, and proposes Learning Good Teacher Matters (LGTM), a training technique incorporating the distillation influence into the teacher's learning process.", "target": "This paper introduces the concept of distillation influence to gauge the impact of each training sample's distillation on the student model's generalization ability, and proposes Learning Good Teacher Matters (LGTM), a training technique incorporating the distillation influence into the teacher's learning process.", "example": "Convert the coordinate to text: [ 3.759  -3.9038]:"}
{"text": "Convert the coordinate to text: [-1.2445 -5.0806]: The authors developed a large-scale Chinese movie benchmark named Movie101 which asks models to generate role-aware narration paragraphs for complete movie clips without dialogue. They also propose a new metric, Movie Narration Score (MNScore), for movie narrating evaluation, which better correlates with human evaluation.", "target": "The authors developed a large-scale Chinese movie benchmark named Movie101 which asks models to generate role-aware narration paragraphs for complete movie clips without dialogue. They also propose a new metric, Movie Narration Score (MNScore), for movie narrating evaluation, which better correlates with human evaluation.", "example": "Convert the coordinate to text: [-1.2445 -5.0806]:"}
{"text": "Convert the coordinate to text: [-3.4419 -6.2975]: The authors propose a new LID model which they train on a curated dataset of monolingual data, and present a thorough analysis of its performance in comparison to other existing models.", "target": "The authors propose a new LID model which they train on a curated dataset of monolingual data, and present a thorough analysis of its performance in comparison to other existing models.", "example": "Convert the coordinate to text: [-3.4419 -6.2975]:"}
{"text": "Convert the coordinate to text: [11.9571 -4.8716]: The authors propose a more balanced adversarial model, where the adversary consists of two separated algorithms: the sampler that chooses the distribution and provides the samples, and the analyst who chooses the adaptive queries without prior knowledge of the underlying distribution.", "target": "The authors propose a more balanced adversarial model, where the adversary consists of two separated algorithms: the sampler that chooses the distribution and provides the samples, and the analyst who chooses the adaptive queries without prior knowledge of the underlying distribution.", "example": "Convert the coordinate to text: [11.9571 -4.8716]:"}
{"text": "Convert the coordinate to text: [-1.7665  6.5124]: This paper puts into question the importance of such explanations, finding that corrupted explanations can still result in competitive or superior performance. It is proposed that explanations' main effect is the provision of extra context space, rather than their inductive biases.", "target": "This paper puts into question the importance of such explanations, finding that corrupted explanations can still result in competitive or superior performance. It is proposed that explanations' main effect is the provision of extra context space, rather than their inductive biases.", "example": "Convert the coordinate to text: [-1.7665  6.5124]:"}
{"text": "Convert the coordinate to text: [-10.8742  -1.8469]: The paper introduces a new large-scale Korean dataset named Sensitive Questions and Acceptable Response (SQuARe), consisting of 49k sensitive questions accompanied by 42k acceptable and 46k non-acceptable responses. This dataset aims to support safer models in sensitive discussions.", "target": "The paper introduces a new large-scale Korean dataset named Sensitive Questions and Acceptable Response (SQuARe), consisting of 49k sensitive questions accompanied by 42k acceptable and 46k non-acceptable responses. This dataset aims to support safer models in sensitive discussions.", "example": "Convert the coordinate to text: [-10.8742  -1.8469]:"}
{"text": "Convert the coordinate to text: [-2.0351 -5.5206]: The authors make use of general-purpose language models, trained on large amounts of diverse data, to solve tasks without task-specific training, with a focus on the ChatGPT research preview for zero-shot DST.", "target": "The authors make use of general-purpose language models, trained on large amounts of diverse data, to solve tasks without task-specific training, with a focus on the ChatGPT research preview for zero-shot DST.", "example": "Convert the coordinate to text: [-2.0351 -5.5206]:"}
{"text": "Convert the coordinate to text: [0.0987 2.8146]: The authors propose scalable methods, namely, fairness-based participant sampling (FPS) and fairness as context (FAC), that use node representations learned from diffusion cascades rather than social connectivity for achieving influence maximization with fairness on large networks.", "target": "The authors propose scalable methods, namely, fairness-based participant sampling (FPS) and fairness as context (FAC), that use node representations learned from diffusion cascades rather than social connectivity for achieving influence maximization with fairness on large networks.", "example": "Convert the coordinate to text: [0.0987 2.8146]:"}
{"text": "Convert the coordinate to text: [1.3753 0.5948]: The paper suggests a method to examine the unwanted dependencies learned by abusive language classifiers by assessing their accuracy on a challenge set across all decision thresholds. It introduces concept-based explanation metrics to assess the influence of a concept on labels which allows comparison of classifiers in terms of the degree of false global sufficiency they have learned.", "target": "The paper suggests a method to examine the unwanted dependencies learned by abusive language classifiers by assessing their accuracy on a challenge set across all decision thresholds. It introduces concept-based explanation metrics to assess the influence of a concept on labels which allows comparison of classifiers in terms of the degree of false global sufficiency they have learned.", "example": "Convert the coordinate to text: [1.3753 0.5948]:"}
{"text": "Convert the coordinate to text: [-8.7776 -1.7655]: The authors implemented methods to improve review quality, create a clearer workflow for area chairs, improve paper-reviewer matching for a variety of NLP work, and boost incentives for all participants involved in the peer review process at the ACL'23 conference.", "target": "The authors implemented methods to improve review quality, create a clearer workflow for area chairs, improve paper-reviewer matching for a variety of NLP work, and boost incentives for all participants involved in the peer review process at the ACL'23 conference.", "example": "Convert the coordinate to text: [-8.7776 -1.7655]:"}
{"text": "Convert the coordinate to text: [-2.9593 -8.313 ]: The authors leverage pretrained models that have been exposed to large-scale audio and text data. They introduce several stages of additional pretraining and fine-tuning to adapt the system for the downstream speech translation task, supplemented with techniques such as data augmentation, domain tagging, knowledge distillation, and model ensemble.", "target": "The authors leverage pretrained models that have been exposed to large-scale audio and text data. They introduce several stages of additional pretraining and fine-tuning to adapt the system for the downstream speech translation task, supplemented with techniques such as data augmentation, domain tagging, knowledge distillation, and model ensemble.", "example": "Convert the coordinate to text: [-2.9593 -8.313 ]:"}
{"text": "Convert the coordinate to text: [-1.5337 -4.6602]: This paper provides an overview of complex reasoning tasks where standard pretrained language models fail then reviews recent promising methods for tackling these tasks, which explicitly consider problem structures. These methods include: knowledge-augmented method, few-shot prompting methods, neuro-symbolic methods, and rationale-based methods.", "target": "This paper provides an overview of complex reasoning tasks where standard pretrained language models fail then reviews recent promising methods for tackling these tasks, which explicitly consider problem structures. These methods include: knowledge-augmented method, few-shot prompting methods, neuro-symbolic methods, and rationale-based methods.", "example": "Convert the coordinate to text: [-1.5337 -4.6602]:"}
{"text": "Convert the coordinate to text: [-3.1919 -5.2793]: The authors introduce a benchmark dataset named CLUB (Chemical Language Understanding Benchmark), one of the first chemical language understanding benchmark datasets consisting of tasks for both patent and literature articles provided by an industrial organization.", "target": "The authors introduce a benchmark dataset named CLUB (Chemical Language Understanding Benchmark), one of the first chemical language understanding benchmark datasets consisting of tasks for both patent and literature articles provided by an industrial organization.", "example": "Convert the coordinate to text: [-3.1919 -5.2793]:"}
{"text": "Convert the coordinate to text: [-3.3059 -5.5609]: SEScore2, a self-supervised approach for training a model-based metric for text generation evaluation, is proposed. The key concept is to synthesize realistic model mistakes by perturbing sentences retrieved from a corpus.", "target": "SEScore2, a self-supervised approach for training a model-based metric for text generation evaluation, is proposed. The key concept is to synthesize realistic model mistakes by perturbing sentences retrieved from a corpus.", "example": "Convert the coordinate to text: [-3.3059 -5.5609]:"}
{"text": "Convert the coordinate to text: [-8.4793 -3.7511]: Cornet is introduced, a system that automatically learns conditional formatting rules from user examples, efficiently eliminating the need for manual rule writing.", "target": "Cornet is introduced, a system that automatically learns conditional formatting rules from user examples, efficiently eliminating the need for manual rule writing.", "example": "Convert the coordinate to text: [-8.4793 -3.7511]:"}
{"text": "Convert the coordinate to text: [ 0.404  -9.2103]: The authors propose RLEG, a novel vision-language representation learning method that uses diffusion models to generate feature embeddings online, which aids in learning effective vision-language representation.", "target": "The authors propose RLEG, a novel vision-language representation learning method that uses diffusion models to generate feature embeddings online, which aids in learning effective vision-language representation.", "example": "Convert the coordinate to text: [ 0.404  -9.2103]:"}
{"text": "Convert the coordinate to text: [ 7.1575 -4.4058]: A novel Confidence-based Visual Dispersal Transfer learning method (C-VisDiT) for Few-shot Unsupervised Domain Adaptation (FUDA) is proposed which consists of a cross-domain visual dispersal strategy that transfers only high-confidence source knowledge for model adaptation and an intra-domain visual dispersal strategy that guides the learning of hard target samples with easy ones.", "target": "A novel Confidence-based Visual Dispersal Transfer learning method (C-VisDiT) for Few-shot Unsupervised Domain Adaptation (FUDA) is proposed which consists of a cross-domain visual dispersal strategy that transfers only high-confidence source knowledge for model adaptation and an intra-domain visual dispersal strategy that guides the learning of hard target samples with easy ones.", "example": "Convert the coordinate to text: [ 7.1575 -4.4058]:"}
{"text": "Convert the coordinate to text: [ 4.8122 -9.5856]: This study proposes the novel concept of 'Relative Visual Tempo', arguing that it is more in line with human intuition and hence provides more effective supervision signals. The authors develop a new framework called Relative Visual Tempo Contrastive Learning for skeleton action Representation (RVTCLR).", "target": "This study proposes the novel concept of 'Relative Visual Tempo', arguing that it is more in line with human intuition and hence provides more effective supervision signals. The authors develop a new framework called Relative Visual Tempo Contrastive Learning for skeleton action Representation (RVTCLR).", "example": "Convert the coordinate to text: [ 4.8122 -9.5856]:"}
{"text": "Convert the coordinate to text: [ 4.731  -1.3466]: A novel learning framework is proposed that selectively suppresses noisy samples while avoiding underfitting clean data. This framework incorporates label confidence as a measure of label noise, enabling the network model to prioritize the training of samples deemed to be noise-free.", "target": "A novel learning framework is proposed that selectively suppresses noisy samples while avoiding underfitting clean data. This framework incorporates label confidence as a measure of label noise, enabling the network model to prioritize the training of samples deemed to be noise-free.", "example": "Convert the coordinate to text: [ 4.731  -1.3466]:"}
{"text": "Convert the coordinate to text: [3.091  0.9857]: This work theorizes that the size of a Rashomon ratio is determined by the combination of the data generation process and the choices made by analysts during the learning process. Specifically, it argues that noisier datasets lead to larger Rashomon ratios due to how practitioners train models.", "target": "This work theorizes that the size of a Rashomon ratio is determined by the combination of the data generation process and the choices made by analysts during the learning process. Specifically, it argues that noisier datasets lead to larger Rashomon ratios due to how practitioners train models.", "example": "Convert the coordinate to text: [3.091  0.9857]:"}
{"text": "Convert the coordinate to text: [ 7.6509 12.6542]: The authors propose a Neural Network-Accompanied Gaussian Process (NN-AGP) model that leverages neural networks to approximate the unknown and complex reward function related to the contextual variable, and maintains a Gaussian process surrogate model with respect to the decision variable.", "target": "The authors propose a Neural Network-Accompanied Gaussian Process (NN-AGP) model that leverages neural networks to approximate the unknown and complex reward function related to the contextual variable, and maintains a Gaussian process surrogate model with respect to the decision variable.", "example": "Convert the coordinate to text: [ 7.6509 12.6542]:"}
{"text": "Convert the coordinate to text: [-0.0478 -3.8979]: The authors propose a novel task of low-resource APR and introduce a new meta-learning framework, Meta-APR, which integrates with code pretrained language models to generate fixes for low-resource bugs with limited training samples. This framework uses a first-order meta-learning optimization to efficiently learn error-specific knowledge from high-resource bugs, enabling quick adaptation to low-resource bugs.", "target": "The authors propose a novel task of low-resource APR and introduce a new meta-learning framework, Meta-APR, which integrates with code pretrained language models to generate fixes for low-resource bugs with limited training samples. This framework uses a first-order meta-learning optimization to efficiently learn error-specific knowledge from high-resource bugs, enabling quick adaptation to low-resource bugs.", "example": "Convert the coordinate to text: [-0.0478 -3.8979]:"}
{"text": "Convert the coordinate to text: [-9.578 -4.989]: The authors address the limitations of existing CD-ECR approaches by considering discourse structure as global information, which is hoped to improve CD-ECR.", "target": "The authors address the limitations of existing CD-ECR approaches by considering discourse structure as global information, which is hoped to improve CD-ECR.", "example": "Convert the coordinate to text: [-9.578 -4.989]:"}
{"text": "Convert the coordinate to text: [-7.8446 -1.381 ]: The authors propose a new manually annotated dataset for Information Extraction (IE) from legal wills, consisting of entities, binary relations between the entities, and n-ary events extracted from 45 legal wills from two US states.", "target": "The authors propose a new manually annotated dataset for Information Extraction (IE) from legal wills, consisting of entities, binary relations between the entities, and n-ary events extracted from 45 legal wills from two US states.", "example": "Convert the coordinate to text: [-7.8446 -1.381 ]:"}
{"text": "Convert the coordinate to text: [-3.2921 -6.5335]: The authors propose MINT, a new multilingual intimacy analysis dataset covering 13,372 tweets in 10 different languages.", "target": "The authors propose MINT, a new multilingual intimacy analysis dataset covering 13,372 tweets in 10 different languages.", "example": "Convert the coordinate to text: [-3.2921 -6.5335]:"}
{"text": "Convert the coordinate to text: [ 2.9217 -7.7569]: The authors propose AtMan, a modality-agnostic perturbation method that manipulates the attention mechanisms of transformers to produce relevance maps for the input with respect to the output prediction, eliminating the need for backpropagation.", "target": "The authors propose AtMan, a modality-agnostic perturbation method that manipulates the attention mechanisms of transformers to produce relevance maps for the input with respect to the output prediction, eliminating the need for backpropagation.", "example": "Convert the coordinate to text: [ 2.9217 -7.7569]:"}
{"text": "Convert the coordinate to text: [-1.013  -5.0858]: The authors propose MPC (Modular Prompted Chatbot), a method that utilizes pre-trained large language models as individual modules by using techniques such as few-shot prompting, chain-of-thought, and external memory to address inconsistency and inflexibility problems.", "target": "The authors propose MPC (Modular Prompted Chatbot), a method that utilizes pre-trained large language models as individual modules by using techniques such as few-shot prompting, chain-of-thought, and external memory to address inconsistency and inflexibility problems.", "example": "Convert the coordinate to text: [-1.013  -5.0858]:"}
{"text": "Convert the coordinate to text: [-3.9526  7.77  ]: The core idea proposed in this study is to perform an empirical examination of these unanswered questions, seeking to provide valuable insights about the limitations of current approaches.", "target": "The core idea proposed in this study is to perform an empirical examination of these unanswered questions, seeking to provide valuable insights about the limitations of current approaches.", "example": "Convert the coordinate to text: [-3.9526  7.77  ]:"}
{"text": "Convert the coordinate to text: [ 0.3649 -6.057 ]: The authors created a benchmark for diverse-modal entity linking (DMEL) using existing datasets and propose a generative diverse-modal model (GDMM) grounded in a multimodal-encoder-decoder paradigm, which allows for more efficient storage without needing the entire knowledge base for inference.", "target": "The authors created a benchmark for diverse-modal entity linking (DMEL) using existing datasets and propose a generative diverse-modal model (GDMM) grounded in a multimodal-encoder-decoder paradigm, which allows for more efficient storage without needing the entire knowledge base for inference.", "example": "Convert the coordinate to text: [ 0.3649 -6.057 ]:"}
{"text": "Convert the coordinate to text: [-7.8911  4.9175]: The authors present a Variance Reduction System (VRS) for achieving more equitable outcomes in personalized ads. VRS seeks to achieve a distribution of impressions that more closely aligns the demographics of an ad's eligible audience with the audience who sees that ad, in a privacy-preserving manner.", "target": "The authors present a Variance Reduction System (VRS) for achieving more equitable outcomes in personalized ads. VRS seeks to achieve a distribution of impressions that more closely aligns the demographics of an ad's eligible audience with the audience who sees that ad, in a privacy-preserving manner.", "example": "Convert the coordinate to text: [-7.8911  4.9175]:"}
{"text": "Convert the coordinate to text: [-1.879  -5.0315]: This study investigates the ability of LLMs to generate better cognitive assessment items by devising a novel prompting strategy based on selecting items with both the best and worst properties to use in the prompt, and applying this to generate new natural language inference (NLI) items using GPT-3.", "target": "This study investigates the ability of LLMs to generate better cognitive assessment items by devising a novel prompting strategy based on selecting items with both the best and worst properties to use in the prompt, and applying this to generate new natural language inference (NLI) items using GPT-3.", "example": "Convert the coordinate to text: [-1.879  -5.0315]:"}
{"text": "Convert the coordinate to text: [18.5365 -3.1911]: The paper suggests an approach for both classifying spoilers in clickbait posts and generating them, predominantly using transformer models like XLNET and RoBERTa Large.", "target": "The paper suggests an approach for both classifying spoilers in clickbait posts and generating them, predominantly using transformer models like XLNET and RoBERTa Large.", "example": "Convert the coordinate to text: [18.5365 -3.1911]:"}
{"text": "Convert the coordinate to text: [-0.0128 -9.2607]: The paper presents an approach to tackle the image disambiguation task by leveraging the knowledge captured in multimodal and language models and applying a generative model for text creation given an ambiguous phrase.", "target": "The paper presents an approach to tackle the image disambiguation task by leveraging the knowledge captured in multimodal and language models and applying a generative model for text creation given an ambiguous phrase.", "example": "Convert the coordinate to text: [-0.0128 -9.2607]:"}
{"text": "Convert the coordinate to text: [ 1.495  -4.3558]: The authors present CONTRACLM, a novel contrastive learning framework for causal language models at both the token-level and the sequence-level.", "target": "The authors present CONTRACLM, a novel contrastive learning framework for causal language models at both the token-level and the sequence-level.", "example": "Convert the coordinate to text: [ 1.495  -4.3558]:"}
{"text": "Convert the coordinate to text: [10.7148 -6.2797]: In this paper, a novel unsupervised anomaly detection method using a score-based model, also known as a denoising diffusion model, is proposed. The paper centers around the concept of 'score-based perturbation resilience' \u2013 the ability of samples on the data manifold to be instantaneously restored by the score, even when randomly perturbed.", "target": "In this paper, a novel unsupervised anomaly detection method using a score-based model, also known as a denoising diffusion model, is proposed. The paper centers around the concept of 'score-based perturbation resilience' \u2013 the ability of samples on the data manifold to be instantaneously restored by the score, even when randomly perturbed.", "example": "Convert the coordinate to text: [10.7148 -6.2797]:"}
{"text": "Convert the coordinate to text: [  8.6388 -19.7357]: The paper introduces a new, faster solver for estimating the surface normal using a globally optimal solution that can be solved efficiently through a linear system.", "target": "The paper introduces a new, faster solver for estimating the surface normal using a globally optimal solution that can be solved efficiently through a linear system.", "example": "Convert the coordinate to text: [  8.6388 -19.7357]:"}
{"text": "Convert the coordinate to text: [ 4.0545 -8.7103]: This paper presents a novel framework, Concordant Attention Learning (CAL), for VI Re-ID, and specifically designs the Target-aware Concordant Alignment paradigm, allowing target-aware attention adaptation when aligning heterogeneous samples and developing modality-agnostic correspondence-searching strategies.", "target": "This paper presents a novel framework, Concordant Attention Learning (CAL), for VI Re-ID, and specifically designs the Target-aware Concordant Alignment paradigm, allowing target-aware attention adaptation when aligning heterogeneous samples and developing modality-agnostic correspondence-searching strategies.", "example": "Convert the coordinate to text: [ 4.0545 -8.7103]:"}
{"text": "Convert the coordinate to text: [ 7.4158 -7.9176]: The paper introduces a multi-frequency representation enhancement module (MFE) that performs spatial-temporal information aggregation in the frequency domain, along with a new model training method named privilege training that leverages high-resolution videos to facilitate model training.", "target": "The paper introduces a multi-frequency representation enhancement module (MFE) that performs spatial-temporal information aggregation in the frequency domain, along with a new model training method named privilege training that leverages high-resolution videos to facilitate model training.", "example": "Convert the coordinate to text: [ 7.4158 -7.9176]:"}
{"text": "Convert the coordinate to text: [  9.2179 -16.6538]: The authors introduce a framework that formulates the 3D registration task as a denoising diffusion process, which refines the pose of the source point cloud for precise alignment. It involves two operations: an SE(3) diffusion process that perturbs the optimal rigid transformation and an SE(3) reverse process that focuses on refining the noisy transformation.", "target": "The authors introduce a framework that formulates the 3D registration task as a denoising diffusion process, which refines the pose of the source point cloud for precise alignment. It involves two operations: an SE(3) diffusion process that perturbs the optimal rigid transformation and an SE(3) reverse process that focuses on refining the noisy transformation.", "example": "Convert the coordinate to text: [  9.2179 -16.6538]:"}
{"text": "Convert the coordinate to text: [ 5.8262 -7.1114]: SutraNets, a novel method, is proposed for neural probabilistic forecasting of long-sequence time series which treats long, univariate prediction as multivariate prediction over lower-frequency sub-series, thereby reducing error accumulation and signal path distances.", "target": "SutraNets, a novel method, is proposed for neural probabilistic forecasting of long-sequence time series which treats long, univariate prediction as multivariate prediction over lower-frequency sub-series, thereby reducing error accumulation and signal path distances.", "example": "Convert the coordinate to text: [ 5.8262 -7.1114]:"}
{"text": "Convert the coordinate to text: [ 9.3057 -6.6799]: The authors propose FouriDown, a novel down-sampling paradigm in the Fourier domain that unifies existing down-sampling techniques by parameterizing the non-parameter static weighting down-sampling operator as a learnable and context-adaptive operator within a unified Fourier function.", "target": "The authors propose FouriDown, a novel down-sampling paradigm in the Fourier domain that unifies existing down-sampling techniques by parameterizing the non-parameter static weighting down-sampling operator as a learnable and context-adaptive operator within a unified Fourier function.", "example": "Convert the coordinate to text: [ 9.3057 -6.6799]:"}
{"text": "Convert the coordinate to text: [9.4478 6.5421]: The paper proposes a novel notion called data-algorithm compatibility to analyze the generalization behavior of overparameterized models both in a data-relevant and algorithm-relevant manner. This analysis considers the generalization behavior of the entire data-dependent training trajectory rather than just the last-iterate analysis.", "target": "The paper proposes a novel notion called data-algorithm compatibility to analyze the generalization behavior of overparameterized models both in a data-relevant and algorithm-relevant manner. This analysis considers the generalization behavior of the entire data-dependent training trajectory rather than just the last-iterate analysis.", "example": "Convert the coordinate to text: [9.4478 6.5421]:"}
{"text": "Convert the coordinate to text: [-5.3675 10.6211]: The authors propose LAPDOG (Learning Retrieval Augmentation for Personalized Dialogue Generation), a model that studies the potential of leveraging external knowledge for persona dialogue generation by using a story retriever and a dialogue generator. The story retriever uses a persona profile to retrieve relevant information from the story document, and the dialogue generator uses the dialogue history and the augmented persona profile to generate personalized responses.", "target": "The authors propose LAPDOG (Learning Retrieval Augmentation for Personalized Dialogue Generation), a model that studies the potential of leveraging external knowledge for persona dialogue generation by using a story retriever and a dialogue generator. The story retriever uses a persona profile to retrieve relevant information from the story document, and the dialogue generator uses the dialogue history and the augmented persona profile to generate personalized responses.", "example": "Convert the coordinate to text: [-5.3675 10.6211]:"}
{"text": "Convert the coordinate to text: [  0.2177 -15.3972]: This paper introduces DSNet, an end-to-end spatial convolutional neural network specifically tailored to classify depression based on resting-state EEG signals. DSNet specifically captures the spatial differences between depressed and normal individuals.", "target": "This paper introduces DSNet, an end-to-end spatial convolutional neural network specifically tailored to classify depression based on resting-state EEG signals. DSNet specifically captures the spatial differences between depressed and normal individuals.", "example": "Convert the coordinate to text: [  0.2177 -15.3972]:"}
{"text": "Convert the coordinate to text: [ 6.4915 -5.9426]: The authors tackle the challenge of interpretability in part-prototype networks, proposing a quantitative and objective evaluation methodology for interpretability coupled with an enhanced part-prototype network model that improves interpretability of prototypes.", "target": "The authors tackle the challenge of interpretability in part-prototype networks, proposing a quantitative and objective evaluation methodology for interpretability coupled with an enhanced part-prototype network model that improves interpretability of prototypes.", "example": "Convert the coordinate to text: [ 6.4915 -5.9426]:"}
{"text": "Convert the coordinate to text: [ 2.409  15.7979]: This paper studies different proportionality axioms in relation to large classes of approval-based satisfaction functions, while considering how outcomes could be proportional with respect to more than one satisfaction function.", "target": "This paper studies different proportionality axioms in relation to large classes of approval-based satisfaction functions, while considering how outcomes could be proportional with respect to more than one satisfaction function.", "example": "Convert the coordinate to text: [ 2.409  15.7979]:"}
{"text": "Convert the coordinate to text: [-8.0358 -1.4759]: The authors introduce WebIE, the first large-scale, entity-linked closed IE dataset containing 1.6M sentences obtained from the English Common Crawl corpus. They also propose three training strategies that use entity linking as an auxiliary task.", "target": "The authors introduce WebIE, the first large-scale, entity-linked closed IE dataset containing 1.6M sentences obtained from the English Common Crawl corpus. They also propose three training strategies that use entity linking as an auxiliary task.", "example": "Convert the coordinate to text: [-8.0358 -1.4759]:"}
{"text": "Convert the coordinate to text: [-7.3811  0.1968]: The authors find that the performance gain in the state-of-the-art Retro model is better attributed to surface-level similarities (such as token overlap), leading them to replace the semantic retrieval mechanism in Retro with a surface-level method based on BM25.", "target": "The authors find that the performance gain in the state-of-the-art Retro model is better attributed to surface-level similarities (such as token overlap), leading them to replace the semantic retrieval mechanism in Retro with a surface-level method based on BM25.", "example": "Convert the coordinate to text: [-7.3811  0.1968]:"}
{"text": "Convert the coordinate to text: [-0.1606 -6.2874]: A new model, Rational Fusion-in-Decoder (RFiD), is proposed. It harnesses the encoders of FiD to differentiate between causal relationships and spurious features, subsequently guiding the decoder to generate answers based on this differentiation.", "target": "A new model, Rational Fusion-in-Decoder (RFiD), is proposed. It harnesses the encoders of FiD to differentiate between causal relationships and spurious features, subsequently guiding the decoder to generate answers based on this differentiation.", "example": "Convert the coordinate to text: [-0.1606 -6.2874]:"}
{"text": "Convert the coordinate to text: [-1.8871 -5.3187]: This paper investigates the performance and controllability of prompt-based methods with GPT-3 for GEC tasks, exploring the impact of task instructions and examples on GPT-3's output. Focus is given to controlling aspects such as minimal edits, fluency edits, and learner levels.", "target": "This paper investigates the performance and controllability of prompt-based methods with GPT-3 for GEC tasks, exploring the impact of task instructions and examples on GPT-3's output. Focus is given to controlling aspects such as minimal edits, fluency edits, and learner levels.", "example": "Convert the coordinate to text: [-1.8871 -5.3187]:"}
{"text": "Convert the coordinate to text: [-6.7497  2.9868]: The authors present a novel system for vandalism detection on Wikipedia that applies advanced filtering and feature engineering techniques, including multilingual masked language modeling to build the training dataset from human-generated data.", "target": "The authors present a novel system for vandalism detection on Wikipedia that applies advanced filtering and feature engineering techniques, including multilingual masked language modeling to build the training dataset from human-generated data.", "example": "Convert the coordinate to text: [-6.7497  2.9868]:"}
{"text": "Convert the coordinate to text: [-1.3684 -2.8582]: The paper proposes a novel approach, Task-Adaptive Reference Transformation (TART), to overcome the issue of similar semantics in few-shot text classification. TART aims to strengthen generalization by transforming class prototypes into per-class reference points in task-adaptive metric spaces.", "target": "The paper proposes a novel approach, Task-Adaptive Reference Transformation (TART), to overcome the issue of similar semantics in few-shot text classification. TART aims to strengthen generalization by transforming class prototypes into per-class reference points in task-adaptive metric spaces.", "example": "Convert the coordinate to text: [-1.3684 -2.8582]:"}
{"text": "Convert the coordinate to text: [-1.1353 -5.1849]: MetricPrompt is proposed, reformulating few-shot text classification task into text pair relevance estimation task and adopting prompting model as the relevance metric to ease verbalizer design difficulty. It enables Pre-trained Language Model's (PLM) smooth adaption by bridging the gap between PLM's pre-training objective and text classification task.", "target": "MetricPrompt is proposed, reformulating few-shot text classification task into text pair relevance estimation task and adopting prompting model as the relevance metric to ease verbalizer design difficulty. It enables Pre-trained Language Model's (PLM) smooth adaption by bridging the gap between PLM's pre-training objective and text classification task.", "example": "Convert the coordinate to text: [-1.1353 -5.1849]:"}
{"text": "Convert the coordinate to text: [ 6.2967 13.0531]: The authors formulate a new problem setting, policy customization, which seeks to train a policy that inherits the characteristics of the prior policy while also satisfying additional requirements imposed by a target downstream task. To address this, they propose a new framework, Residual Q-learning, which solves the associated Markov Decision Process without needing knowledge of the inherent reward or value function of the prior policy.", "target": "The authors formulate a new problem setting, policy customization, which seeks to train a policy that inherits the characteristics of the prior policy while also satisfying additional requirements imposed by a target downstream task. To address this, they propose a new framework, Residual Q-learning, which solves the associated Markov Decision Process without needing knowledge of the inherent reward or value function of the prior policy.", "example": "Convert the coordinate to text: [ 6.2967 13.0531]:"}
{"text": "Convert the coordinate to text: [-2.1387 -5.9441]: The key idea proposed by the study was the creation of a model built on a sentence-based BERT similarity model pre-trained on ClinicalBERT embeddings to perform textual entailment and evidence retrieval tasks.", "target": "The key idea proposed by the study was the creation of a model built on a sentence-based BERT similarity model pre-trained on ClinicalBERT embeddings to perform textual entailment and evidence retrieval tasks.", "example": "Convert the coordinate to text: [-2.1387 -5.9441]:"}
{"text": "Convert the coordinate to text: [-8.3682 -6.3468]: The third iteration of the DISRPT Shared Task has added 10 new corpora, including 2 new languages (Thai and Italian) and 3 discourse treebanks annotated in the discourse dependency representation in addition to the previously included frameworks: RST, SDRT, and PDTB.", "target": "The third iteration of the DISRPT Shared Task has added 10 new corpora, including 2 new languages (Thai and Italian) and 3 discourse treebanks annotated in the discourse dependency representation in addition to the previously included frameworks: RST, SDRT, and PDTB.", "example": "Convert the coordinate to text: [-8.3682 -6.3468]:"}
{"text": "Convert the coordinate to text: [-1.9446 -6.4107]: This paper investigates different pre-training methods, including training the biomedical LM from scratch and in a continued fashion. A new pre-training method is proposed that initializes weights for new tokens using the existing weights of the BERT model, and a new model, BIOptimus, which is pre-trained using Curriculum Learning (CL) and contextualized weight distillation method.", "target": "This paper investigates different pre-training methods, including training the biomedical LM from scratch and in a continued fashion. A new pre-training method is proposed that initializes weights for new tokens using the existing weights of the BERT model, and a new model, BIOptimus, which is pre-trained using Curriculum Learning (CL) and contextualized weight distillation method.", "example": "Convert the coordinate to text: [-1.9446 -6.4107]:"}
{"text": "Convert the coordinate to text: [-8.8506 -2.7162]: The authors of this position paper propose a new perspective towards evaluation in NLP as a force for driving change, carrying sociological and political weight beyond its technical aspects. They argue that evaluation achieves success when it brings the desired change.", "target": "The authors of this position paper propose a new perspective towards evaluation in NLP as a force for driving change, carrying sociological and political weight beyond its technical aspects. They argue that evaluation achieves success when it brings the desired change.", "example": "Convert the coordinate to text: [-8.8506 -2.7162]:"}
{"text": "Convert the coordinate to text: [-8.1263 -6.7102]: The authors propose a two-phase rewriting framework for incorrect or ambiguous utterances. The first phase predicts the empty slots in the utterance, and the second produces the part to be filled into each position.", "target": "The authors propose a two-phase rewriting framework for incorrect or ambiguous utterances. The first phase predicts the empty slots in the utterance, and the second produces the part to be filled into each position.", "example": "Convert the coordinate to text: [-8.1263 -6.7102]:"}
{"text": "Convert the coordinate to text: [ -5.1487 -10.1729]: The paper examines the complex relationship between ASR and NER errors, which limit the ability of NER models to recover entity mentions from spontaneous speech transcripts, and introduces a taxonomy of ASR-NER errors.", "target": "The paper examines the complex relationship between ASR and NER errors, which limit the ability of NER models to recover entity mentions from spontaneous speech transcripts, and introduces a taxonomy of ASR-NER errors.", "example": "Convert the coordinate to text: [ -5.1487 -10.1729]:"}
{"text": "Convert the coordinate to text: [13.5731 -7.6436]: The authors propose a novel reconstruction-based framework for ECG anomaly detection named ECGGAN. It leverages periodic metadata, specifically the 'beat', in ECGs to learn common patterns from representative normal data. They also introduce a reconstruction model that uses leads as constraints to capture unique characteristics of different leads in ECG data.", "target": "The authors propose a novel reconstruction-based framework for ECG anomaly detection named ECGGAN. It leverages periodic metadata, specifically the 'beat', in ECGs to learn common patterns from representative normal data. They also introduce a reconstruction model that uses leads as constraints to capture unique characteristics of different leads in ECG data.", "example": "Convert the coordinate to text: [13.5731 -7.6436]:"}
{"text": "Convert the coordinate to text: [ 4.6208 -1.1536]: This paper proposes a method, referred to as KAKURENBO, that adaptively hides the least important samples during the training of deep neural networks in order to increase training efficiency without significantly impacting accuracy.", "target": "This paper proposes a method, referred to as KAKURENBO, that adaptively hides the least important samples during the training of deep neural networks in order to increase training efficiency without significantly impacting accuracy.", "example": "Convert the coordinate to text: [ 4.6208 -1.1536]:"}
{"text": "Convert the coordinate to text: [ 0.1165 -3.6266]: The paper proposes the idea that interactive concepts that involve more input variables, implying more complex concepts, are harder for the DNNs to learn.", "target": "The paper proposes the idea that interactive concepts that involve more input variables, implying more complex concepts, are harder for the DNNs to learn.", "example": "Convert the coordinate to text: [ 0.1165 -3.6266]:"}
{"text": "Convert the coordinate to text: [-3.8152 -4.8194]: The authors propose an approach to generate semantically tailored word embeddings for each task by fully leveraging contextual information. They do this by condensing the contextual syntactic dependencies of words into a semantic graph for each task, which is modeled by a Variational Graph Auto-Encoder to produce task-specific word representations.", "target": "The authors propose an approach to generate semantically tailored word embeddings for each task by fully leveraging contextual information. They do this by condensing the contextual syntactic dependencies of words into a semantic graph for each task, which is modeled by a Variational Graph Auto-Encoder to produce task-specific word representations.", "example": "Convert the coordinate to text: [-3.8152 -4.8194]:"}
{"text": "Convert the coordinate to text: [-8.1811 -7.8145]: The authors introduce and define a new mode of textual attack, labeled punctuation-level attack, which includes various types of perturbations such as insertion, displacement, deletion, and replacement of punctuation marks.", "target": "The authors introduce and define a new mode of textual attack, labeled punctuation-level attack, which includes various types of perturbations such as insertion, displacement, deletion, and replacement of punctuation marks.", "example": "Convert the coordinate to text: [-8.1811 -7.8145]:"}
{"text": "Convert the coordinate to text: [-4.3512 -9.6125]: The authors propose an inference algorithm that improves the prediction of state-of-the-art ASR models using nearest-neighbor-based matching on an inference-time word list. This involves indexing a list of rare entities in a memory by synthesizing speech for each entry, and storing the internal acoustic and language model states obtained from the best possible alignment on the ASR model.", "target": "The authors propose an inference algorithm that improves the prediction of state-of-the-art ASR models using nearest-neighbor-based matching on an inference-time word list. This involves indexing a list of rare entities in a memory by synthesizing speech for each entry, and storing the internal acoustic and language model states obtained from the best possible alignment on the ASR model.", "example": "Convert the coordinate to text: [-4.3512 -9.6125]:"}
{"text": "Convert the coordinate to text: [-2.2788 -5.5785]: This paper undertakes a comprehensive study on the use of the latest Sentence Encoders and Large Language Models (LLMs) like ChatGPT-3.5 and PaLM for the task of definition-wild zero-shot topic inference.", "target": "This paper undertakes a comprehensive study on the use of the latest Sentence Encoders and Large Language Models (LLMs) like ChatGPT-3.5 and PaLM for the task of definition-wild zero-shot topic inference.", "example": "Convert the coordinate to text: [-2.2788 -5.5785]:"}
{"text": "Convert the coordinate to text: [ 4.7899 -6.121 ]: The paper's central aim is to understand the interplay between global and local elements in graph-based spatiotemporal forecasting and to propose a new methodological framework that involves the use of trainable node embeddings to aid in learning.", "target": "The paper's central aim is to understand the interplay between global and local elements in graph-based spatiotemporal forecasting and to propose a new methodological framework that involves the use of trainable node embeddings to aid in learning.", "example": "Convert the coordinate to text: [ 4.7899 -6.121 ]:"}
{"text": "Convert the coordinate to text: [ 4.6029 -0.3666]: This study investigates the effectiveness of biased soft labels in learning, proposing two indicators to measure this effectiveness and providing sufficient conditions to ensure learners using biased soft labels are classifier-consistent and empirically risk minimization (ERM) learnable.", "target": "This study investigates the effectiveness of biased soft labels in learning, proposing two indicators to measure this effectiveness and providing sufficient conditions to ensure learners using biased soft labels are classifier-consistent and empirically risk minimization (ERM) learnable.", "example": "Convert the coordinate to text: [ 4.6029 -0.3666]:"}
{"text": "Convert the coordinate to text: [  5.0702 -12.8623]: The authors propose the Segment Anything project which combines a novel task, model, and dataset for image segmentation that is designed to be promptable and can transfer zero-shot to new image distributions and tasks.", "target": "The authors propose the Segment Anything project which combines a novel task, model, and dataset for image segmentation that is designed to be promptable and can transfer zero-shot to new image distributions and tasks.", "example": "Convert the coordinate to text: [  5.0702 -12.8623]:"}
{"text": "Convert the coordinate to text: [-11.3975  16.9084]: The authors propose a visuo-haptic crossmodal model of shape perception for shape-changing handheld controllers, using the inertia tensor of an object to bridge visual and haptic senses.", "target": "The authors propose a visuo-haptic crossmodal model of shape perception for shape-changing handheld controllers, using the inertia tensor of an object to bridge visual and haptic senses.", "example": "Convert the coordinate to text: [-11.3975  16.9084]:"}
{"text": "Convert the coordinate to text: [-2.8084 -4.1004]: The authors propose SenteCon, a method to introduce human interpretability into deep language representations. SenteCon encodes text as a layer of interpretable categories where each dimension corresponds to the relevance of a specific category.", "target": "The authors propose SenteCon, a method to introduce human interpretability into deep language representations. SenteCon encodes text as a layer of interpretable categories where each dimension corresponds to the relevance of a specific category.", "example": "Convert the coordinate to text: [-2.8084 -4.1004]:"}
{"text": "Convert the coordinate to text: [-9.8643  0.5996]: The authors propose to leverage mature methods from the Information Retrieval (IR) field and integrate Pyserini, an IR toolkit, with Hugging Face, an ecosystem of open-source AI libraries and artifacts. The aim is to provide NLP researchers with more agile and convenient data analytics instrumentation.", "target": "The authors propose to leverage mature methods from the Information Retrieval (IR) field and integrate Pyserini, an IR toolkit, with Hugging Face, an ecosystem of open-source AI libraries and artifacts. The aim is to provide NLP researchers with more agile and convenient data analytics instrumentation.", "example": "Convert the coordinate to text: [-9.8643  0.5996]:"}
{"text": "Convert the coordinate to text: [-2.7644 -3.363 ]: This paper proposes a similarity flooding perspective to explain existing translation-based and aggregation-based EA models. It posits that their embedding learning process seeks a fixpoint of pairwise similarities between entities.", "target": "This paper proposes a similarity flooding perspective to explain existing translation-based and aggregation-based EA models. It posits that their embedding learning process seeks a fixpoint of pairwise similarities between entities.", "example": "Convert the coordinate to text: [-2.7644 -3.363 ]:"}
{"text": "Convert the coordinate to text: [6.535 5.007]: This paper introduces OpenDelta, an open-source library providing a plug-and-play implementation of various delta tuning methods, eliminating the need to modify the backbone PTMs' code, and making it compatible with different and novel PTMs.", "target": "This paper introduces OpenDelta, an open-source library providing a plug-and-play implementation of various delta tuning methods, eliminating the need to modify the backbone PTMs' code, and making it compatible with different and novel PTMs.", "example": "Convert the coordinate to text: [6.535 5.007]:"}
{"text": "Convert the coordinate to text: [-1.6458 -6.4576]: The authors propose a method that uses a pre-trained language model, DeBERTa, to tokenize and concatenate the text before feeding it into a fully connected neural network. They also believe that leveraging the hierarchy in values can improve performance.", "target": "The authors propose a method that uses a pre-trained language model, DeBERTa, to tokenize and concatenate the text before feeding it into a fully connected neural network. They also believe that leveraging the hierarchy in values can improve performance.", "example": "Convert the coordinate to text: [-1.6458 -6.4576]:"}
{"text": "Convert the coordinate to text: [-4.1153 -3.1517]: The authors propose that entities can act as bridges between different ACs as they convey significant semantic information and introduce an Entity Coreference and Co-occurrence aware Argument Mining (ECCAM) framework based on an edge-oriented graph model for BAM.", "target": "The authors propose that entities can act as bridges between different ACs as they convey significant semantic information and introduce an Entity Coreference and Co-occurrence aware Argument Mining (ECCAM) framework based on an edge-oriented graph model for BAM.", "example": "Convert the coordinate to text: [-4.1153 -3.1517]:"}
{"text": "Convert the coordinate to text: [-1.0088 -5.128 ]: The Adversarial Knowledge Stimulated Contrastive Prompting (AKSCP) framework is proposed to improve few-shot NLU tasks for language models by implicitly stimulating knowledge from a pretrained language model. It introduces a novel paradigm 'Cloze-driven prompt' for joint prompt tuning across word cloze task and prompt-based learning.", "target": "The Adversarial Knowledge Stimulated Contrastive Prompting (AKSCP) framework is proposed to improve few-shot NLU tasks for language models by implicitly stimulating knowledge from a pretrained language model. It introduces a novel paradigm 'Cloze-driven prompt' for joint prompt tuning across word cloze task and prompt-based learning.", "example": "Convert the coordinate to text: [-1.0088 -5.128 ]:"}
{"text": "Convert the coordinate to text: [ 6.8663 -4.0653]: The paper proposes DaMSTF, a self-training framework for domain adaptation. It employs meta-learning to estimate the importance of each pseudo instance, reducing label noise and preserving hard examples. It includes a meta constructor for creating the meta-validation set and uses domain adversarial learning to help the meta-learning module reach better optimal convergence.", "target": "The paper proposes DaMSTF, a self-training framework for domain adaptation. It employs meta-learning to estimate the importance of each pseudo instance, reducing label noise and preserving hard examples. It includes a meta constructor for creating the meta-validation set and uses domain adversarial learning to help the meta-learning module reach better optimal convergence.", "example": "Convert the coordinate to text: [ 6.8663 -4.0653]:"}
{"text": "Convert the coordinate to text: [  5.8771 -11.2753]: This paper introduces ES-Mask, a model-agnostic, post-hoc, evolutionary strip mask-based saliency technique designed for time series applications. ES-Mask produces binary, sustained feature importance scores over time for easy interpretation of time series by using the same salient value in consecutive time steps.", "target": "This paper introduces ES-Mask, a model-agnostic, post-hoc, evolutionary strip mask-based saliency technique designed for time series applications. ES-Mask produces binary, sustained feature importance scores over time for easy interpretation of time series by using the same salient value in consecutive time steps.", "example": "Convert the coordinate to text: [  5.8771 -11.2753]:"}
{"text": "Convert the coordinate to text: [  7.5859 -15.2329]: The authors propose a weakly supervised learning algorithm that decomposes the correspondence learning problem into three stages: image-level matching, region-level matching, and pixel-level matching. The pixel-to-pixel matching pairs are propagated, filtered, and enhanced in these stages with only image-level supervision.", "target": "The authors propose a weakly supervised learning algorithm that decomposes the correspondence learning problem into three stages: image-level matching, region-level matching, and pixel-level matching. The pixel-to-pixel matching pairs are propagated, filtered, and enhanced in these stages with only image-level supervision.", "example": "Convert the coordinate to text: [  7.5859 -15.2329]:"}
{"text": "Convert the coordinate to text: [-8.5029 -5.5173]: The authors propose a new model that addresses compositional generalization by clustering predicates into groups and generates text in a sentence-by-sentence manner, relying on one cluster of predicates at a time.", "target": "The authors propose a new model that addresses compositional generalization by clustering predicates into groups and generates text in a sentence-by-sentence manner, relying on one cluster of predicates at a time.", "example": "Convert the coordinate to text: [-8.5029 -5.5173]:"}
{"text": "Convert the coordinate to text: [-2.7011  0.4709]: The authors developed a character substitution scraping method to assemble the Offensive Tweets with Homoglyphs (OTH) Dataset, and assessed the performance of seven transformer-based hate speech detection models.", "target": "The authors developed a character substitution scraping method to assemble the Offensive Tweets with Homoglyphs (OTH) Dataset, and assessed the performance of seven transformer-based hate speech detection models.", "example": "Convert the coordinate to text: [-2.7011  0.4709]:"}
{"text": "Convert the coordinate to text: [9.0107 7.6299]: The authors aim to output a hypothesis with 0-1 loss OPT+\u03b5, where OPT is the 0-1 loss of the best-fitting halfspace, under the assumption of the sub-exponential time hardness of the Learning with Errors (LWE) problem.", "target": "The authors aim to output a hypothesis with 0-1 loss OPT+\u03b5, where OPT is the 0-1 loss of the best-fitting halfspace, under the assumption of the sub-exponential time hardness of the Learning with Errors (LWE) problem.", "example": "Convert the coordinate to text: [9.0107 7.6299]:"}
{"text": "Convert the coordinate to text: [-6.9213 -9.2591]: The researchers propose READIN: a Chinese multi-task benchmark system designed to incorporate REalistic And Diverse INput noises.", "target": "The researchers propose READIN: a Chinese multi-task benchmark system designed to incorporate REalistic And Diverse INput noises.", "example": "Convert the coordinate to text: [-6.9213 -9.2591]:"}
{"text": "Convert the coordinate to text: [-9.1226 -2.4079]: The authors introduce OpenICL, an open-source toolkit designed for ICL and LLM evaluation that provides a highly flexible architecture and includes various state-of-the-art retrieval and inference methods.", "target": "The authors introduce OpenICL, an open-source toolkit designed for ICL and LLM evaluation that provides a highly flexible architecture and includes various state-of-the-art retrieval and inference methods.", "example": "Convert the coordinate to text: [-9.1226 -2.4079]:"}
{"text": "Convert the coordinate to text: [-2.6465 -7.3753]: The authors propose to investigate the types of noise encountered within a pipeline for unsupervised morphological paradigm completion and its impact on morphological inflection systems. In addition, they propose a novel character-level masked language modeling (CMLM) pretraining objective to increase model's resistance to noise.", "target": "The authors propose to investigate the types of noise encountered within a pipeline for unsupervised morphological paradigm completion and its impact on morphological inflection systems. In addition, they propose a novel character-level masked language modeling (CMLM) pretraining objective to increase model's resistance to noise.", "example": "Convert the coordinate to text: [-2.6465 -7.3753]:"}
{"text": "Convert the coordinate to text: [ 2.9464 -0.4436]: The authors propose D-CALM, an adaptive clustering-based active learning algorithm that dynamically adjusts clustering and annotation efforts in response to an estimated classifier error-rate and can potentially reduce bias present in models.", "target": "The authors propose D-CALM, an adaptive clustering-based active learning algorithm that dynamically adjusts clustering and annotation efforts in response to an estimated classifier error-rate and can potentially reduce bias present in models.", "example": "Convert the coordinate to text: [ 2.9464 -0.4436]:"}
{"text": "Convert the coordinate to text: [-7.4252 -7.3285]: The authors suggest returning to the fastest pattern-based natural language processing methods and optimizing them for accuracy, to create a highly efficient, accurate Japanese morphological analyzer.", "target": "The authors suggest returning to the fastest pattern-based natural language processing methods and optimizing them for accuracy, to create a highly efficient, accurate Japanese morphological analyzer.", "example": "Convert the coordinate to text: [-7.4252 -7.3285]:"}
{"text": "Convert the coordinate to text: [11.8489 -4.3324]: The study introduces a novel procedure, called distribution shift risk minimization (DSRM), which estimates the adversarial loss by perturbing the input data's probability distribution and not their embeddings. It results in a robust model that minimizes the expected global loss under adversarial attacks. This new approach does not require any adversarial samples for training.", "target": "The study introduces a novel procedure, called distribution shift risk minimization (DSRM), which estimates the adversarial loss by perturbing the input data's probability distribution and not their embeddings. It results in a robust model that minimizes the expected global loss under adversarial attacks. This new approach does not require any adversarial samples for training.", "example": "Convert the coordinate to text: [11.8489 -4.3324]:"}
{"text": "Convert the coordinate to text: [6.1053 1.1469]: The authors propose a lightweight and non-parametric alternative to deep neural networks for text classification: a combination of a compressor like gzip and a k-nearest-neighbor classifier.", "target": "The authors propose a lightweight and non-parametric alternative to deep neural networks for text classification: a combination of a compressor like gzip and a k-nearest-neighbor classifier.", "example": "Convert the coordinate to text: [6.1053 1.1469]:"}
{"text": "Convert the coordinate to text: [-4.1765 -0.3691]: The team proposed a two-fold approach: an unsupervised method that maps arguments to concepts, and a supervised classification model that then maps these concepts to human values.", "target": "The team proposed a two-fold approach: an unsupervised method that maps arguments to concepts, and a supervised classification model that then maps these concepts to human values.", "example": "Convert the coordinate to text: [-4.1765 -0.3691]:"}
{"text": "Convert the coordinate to text: [-3.6283 -9.2603]: The authors propose the extscMineTrans English-to-Chinese speech translation systems for IWSLT 2023's Offline Speech Translation (S2T) and Speech-to-Speech Translation (S2ST). The S2T employs a cascaded system comprising ASR, PC, and MT, using multiple ASR architectures and two MT strategies. The S2ST uses a speech-to-unit (S2U) framework encoding target speech as discrete units, then using sequence-to-sequence models to learn mapping, devoid of auxiliary recognition tasks.", "target": "The authors propose the extscMineTrans English-to-Chinese speech translation systems for IWSLT 2023's Offline Speech Translation (S2T) and Speech-to-Speech Translation (S2ST). The S2T employs a cascaded system comprising ASR, PC, and MT, using multiple ASR architectures and two MT strategies. The S2ST uses a speech-to-unit (S2U) framework encoding target speech as discrete units, then using sequence-to-sequence models to learn mapping, devoid of auxiliary recognition tasks.", "example": "Convert the coordinate to text: [-3.6283 -9.2603]:"}
{"text": "Convert the coordinate to text: [-2.0379 -5.7617]: This paper presents a domain-specific BERT-based model using a transfer learning approach for predicting the veracity of claim-evidence pairs for verifying health-related facts. Additionally, it proposes an improved method for combining multiple evidences for a single claim, even with conflicting evidences.", "target": "This paper presents a domain-specific BERT-based model using a transfer learning approach for predicting the veracity of claim-evidence pairs for verifying health-related facts. Additionally, it proposes an improved method for combining multiple evidences for a single claim, even with conflicting evidences.", "example": "Convert the coordinate to text: [-2.0379 -5.7617]:"}
{"text": "Convert the coordinate to text: [-8.616  -4.2678]: The authors propose the development of a modern linguistic assessment for degree of anxiety, incorporating discourse-level information in addition to standard lexical-level large language model embeddings.", "target": "The authors propose the development of a modern linguistic assessment for degree of anxiety, incorporating discourse-level information in addition to standard lexical-level large language model embeddings.", "example": "Convert the coordinate to text: [-8.616  -4.2678]:"}
{"text": "Convert the coordinate to text: [-0.2679 -7.8871]: The authors propose a two-stream model, Multimodal BERT-ViT, featuring a novel intra-CLS token fusion for more effectively exploiting the weaker modality, coupled with a dynamic adjustment that maintains a balance between specialization and generalization during the training to avoid overfitting.", "target": "The authors propose a two-stream model, Multimodal BERT-ViT, featuring a novel intra-CLS token fusion for more effectively exploiting the weaker modality, coupled with a dynamic adjustment that maintains a balance between specialization and generalization during the training to avoid overfitting.", "example": "Convert the coordinate to text: [-0.2679 -7.8871]:"}
{"text": "Convert the coordinate to text: [-2.2496 -7.4757]: The authors introduce CLPM (Cross-lingual Prototype Masking), a dynamic, token-wise masking scheme for multilingual pre-training. This uses a special token [\ud835\udc9e]x to replace a random token x in the input sentence, forming an explicit cross-lingual forward pass.", "target": "The authors introduce CLPM (Cross-lingual Prototype Masking), a dynamic, token-wise masking scheme for multilingual pre-training. This uses a special token [\ud835\udc9e]x to replace a random token x in the input sentence, forming an explicit cross-lingual forward pass.", "example": "Convert the coordinate to text: [-2.2496 -7.4757]:"}
{"text": "Convert the coordinate to text: [ 6.1981 -5.208 ]: This study focuses on the active symmetries of GNNs, considering a learning setting where signals are supported on a fixed graph. The natural symmetries of GNNs are formalized as approximate symmetries via graph coarsening.", "target": "This study focuses on the active symmetries of GNNs, considering a learning setting where signals are supported on a fixed graph. The natural symmetries of GNNs are formalized as approximate symmetries via graph coarsening.", "example": "Convert the coordinate to text: [ 6.1981 -5.208 ]:"}
{"text": "Convert the coordinate to text: [13.0509 -1.7383]: The authors propose a closed-loop system that uses a test-time feedback signal to adapt a network on the fly, resulting in a learning-based function that acts as an amortized optimizer for the network. They call this Rapid Network Adaptation (RNA).", "target": "The authors propose a closed-loop system that uses a test-time feedback signal to adapt a network on the fly, resulting in a learning-based function that acts as an amortized optimizer for the network. They call this Rapid Network Adaptation (RNA).", "example": "Convert the coordinate to text: [13.0509 -1.7383]:"}
{"text": "Convert the coordinate to text: [10.8521 -6.0365]: The authors address the issue of prediction diversity by proposing a generative model, GePSAn, that anticipates future steps for procedural videos. The model is designed to generate diverse and plausible options, described in natural language, for the next procedure step in a given series of video clips.", "target": "The authors address the issue of prediction diversity by proposing a generative model, GePSAn, that anticipates future steps for procedural videos. The model is designed to generate diverse and plausible options, described in natural language, for the next procedure step in a given series of video clips.", "example": "Convert the coordinate to text: [10.8521 -6.0365]:"}
{"text": "Convert the coordinate to text: [-2.2378 -6.6857]: The authors propose an ensemble of fully trained and adapter mBERT models for news genre classification, two separate ensembles: a monolingual RoBERTa-MUPPETLARGE and an ensemble of XLM-RoBERTaLARGE with adapters and task adaptive pretraining for framing detection, and a monolingual RoBERTa-Base model for English and a multilingual mBERT model for persuasion techniques detection.", "target": "The authors propose an ensemble of fully trained and adapter mBERT models for news genre classification, two separate ensembles: a monolingual RoBERTa-MUPPETLARGE and an ensemble of XLM-RoBERTaLARGE with adapters and task adaptive pretraining for framing detection, and a monolingual RoBERTa-Base model for English and a multilingual mBERT model for persuasion techniques detection.", "example": "Convert the coordinate to text: [-2.2378 -6.6857]:"}
{"text": "Convert the coordinate to text: [ 0.5802 -8.7622]: The authors propose a novel framework that constrains the cross-modality space into the same space of natural-language. This allows the visual features to be preserved directly, and the model to benefit from the vast knowledge in natural-language space. The framework consists of a multimodal encoder, a textual encoder, and an answer decoder.", "target": "The authors propose a novel framework that constrains the cross-modality space into the same space of natural-language. This allows the visual features to be preserved directly, and the model to benefit from the vast knowledge in natural-language space. The framework consists of a multimodal encoder, a textual encoder, and an answer decoder.", "example": "Convert the coordinate to text: [ 0.5802 -8.7622]:"}
{"text": "Convert the coordinate to text: [ 1.9562 -4.3103]: The authors propose a semantic-consistent learning method (ScTD) to enhance token dropping. This method aims to encourage the model to preserve the semantic information in the representation space.", "target": "The authors propose a semantic-consistent learning method (ScTD) to enhance token dropping. This method aims to encourage the model to preserve the semantic information in the representation space.", "example": "Convert the coordinate to text: [ 1.9562 -4.3103]:"}
{"text": "Convert the coordinate to text: [ 0.7383 -3.3209]: The authors propose to improve the multi-step reasoning capabilities of smaller LMs by continuously pre-training them on a synthetic dataset called MsAT, composed of Multi-step Arithmetic Tasks.", "target": "The authors propose to improve the multi-step reasoning capabilities of smaller LMs by continuously pre-training them on a synthetic dataset called MsAT, composed of Multi-step Arithmetic Tasks.", "example": "Convert the coordinate to text: [ 0.7383 -3.3209]:"}
{"text": "Convert the coordinate to text: [-4.3694 10.3885]: The Candide model is introduced as a solution to this issue, with a groundwork basis that narratives encapsulate personal experiences, applying machine-logic to predict divergent interpretations of given observations and update belief systems accordingly.", "target": "The Candide model is introduced as a solution to this issue, with a groundwork basis that narratives encapsulate personal experiences, applying machine-logic to predict divergent interpretations of given observations and update belief systems accordingly.", "example": "Convert the coordinate to text: [-4.3694 10.3885]:"}
{"text": "Convert the coordinate to text: [-9.8645 -1.7042]: The study explores multiple task formulations for this problem, including sequence classification, question answering, and question answering with a concept known as chain-of-thought prompting.", "target": "The study explores multiple task formulations for this problem, including sequence classification, question answering, and question answering with a concept known as chain-of-thought prompting.", "example": "Convert the coordinate to text: [-9.8645 -1.7042]:"}
{"text": "Convert the coordinate to text: [-4.2597 -8.8752]: The authors propose investigating the mutual transfer between Tunisian Arabic and Modern Standard Arabic (MSA) for enhancing the performance of speech translation. This includes integrating a Tunisian-MSA translation module into the end-to-end Speech Translation (ST) model and synthesizing pseudo Tunisian-English paired data using a multi-step pre-training approach.", "target": "The authors propose investigating the mutual transfer between Tunisian Arabic and Modern Standard Arabic (MSA) for enhancing the performance of speech translation. This includes integrating a Tunisian-MSA translation module into the end-to-end Speech Translation (ST) model and synthesizing pseudo Tunisian-English paired data using a multi-step pre-training approach.", "example": "Convert the coordinate to text: [-4.2597 -8.8752]:"}
{"text": "Convert the coordinate to text: [-5.738  -0.7246]: The authors propose an approach that selectively prioritizes certain sections from the dataset (Introduction, Abstract, and some parts of Results), estimates the optimal lengths of these sections for summation, and utilizes the Facebook/bart-base as a pre-trained model. The authors also introduce a chunking approach due to the large text lengths.", "target": "The authors propose an approach that selectively prioritizes certain sections from the dataset (Introduction, Abstract, and some parts of Results), estimates the optimal lengths of these sections for summation, and utilizes the Facebook/bart-base as a pre-trained model. The authors also introduce a chunking approach due to the large text lengths.", "example": "Convert the coordinate to text: [-5.738  -0.7246]:"}
{"text": "Convert the coordinate to text: [ 1.0805 -3.716 ]: The authors propose the Label-aware Compact Linguistics Representation (LCLR) method which uses label embeddings to jointly guide the decoding process of both tasks which could be represented as linear combinations of label embeddings.", "target": "The authors propose the Label-aware Compact Linguistics Representation (LCLR) method which uses label embeddings to jointly guide the decoding process of both tasks which could be represented as linear combinations of label embeddings.", "example": "Convert the coordinate to text: [ 1.0805 -3.716 ]:"}
{"text": "Convert the coordinate to text: [10.5812  7.2728]: The paper proposes NeuralEF, a fast neural approximation framework that robustly forecasts the result of the EF convex optimization problem with respect to a range of linear constraints and a variable number of optimization inputs, by reformulating the optimization problem as a sequence to sequence problem.", "target": "The paper proposes NeuralEF, a fast neural approximation framework that robustly forecasts the result of the EF convex optimization problem with respect to a range of linear constraints and a variable number of optimization inputs, by reformulating the optimization problem as a sequence to sequence problem.", "example": "Convert the coordinate to text: [10.5812  7.2728]:"}
{"text": "Convert the coordinate to text: [ 11.1802 -17.0596]: The authors solve this issue by developing a correct non-linear parametrization of manifolds, called eventails, which works with event-based linear motion estimation. They also introduce a novel 5-point solver that estimates line parameters and linear camera velocity projections.", "target": "The authors solve this issue by developing a correct non-linear parametrization of manifolds, called eventails, which works with event-based linear motion estimation. They also introduce a novel 5-point solver that estimates line parameters and linear camera velocity projections.", "example": "Convert the coordinate to text: [ 11.1802 -17.0596]:"}
{"text": "Convert the coordinate to text: [ 1.994  -3.3145]: This paper offers a new perspective on catastrophic forgetting in IOD tasks, describing it as a disruption of the semantic feature space, and presents a new method that dynamically distills both semantic and feature information, considering both within-class consistency and between-class discriminativeness on a Transformer-based detector.", "target": "This paper offers a new perspective on catastrophic forgetting in IOD tasks, describing it as a disruption of the semantic feature space, and presents a new method that dynamically distills both semantic and feature information, considering both within-class consistency and between-class discriminativeness on a Transformer-based detector.", "example": "Convert the coordinate to text: [ 1.994  -3.3145]:"}
{"text": "Convert the coordinate to text: [10.7258 -3.2236]: The authors propose that sparse coding, a ubiquitous principle in brain function, can introduce shape bias into deep learning networks.", "target": "The authors propose that sparse coding, a ubiquitous principle in brain function, can introduce shape bias into deep learning networks.", "example": "Convert the coordinate to text: [10.7258 -3.2236]:"}
{"text": "Convert the coordinate to text: [10.887  -5.7795]: The authors propose SidechainDiff, a representation learning-based approach that utilizes a Riemannian diffusion model to learn the generative process of side-chain conformations and can provide the structural context representations of mutations on the protein-protein interface.", "target": "The authors propose SidechainDiff, a representation learning-based approach that utilizes a Riemannian diffusion model to learn the generative process of side-chain conformations and can provide the structural context representations of mutations on the protein-protein interface.", "example": "Convert the coordinate to text: [10.887  -5.7795]:"}
{"text": "Convert the coordinate to text: [  9.6152 -11.5784]: The authors propose a new deep learning framework that jointly reconstructs the inner, outer, and midthickness surfaces and estimates cortical thickness directly from 3D MRIs with a topological correctness regularizer.", "target": "The authors propose a new deep learning framework that jointly reconstructs the inner, outer, and midthickness surfaces and estimates cortical thickness directly from 3D MRIs with a topological correctness regularizer.", "example": "Convert the coordinate to text: [  9.6152 -11.5784]:"}
{"text": "Convert the coordinate to text: [15.5657 -0.1305]: The authors propose an efficient Quantized Diffusion Model (Q-DM) through the introduction of a Timestep-aware Quantization (TaQ) method and a Noise-estimating Mimicking (NeM) scheme which serve to effectively address the large distribution oscillation on activations and accumulated quantization error caused by the multi-step denoising process.", "target": "The authors propose an efficient Quantized Diffusion Model (Q-DM) through the introduction of a Timestep-aware Quantization (TaQ) method and a Noise-estimating Mimicking (NeM) scheme which serve to effectively address the large distribution oscillation on activations and accumulated quantization error caused by the multi-step denoising process.", "example": "Convert the coordinate to text: [15.5657 -0.1305]:"}
{"text": "Convert the coordinate to text: [-1.8956 -6.0651]: The authors aim to examine the theoretical aspects of the data augmentation strategy StemCorrupt, which randomly substitutes stem characters to create synthetic examples, and how it changes the underlying data distribution to reveal compositional concatenative structure.", "target": "The authors aim to examine the theoretical aspects of the data augmentation strategy StemCorrupt, which randomly substitutes stem characters to create synthetic examples, and how it changes the underlying data distribution to reveal compositional concatenative structure.", "example": "Convert the coordinate to text: [-1.8956 -6.0651]:"}
{"text": "Convert the coordinate to text: [-5.4664 -2.8676]: In order to address the challenges in name disambiguation, the authors present WhoIsWho, a large-scale benchmark with over a million papers, a leaderboard presenting comprehensive tasks, and an easy-to-use toolkit that provides useful features and baseline models for these tasks.", "target": "In order to address the challenges in name disambiguation, the authors present WhoIsWho, a large-scale benchmark with over a million papers, a leaderboard presenting comprehensive tasks, and an easy-to-use toolkit that provides useful features and baseline models for these tasks.", "example": "Convert the coordinate to text: [-5.4664 -2.8676]:"}
{"text": "Convert the coordinate to text: [-1.3728  0.0857]: The key idea of this paper is to use an ensemble model based on fine-tuning BERT-based models with a Majority Voting approach to improve the performance of the detection of online sexism.", "target": "The key idea of this paper is to use an ensemble model based on fine-tuning BERT-based models with a Majority Voting approach to improve the performance of the detection of online sexism.", "example": "Convert the coordinate to text: [-1.3728  0.0857]:"}
{"text": "Convert the coordinate to text: [ 1.6076 -0.845 ]: The authors propose to fine-tune a BERT model to capture disagreement in annotations and argue for the importance of taking into account individual annotator modeling and aggregation, instead of training directly on the soft labels.", "target": "The authors propose to fine-tune a BERT model to capture disagreement in annotations and argue for the importance of taking into account individual annotator modeling and aggregation, instead of training directly on the soft labels.", "example": "Convert the coordinate to text: [ 1.6076 -0.845 ]:"}
{"text": "Convert the coordinate to text: [-10.5625  -1.9657]: The paper presents the new task of unsupervised long-document question answering (ULQA), which aims to generate high-quality long-document QA instances in an unsupervised manner. To solve this task, the authors propose AttenWalker, a method that aggregates and generates answers with long-range dependency to construct long-document QA pairs.", "target": "The paper presents the new task of unsupervised long-document question answering (ULQA), which aims to generate high-quality long-document QA instances in an unsupervised manner. To solve this task, the authors propose AttenWalker, a method that aggregates and generates answers with long-range dependency to construct long-document QA pairs.", "example": "Convert the coordinate to text: [-10.5625  -1.9657]:"}
{"text": "Convert the coordinate to text: [-0.909  -2.3495]: The study presents a method named Multi-generator Rationalization (MGR) which employs multiple generators to improve the occurrence stability of real pieces and deliver more meaningful pieces to the predictor, aiming to simultaneously deal with both problems faced in rationalization.", "target": "The study presents a method named Multi-generator Rationalization (MGR) which employs multiple generators to improve the occurrence stability of real pieces and deliver more meaningful pieces to the predictor, aiming to simultaneously deal with both problems faced in rationalization.", "example": "Convert the coordinate to text: [-0.909  -2.3495]:"}
{"text": "Convert the coordinate to text: [-0.9076 -8.1719]: The authors propose a novel approach that uses a labeler to extract comparison prior information from radiology reports. This comparison prior is then integrated into transformer-based models, enabling them to generate more realistic and comprehensive reports.", "target": "The authors propose a novel approach that uses a labeler to extract comparison prior information from radiology reports. This comparison prior is then integrated into transformer-based models, enabling them to generate more realistic and comprehensive reports.", "example": "Convert the coordinate to text: [-0.9076 -8.1719]:"}
{"text": "Convert the coordinate to text: [ 8.596  -6.2161]: The authors propose a new framework known as 'classifier decomposition' to deal with biases in the vanilla strategy. This framework involves splitting the last feedforward neural network (FFN) layer into separate previous and current classifiers, allowing the model to maintain prior knowledge and learn more robust representations.", "target": "The authors propose a new framework known as 'classifier decomposition' to deal with biases in the vanilla strategy. This framework involves splitting the last feedforward neural network (FFN) layer into separate previous and current classifiers, allowing the model to maintain prior knowledge and learn more robust representations.", "example": "Convert the coordinate to text: [ 8.596  -6.2161]:"}
{"text": "Convert the coordinate to text: [ 1.2519 -4.0011]: PESCO, a novel contrastive learning framework for zero-shot text classification, is introduced. Text classification is formulated as a neural text matching problem, where each document is treated as a query and enhanced with prompts for label matching, and retrieved labels are used to enrich the training set through a self-training loop of contrastive learning.", "target": "PESCO, a novel contrastive learning framework for zero-shot text classification, is introduced. Text classification is formulated as a neural text matching problem, where each document is treated as a query and enhanced with prompts for label matching, and retrieved labels are used to enrich the training set through a self-training loop of contrastive learning.", "example": "Convert the coordinate to text: [ 1.2519 -4.0011]:"}
{"text": "Convert the coordinate to text: [-4.9782 -7.7202]: The paper proposes the hypothesis that leveraging multiple sources will improve translation quality if the sources complement one another in terms of correct information they contain.", "target": "The paper proposes the hypothesis that leveraging multiple sources will improve translation quality if the sources complement one another in terms of correct information they contain.", "example": "Convert the coordinate to text: [-4.9782 -7.7202]:"}
{"text": "Convert the coordinate to text: [-11.9624   2.4302]: The authors introduce infoVerse, a universal framework for dataset characterization, which uses model-driven meta-information to provide a new feature space that effectively captures multidimensional characteristics of datasets.", "target": "The authors introduce infoVerse, a universal framework for dataset characterization, which uses model-driven meta-information to provide a new feature space that effectively captures multidimensional characteristics of datasets.", "example": "Convert the coordinate to text: [-11.9624   2.4302]:"}
{"text": "Convert the coordinate to text: [12.7982 11.4408]: The authors propose TS-DShapley, an algorithm that reduces computational cost of Shapley-based data valuation through: an efficient sampling-based method that aggregates Shapley values computed from subsets for valuation of the entire training set, and a value transfer method that leverages value information extracted from a simple classifier trained using representations from the target language model.", "target": "The authors propose TS-DShapley, an algorithm that reduces computational cost of Shapley-based data valuation through: an efficient sampling-based method that aggregates Shapley values computed from subsets for valuation of the entire training set, and a value transfer method that leverages value information extracted from a simple classifier trained using representations from the target language model.", "example": "Convert the coordinate to text: [12.7982 11.4408]:"}
{"text": "Convert the coordinate to text: [-1.2805 -5.2156]: The authors propose the use of language as an auxiliary source of supervision to improve long-horizon imitation. An instruction prediction loss is introduced to encourage the learning of temporally extended representations that operate at a high level of abstraction.", "target": "The authors propose the use of language as an auxiliary source of supervision to improve long-horizon imitation. An instruction prediction loss is introduced to encourage the learning of temporally extended representations that operate at a high level of abstraction.", "example": "Convert the coordinate to text: [-1.2805 -5.2156]:"}
{"text": "Convert the coordinate to text: [-1.4967  0.1515]: This paper describes the approaches to SemEval-2023 Task 10, Explainable Online Sexism Detection (EDOS), with the aim of identifying different classes of sexist comments online.", "target": "This paper describes the approaches to SemEval-2023 Task 10, Explainable Online Sexism Detection (EDOS), with the aim of identifying different classes of sexist comments online.", "example": "Convert the coordinate to text: [-1.4967  0.1515]:"}
{"text": "Convert the coordinate to text: [-6.1004 -0.5331]: The Intelligent Knowledge Management (IKM) Laboratory proposed to use a long-text abstractive summarization longformer model and experimented with several prompt methods to tackle this task.", "target": "The Intelligent Knowledge Management (IKM) Laboratory proposed to use a long-text abstractive summarization longformer model and experimented with several prompt methods to tackle this task.", "example": "Convert the coordinate to text: [-6.1004 -0.5331]:"}
{"text": "Convert the coordinate to text: [-1.7673 -5.375 ]: The authors propose two methods: 1) fine-tuning a pre-trained language model (DialoGPT) using reinforcement learning, and 2) providing a few-shot prompt to a large language model (GPT-3), to generate dialogue responses which include specified grammatical items.", "target": "The authors propose two methods: 1) fine-tuning a pre-trained language model (DialoGPT) using reinforcement learning, and 2) providing a few-shot prompt to a large language model (GPT-3), to generate dialogue responses which include specified grammatical items.", "example": "Convert the coordinate to text: [-1.7673 -5.375 ]:"}
{"text": "Convert the coordinate to text: [13.9598 -2.7039]: The authors propose using the connectivity patterns of neurons as a unique identifier associated with a task to construct task embeddings, inspired by the operation mechanism of deep neural networks (DNNs) and biological brains.", "target": "The authors propose using the connectivity patterns of neurons as a unique identifier associated with a task to construct task embeddings, inspired by the operation mechanism of deep neural networks (DNNs) and biological brains.", "example": "Convert the coordinate to text: [13.9598 -2.7039]:"}
{"text": "Convert the coordinate to text: [ 2.0469 -1.7244]: The authors propose a new technique called Partitioned Contrastive Gradient Unlearning (PCGU), a gray-box method for debiasing pretrained masked language models. PCGU aims to only optimize the weights that contribute most to a specific bias domain, by computing a first-order approximation based on the gradients of contrastive sentence pairs.", "target": "The authors propose a new technique called Partitioned Contrastive Gradient Unlearning (PCGU), a gray-box method for debiasing pretrained masked language models. PCGU aims to only optimize the weights that contribute most to a specific bias domain, by computing a first-order approximation based on the gradients of contrastive sentence pairs.", "example": "Convert the coordinate to text: [ 2.0469 -1.7244]:"}
{"text": "Convert the coordinate to text: [-5.4525 10.154 ]: The authors aim to build a system that performs dialogue act classification and domain-specific slot tagging. They utilised adapter models (Pfeiffer et al., 2020) which benefit from additional dialogue context and speaker information for this purpose.", "target": "The authors aim to build a system that performs dialogue act classification and domain-specific slot tagging. They utilised adapter models (Pfeiffer et al., 2020) which benefit from additional dialogue context and speaker information for this purpose.", "example": "Convert the coordinate to text: [-5.4525 10.154 ]:"}
{"text": "Convert the coordinate to text: [-0.9272 -6.9308]: In this paper, the authors study the effect of parameter size in Transformer-based language models. The authors note that larger models generate probabilistic estimates, which are less predictive for early eye-tracking measurements, but do better at capturing late eye-tracking measurements.", "target": "In this paper, the authors study the effect of parameter size in Transformer-based language models. The authors note that larger models generate probabilistic estimates, which are less predictive for early eye-tracking measurements, but do better at capturing late eye-tracking measurements.", "example": "Convert the coordinate to text: [-0.9272 -6.9308]:"}
{"text": "Convert the coordinate to text: [-5.5314 -0.9042]: A novel pretraining objective is introduced for MDS. This involves selecting the ROUGE-based centroid of each document cluster as a proxy for its summary, which does not require human-written summaries.", "target": "A novel pretraining objective is introduced for MDS. This involves selecting the ROUGE-based centroid of each document cluster as a proxy for its summary, which does not require human-written summaries.", "example": "Convert the coordinate to text: [-5.5314 -0.9042]:"}
{"text": "Convert the coordinate to text: [-0.1914 -4.5385]: The authors introduce a novel DST framework called BREAK that utilizes a two-step process: generating k-best dialogue state candidates with a beam search, and subsequently re-ranking these candidates to select the optimal dialogue state.", "target": "The authors introduce a novel DST framework called BREAK that utilizes a two-step process: generating k-best dialogue state candidates with a beam search, and subsequently re-ranking these candidates to select the optimal dialogue state.", "example": "Convert the coordinate to text: [-0.1914 -4.5385]:"}
{"text": "Convert the coordinate to text: [ 6.8853 13.6362]: The authors propose a transition from online schemes to an offline learning method for QRL, introducing the first offline QRL algorithm named CQ2L (Conservative Quantum Q-learning), which does not require real-time interaction with the environment.", "target": "The authors propose a transition from online schemes to an offline learning method for QRL, introducing the first offline QRL algorithm named CQ2L (Conservative Quantum Q-learning), which does not require real-time interaction with the environment.", "example": "Convert the coordinate to text: [ 6.8853 13.6362]:"}
{"text": "Convert the coordinate to text: [ 1.5944 -7.7949]: A new text segmentation model, SegFormer, is designed with unidirectional attention blocks for improved sentence representation. It also features an additional context aggregator and a topic classification loss to deal with noise information interference, and uses an iterative prediction algorithm to progressively find optimal boundaries.", "target": "A new text segmentation model, SegFormer, is designed with unidirectional attention blocks for improved sentence representation. It also features an additional context aggregator and a topic classification loss to deal with noise information interference, and uses an iterative prediction algorithm to progressively find optimal boundaries.", "example": "Convert the coordinate to text: [ 1.5944 -7.7949]:"}
{"text": "Convert the coordinate to text: [10.7365  7.7527]: The authors expand on the area of FCCO by exploring non-smooth weakly-convex FCCO, where the outer function is weakly convex and non-decreasing, and the inner function is weakly-convex. They also extend this concept to tri-level finite-sum coupled compositional optimization problems.", "target": "The authors expand on the area of FCCO by exploring non-smooth weakly-convex FCCO, where the outer function is weakly convex and non-decreasing, and the inner function is weakly-convex. They also extend this concept to tri-level finite-sum coupled compositional optimization problems.", "example": "Convert the coordinate to text: [10.7365  7.7527]:"}
{"text": "Convert the coordinate to text: [13.857  -7.5399]: The paper explores the new paradigm of generating gestures by continually learning new speaker styles with only a few minutes of per-speaker data, while retaining previously learnt styles. The proposed approach, C-DiffGAN, mitigates catastrophic forgetting through crossmodal alignment to reminiscences of previous low-resource speaker data.", "target": "The paper explores the new paradigm of generating gestures by continually learning new speaker styles with only a few minutes of per-speaker data, while retaining previously learnt styles. The proposed approach, C-DiffGAN, mitigates catastrophic forgetting through crossmodal alignment to reminiscences of previous low-resource speaker data.", "example": "Convert the coordinate to text: [13.857  -7.5399]:"}
{"text": "Convert the coordinate to text: [6.6452 0.6288]: The authors propose treating affinity modeling as an affinity propagation process, incorporating local and global pairwise affinity elements to generate precise pseudo labels. In addition, they develop an efficient algorithm to significantly reduce computational cost.", "target": "The authors propose treating affinity modeling as an affinity propagation process, incorporating local and global pairwise affinity elements to generate precise pseudo labels. In addition, they develop an efficient algorithm to significantly reduce computational cost.", "example": "Convert the coordinate to text: [6.6452 0.6288]:"}
{"text": "Convert the coordinate to text: [6.8642 7.4916]: The authors propose a solution that involves generating a private sketch that maintains differential privacy while allowing for approximate answers to linear queries and optimization problems over joins. The unique feature of their method is its non-interactivity which allows the sketch to be published to a repository for anyone to join with.", "target": "The authors propose a solution that involves generating a private sketch that maintains differential privacy while allowing for approximate answers to linear queries and optimization problems over joins. The unique feature of their method is its non-interactivity which allows the sketch to be published to a repository for anyone to join with.", "example": "Convert the coordinate to text: [6.8642 7.4916]:"}
{"text": "Convert the coordinate to text: [ 0.8545 -9.6411]: The paper introduces visual-textual knowledge graphs (VTKGs), wherein both the entities and the triplets can be depicted using images, and the entities and relations can have associated text descriptions. Additionally, the authors describe their creation of a new benchmark dataset showcasing commonsense knowledge that can be visually expressed.", "target": "The paper introduces visual-textual knowledge graphs (VTKGs), wherein both the entities and the triplets can be depicted using images, and the entities and relations can have associated text descriptions. Additionally, the authors describe their creation of a new benchmark dataset showcasing commonsense knowledge that can be visually expressed.", "example": "Convert the coordinate to text: [ 0.8545 -9.6411]:"}
{"text": "Convert the coordinate to text: [-2.1431  5.041 ]: New emerging solutions are suggested, including self-supervised learning methods, deep learning algorithms, network/graph-based solutions as well as linguistic approaches to tackle the numerous challenges in the finance industry.", "target": "New emerging solutions are suggested, including self-supervised learning methods, deep learning algorithms, network/graph-based solutions as well as linguistic approaches to tackle the numerous challenges in the finance industry.", "example": "Convert the coordinate to text: [-2.1431  5.041 ]:"}
{"text": "Convert the coordinate to text: [10.9753 -5.8934]: The authors propose the Fine-purifying approach which uses diffusion theory to examine the dynamic process of fine-tuning in order to locate potentially poisonous dimensions.", "target": "The authors propose the Fine-purifying approach which uses diffusion theory to examine the dynamic process of fine-tuning in order to locate potentially poisonous dimensions.", "example": "Convert the coordinate to text: [10.9753 -5.8934]:"}
{"text": "Convert the coordinate to text: [8.2988 5.5956]: The authors study the adversarial robustness of amortized Bayesian inference, focusing on simulation-based estimation of multi-dimensional posterior distributions, and propose a regularization scheme based on penalizing the Fisher information of the conditional density estimator.", "target": "The authors study the adversarial robustness of amortized Bayesian inference, focusing on simulation-based estimation of multi-dimensional posterior distributions, and propose a regularization scheme based on penalizing the Fisher information of the conditional density estimator.", "example": "Convert the coordinate to text: [8.2988 5.5956]:"}
{"text": "Convert the coordinate to text: [-5.3088 -0.5071]: To overcome these limitations, the authors propose the Unified Multi-scenario Summarization Evaluation Model (UMSE). This innovative framework uses a perturbed prefix tuning method to share knowledge between scenarios, and a self-supervised training paradigm to optimize the model without need for extra human labeling.", "target": "To overcome these limitations, the authors propose the Unified Multi-scenario Summarization Evaluation Model (UMSE). This innovative framework uses a perturbed prefix tuning method to share knowledge between scenarios, and a self-supervised training paradigm to optimize the model without need for extra human labeling.", "example": "Convert the coordinate to text: [-5.3088 -0.5071]:"}
{"text": "Convert the coordinate to text: [-2.8313  9.9319]: The authors propose the use of intuitive language-based abstractions from large pre-trained language models (PLMs) for analogical reasoning in AI systems, specifically for the visual Raven's Progressive Matrices (RPM), a common relational reasoning test.", "target": "The authors propose the use of intuitive language-based abstractions from large pre-trained language models (PLMs) for analogical reasoning in AI systems, specifically for the visual Raven's Progressive Matrices (RPM), a common relational reasoning test.", "example": "Convert the coordinate to text: [-2.8313  9.9319]:"}
{"text": "Convert the coordinate to text: [ 1.1448 -9.936 ]: The authors present a large-scale video subtitle translation dataset called BigVideo, which is over 10 times larger than existing datasets. They also propose two test sets designed to verify the necessity of visual information, and a contrastive learning method in the cross-modal encoder to model the common semantics across texts and videos.", "target": "The authors present a large-scale video subtitle translation dataset called BigVideo, which is over 10 times larger than existing datasets. They also propose two test sets designed to verify the necessity of visual information, and a contrastive learning method in the cross-modal encoder to model the common semantics across texts and videos.", "example": "Convert the coordinate to text: [ 1.1448 -9.936 ]:"}
{"text": "Convert the coordinate to text: [-1.5979 -6.278 ]: This research explores the use of transformers and language models in prognostic prediction for immunotherapy using real-world patients\u2019 clinical data and molecular profiles, also addressing the challenge of few-shot learning in predicting rare disease areas.", "target": "This research explores the use of transformers and language models in prognostic prediction for immunotherapy using real-world patients\u2019 clinical data and molecular profiles, also addressing the challenge of few-shot learning in predicting rare disease areas.", "example": "Convert the coordinate to text: [-1.5979 -6.278 ]:"}
{"text": "Convert the coordinate to text: [-2.7033  0.18  ]: The authors propose an individualised approach to text classification for the Semeval-2023 Task 11, where disagreements are treated as a useful source of information that could be utilised in the training pipeline. This approach uses partially disaggregated data and additional information about annotators to train a BERT-based model for offensive text classification.", "target": "The authors propose an individualised approach to text classification for the Semeval-2023 Task 11, where disagreements are treated as a useful source of information that could be utilised in the training pipeline. This approach uses partially disaggregated data and additional information about annotators to train a BERT-based model for offensive text classification.", "example": "Convert the coordinate to text: [-2.7033  0.18  ]:"}
{"text": "Convert the coordinate to text: [-1.3604  0.0554]: The author proposes to use BERT and RoBERTa transformer models, fine-tuned on the EDOS dataset to classify text into different categories of sexism in three different subtasks: i) Determining if a text is sexist or not, ii) Identifying the specific category of sexism, and iii) Predicting a fine-grained vector representation of sexism.", "target": "The author proposes to use BERT and RoBERTa transformer models, fine-tuned on the EDOS dataset to classify text into different categories of sexism in three different subtasks: i) Determining if a text is sexist or not, ii) Identifying the specific category of sexism, and iii) Predicting a fine-grained vector representation of sexism.", "example": "Convert the coordinate to text: [-1.3604  0.0554]:"}
{"text": "Convert the coordinate to text: [ -0.6678 -11.9502]: This study introduces additional signals into the training of GEC models and utilizes a non-autoregressive model as an auxiliary model. A new regularization term is developed to consider the difference in predictions between autoregressive and non-autoregressive models.", "target": "This study introduces additional signals into the training of GEC models and utilizes a non-autoregressive model as an auxiliary model. A new regularization term is developed to consider the difference in predictions between autoregressive and non-autoregressive models.", "example": "Convert the coordinate to text: [ -0.6678 -11.9502]:"}
{"text": "Convert the coordinate to text: [-13.9163  -1.3939]: The authors explore the feasibility of applying recent model compression techniques to sketch-based and sequence-to-sequence Text-to-SQL models.", "target": "The authors explore the feasibility of applying recent model compression techniques to sketch-based and sequence-to-sequence Text-to-SQL models.", "example": "Convert the coordinate to text: [-13.9163  -1.3939]:"}
{"text": "Convert the coordinate to text: [-9.777  -5.2278]: The authors introduce a benchmark called WebDP to facilitate a new task: Web Document Discourse Parsing. A web document discourse structure representation schema is proposed by extending classical discourse theories and adding special features to represent discourse characteristics of web documents.", "target": "The authors introduce a benchmark called WebDP to facilitate a new task: Web Document Discourse Parsing. A web document discourse structure representation schema is proposed by extending classical discourse theories and adding special features to represent discourse characteristics of web documents.", "example": "Convert the coordinate to text: [-9.777  -5.2278]:"}
{"text": "Convert the coordinate to text: [-3.7452 -2.6975]: This work proposes to make use of medical knowledge graphs to extract entities and relations from Chinese Medical Texts collectively. It involves the construction of a high-order heterogeneous graph based on the medical knowledge graph, that is linked to the entity mentions in the text.", "target": "This work proposes to make use of medical knowledge graphs to extract entities and relations from Chinese Medical Texts collectively. It involves the construction of a high-order heterogeneous graph based on the medical knowledge graph, that is linked to the entity mentions in the text.", "example": "Convert the coordinate to text: [-3.7452 -2.6975]:"}
{"text": "Convert the coordinate to text: [-1.7137 -5.0092]: The authors propose to leverage large language models for dialogue augmentation in the task of emotional support conversation (ESC). The dialogue augmentation is treated as a dialogue completion task, prompting a fine-tuned language model to complete full dialogues from available dialogue posts of various topics.", "target": "The authors propose to leverage large language models for dialogue augmentation in the task of emotional support conversation (ESC). The dialogue augmentation is treated as a dialogue completion task, prompting a fine-tuned language model to complete full dialogues from available dialogue posts of various topics.", "example": "Convert the coordinate to text: [-1.7137 -5.0092]:"}
{"text": "Convert the coordinate to text: [-3.9542 -2.4089]: The authors propose a framework to analyze sections of clinical notes with high predictive power in the context of a limited-length language model predictor.", "target": "The authors propose a framework to analyze sections of clinical notes with high predictive power in the context of a limited-length language model predictor.", "example": "Convert the coordinate to text: [-3.9542 -2.4089]:"}
{"text": "Convert the coordinate to text: [-5.7824 -0.8498]: The authors present CrossSum, which they claim to be the largest cross-lingual summarization dataset with 1.68 million article-summary samples over 1,500+ languages. They also devise LaSE, a novel embedding-based metric for evaluating model-generated summaries.", "target": "The authors present CrossSum, which they claim to be the largest cross-lingual summarization dataset with 1.68 million article-summary samples over 1,500+ languages. They also devise LaSE, a novel embedding-based metric for evaluating model-generated summaries.", "example": "Convert the coordinate to text: [-5.7824 -0.8498]:"}
{"text": "Convert the coordinate to text: [13.3753 -4.6414]: The authors propose the adaptability hypothesis to understand when and why a backdoor attack works for general learning models, including deep neural networks. The hypothesis suggests that for an effective attack, the effect of incorporating a new dataset on the predictions of the original data points should be minimal, given that the original data points are distanced from the new dataset.", "target": "The authors propose the adaptability hypothesis to understand when and why a backdoor attack works for general learning models, including deep neural networks. The hypothesis suggests that for an effective attack, the effect of incorporating a new dataset on the predictions of the original data points should be minimal, given that the original data points are distanced from the new dataset.", "example": "Convert the coordinate to text: [13.3753 -4.6414]:"}
{"text": "Convert the coordinate to text: [  9.3084 -14.3483]: This study proposes to leverage the inevitable uncertainty in unsupervised multi-object tracking to improve learned consistency. It introduces an uncertainty-based metric to verify and rectify risky associations, and a tracklet-guided augmentation strategy that simulates tracklets' motion using a hierarchical uncertainty-based sampling mechanism.", "target": "This study proposes to leverage the inevitable uncertainty in unsupervised multi-object tracking to improve learned consistency. It introduces an uncertainty-based metric to verify and rectify risky associations, and a tracklet-guided augmentation strategy that simulates tracklets' motion using a hierarchical uncertainty-based sampling mechanism.", "example": "Convert the coordinate to text: [  9.3084 -14.3483]:"}
{"text": "Convert the coordinate to text: [4.1133 7.6178]: The authors propose a practical, universal method for randomizing paper assignment that aspires to perform adequately across different motivations for randomness.", "target": "The authors propose a practical, universal method for randomizing paper assignment that aspires to perform adequately across different motivations for randomness.", "example": "Convert the coordinate to text: [4.1133 7.6178]:"}
{"text": "Convert the coordinate to text: [ 11.8961 -10.8431]: The authors propose a pose-garment keypoints guided inpainting method for the image-based virtual try-on task that produces high-fidelity try-on images and well preserves the garment's shapes and patterns.", "target": "The authors propose a pose-garment keypoints guided inpainting method for the image-based virtual try-on task that produces high-fidelity try-on images and well preserves the garment's shapes and patterns.", "example": "Convert the coordinate to text: [ 11.8961 -10.8431]:"}
{"text": "Convert the coordinate to text: [13.1511 -8.6755]: The paper proposes DeformToon3d, a toonification framework tailored for hierarchical 3D GAN that overcomes the limitations of the existing approaches. The framework decomposes 3D toonification into subproblems of geometry and texture stylization to preserve the original latent space, and utilizes a StyleField that predicts conditional 3D deformation for geometry stylization.", "target": "The paper proposes DeformToon3d, a toonification framework tailored for hierarchical 3D GAN that overcomes the limitations of the existing approaches. The framework decomposes 3D toonification into subproblems of geometry and texture stylization to preserve the original latent space, and utilizes a StyleField that predicts conditional 3D deformation for geometry stylization.", "example": "Convert the coordinate to text: [13.1511 -8.6755]:"}
{"text": "Convert the coordinate to text: [  6.2009 -11.8127]: The authors propose a method of non-uniformly resizing the cropped image to make the target area, where the entity is more likely to appear, have higher resolution while surrounding areas have lower resolution in order to achieve high-speed and high-accuracy tracking.", "target": "The authors propose a method of non-uniformly resizing the cropped image to make the target area, where the entity is more likely to appear, have higher resolution while surrounding areas have lower resolution in order to achieve high-speed and high-accuracy tracking.", "example": "Convert the coordinate to text: [  6.2009 -11.8127]:"}
{"text": "Convert the coordinate to text: [ 5.8076 -5.8822]: The authors propose a new method known as G-triple-correlation (G-TC) layer, a novel approach that applies the theory of the triple-correlation on groups to achieve robust group-invariance in G-CNNs. This method yields unique, low-degree polynomial invariant maps that are also complete, removing only variations due to the actions of the group but preserving the signal structure.", "target": "The authors propose a new method known as G-triple-correlation (G-TC) layer, a novel approach that applies the theory of the triple-correlation on groups to achieve robust group-invariance in G-CNNs. This method yields unique, low-degree polynomial invariant maps that are also complete, removing only variations due to the actions of the group but preserving the signal structure.", "example": "Convert the coordinate to text: [ 5.8076 -5.8822]:"}
{"text": "Convert the coordinate to text: [-0.8063 -4.0772]: This paper introduces a new task, Multi-Lingual Commonsense Knowledge-Aware Response Generation (MCKRG), aiming to utilize commonsense knowledge from various languages to enhance dialogue generation, and proposes the MCK-T5 model.", "target": "This paper introduces a new task, Multi-Lingual Commonsense Knowledge-Aware Response Generation (MCKRG), aiming to utilize commonsense knowledge from various languages to enhance dialogue generation, and proposes the MCK-T5 model.", "example": "Convert the coordinate to text: [-0.8063 -4.0772]:"}
{"text": "Convert the coordinate to text: [ 5.5914 -0.7236]: To address the issue of label skew in one-shot FL, the authors propose a new method called FedOV. This approach generates diverse outliers and introduces them as an additional unknown class in local training to improve the voting performance.", "target": "To address the issue of label skew in one-shot FL, the authors propose a new method called FedOV. This approach generates diverse outliers and introduces them as an additional unknown class in local training to improve the voting performance.", "example": "Convert the coordinate to text: [ 5.5914 -0.7236]:"}
{"text": "Convert the coordinate to text: [-2.9736  3.8598]: The authors propose a novel method, the Identifiable Deconfounder (iDCF), which uses a set of proxy variables (observed user features) to address non-identification issues associated with latent confounders in recommendation systems.", "target": "The authors propose a novel method, the Identifiable Deconfounder (iDCF), which uses a set of proxy variables (observed user features) to address non-identification issues associated with latent confounders in recommendation systems.", "example": "Convert the coordinate to text: [-2.9736  3.8598]:"}
{"text": "Convert the coordinate to text: [-2.1213 -5.4903]: The researchers seek to empirically analyze the zero-shot learning ability of ChatGPT by evaluating it on multiple NLP datasets covering several representative task categories.", "target": "The researchers seek to empirically analyze the zero-shot learning ability of ChatGPT by evaluating it on multiple NLP datasets covering several representative task categories.", "example": "Convert the coordinate to text: [-2.1213 -5.4903]:"}
{"text": "Convert the coordinate to text: [ -0.1387 -10.5264]: The authors introduce the task of Open-domain Visual Entity recognitioN (OVEN) and construct the OVEN-Wiki dataset by repurposing 14 existing datasets with all labels grounded onto one single label space: Wikipedia entities.", "target": "The authors introduce the task of Open-domain Visual Entity recognitioN (OVEN) and construct the OVEN-Wiki dataset by repurposing 14 existing datasets with all labels grounded onto one single label space: Wikipedia entities.", "example": "Convert the coordinate to text: [ -0.1387 -10.5264]:"}
{"text": "Convert the coordinate to text: [ 4.3235 -3.2082]: The authors present the first attempt at cold-start calibration for KGC determined by ACTC, which finds efficient per-relation thresholds based on a limited set of annotated tuples and no initial annotated examples for calibration.", "target": "The authors present the first attempt at cold-start calibration for KGC determined by ACTC, which finds efficient per-relation thresholds based on a limited set of annotated tuples and no initial annotated examples for calibration.", "example": "Convert the coordinate to text: [ 4.3235 -3.2082]:"}
{"text": "Convert the coordinate to text: [-1.0683 -6.6221]: The authors propose a bidirectional Transformer reranker (BTR) that re-estimates the probability of each candidate sentence generated by the pre-trained seq2seq model. The BTR adopts negative sampling in the objective function to minimize the unlikelihood.", "target": "The authors propose a bidirectional Transformer reranker (BTR) that re-estimates the probability of each candidate sentence generated by the pre-trained seq2seq model. The BTR adopts negative sampling in the objective function to minimize the unlikelihood.", "example": "Convert the coordinate to text: [-1.0683 -6.6221]:"}
{"text": "Convert the coordinate to text: [-5.5548  0.9708]: The paper operationalizes the concept of appropriate language in argumentation for the first time, modeling appropriateness through the absence of flaws, especially those grounded in rhetoric. This leads to a new taxonomy of 14 dimensions determining inappropriate language in online discussions.", "target": "The paper operationalizes the concept of appropriate language in argumentation for the first time, modeling appropriateness through the absence of flaws, especially those grounded in rhetoric. This leads to a new taxonomy of 14 dimensions determining inappropriate language in online discussions.", "example": "Convert the coordinate to text: [-5.5548  0.9708]:"}
{"text": "Convert the coordinate to text: [-2.2548 -6.2737]: The authors propose two pre-training strategies, Implicit and Explicit pre-training, that aim to improve the ability of pre-trained language models to generalize to both seen and unseen data across varying aspects and domains.", "target": "The authors propose two pre-training strategies, Implicit and Explicit pre-training, that aim to improve the ability of pre-trained language models to generalize to both seen and unseen data across varying aspects and domains.", "example": "Convert the coordinate to text: [-2.2548 -6.2737]:"}
{"text": "Convert the coordinate to text: [ 1.7678 -4.2488]: The authors propose CHRT (Control Hidden Representation Transformation), a framework that gains attribute control by modifying the hidden representation of the base model through learned transformations, using a contrastive-learning framework for this purpose.", "target": "The authors propose CHRT (Control Hidden Representation Transformation), a framework that gains attribute control by modifying the hidden representation of the base model through learned transformations, using a contrastive-learning framework for this purpose.", "example": "Convert the coordinate to text: [ 1.7678 -4.2488]:"}
{"text": "Convert the coordinate to text: [ 4.7949 -5.1839]: This study introduces a new problem of classifying edge-dependent node labels in hypergraphs. A novel hypergraph neural network, WHATsNet, is proposed to tackle this problem, differing node representation based on the hyperedges it participates in and the varying importance in those hyperedges.", "target": "This study introduces a new problem of classifying edge-dependent node labels in hypergraphs. A novel hypergraph neural network, WHATsNet, is proposed to tackle this problem, differing node representation based on the hyperedges it participates in and the varying importance in those hyperedges.", "example": "Convert the coordinate to text: [ 4.7949 -5.1839]:"}
{"text": "Convert the coordinate to text: [-2.1904 -5.0077]: The researchers propose that PLMs already possess the knowledge to address such tricky questions and focus on finding ways to activate this knowledge. They specifically investigate the models' ability to respond to false premises questions (FPQs).", "target": "The researchers propose that PLMs already possess the knowledge to address such tricky questions and focus on finding ways to activate this knowledge. They specifically investigate the models' ability to respond to false premises questions (FPQs).", "example": "Convert the coordinate to text: [-2.1904 -5.0077]:"}
{"text": "Convert the coordinate to text: [2.3494 0.2733]: Authors propose Counterfactual Active Learning (CounterAL), a method that combines active learning with counterfactual thinking to bridge the gap between seen samples and unseen cases. CounterAL not only requires annotating normal samples but also answering counterfactual questions to construct training data.", "target": "Authors propose Counterfactual Active Learning (CounterAL), a method that combines active learning with counterfactual thinking to bridge the gap between seen samples and unseen cases. CounterAL not only requires annotating normal samples but also answering counterfactual questions to construct training data.", "example": "Convert the coordinate to text: [2.3494 0.2733]:"}
{"text": "Convert the coordinate to text: [-1.821  -6.2893]: The paper proposes a LEGAL-BERT based hierarchical BiLSTM model with a conditional random field (CRF) for RR prediction. The model primarily comprises of word-level and sentence-level encoders.", "target": "The paper proposes a LEGAL-BERT based hierarchical BiLSTM model with a conditional random field (CRF) for RR prediction. The model primarily comprises of word-level and sentence-level encoders.", "example": "Convert the coordinate to text: [-1.821  -6.2893]:"}
{"text": "Convert the coordinate to text: [-3.0769 -6.709 ]: The team NLUBot101 proposed a cross-lingual data augmentation approach and leveraged a recently proposed multilingual natural language inference model to tackle the task of persuasion technique detection in online news articles at the paragraph level.", "target": "The team NLUBot101 proposed a cross-lingual data augmentation approach and leveraged a recently proposed multilingual natural language inference model to tackle the task of persuasion technique detection in online news articles at the paragraph level.", "example": "Convert the coordinate to text: [-3.0769 -6.709 ]:"}
{"text": "Convert the coordinate to text: [-2.0366 -6.4888]: The authors opt for using a pre-trained model, RoBERTa, to perform sequence and token classification for multi-label classification of class labels in online news articles.", "target": "The authors opt for using a pre-trained model, RoBERTa, to perform sequence and token classification for multi-label classification of class labels in online news articles.", "example": "Convert the coordinate to text: [-2.0366 -6.4888]:"}
{"text": "Convert the coordinate to text: [-1.773  -7.9464]: The authors propose a novel online policy for attentional encoder-decoder models, which prevents the model from generating translations beyond the current speech input using an auxiliary CTC output layer.", "target": "The authors propose a novel online policy for attentional encoder-decoder models, which prevents the model from generating translations beyond the current speech input using an auxiliary CTC output layer.", "example": "Convert the coordinate to text: [-1.773  -7.9464]:"}
{"text": "Convert the coordinate to text: [-2.3796 -4.8943]: The paper proposes a novel Entity-to-Text based data augmentation technique called EnTDA, which can add, delete, replace, or swap entities in the entity list of original texts to generate semantically coherent and entity-preserving texts for a variety of NER tasks.", "target": "The paper proposes a novel Entity-to-Text based data augmentation technique called EnTDA, which can add, delete, replace, or swap entities in the entity list of original texts to generate semantically coherent and entity-preserving texts for a variety of NER tasks.", "example": "Convert the coordinate to text: [-2.3796 -4.8943]:"}
{"text": "Convert the coordinate to text: [-0.587   3.5941]: A new framework, ItCAREToE, is proposed which overcomes this limitation by modeling relations between nodes using relation-specific, stochastic transitions based on stochastic ItCARETo processes operating on low-dimensional manifolds.", "target": "A new framework, ItCAREToE, is proposed which overcomes this limitation by modeling relations between nodes using relation-specific, stochastic transitions based on stochastic ItCARETo processes operating on low-dimensional manifolds.", "example": "Convert the coordinate to text: [-0.587   3.5941]:"}
{"text": "Convert the coordinate to text: [-6.8464 -1.3371]: The authors propose a paradigm shift by modeling the unsupervised keyphrase extraction task from a set-wise perspective, where the document and the candidate set are globally matched in the semantic space to account for interactions among all candidate phrases.", "target": "The authors propose a paradigm shift by modeling the unsupervised keyphrase extraction task from a set-wise perspective, where the document and the candidate set are globally matched in the semantic space to account for interactions among all candidate phrases.", "example": "Convert the coordinate to text: [-6.8464 -1.3371]:"}
{"text": "Convert the coordinate to text: [-3.3533 15.7094]: This paper presents NavTL, a learning-based framework designed to control traffic signals and reroute autonomous vehicles in mixed traffic scenarios. This framework is designed to improve travel efficiency and reduce total travel time by minimizing intersection congestion and guiding autonomous vehicles to avoid temporarily congested roads.", "target": "This paper presents NavTL, a learning-based framework designed to control traffic signals and reroute autonomous vehicles in mixed traffic scenarios. This framework is designed to improve travel efficiency and reduce total travel time by minimizing intersection congestion and guiding autonomous vehicles to avoid temporarily congested roads.", "example": "Convert the coordinate to text: [-3.3533 15.7094]:"}
{"text": "Convert the coordinate to text: [ 1.3082 -9.8844]: The authors propose a framework for making each neuron in a vision network interpretable through the generation of textual descriptions of their functionality. This is achieved through leveraging recent advances in multimodal vision-text models and introducing stochastic local competition between linear units in network layers.", "target": "The authors propose a framework for making each neuron in a vision network interpretable through the generation of textual descriptions of their functionality. This is achieved through leveraging recent advances in multimodal vision-text models and introducing stochastic local competition between linear units in network layers.", "example": "Convert the coordinate to text: [ 1.3082 -9.8844]:"}
{"text": "Convert the coordinate to text: [-0.9227 -5.2505]: The authors propose Domain-Adaptive Prompt (DAP), a pool-free approach that generates a suitable prompt in an instance-level manner at inference time. The goal of DAP is to create instance-specific fine-grained instructions required for each input, thereby enabling enhanced model plasticity and reduced forgetting.", "target": "The authors propose Domain-Adaptive Prompt (DAP), a pool-free approach that generates a suitable prompt in an instance-level manner at inference time. The goal of DAP is to create instance-specific fine-grained instructions required for each input, thereby enabling enhanced model plasticity and reduced forgetting.", "example": "Convert the coordinate to text: [-0.9227 -5.2505]:"}
{"text": "Convert the coordinate to text: [  3.6964 -15.7208]: This study presents CO-PILOT, a dynamic and hierarchical point-cloud-based method for processing cellular graphs from histopathology images. The approach uses bottom-up information propagation and top-down conditional attention to give an adaptive focus across different levels of tissue hierarchy.", "target": "This study presents CO-PILOT, a dynamic and hierarchical point-cloud-based method for processing cellular graphs from histopathology images. The approach uses bottom-up information propagation and top-down conditional attention to give an adaptive focus across different levels of tissue hierarchy.", "example": "Convert the coordinate to text: [  3.6964 -15.7208]:"}
{"text": "Convert the coordinate to text: [8.6634 7.2154]: Incremental Minimax Risk Classifiers (IMRCs) are introduced in this study, that effectively exploit forward and backward learning and account for evolving tasks.", "target": "Incremental Minimax Risk Classifiers (IMRCs) are introduced in this study, that effectively exploit forward and backward learning and account for evolving tasks.", "example": "Convert the coordinate to text: [8.6634 7.2154]:"}
{"text": "Convert the coordinate to text: [ 1.6463 -6.9117]: The authors propose a solution to reduce the modality gap by learning the vision proxy directly from unlabeled target vision data with help from the text proxy for zero-shot transfer. Additionally, they develop strategies to refine the pseudo label obtained by the text proxy through a method called intra-modal proxy learning (InMaP).", "target": "The authors propose a solution to reduce the modality gap by learning the vision proxy directly from unlabeled target vision data with help from the text proxy for zero-shot transfer. Additionally, they develop strategies to refine the pseudo label obtained by the text proxy through a method called intra-modal proxy learning (InMaP).", "example": "Convert the coordinate to text: [ 1.6463 -6.9117]:"}
{"text": "Convert the coordinate to text: [11.0649 -1.526 ]: This work posits that biases are inherent to the neural network architectures themselves, necessitating a rethinking of bias mitigation strategies.", "target": "This work posits that biases are inherent to the neural network architectures themselves, necessitating a rethinking of bias mitigation strategies.", "example": "Convert the coordinate to text: [11.0649 -1.526 ]:"}
{"text": "Convert the coordinate to text: [ 6.5153 13.3502]: The authors propose a new RL algorithm, Contrastive Retrospection (ConSpec), which uses offline contrastive learning to focus on these critical steps. ConSpec, applicable with any existing RL algorithm, learns a set of prototypes for the critical steps with a novel contrastive loss and delivers an intrinsic reward when the current state matches one of the prototypes.", "target": "The authors propose a new RL algorithm, Contrastive Retrospection (ConSpec), which uses offline contrastive learning to focus on these critical steps. ConSpec, applicable with any existing RL algorithm, learns a set of prototypes for the critical steps with a novel contrastive loss and delivers an intrinsic reward when the current state matches one of the prototypes.", "example": "Convert the coordinate to text: [ 6.5153 13.3502]:"}
{"text": "Convert the coordinate to text: [10.2399 -3.9199]: The authors propose a gradient-based gradual pruning technique for MNMT which aims to identify an optimal subnetwork for each language pair within the multilingual model by using gradient information as a pruning criterion and gradually increasing the pruning ratio.", "target": "The authors propose a gradient-based gradual pruning technique for MNMT which aims to identify an optimal subnetwork for each language pair within the multilingual model by using gradient information as a pruning criterion and gradually increasing the pruning ratio.", "example": "Convert the coordinate to text: [10.2399 -3.9199]:"}
{"text": "Convert the coordinate to text: [12.7141  7.3959]: The authors propose a Byzantine-resilient local SGD algorithm, which includes an efficient high-dimensional robust mean estimation algorithm used at the server to filter out corrupt vectors.", "target": "The authors propose a Byzantine-resilient local SGD algorithm, which includes an efficient high-dimensional robust mean estimation algorithm used at the server to filter out corrupt vectors.", "example": "Convert the coordinate to text: [12.7141  7.3959]:"}
{"text": "Convert the coordinate to text: [-16.8096   5.2431]: The authors propose the use of blockchain to create new types of value exchange and governance in the food system and explore the concept of a thriving multispecies food commons.", "target": "The authors propose the use of blockchain to create new types of value exchange and governance in the food system and explore the concept of a thriving multispecies food commons.", "example": "Convert the coordinate to text: [-16.8096   5.2431]:"}
{"text": "Convert the coordinate to text: [11.7234  3.3443]: The authors present a novel matrix computational framework named RPSP (Random Probing based submatrix Propagation) that offers a solution for both LCV and LLR problems in MLLRR by detecting local low rank patterns from small submatrices identifiable by random projection.", "target": "The authors present a novel matrix computational framework named RPSP (Random Probing based submatrix Propagation) that offers a solution for both LCV and LLR problems in MLLRR by detecting local low rank patterns from small submatrices identifiable by random projection.", "example": "Convert the coordinate to text: [11.7234  3.3443]:"}
{"text": "Convert the coordinate to text: [-2.763  -6.8452]: The authors propose an ensemble solution based on the XLM-T, a multilingual RoBERTa model adapted for the Twitter domain. Additionally, they enhance the performance of unseen languages by supplementing each tweet with its English translation.", "target": "The authors propose an ensemble solution based on the XLM-T, a multilingual RoBERTa model adapted for the Twitter domain. Additionally, they enhance the performance of unseen languages by supplementing each tweet with its English translation.", "example": "Convert the coordinate to text: [-2.763  -6.8452]:"}
{"text": "Convert the coordinate to text: [13.0599 -6.7122]: NetGuard, a novel method to protect against model inversion attacks, is introduced; this method misleads attackers by inserting fake samples, created by a generative adversarial network (GAN), during the training process, thus preserving the performance of the victim model.", "target": "NetGuard, a novel method to protect against model inversion attacks, is introduced; this method misleads attackers by inserting fake samples, created by a generative adversarial network (GAN), during the training process, thus preserving the performance of the victim model.", "example": "Convert the coordinate to text: [13.0599 -6.7122]:"}
{"text": "Convert the coordinate to text: [-0.107  -9.1283]: The study proposes to better understand and quantify progress in the direction of fine-grained vision-and-language understanding, by investigating four competitive V&L models on four fine-grained benchmarks.", "target": "The study proposes to better understand and quantify progress in the direction of fine-grained vision-and-language understanding, by investigating four competitive V&L models on four fine-grained benchmarks.", "example": "Convert the coordinate to text: [-0.107  -9.1283]:"}
{"text": "Convert the coordinate to text: [-5.4221 -0.2864]: The authors propose a novel training method, which re-ranks candidate summaries by balancing both lexical and semantic quality, and includes a new definition of false positives in ranking along with a strategy to reduce their influence.", "target": "The authors propose a novel training method, which re-ranks candidate summaries by balancing both lexical and semantic quality, and includes a new definition of false positives in ranking along with a strategy to reduce their influence.", "example": "Convert the coordinate to text: [-5.4221 -0.2864]:"}
{"text": "Convert the coordinate to text: [-0.588  -4.8567]: To uncover how models use instructions during IT, the study compares training with original instructions to training with altered instructions (simplified task definitions or delusive examples). The authors also introduce a random baseline to perform zero-shot classification tasks.", "target": "To uncover how models use instructions during IT, the study compares training with original instructions to training with altered instructions (simplified task definitions or delusive examples). The authors also introduce a random baseline to perform zero-shot classification tasks.", "example": "Convert the coordinate to text: [-0.588  -4.8567]:"}
{"text": "Convert the coordinate to text: [-4.6804 -7.572 ]: This study revisits the importance of the MT component in cross-lingual classification, arguing that by using a stronger MT system and mitigating the mismatch between training on original text and running inference on machine translated text, the translate-test can provide better results than previously assumed.", "target": "This study revisits the importance of the MT component in cross-lingual classification, arguing that by using a stronger MT system and mitigating the mismatch between training on original text and running inference on machine translated text, the translate-test can provide better results than previously assumed.", "example": "Convert the coordinate to text: [-4.6804 -7.572 ]:"}
{"text": "Convert the coordinate to text: [ 9.8111 11.2896]: The authors introduce LibAUC, a deep learning library specifically designed for optimizing X-risks. The library uses a new mini-batch based pipeline for implementing deep X-risk optimization algorithms, which distinguishes it from existing deep learning pipelines through its controlled data samplers and dynamic mini-batch losses.", "target": "The authors introduce LibAUC, a deep learning library specifically designed for optimizing X-risks. The library uses a new mini-batch based pipeline for implementing deep X-risk optimization algorithms, which distinguishes it from existing deep learning pipelines through its controlled data samplers and dynamic mini-batch losses.", "example": "Convert the coordinate to text: [ 9.8111 11.2896]:"}
{"text": "Convert the coordinate to text: [-7.8617  9.4169]: This work aims to develop a theoretically grounded annotation framework that encompasses both counselors' strategies and client reaction behaviors, addressing the gap in analysis of client reactions in online mental health counseling.", "target": "This work aims to develop a theoretically grounded annotation framework that encompasses both counselors' strategies and client reaction behaviors, addressing the gap in analysis of client reactions in online mental health counseling.", "example": "Convert the coordinate to text: [-7.8617  9.4169]:"}
{"text": "Convert the coordinate to text: [-5.5411  0.9773]: The SemEval-2023 task 3 is introduced which involves three subtasks: determining the genre of news articles, identifying one or more frames used in a news article from a set of 14 generic frames, and identifying the persuasion techniques used in each paragraph of a news article using a taxonomy of 23 persuasion techniques. The task is applied on news articles in nine different languages.", "target": "The SemEval-2023 task 3 is introduced which involves three subtasks: determining the genre of news articles, identifying one or more frames used in a news article from a set of 14 generic frames, and identifying the persuasion techniques used in each paragraph of a news article using a taxonomy of 23 persuasion techniques. The task is applied on news articles in nine different languages.", "example": "Convert the coordinate to text: [-5.5411  0.9773]:"}
{"text": "Convert the coordinate to text: [-3.188  -4.3365]: The authors present the task of correcting named entity recognition errors without re-training the model. They propose a method called type enhanced BERT (TyBERT), that integrates entity types information into BERT via an adapter layer. The errors are corrected by updating a gazetteer containing named entities and their possible entity types.", "target": "The authors present the task of correcting named entity recognition errors without re-training the model. They propose a method called type enhanced BERT (TyBERT), that integrates entity types information into BERT via an adapter layer. The errors are corrected by updating a gazetteer containing named entities and their possible entity types.", "example": "Convert the coordinate to text: [-3.188  -4.3365]:"}
{"text": "Convert the coordinate to text: [-1.3788 -4.9825]: The authors propose a novel prompt-based approach for EAE that introduces 'soft prompts' to encode individual example context and information from multiple relevant documents to enhance EAE.", "target": "The authors propose a novel prompt-based approach for EAE that introduces 'soft prompts' to encode individual example context and information from multiple relevant documents to enhance EAE.", "example": "Convert the coordinate to text: [-1.3788 -4.9825]:"}
{"text": "Convert the coordinate to text: [-0.5609 -6.1261]: The authors propose the application of external knowledge to improve model accuracy in low-resource and low-compute settings, with the introduction of knowledge-enhanced encoders within seq2seq models.", "target": "The authors propose the application of external knowledge to improve model accuracy in low-resource and low-compute settings, with the introduction of knowledge-enhanced encoders within seq2seq models.", "example": "Convert the coordinate to text: [-0.5609 -6.1261]:"}
{"text": "Convert the coordinate to text: [ 9.1100e-04 -9.1003e+00]: The authors introduce LAVIS, a one-stop, open-source deep learning library for LAnguage-VISion research and application that offers a unified interface and supports various tasks including multimodal classification, retrieval, captioning, and visual question answering.", "target": "The authors introduce LAVIS, a one-stop, open-source deep learning library for LAnguage-VISion research and application that offers a unified interface and supports various tasks including multimodal classification, retrieval, captioning, and visual question answering.", "example": "Convert the coordinate to text: [ 9.1100e-04 -9.1003e+00]:"}
{"text": "Convert the coordinate to text: [ 1.1394 -3.7067]: The authors propose an Augmentative and Contrastive Knowledge Dialogue Expansion Framework (ACK-DEF), where they construct augmentative and contrastive knowledge dialogue samples to expand the original training set and smooth the polarized optimization objective.", "target": "The authors propose an Augmentative and Contrastive Knowledge Dialogue Expansion Framework (ACK-DEF), where they construct augmentative and contrastive knowledge dialogue samples to expand the original training set and smooth the polarized optimization objective.", "example": "Convert the coordinate to text: [ 1.1394 -3.7067]:"}
{"text": "Convert the coordinate to text: [-1.5797  0.523 ]: A new framework named HyDE (Hybrid Diagnosis Extractor) is proposed that integrates labeling functions and a disease-agnostic neural network to assign diagnoses to patients from unstructured clinical notes. The model is trained to correct predictions made by the labelling functions.", "target": "A new framework named HyDE (Hybrid Diagnosis Extractor) is proposed that integrates labeling functions and a disease-agnostic neural network to assign diagnoses to patients from unstructured clinical notes. The model is trained to correct predictions made by the labelling functions.", "example": "Convert the coordinate to text: [-1.5797  0.523 ]:"}
{"text": "Convert the coordinate to text: [-9.497  -6.9487]: The authors propose a novel bi-lexical dependency parsing graph which is converted to a unified 2D table-filling scheme, namely USSA. It resolves the kernel bottleneck of previous SSA methods by utilizing 13 different types of relations.", "target": "The authors propose a novel bi-lexical dependency parsing graph which is converted to a unified 2D table-filling scheme, namely USSA. It resolves the kernel bottleneck of previous SSA methods by utilizing 13 different types of relations.", "example": "Convert the coordinate to text: [-9.497  -6.9487]:"}
{"text": "Convert the coordinate to text: [ 2.1881 13.7926]: This paper adapts the classic Stackelberg security game (SSG) to a new SSG-DUI game to describe the strategic interactions in catching DUI-drivers and proposes OPRADI, a systematic approach for advising better strategies in setting up checkpoints.", "target": "This paper adapts the classic Stackelberg security game (SSG) to a new SSG-DUI game to describe the strategic interactions in catching DUI-drivers and proposes OPRADI, a systematic approach for advising better strategies in setting up checkpoints.", "example": "Convert the coordinate to text: [ 2.1881 13.7926]:"}
{"text": "Convert the coordinate to text: [  8.3916 -12.8894]: The authors propose a new paradigm for 3D object detection called ObjectFusion, which eliminates camera-to-BEV transformation in favor of aligning object-centric features across different modalities.", "target": "The authors propose a new paradigm for 3D object detection called ObjectFusion, which eliminates camera-to-BEV transformation in favor of aligning object-centric features across different modalities.", "example": "Convert the coordinate to text: [  8.3916 -12.8894]:"}
{"text": "Convert the coordinate to text: [ 0.561  -7.2109]: The authors propose the Stochastic Transformer-based wORld Model (STORM), an efficient world model architecture that combines sequence modeling and generation capabilities of Transformers with the stochastic nature of variational autoencoders.", "target": "The authors propose the Stochastic Transformer-based wORld Model (STORM), an efficient world model architecture that combines sequence modeling and generation capabilities of Transformers with the stochastic nature of variational autoencoders.", "example": "Convert the coordinate to text: [ 0.561  -7.2109]:"}
{"text": "Convert the coordinate to text: [8.3284 6.8147]: The authors propose a novel data-pruning approach named moving-one-sample-out (MoSo). The core premise is to determine the importance of each sample by assessing its impact on the optimal empirical risk, i.e., changes in empirical risk when a specific sample is removed. This is achieved via an efficient first-order approximator using gradient information from different training stages.", "target": "The authors propose a novel data-pruning approach named moving-one-sample-out (MoSo). The core premise is to determine the importance of each sample by assessing its impact on the optimal empirical risk, i.e., changes in empirical risk when a specific sample is removed. This is achieved via an efficient first-order approximator using gradient information from different training stages.", "example": "Convert the coordinate to text: [8.3284 6.8147]:"}
{"text": "Convert the coordinate to text: [0.6138 0.7879]: Addressing the limitations of current methods, this study introduces a revised methodology for training and validating debiased models in a completely bias-unsupervised manner.", "target": "Addressing the limitations of current methods, this study introduces a revised methodology for training and validating debiased models in a completely bias-unsupervised manner.", "example": "Convert the coordinate to text: [0.6138 0.7879]:"}
{"text": "Convert the coordinate to text: [ 5.0545 -0.6163]: The authors suggest using Multi-Objective Optimization (MOO) to tackle the Multi-Label Learning to Rank problem. They propose a framework that allows information from labels to be mixed in many ways to equitably characterize trade-offs among the goals, and is adaptable to any gradient-based MOO algorithm.", "target": "The authors suggest using Multi-Objective Optimization (MOO) to tackle the Multi-Label Learning to Rank problem. They propose a framework that allows information from labels to be mixed in many ways to equitably characterize trade-offs among the goals, and is adaptable to any gradient-based MOO algorithm.", "example": "Convert the coordinate to text: [ 5.0545 -0.6163]:"}
{"text": "Convert the coordinate to text: [-0.9984  2.2124]: This study proposes to analyze instability not only through the standard deviation of performance scores but at different levels of granularity utilizing six other different measures. Additionally, a systematic framework to evaluate the validity of these measures is proposed.", "target": "This study proposes to analyze instability not only through the standard deviation of performance scores but at different levels of granularity utilizing six other different measures. Additionally, a systematic framework to evaluate the validity of these measures is proposed.", "example": "Convert the coordinate to text: [-0.9984  2.2124]:"}
{"text": "Convert the coordinate to text: [-5.451  10.6996]: The authors study the problem of mixed-initiative ESC, where both the user and system take the initiative in leading the conversation, and propose a knowledge-enhanced mixed-initiative framework (KEMI) for ESC capable of generating mixed-initiative responses by retrieving knowledge from a large-scale mental health knowledge graph.", "target": "The authors study the problem of mixed-initiative ESC, where both the user and system take the initiative in leading the conversation, and propose a knowledge-enhanced mixed-initiative framework (KEMI) for ESC capable of generating mixed-initiative responses by retrieving knowledge from a large-scale mental health knowledge graph.", "example": "Convert the coordinate to text: [-5.451  10.6996]:"}
{"text": "Convert the coordinate to text: [-4.754  -5.8739]: The authors present ISI-Clear, a cross-lingual, zero-shot event extraction system and user interface for event visualization & search that can process user-supplied text in 100 languages using only English training data.", "target": "The authors present ISI-Clear, a cross-lingual, zero-shot event extraction system and user interface for event visualization & search that can process user-supplied text in 100 languages using only English training data.", "example": "Convert the coordinate to text: [-4.754  -5.8739]:"}
{"text": "Convert the coordinate to text: [-2.0264  2.8957]: The authors propose a listwise attention network that captures the MRHP ranking context and a listwise optimization objective to improve model generalization. They also propose using a gradient-boosted decision tree as the score predictor to partition product reviews' representations efficiently.", "target": "The authors propose a listwise attention network that captures the MRHP ranking context and a listwise optimization objective to improve model generalization. They also propose using a gradient-boosted decision tree as the score predictor to partition product reviews' representations efficiently.", "example": "Convert the coordinate to text: [-2.0264  2.8957]:"}
{"text": "Convert the coordinate to text: [-1.2451 -4.4259]: This paper explores the scheme of a generic retrieval plug-in, where the retriever assists LMs that may not be known beforehand or are unable to be fine-tuned together. The authors propose the Augmentation-Adapted Retriever (AAR), which learns an LM's preferences obtained from a known source LM.", "target": "This paper explores the scheme of a generic retrieval plug-in, where the retriever assists LMs that may not be known beforehand or are unable to be fine-tuned together. The authors propose the Augmentation-Adapted Retriever (AAR), which learns an LM's preferences obtained from a known source LM.", "example": "Convert the coordinate to text: [-1.2451 -4.4259]:"}
{"text": "Convert the coordinate to text: [-5.4662 -5.985 ]: The authors present a novel algorithm that uses glosses from BabelNet in combination with text and image encoders, and investigates the application of English encoders to translated texts and context augmentation with descriptions generated by a language model for V-WSD.", "target": "The authors present a novel algorithm that uses glosses from BabelNet in combination with text and image encoders, and investigates the application of English encoders to translated texts and context augmentation with descriptions generated by a language model for V-WSD.", "example": "Convert the coordinate to text: [-5.4662 -5.985 ]:"}
{"text": "Convert the coordinate to text: [-0.3145 -3.4402]: A new KGE model called CompoundE is proposed, which leverages all geometric operations - translation, rotation, and scaling by cascading them to form a composite operation. It also extends the simple distance-based scoring functions to relation-dependent compound operations on head and/or tail entities.", "target": "A new KGE model called CompoundE is proposed, which leverages all geometric operations - translation, rotation, and scaling by cascading them to form a composite operation. It also extends the simple distance-based scoring functions to relation-dependent compound operations on head and/or tail entities.", "example": "Convert the coordinate to text: [-0.3145 -3.4402]:"}
{"text": "Convert the coordinate to text: [-3.0329 -6.5275]: The authors propose an ensemble architecture system based on the soft voting technique and various pre-trained transformer-based language models for performing sentiment analysis on African languages.", "target": "The authors propose an ensemble architecture system based on the soft voting technique and various pre-trained transformer-based language models for performing sentiment analysis on African languages.", "example": "Convert the coordinate to text: [-3.0329 -6.5275]:"}
{"text": "Convert the coordinate to text: [-1.7796 -5.1867]: The authors present a simple approach of fine-tuning a language model with Reinforcement Learning to generate teacher responses in educational dialogues, utilizing the novel NLPO algorithm that masks out tokens during generation to maximize a reward function.", "target": "The authors present a simple approach of fine-tuning a language model with Reinforcement Learning to generate teacher responses in educational dialogues, utilizing the novel NLPO algorithm that masks out tokens during generation to maximize a reward function.", "example": "Convert the coordinate to text: [-1.7796 -5.1867]:"}
{"text": "Convert the coordinate to text: [-3.8572 -4.169 ]: The authors address the textual confounding problem by extending variable ratio nearest neighbor matching to incorporate text embeddings.", "target": "The authors address the textual confounding problem by extending variable ratio nearest neighbor matching to incorporate text embeddings.", "example": "Convert the coordinate to text: [-3.8572 -4.169 ]:"}
{"text": "Convert the coordinate to text: [-6.074  -7.4563]: The authors propose a new method that maximizes alignment between texts and a composition of their phrasal constituents, rather than relying on the alignment of minimally perturbed embeddings.", "target": "The authors propose a new method that maximizes alignment between texts and a composition of their phrasal constituents, rather than relying on the alignment of minimally perturbed embeddings.", "example": "Convert the coordinate to text: [-6.074  -7.4563]:"}
{"text": "Convert the coordinate to text: [-1.3017 -5.6174]: Based on theoretical and empirical analyses of prefix interference, the authors propose a new method using trainable gates to normalize the intervention of prefixes, thereby reducing interference. This approach allows controlling unseen combinations of aspects by simply concatenating corresponding plugins and extending new constraints at a lower cost. The authors also proposed a unified method for processing both categorical and free-form constraints.", "target": "Based on theoretical and empirical analyses of prefix interference, the authors propose a new method using trainable gates to normalize the intervention of prefixes, thereby reducing interference. This approach allows controlling unseen combinations of aspects by simply concatenating corresponding plugins and extending new constraints at a lower cost. The authors also proposed a unified method for processing both categorical and free-form constraints.", "example": "Convert the coordinate to text: [-1.3017 -5.6174]:"}
{"text": "Convert the coordinate to text: [-0.362  -8.7487]: Instead of relying on translations, this study posits that the universal multilingual representation learned from texts allows cross-modal interaction learned in English to be transferable to other languages, under the new setting of weakly supervised multilingual VLP with only English image-text pairs and multilingual text corpora.", "target": "Instead of relying on translations, this study posits that the universal multilingual representation learned from texts allows cross-modal interaction learned in English to be transferable to other languages, under the new setting of weakly supervised multilingual VLP with only English image-text pairs and multilingual text corpora.", "example": "Convert the coordinate to text: [-0.362  -8.7487]:"}
{"text": "Convert the coordinate to text: [-5.8876  3.9326]: The speaker's vision is to create a trustworthy online ecosystem by developing advanced AI methods to detect, predict, mitigate online threats through novel applications in graph, content (NLP, multimodality), and adversarial machine learning methods.", "target": "The speaker's vision is to create a trustworthy online ecosystem by developing advanced AI methods to detect, predict, mitigate online threats through novel applications in graph, content (NLP, multimodality), and adversarial machine learning methods.", "example": "Convert the coordinate to text: [-5.8876  3.9326]:"}
{"text": "Convert the coordinate to text: [ 8.7182 -5.0252]: The study introduces an augmented coupling flow that respects SE(3) and permutation equivariance by performing coordinate splits along augmented dimensions. The flow maps atoms' positions into learned SE(3) invariant bases before applying standard flow transformations.", "target": "The study introduces an augmented coupling flow that respects SE(3) and permutation equivariance by performing coordinate splits along augmented dimensions. The flow maps atoms' positions into learned SE(3) invariant bases before applying standard flow transformations.", "example": "Convert the coordinate to text: [ 8.7182 -5.0252]:"}
{"text": "Convert the coordinate to text: [ 7.4858 -2.2663]: The authors propose to address the personalized strategy learning challenge in federated learning by considering meta-nets that induce batch-norm and learning rate parameters for each client based on their local data statistics.", "target": "The authors propose to address the personalized strategy learning challenge in federated learning by considering meta-nets that induce batch-norm and learning rate parameters for each client based on their local data statistics.", "example": "Convert the coordinate to text: [ 7.4858 -2.2663]:"}
{"text": "Convert the coordinate to text: [ 3.4998 -4.4263]: The authors propose an effective framework called DK-DETR that distills the knowledge from a VLM to a Detector Transformer (DETR)-like detector, by employing two distillation schemes called semantic knowledge distillation (SKD) and relational knowledge distillation (RKD).", "target": "The authors propose an effective framework called DK-DETR that distills the knowledge from a VLM to a Detector Transformer (DETR)-like detector, by employing two distillation schemes called semantic knowledge distillation (SKD) and relational knowledge distillation (RKD).", "example": "Convert the coordinate to text: [ 3.4998 -4.4263]:"}
{"text": "Convert the coordinate to text: [6.0502 1.2674]: The authors propose a method to create diverse data partitions iteratively in an unsupervised fashion. Each data partition serves as a self-annotated confounder which enables their Invariant Feature Regularization (INV-REG) to deconfound.", "target": "The authors propose a method to create diverse data partitions iteratively in an unsupervised fashion. Each data partition serves as a self-annotated confounder which enables their Invariant Feature Regularization (INV-REG) to deconfound.", "example": "Convert the coordinate to text: [6.0502 1.2674]:"}
{"text": "Convert the coordinate to text: [ 10.365  -12.6094]: The paper proposes the concept of Triangulation Residual loss (TR loss), which provides a self-supervised loss considering global multiview geometric consistency to enable a data-efficient multiview 3D pose estimation, starting from initial 2D keypoint estimates.", "target": "The paper proposes the concept of Triangulation Residual loss (TR loss), which provides a self-supervised loss considering global multiview geometric consistency to enable a data-efficient multiview 3D pose estimation, starting from initial 2D keypoint estimates.", "example": "Convert the coordinate to text: [ 10.365  -12.6094]:"}
{"text": "Convert the coordinate to text: [  1.0341 -10.0246]: The authors curate CompPrompts, a set of increasingly compositional image captions that VL models should be able to capture and train text-only recovery probes to reconstruct captions from single-vector text representations produced by several VL models.", "target": "The authors curate CompPrompts, a set of increasingly compositional image captions that VL models should be able to capture and train text-only recovery probes to reconstruct captions from single-vector text representations produced by several VL models.", "example": "Convert the coordinate to text: [  1.0341 -10.0246]:"}
{"text": "Convert the coordinate to text: [6.702  7.7473]: The study investigates the impact of removing personally identifiable information (PII) and applying differential privacy (DP) rewriting on the possibility of using text with privacy-sensitive information for crowdsourcing tasks without compromising user privacy.", "target": "The study investigates the impact of removing personally identifiable information (PII) and applying differential privacy (DP) rewriting on the possibility of using text with privacy-sensitive information for crowdsourcing tasks without compromising user privacy.", "example": "Convert the coordinate to text: [6.702  7.7473]:"}
{"text": "Convert the coordinate to text: [-0.0735  1.0304]: The study introduces HRS-Bench, a new evaluation benchmark for T2I models that is holistic, reliable, and scalable. The benchmark measures 13 skills categorized into five categories: accuracy, robustness, generalization, fairness, and bias. Also, it covers 50 scenarios including fashion, animals, transportation, food, and clothes.", "target": "The study introduces HRS-Bench, a new evaluation benchmark for T2I models that is holistic, reliable, and scalable. The benchmark measures 13 skills categorized into five categories: accuracy, robustness, generalization, fairness, and bias. Also, it covers 50 scenarios including fashion, animals, transportation, food, and clothes.", "example": "Convert the coordinate to text: [-0.0735  1.0304]:"}
{"text": "Convert the coordinate to text: [-8.429  9.933]: This paper focuses on understanding how situations of 'information dissonance'\u2014where there's a difference between augmented information and verbally uttered information\u2014affect users' perception of their conversation partner and who they trust more: the augmentation or the interlocutor.", "target": "This paper focuses on understanding how situations of 'information dissonance'\u2014where there's a difference between augmented information and verbally uttered information\u2014affect users' perception of their conversation partner and who they trust more: the augmentation or the interlocutor.", "example": "Convert the coordinate to text: [-8.429  9.933]:"}
{"text": "Convert the coordinate to text: [-7.4239 -2.2338]: The main goal of this paper is to analyze semantic embedding APIs in realistic retrieval scenarios in order to better guide the community in finding suitable services for their needs. This involves investigating their capabilities on domain generalization and multilingual retrieval.", "target": "The main goal of this paper is to analyze semantic embedding APIs in realistic retrieval scenarios in order to better guide the community in finding suitable services for their needs. This involves investigating their capabilities on domain generalization and multilingual retrieval.", "example": "Convert the coordinate to text: [-7.4239 -2.2338]:"}
{"text": "Convert the coordinate to text: [-4.9375  0.0714]: The authors propose an unsupervised method for opinion summarization that employs encoding sentences from customer reviews into a hierarchical discrete latent space and identifying common opinions based on the frequency of these encodings.", "target": "The authors propose an unsupervised method for opinion summarization that employs encoding sentences from customer reviews into a hierarchical discrete latent space and identifying common opinions based on the frequency of these encodings.", "example": "Convert the coordinate to text: [-4.9375  0.0714]:"}
{"text": "Convert the coordinate to text: [-5.6652  1.0739]: FActScore is introduced as a new evaluation method that breaks down a generation into atomic facts and computes the percentage of these facts that are supported by a reliable knowledge source.", "target": "FActScore is introduced as a new evaluation method that breaks down a generation into atomic facts and computes the percentage of these facts that are supported by a reliable knowledge source.", "example": "Convert the coordinate to text: [-5.6652  1.0739]:"}
{"text": "Convert the coordinate to text: [-9.2911  0.6639]: The authors introduce an end-to-end pipeline for retrieving, processing, and extracting information from legal cases, specifically in the domain of refugee law in Canada. The proposed system extends existing models to retrieve 19 useful categories of items from refugee cases.", "target": "The authors introduce an end-to-end pipeline for retrieving, processing, and extracting information from legal cases, specifically in the domain of refugee law in Canada. The proposed system extends existing models to retrieve 19 useful categories of items from refugee cases.", "example": "Convert the coordinate to text: [-9.2911  0.6639]:"}
{"text": "Convert the coordinate to text: [-3.2705 -6.317 ]: This paper investigates how the effects of pre-training are observed when the problem size is reduced, modelling a smaller, reduced-vocabulary language.", "target": "This paper investigates how the effects of pre-training are observed when the problem size is reduced, modelling a smaller, reduced-vocabulary language.", "example": "Convert the coordinate to text: [-3.2705 -6.317 ]:"}
{"text": "Convert the coordinate to text: [-3.0287 -3.8237]: A multi-granularity system for CTR-based textual entailment and evidence retrieval is proposed, which includes a Multi-granularity Inference Network (MGNet) that uses sentence-level and token-level encoding, and a T5-based model, SciFive, to enhance numerical inference capability.", "target": "A multi-granularity system for CTR-based textual entailment and evidence retrieval is proposed, which includes a Multi-granularity Inference Network (MGNet) that uses sentence-level and token-level encoding, and a T5-based model, SciFive, to enhance numerical inference capability.", "example": "Convert the coordinate to text: [-3.0287 -3.8237]:"}
{"text": "Convert the coordinate to text: [-9.438  -5.2259]: The authors design an end-to-end neural model inspired by the annotation process of Penn Discourse Treebank (PDTB), which explicitly generates discourse connectives between arguments and predicts discourse relations based on the arguments and the generated connectives.", "target": "The authors design an end-to-end neural model inspired by the annotation process of Penn Discourse Treebank (PDTB), which explicitly generates discourse connectives between arguments and predicts discourse relations based on the arguments and the generated connectives.", "example": "Convert the coordinate to text: [-9.438  -5.2259]:"}
{"text": "Convert the coordinate to text: [-1.5715 -0.0198]: The authors propose to explore the performance of multiple models for misogyny detection in memes. The researchers hypothesize that domain-specific pretraining might improve the models' performance.", "target": "The authors propose to explore the performance of multiple models for misogyny detection in memes. The researchers hypothesize that domain-specific pretraining might improve the models' performance.", "example": "Convert the coordinate to text: [-1.5715 -0.0198]:"}
{"text": "Convert the coordinate to text: [-3.3174 -3.6711]: The authors propose a label-aware system that reframes the multi-label classification task into a binary task resembling a Natural Language Inference (NLI) task, incorporating the semantic description of human values and checking for entailment with the argument.", "target": "The authors propose a label-aware system that reframes the multi-label classification task into a binary task resembling a Natural Language Inference (NLI) task, incorporating the semantic description of human values and checking for entailment with the argument.", "example": "Convert the coordinate to text: [-3.3174 -3.6711]:"}
{"text": "Convert the coordinate to text: [-4.2758 -3.0772]: This study proposes a context-aware approach for the Rhetorical Roles Prediction task and a Named Entity Recognition approach for the extraction and classification of entities like names of petitioner, respondent, court or statute of a given document.", "target": "This study proposes a context-aware approach for the Rhetorical Roles Prediction task and a Named Entity Recognition approach for the extraction and classification of entities like names of petitioner, respondent, court or statute of a given document.", "example": "Convert the coordinate to text: [-4.2758 -3.0772]:"}
{"text": "Convert the coordinate to text: [-2.1005 -5.3692]: This study examines the feasibility of deploying ChatGPT, a language model, for generating explanations for the options in multiple-choice questions on reading comprehension tests, and compares its explanations with those generated by human item-writers.", "target": "This study examines the feasibility of deploying ChatGPT, a language model, for generating explanations for the options in multiple-choice questions on reading comprehension tests, and compares its explanations with those generated by human item-writers.", "example": "Convert the coordinate to text: [-2.1005 -5.3692]:"}
{"text": "Convert the coordinate to text: [-0.7958  6.3396]: The authors propose a Compositional Math Word Problem Solver (C-MWP) which works in a bi-modal setting, encoding in an interactive way to handle both semantics and quantity-demanding problems.", "target": "The authors propose a Compositional Math Word Problem Solver (C-MWP) which works in a bi-modal setting, encoding in an interactive way to handle both semantics and quantity-demanding problems.", "example": "Convert the coordinate to text: [-0.7958  6.3396]:"}
{"text": "Convert the coordinate to text: [6.8584 7.7529]: The authors propose a novel Customized Text sanitization (CusText) mechanism based on the original \ud835\udf16-differential privacy (DP) definition, rather than MLDP, making it compatible with any similarity measure. Unlike current methods, CusText assigns each input token a customized output set to provide more advanced privacy protection at the token level.", "target": "The authors propose a novel Customized Text sanitization (CusText) mechanism based on the original \ud835\udf16-differential privacy (DP) definition, rather than MLDP, making it compatible with any similarity measure. Unlike current methods, CusText assigns each input token a customized output set to provide more advanced privacy protection at the token level.", "example": "Convert the coordinate to text: [6.8584 7.7529]:"}
{"text": "Convert the coordinate to text: [ 3.4772 -4.1195]: This paper proposes CKDST, a comprehensive knowledge distillation framework for speech translation, that effectively distills knowledge from machine translation to speech translation in two ways: cross-modal contrastive representation distillation and simultaneous decoupled knowledge distillation.", "target": "This paper proposes CKDST, a comprehensive knowledge distillation framework for speech translation, that effectively distills knowledge from machine translation to speech translation in two ways: cross-modal contrastive representation distillation and simultaneous decoupled knowledge distillation.", "example": "Convert the coordinate to text: [ 3.4772 -4.1195]:"}
{"text": "Convert the coordinate to text: [11.8987  9.8844]: The authors propose a new objective, denoted as RoC (Ratio of Complementarity), which captures a fuller notion of complementarity compared to the existing models. This is accomplished by using a two-level orthogonality designed to improve RoC.", "target": "The authors propose a new objective, denoted as RoC (Ratio of Complementarity), which captures a fuller notion of complementarity compared to the existing models. This is accomplished by using a two-level orthogonality designed to improve RoC.", "example": "Convert the coordinate to text: [11.8987  9.8844]:"}
{"text": "Convert the coordinate to text: [-3.72   -7.0222]: The authors introduce CodeGeeX, a multilingual model to generate code which is pre-trained on tokens of 23 programming languages.", "target": "The authors introduce CodeGeeX, a multilingual model to generate code which is pre-trained on tokens of 23 programming languages.", "example": "Convert the coordinate to text: [-3.72   -7.0222]:"}
{"text": "Convert the coordinate to text: [ 7.0269 -3.3135]: The authors propose a generalization bound that considers the adaptivity gap, fostering two strategies: ensembling multiple classifiers to enrich the hypothesis space and using online target samples to adapt model parameters for direct gap minimization. Based on these strategies, they also put forward a new Domain-specific Risk Minimization (DRM) technique.", "target": "The authors propose a generalization bound that considers the adaptivity gap, fostering two strategies: ensembling multiple classifiers to enrich the hypothesis space and using online target samples to adapt model parameters for direct gap minimization. Based on these strategies, they also put forward a new Domain-specific Risk Minimization (DRM) technique.", "example": "Convert the coordinate to text: [ 7.0269 -3.3135]:"}
{"text": "Convert the coordinate to text: [ 4.8076 13.3697]: The authors propose the Proactively Synchronizing Tempo (ProST) framework that computes optimal interaction times to balance policy training time (agent tempo) and how quickly the environment changes (environment tempo), potentially addressing the time synchronization issue.", "target": "The authors propose the Proactively Synchronizing Tempo (ProST) framework that computes optimal interaction times to balance policy training time (agent tempo) and how quickly the environment changes (environment tempo), potentially addressing the time synchronization issue.", "example": "Convert the coordinate to text: [ 4.8076 13.3697]:"}
{"text": "Convert the coordinate to text: [ 3.8231 -4.0178]: The paper presents a technique called Masked Knowledge Distillation (MKD) that enhances KD using a masked autoencoding scheme where random patches of the input image are masked, and the corresponding missing feature is recovered by forcing it to mimic the output of the teacher model.", "target": "The paper presents a technique called Masked Knowledge Distillation (MKD) that enhances KD using a masked autoencoding scheme where random patches of the input image are masked, and the corresponding missing feature is recovered by forcing it to mimic the output of the teacher model.", "example": "Convert the coordinate to text: [ 3.8231 -4.0178]:"}
{"text": "Convert the coordinate to text: [8.2241 2.1948]: The authors suggest an algorithmic framework that builds a sparse approximation of the fully connected similarity graph while preserving its cluster structure. The proposed algorithm is derived from the kernel density estimation problem, and can be applied to any kernel function.", "target": "The authors suggest an algorithmic framework that builds a sparse approximation of the fully connected similarity graph while preserving its cluster structure. The proposed algorithm is derived from the kernel density estimation problem, and can be applied to any kernel function.", "example": "Convert the coordinate to text: [8.2241 2.1948]:"}
{"text": "Convert the coordinate to text: [ -0.9283 -12.3688]: This paper proposes a novel approach to MetaMAE, which interprets MAE as a modality-agnostic learner and enhances MAE for improved SSL across diverse modalities. The key idea is to view the mask reconstruction of MAE as a meta-learning task, where masked tokens are predicted by adapting the Transformer meta-learner through the amortization of unmasked tokens.", "target": "This paper proposes a novel approach to MetaMAE, which interprets MAE as a modality-agnostic learner and enhances MAE for improved SSL across diverse modalities. The key idea is to view the mask reconstruction of MAE as a meta-learning task, where masked tokens are predicted by adapting the Transformer meta-learner through the amortization of unmasked tokens.", "example": "Convert the coordinate to text: [ -0.9283 -12.3688]:"}
{"text": "Convert the coordinate to text: [11.5821 -1.6209]: The authors provide statistical sample complexity bounds for score-matching, demonstrating that accurate estimation of the score function can be achieved by training a deep ReLU neural network using stochastic gradient descent.", "target": "The authors provide statistical sample complexity bounds for score-matching, demonstrating that accurate estimation of the score function can be achieved by training a deep ReLU neural network using stochastic gradient descent.", "example": "Convert the coordinate to text: [11.5821 -1.6209]:"}
{"text": "Convert the coordinate to text: [4.4864 2.5621]: The authors establish the stability of random forests under milder conditions, such as the squared response not having a heavy tail, and prove a non-asymptotic lower bound for the coverage probability of prediction intervals constructed from the out-of-bag error of random forests.", "target": "The authors establish the stability of random forests under milder conditions, such as the squared response not having a heavy tail, and prove a non-asymptotic lower bound for the coverage probability of prediction intervals constructed from the out-of-bag error of random forests.", "example": "Convert the coordinate to text: [4.4864 2.5621]:"}
{"text": "Convert the coordinate to text: [9.4051 7.5792]: This paper proposes improvements to the objective perturbation mechanism, providing tighter privacy analyses and new computational tools to boost its performance on unconstrained convex generalized linear problems.", "target": "This paper proposes improvements to the objective perturbation mechanism, providing tighter privacy analyses and new computational tools to boost its performance on unconstrained convex generalized linear problems.", "example": "Convert the coordinate to text: [9.4051 7.5792]:"}
{"text": "Convert the coordinate to text: [13.8272 -0.0931]: The authors introduce Modulated Neural ODEs (MoNODEs), a new framework that separates dynamics states from underlying static factors of variation, improving the existing NODE methods. They propose time-invariant modulator variables that are learned from the data.", "target": "The authors introduce Modulated Neural ODEs (MoNODEs), a new framework that separates dynamics states from underlying static factors of variation, improving the existing NODE methods. They propose time-invariant modulator variables that are learned from the data.", "example": "Convert the coordinate to text: [13.8272 -0.0931]:"}
{"text": "Convert the coordinate to text: [ -1.3904 -13.2677]: The authors propose a novel framework, LatentLogic, which utilizes a pre-trained Variational AutoEncoder (VAE) and a discriminator to mine logic rules by controllable generation in a latent space.", "target": "The authors propose a novel framework, LatentLogic, which utilizes a pre-trained Variational AutoEncoder (VAE) and a discriminator to mine logic rules by controllable generation in a latent space.", "example": "Convert the coordinate to text: [ -1.3904 -13.2677]:"}
{"text": "Convert the coordinate to text: [13.3821 -4.5198]: The authors propose an untargeted attack on federated news recommendation systems, called UA-FedRec. Using the prior knowledge of news recommendation and federated learning, UA-FedRec aims to degrade the model performance with a small percentage of malicious clients by interrupting news and user modeling as well as manipulating updates from clients.", "target": "The authors propose an untargeted attack on federated news recommendation systems, called UA-FedRec. Using the prior knowledge of news recommendation and federated learning, UA-FedRec aims to degrade the model performance with a small percentage of malicious clients by interrupting news and user modeling as well as manipulating updates from clients.", "example": "Convert the coordinate to text: [13.3821 -4.5198]:"}
{"text": "Convert the coordinate to text: [-1.5591 -8.3661]: The authors propose a fast non-autoregressive sequence generation model, FANS, which uses a non-autoregressive generation mechanism to enhance inference efficiency and quality for item list continuation. The model also includes a two-stage classifier to further reduce decoding time, and employs a curriculum learning strategy for training.", "target": "The authors propose a fast non-autoregressive sequence generation model, FANS, which uses a non-autoregressive generation mechanism to enhance inference efficiency and quality for item list continuation. The model also includes a two-stage classifier to further reduce decoding time, and employs a curriculum learning strategy for training.", "example": "Convert the coordinate to text: [-1.5591 -8.3661]:"}
{"text": "Convert the coordinate to text: [-2.9728 -6.6496]: The authors attempt these tasks using several methods: classical machine learning classifiers, Afro-centric language models, language-specific models, and multilingual pre-trained language models for different tasks. For zero-shot sentiment classification, a parameter-efficient Adapter approach is employed.", "target": "The authors attempt these tasks using several methods: classical machine learning classifiers, Afro-centric language models, language-specific models, and multilingual pre-trained language models for different tasks. For zero-shot sentiment classification, a parameter-efficient Adapter approach is employed.", "example": "Convert the coordinate to text: [-2.9728 -6.6496]:"}
{"text": "Convert the coordinate to text: [-4.9697 13.551 ]: This paper explores another perspective, that of having robots mediate human relationships (human-human-robot interaction). The role of the robot in this scenario is significant, impacting its function and form.", "target": "This paper explores another perspective, that of having robots mediate human relationships (human-human-robot interaction). The role of the robot in this scenario is significant, impacting its function and form.", "example": "Convert the coordinate to text: [-4.9697 13.551 ]:"}
{"text": "Convert the coordinate to text: [-6.5359  2.4094]: The authors propose VendorLink, an NLP-based approach that examines writing patterns to verify, identify, and link unique vendor accounts across text advertisements on seven public Darknet markets.", "target": "The authors propose VendorLink, an NLP-based approach that examines writing patterns to verify, identify, and link unique vendor accounts across text advertisements on seven public Darknet markets.", "example": "Convert the coordinate to text: [-6.5359  2.4094]:"}
{"text": "Convert the coordinate to text: [-4.3546 -1.7728]: The paper proposes to solve these challenges through event extraction from a novel domain of historical texts and introduces a new multilingual dataset. The problem is formulated as an extractive QA task and leverages existing datasets and models for modern languages.", "target": "The paper proposes to solve these challenges through event extraction from a novel domain of historical texts and introduces a new multilingual dataset. The problem is formulated as an extractive QA task and leverages existing datasets and models for modern languages.", "example": "Convert the coordinate to text: [-4.3546 -1.7728]:"}
{"text": "Convert the coordinate to text: [-2.8036 -5.0452]: This study investigates whether LLMs display human-like referential biases using stimuli and procedures from real psycholinguistic experiments.", "target": "This study investigates whether LLMs display human-like referential biases using stimuli and procedures from real psycholinguistic experiments.", "example": "Convert the coordinate to text: [-2.8036 -5.0452]:"}
{"text": "Convert the coordinate to text: [-5.8928 10.8794]: The authors propose to explore two auxiliary subtasks, User Intent Detection and Instruction State Tracking, to help address the issue of incorrect delivery of cooking instructions in dialogue systems.", "target": "The authors propose to explore two auxiliary subtasks, User Intent Detection and Instruction State Tracking, to help address the issue of incorrect delivery of cooking instructions in dialogue systems.", "example": "Convert the coordinate to text: [-5.8928 10.8794]:"}
{"text": "Convert the coordinate to text: [-0.8477 -6.8987]: The authors investigate the ability of transformer language models to learn to generalize hierarchically and argue that this capability emerges after extremely lengthy training periods, a phenomenon they term 'structural grokking'.", "target": "The authors investigate the ability of transformer language models to learn to generalize hierarchically and argue that this capability emerges after extremely lengthy training periods, a phenomenon they term 'structural grokking'.", "example": "Convert the coordinate to text: [-0.8477 -6.8987]:"}
{"text": "Convert the coordinate to text: [ 3.3909 -3.0642]: Our team (iREL) studies the multilevel training in this inter-connected task structure to understand the transfer learning from broader to more detailed tasks. At the same time, additional strategies are employed such as domain-adaptive pretraining to adapt the models to the content type and the application of focal loss objective to manage class imbalances.", "target": "Our team (iREL) studies the multilevel training in this inter-connected task structure to understand the transfer learning from broader to more detailed tasks. At the same time, additional strategies are employed such as domain-adaptive pretraining to adapt the models to the content type and the application of focal loss objective to manage class imbalances.", "example": "Convert the coordinate to text: [ 3.3909 -3.0642]:"}
{"text": "Convert the coordinate to text: [-3.7976 -3.5525]: The authors propose garNER, a solution that uses a knowledge augmentation approach by querying entities from the Wikipedia API and appending the summaries of these entities to the input sentence. Entities are either retrieved from the labeled training set (Gold Entity) or from off-the-shelf entity taggers (Entity Extractor).", "target": "The authors propose garNER, a solution that uses a knowledge augmentation approach by querying entities from the Wikipedia API and appending the summaries of these entities to the input sentence. Entities are either retrieved from the labeled training set (Gold Entity) or from off-the-shelf entity taggers (Entity Extractor).", "example": "Convert the coordinate to text: [-3.7976 -3.5525]:"}
{"text": "Convert the coordinate to text: [-6.3992 -9.8726]: This paper proposes a systematic analysis of spell errors, grouping them into error classes. The authors also introduce an approach employing the Transformer model for contextual spell correction, curbed by innovative synthetic data generation techniques for creating ample training pairs without human intervention.", "target": "This paper proposes a systematic analysis of spell errors, grouping them into error classes. The authors also introduce an approach employing the Transformer model for contextual spell correction, curbed by innovative synthetic data generation techniques for creating ample training pairs without human intervention.", "example": "Convert the coordinate to text: [-6.3992 -9.8726]:"}
{"text": "Convert the coordinate to text: [ 1.4768 -1.2106]: The authors introduce a method that self-trains or bootstraps neural relation and explanation classifiers for semi-supervised scenarios. This method iteratively converts the outputs of explainable models into rules and applies them to unlabeled text to produce further annotations.", "target": "The authors introduce a method that self-trains or bootstraps neural relation and explanation classifiers for semi-supervised scenarios. This method iteratively converts the outputs of explainable models into rules and applies them to unlabeled text to produce further annotations.", "example": "Convert the coordinate to text: [ 1.4768 -1.2106]:"}
{"text": "Convert the coordinate to text: [-12.0795  -5.1446]: The authors propose a two-step pipeline for recruiting high-quality Amazon Mechanical Turk workers for evaluating automatic summarization.", "target": "The authors propose a two-step pipeline for recruiting high-quality Amazon Mechanical Turk workers for evaluating automatic summarization.", "example": "Convert the coordinate to text: [-12.0795  -5.1446]:"}
{"text": "Convert the coordinate to text: [-0.499   7.0647]: HermEs is introduced, a novel approach for predicting spreadsheet formulas using hierarchical formulet expansion. It improves accuracy by ensuring correct grammar through hierarchical generation and streamlining token-level decoding with high-level Formulet.", "target": "HermEs is introduced, a novel approach for predicting spreadsheet formulas using hierarchical formulet expansion. It improves accuracy by ensuring correct grammar through hierarchical generation and streamlining token-level decoding with high-level Formulet.", "example": "Convert the coordinate to text: [-0.499   7.0647]:"}
{"text": "Convert the coordinate to text: [ 5.0497 -7.8719]: The paper proposes a new machine learning model named cross-covariance attended compact Feed-Forward Sequential Memory Network (CC-FSMN) specifically for the classification of marine mammals.", "target": "The paper proposes a new machine learning model named cross-covariance attended compact Feed-Forward Sequential Memory Network (CC-FSMN) specifically for the classification of marine mammals.", "example": "Convert the coordinate to text: [ 5.0497 -7.8719]:"}
{"text": "Convert the coordinate to text: [  8.006  -11.4691]: The paper proposes Segmentation Radial Contour DataBase (SegRCDB), a new approach that applies formula-driven supervised learning for semantic segmentation, enabling efficient pre-training without the necessity for real images or manual semantic labels.", "target": "The paper proposes Segmentation Radial Contour DataBase (SegRCDB), a new approach that applies formula-driven supervised learning for semantic segmentation, enabling efficient pre-training without the necessity for real images or manual semantic labels.", "example": "Convert the coordinate to text: [  8.006  -11.4691]:"}
{"text": "Convert the coordinate to text: [ 9.2611 -5.8134]: A new framework for Generalizable INR is proposed, combining a transformer encoder with a locality-aware INR decoder. This framework uses a system of latent tokens to encode local information and features multi-band modulation to predict outputs.", "target": "A new framework for Generalizable INR is proposed, combining a transformer encoder with a locality-aware INR decoder. This framework uses a system of latent tokens to encode local information and features multi-band modulation to predict outputs.", "example": "Convert the coordinate to text: [ 9.2611 -5.8134]:"}
{"text": "Convert the coordinate to text: [11.4593  2.9502]: The authors propose a new optimization scheme that relies on a spectral representation of the linear transfer of information between layers, enabling the calculation of gradients with respect to both eigenvalues and eigenvectors without significantly increasing computational complexity.", "target": "The authors propose a new optimization scheme that relies on a spectral representation of the linear transfer of information between layers, enabling the calculation of gradients with respect to both eigenvalues and eigenvectors without significantly increasing computational complexity.", "example": "Convert the coordinate to text: [11.4593  2.9502]:"}
{"text": "Convert the coordinate to text: [10.9831 -0.2353]: The authors propose a new gauge equivariant architecture using nonlinear message passing to address the issues with current solutions.", "target": "The authors propose a new gauge equivariant architecture using nonlinear message passing to address the issues with current solutions.", "example": "Convert the coordinate to text: [10.9831 -0.2353]:"}
{"text": "Convert the coordinate to text: [ 4.8534 12.5857]: This paper proposes a new regularization for behavior cloning, cunningly named Past Action Leakage Regularization (PALR), designed to prevent the imitation of past actions by using the classic concept of conditional independence to reduce the leakage.", "target": "This paper proposes a new regularization for behavior cloning, cunningly named Past Action Leakage Regularization (PALR), designed to prevent the imitation of past actions by using the classic concept of conditional independence to reduce the leakage.", "example": "Convert the coordinate to text: [ 4.8534 12.5857]:"}
{"text": "Convert the coordinate to text: [-0.9571 -3.5029]: The authors propose a new framework named UltraRE, which enhances RecEraser in model utility and unlearning efficiency by addressing three potential losses: redundancy, relevance, and combination.", "target": "The authors propose a new framework named UltraRE, which enhances RecEraser in model utility and unlearning efficiency by addressing three potential losses: redundancy, relevance, and combination.", "example": "Convert the coordinate to text: [-0.9571 -3.5029]:"}
{"text": "Convert the coordinate to text: [  0.1261 -17.6304]: The authors propose a novel removal attack method that is effective against almost all white-box watermarking schemes. The method utilizes a chain of invariant neuron transforms to tamper with the features of a local neuron group, which the authors found to be fragile and a common dependence in white-box watermarking schemes.", "target": "The authors propose a novel removal attack method that is effective against almost all white-box watermarking schemes. The method utilizes a chain of invariant neuron transforms to tamper with the features of a local neuron group, which the authors found to be fragile and a common dependence in white-box watermarking schemes.", "example": "Convert the coordinate to text: [  0.1261 -17.6304]:"}
{"text": "Convert the coordinate to text: [ 5.9771 12.0777]: The authors propose a new model, the semi-infinitely constrained Markov decision process (SICMDP), which imposes a continuum of constraints, and also introduce a reinforcement learning algorithm for SICMDPs, called SI-CRL.", "target": "The authors propose a new model, the semi-infinitely constrained Markov decision process (SICMDP), which imposes a continuum of constraints, and also introduce a reinforcement learning algorithm for SICMDPs, called SI-CRL.", "example": "Convert the coordinate to text: [ 5.9771 12.0777]:"}
{"text": "Convert the coordinate to text: [ 5.1696 -5.3202]: The paper proposes to capture long-distance dependencies in graphs using shallower models instead of deeper ones. This approach has resulted in a more efficient model for graph representation learning, named LazyGNN.", "target": "The paper proposes to capture long-distance dependencies in graphs using shallower models instead of deeper ones. This approach has resulted in a more efficient model for graph representation learning, named LazyGNN.", "example": "Convert the coordinate to text: [ 5.1696 -5.3202]:"}
{"text": "Convert the coordinate to text: [ 9.8109 12.1991]: In this paper, a framework named Graph Neural Bandits (GNB) is proposed to leverage the collaborative nature among users empowered by graph neural networks (GNNs). Collaborative effects are modelled through estimated user graphs in terms of exploitation and exploration individually.", "target": "In this paper, a framework named Graph Neural Bandits (GNB) is proposed to leverage the collaborative nature among users empowered by graph neural networks (GNNs). Collaborative effects are modelled through estimated user graphs in terms of exploitation and exploration individually.", "example": "Convert the coordinate to text: [ 9.8109 12.1991]:"}
{"text": "Convert the coordinate to text: [ 14.1426 -11.8444]: The authors present TexonMask, a facial expression recognition system using lightweight electrode-augmented commodity facemasks. The system recognizes the wearer's facial expressions based on capacitive sensor readings and can communicate with external devices.", "target": "The authors present TexonMask, a facial expression recognition system using lightweight electrode-augmented commodity facemasks. The system recognizes the wearer's facial expressions based on capacitive sensor readings and can communicate with external devices.", "example": "Convert the coordinate to text: [ 14.1426 -11.8444]:"}
{"text": "Convert the coordinate to text: [-6.684  -1.6105]: The authors introduce a statistical textual exploration pipeline capable of detecting literary features, performing a hypothesis-testing analysis, and extracting and quantifying the importance of features for the classification of components within a text.", "target": "The authors introduce a statistical textual exploration pipeline capable of detecting literary features, performing a hypothesis-testing analysis, and extracting and quantifying the importance of features for the classification of components within a text.", "example": "Convert the coordinate to text: [-6.684  -1.6105]:"}
{"text": "Convert the coordinate to text: [-15.7154  16.7708]: This study introduces RMSSinger, the first Realistic-Music-Score based Singing Voice Synthesis (RMS-SVS) method, which accepts realistic music scores as input, avoiding the need for extensive manual annotation and the associated inconvenience.", "target": "This study introduces RMSSinger, the first Realistic-Music-Score based Singing Voice Synthesis (RMS-SVS) method, which accepts realistic music scores as input, avoiding the need for extensive manual annotation and the associated inconvenience.", "example": "Convert the coordinate to text: [-15.7154  16.7708]:"}
{"text": "Convert the coordinate to text: [-2.2396 -3.0078]: The authors propose treating the discourse structures as latent variables and then jointly inferring them and the pre-training of discourse-aware models through unsupervised latent variable inference methods.", "target": "The authors propose treating the discourse structures as latent variables and then jointly inferring them and the pre-training of discourse-aware models through unsupervised latent variable inference methods.", "example": "Convert the coordinate to text: [-2.2396 -3.0078]:"}
{"text": "Convert the coordinate to text: [0.1264 0.8315]: The authors define a typology for three types of label biases in ICL for text classification: vanilla-label bias, context-label bias, and domain-label bias. They also propose a new simple bias calibration method for mitigating these biases that estimates a language model's label bias using random in-domain words from the task corpus.", "target": "The authors define a typology for three types of label biases in ICL for text classification: vanilla-label bias, context-label bias, and domain-label bias. They also propose a new simple bias calibration method for mitigating these biases that estimates a language model's label bias using random in-domain words from the task corpus.", "example": "Convert the coordinate to text: [0.1264 0.8315]:"}
{"text": "Convert the coordinate to text: [-4.8698 -7.2036]: This study proposes a new data sampling method that uses the available labor budget to sample data in a more representative manner. The goal is to improve the representation of various document lengths in the samples and to produce stable rankings of system translation quality.", "target": "This study proposes a new data sampling method that uses the available labor budget to sample data in a more representative manner. The goal is to improve the representation of various document lengths in the samples and to produce stable rankings of system translation quality.", "example": "Convert the coordinate to text: [-4.8698 -7.2036]:"}
{"text": "Convert the coordinate to text: [ 1.7915 -0.7109]: The authors integrate loss functions specific for subjective tasks and anonymized annotator-specific information to manage disagreement and detect toxicity.", "target": "The authors integrate loss functions specific for subjective tasks and anonymized annotator-specific information to manage disagreement and detect toxicity.", "example": "Convert the coordinate to text: [ 1.7915 -0.7109]:"}
{"text": "Convert the coordinate to text: [-2.7607 -5.8374]: The paper evaluates the effectiveness of general and specialized autoregressive language models in generating lay summaries from abstracts of biomedical research articles.", "target": "The paper evaluates the effectiveness of general and specialized autoregressive language models in generating lay summaries from abstracts of biomedical research articles.", "example": "Convert the coordinate to text: [-2.7607 -5.8374]:"}
{"text": "Convert the coordinate to text: [-4.8386  9.568 ]: This paper presents a novel approach where instead of grounding knowledge given the responses, optimization of the final responses is done for given guided knowledge directly. This allows the entire problem to be re-formulated in a more simplified and scalable way.", "target": "This paper presents a novel approach where instead of grounding knowledge given the responses, optimization of the final responses is done for given guided knowledge directly. This allows the entire problem to be re-formulated in a more simplified and scalable way.", "example": "Convert the coordinate to text: [-4.8386  9.568 ]:"}
{"text": "Convert the coordinate to text: [ 2.1286 -4.2885]: This paper presents the Mutual Learning and Large-Margin Contrastive Learning (ML-LMCL), a framework aiming to improve ASR robustness in SLU through combined fine-tuning on both manual and ASR transcripts using two separate SLU models in a mutual learning setting. The framework also includes a distance polarization regularizer to prevent separating intra-cluster pairs and employs a cyclical annealing schedule to address the KL vanishing problem.", "target": "This paper presents the Mutual Learning and Large-Margin Contrastive Learning (ML-LMCL), a framework aiming to improve ASR robustness in SLU through combined fine-tuning on both manual and ASR transcripts using two separate SLU models in a mutual learning setting. The framework also includes a distance polarization regularizer to prevent separating intra-cluster pairs and employs a cyclical annealing schedule to address the KL vanishing problem.", "example": "Convert the coordinate to text: [ 2.1286 -4.2885]:"}
{"text": "Convert the coordinate to text: [-5.6384 -3.1331]: This paper proposes a retrieval-based neural ASTE approach, named RLI, that exploits the label information of semantic similar triplets, retrieved from the training corpus. To capture both similar semantics and sentiments, a simple yet effective pre-training method is designed for the retriever.", "target": "This paper proposes a retrieval-based neural ASTE approach, named RLI, that exploits the label information of semantic similar triplets, retrieved from the training corpus. To capture both similar semantics and sentiments, a simple yet effective pre-training method is designed for the retriever.", "example": "Convert the coordinate to text: [-5.6384 -3.1331]:"}
{"text": "Convert the coordinate to text: [-3.8853 -3.4475]: The authors propose an end-to-end approach for QAU that jointly solves Named Entity Recognition (NER) and Entity Linking (NEL) and enables open-world reasoning. They also introduce a method for utilizing product graphs to enhance the representation of query entities.", "target": "The authors propose an end-to-end approach for QAU that jointly solves Named Entity Recognition (NER) and Entity Linking (NEL) and enables open-world reasoning. They also introduce a method for utilizing product graphs to enhance the representation of query entities.", "example": "Convert the coordinate to text: [-3.8853 -3.4475]:"}
{"text": "Convert the coordinate to text: [1.4078 2.825 ]: The authors propose using a Structural Causal Model (SCM) to understand demonstration-based learning from causal perspectives and interpret random demonstrations as interventions on the demonstration variable within the causal model.", "target": "The authors propose using a Structural Causal Model (SCM) to understand demonstration-based learning from causal perspectives and interpret random demonstrations as interventions on the demonstration variable within the causal model.", "example": "Convert the coordinate to text: [1.4078 2.825 ]:"}
{"text": "Convert the coordinate to text: [11.4779 -1.059 ]: The authors propose to extend beyond NTKs and develop a more comprehensive theory that can work for networks of differing widths. They construct an exact power-series representation of the neural network and apply the perspective of reproducing kernel Banach space (RKBS) to analyze neural network training.", "target": "The authors propose to extend beyond NTKs and develop a more comprehensive theory that can work for networks of differing widths. They construct an exact power-series representation of the neural network and apply the perspective of reproducing kernel Banach space (RKBS) to analyze neural network training.", "example": "Convert the coordinate to text: [11.4779 -1.059 ]:"}
{"text": "Convert the coordinate to text: [ 4.3488 -7.7846]: The authors propose a novel memory and attention framework, MAMo, that enhances single-image depth estimation networks into video depth estimation models, which can use temporal information to predict more accurate depth. The memory stores learned visual and displacement tokens from previous instances allowing the network to refer to past features when predicting current frame depth.", "target": "The authors propose a novel memory and attention framework, MAMo, that enhances single-image depth estimation networks into video depth estimation models, which can use temporal information to predict more accurate depth. The memory stores learned visual and displacement tokens from previous instances allowing the network to refer to past features when predicting current frame depth.", "example": "Convert the coordinate to text: [ 4.3488 -7.7846]:"}
{"text": "Convert the coordinate to text: [ 7.4499 12.2625]: This study introduces the Augmented Proximal Policy Optimization (APPO), an algorithm that augments the Lagrangian function of the primal constrained problem with a quadratic deviation term, in order to control safety costs precisely and achieve stable convergence.", "target": "This study introduces the Augmented Proximal Policy Optimization (APPO), an algorithm that augments the Lagrangian function of the primal constrained problem with a quadratic deviation term, in order to control safety costs precisely and achieve stable convergence.", "example": "Convert the coordinate to text: [ 7.4499 12.2625]:"}
{"text": "Convert the coordinate to text: [11.9672  6.7972]: The authors hypothesize that GBML implicitly suppresses the Hessian along the optimization trajectory in the inner loop. They introduce an algorithm called SHOT (Suppressing the Hessian along the Optimization Trajectory) that minimizes the distance between the parameters of the target and reference models to suppress the Hessian in the inner loop.", "target": "The authors hypothesize that GBML implicitly suppresses the Hessian along the optimization trajectory in the inner loop. They introduce an algorithm called SHOT (Suppressing the Hessian along the Optimization Trajectory) that minimizes the distance between the parameters of the target and reference models to suppress the Hessian in the inner loop.", "example": "Convert the coordinate to text: [11.9672  6.7972]:"}
{"text": "Convert the coordinate to text: [12.121  -3.5111]: The study develops the first certifiably robust framework in GCL by proposing a unified criteria to evaluate and certify the robustness of GCL and introducing a novel technique, Randomized Edgedrop Smoothing (RES), to ensure certifiable robustness for any GCL model.", "target": "The study develops the first certifiably robust framework in GCL by proposing a unified criteria to evaluate and certify the robustness of GCL and introducing a novel technique, Randomized Edgedrop Smoothing (RES), to ensure certifiable robustness for any GCL model.", "example": "Convert the coordinate to text: [12.121  -3.5111]:"}
{"text": "Convert the coordinate to text: [ 4.6244 10.969 ]: The authors propose a novel algorithm, named the Probability Tree State Abstraction (PTSA), that leverages a general tree state abstraction with path transitivity, which is designed to reduce errors during the aggregation stage and improve MCTS search efficiency.", "target": "The authors propose a novel algorithm, named the Probability Tree State Abstraction (PTSA), that leverages a general tree state abstraction with path transitivity, which is designed to reduce errors during the aggregation stage and improve MCTS search efficiency.", "example": "Convert the coordinate to text: [ 4.6244 10.969 ]:"}
{"text": "Convert the coordinate to text: [  9.0504 -11.7074]: A feature point cloud aggregation framework is proposed to directly propagate 3D depth information between given points and missing ones. This involves extracting a 2D feature map from images and transforming a sparse depth map into a point cloud to extract sparse 3D features. Depth information for a target location is then reconstructed by aggregating adjacent sparse 3D features from known points using cross attention. A neural network called PointDC is designed based on this idea.", "target": "A feature point cloud aggregation framework is proposed to directly propagate 3D depth information between given points and missing ones. This involves extracting a 2D feature map from images and transforming a sparse depth map into a point cloud to extract sparse 3D features. Depth information for a target location is then reconstructed by aggregating adjacent sparse 3D features from known points using cross attention. A neural network called PointDC is designed based on this idea.", "example": "Convert the coordinate to text: [  9.0504 -11.7074]:"}
{"text": "Convert the coordinate to text: [  5.7839 -18.4054]: This study proposes a diffusion-based framework for low-light image enhancement that includes a regularization of the ODE-trajectory of the diffusion process. This regularization, termed global structure-aware regularization, is rooted in the intrinsic non-local structures of image data and gradually enhances contrast while preserving complex details. Furthermore, an uncertainty-guided regularization technique is introduced to facilitate learning in challenging areas of the image.", "target": "This study proposes a diffusion-based framework for low-light image enhancement that includes a regularization of the ODE-trajectory of the diffusion process. This regularization, termed global structure-aware regularization, is rooted in the intrinsic non-local structures of image data and gradually enhances contrast while preserving complex details. Furthermore, an uncertainty-guided regularization technique is introduced to facilitate learning in challenging areas of the image.", "example": "Convert the coordinate to text: [  5.7839 -18.4054]:"}
{"text": "Convert the coordinate to text: [8.3834 3.5105]: The authors propose an analytical investigation of how over-parameterization influences privacy, using a bound for the Kullback-Leibler (KL) divergence between model distributions on neighboring datasets. They find this privacy bound is largely determined by the expected squared gradient norm relative to model parameters during training.", "target": "The authors propose an analytical investigation of how over-parameterization influences privacy, using a bound for the Kullback-Leibler (KL) divergence between model distributions on neighboring datasets. They find this privacy bound is largely determined by the expected squared gradient norm relative to model parameters during training.", "example": "Convert the coordinate to text: [8.3834 3.5105]:"}
{"text": "Convert the coordinate to text: [-0.0292  7.7161]: The authors propose DiffLogic, a differentiable framework that effectively approximates all possible triples' truth scores. This is achieved through a tailored filter that selects essential triples based on the dynamic rules and weights, and a continuous Markov logic network named probabilistic soft logic (PSL).", "target": "The authors propose DiffLogic, a differentiable framework that effectively approximates all possible triples' truth scores. This is achieved through a tailored filter that selects essential triples based on the dynamic rules and weights, and a continuous Markov logic network named probabilistic soft logic (PSL).", "example": "Convert the coordinate to text: [-0.0292  7.7161]:"}
{"text": "Convert the coordinate to text: [  2.0314 -15.9495]: The authors introduce a new framework for understanding stimulus discriminability achieved by retinal representations of naturalistic stimuli, using information geometry. They also use a stochastic encoding model of a population of salamander retinal ganglion cells, based on a three-layer convolutional neural network model.", "target": "The authors introduce a new framework for understanding stimulus discriminability achieved by retinal representations of naturalistic stimuli, using information geometry. They also use a stochastic encoding model of a population of salamander retinal ganglion cells, based on a three-layer convolutional neural network model.", "example": "Convert the coordinate to text: [  2.0314 -15.9495]:"}
{"text": "Convert the coordinate to text: [-1.0326 -2.9525]: The paper introduces a Retrieval Augmented Sequential Model Editing framework (RASE) that uses factual information to enhance editing generalization and to guide the identification of edits by retrieving related facts from a constructed fact-patch memory.", "target": "The paper introduces a Retrieval Augmented Sequential Model Editing framework (RASE) that uses factual information to enhance editing generalization and to guide the identification of edits by retrieving related facts from a constructed fact-patch memory.", "example": "Convert the coordinate to text: [-1.0326 -2.9525]:"}
{"text": "Convert the coordinate to text: [8.7344 5.2775]: An Adaptive IMLE (AIMLE) is proposed, representing the first adaptive gradient estimator for complex discrete distributions. It adaptively identifies the target distribution for IMLE by trading off the density of gradient information with the degree of bias in gradient estimates.", "target": "An Adaptive IMLE (AIMLE) is proposed, representing the first adaptive gradient estimator for complex discrete distributions. It adaptively identifies the target distribution for IMLE by trading off the density of gradient information with the degree of bias in gradient estimates.", "example": "Convert the coordinate to text: [8.7344 5.2775]:"}
{"text": "Convert the coordinate to text: [-2.4669 -6.6373]: The authors propose fine-tuning pre-trained transformer-based language models to tackle the multilingual character and large number of predicted labels in SemEval 2023 Task 3.", "target": "The authors propose fine-tuning pre-trained transformer-based language models to tackle the multilingual character and large number of predicted labels in SemEval 2023 Task 3.", "example": "Convert the coordinate to text: [-2.4669 -6.6373]:"}
{"text": "Convert the coordinate to text: [-3.1367 -4.1687]: The authors present a task to investigate the ability of a language model in inferring the final state of an entity given an English description of the initial state and a series of state-changing operations.", "target": "The authors present a task to investigate the ability of a language model in inferring the final state of an entity given an English description of the initial state and a series of state-changing operations.", "example": "Convert the coordinate to text: [-3.1367 -4.1687]:"}
{"text": "Convert the coordinate to text: [-2.1225 -5.3022]: The researchers conduct a comprehensive assessment of ChatGPT's abilities in causal reasoning, investigating aspects like its response to different prompt styles and its handling of explicit and implicit causality.", "target": "The researchers conduct a comprehensive assessment of ChatGPT's abilities in causal reasoning, investigating aspects like its response to different prompt styles and its handling of explicit and implicit causality.", "example": "Convert the coordinate to text: [-2.1225 -5.3022]:"}
{"text": "Convert the coordinate to text: [ 2.9143 -5.5246]: The paper proposes a taxonomy-aware multi-level hypergraph neural network (TM-HGNN) that assembles useful neutral words with rare keywords via note and taxonomy level hyperedges to retain the clinical semantic information. This approach addresses the limitations of frequent neutral words and uneven hierarchies that can degrade clinical semantic information.", "target": "The paper proposes a taxonomy-aware multi-level hypergraph neural network (TM-HGNN) that assembles useful neutral words with rare keywords via note and taxonomy level hyperedges to retain the clinical semantic information. This approach addresses the limitations of frequent neutral words and uneven hierarchies that can degrade clinical semantic information.", "example": "Convert the coordinate to text: [ 2.9143 -5.5246]:"}
{"text": "Convert the coordinate to text: [-1.0432 -5.    ]: This paper proposes a zero-shot approach to automatically generate multiple prompts similar to a base prompt using positional, reasoning, and paraphrasing techniques, and then ranks these prompts using a new metric, eliminating the need for labelled instances.", "target": "This paper proposes a zero-shot approach to automatically generate multiple prompts similar to a base prompt using positional, reasoning, and paraphrasing techniques, and then ranks these prompts using a new metric, eliminating the need for labelled instances.", "example": "Convert the coordinate to text: [-1.0432 -5.    ]:"}
{"text": "Convert the coordinate to text: [11.6351  7.6969]: The authors propose a memory-efficient zeroth-order optimizer (MeZO), which adapts the classical Zeroth-order Stochastic Gradient Descent method to operate in-place, and thereby fine-tuning language models with the same memory footprint as inference.", "target": "The authors propose a memory-efficient zeroth-order optimizer (MeZO), which adapts the classical Zeroth-order Stochastic Gradient Descent method to operate in-place, and thereby fine-tuning language models with the same memory footprint as inference.", "example": "Convert the coordinate to text: [11.6351  7.6969]:"}
{"text": "Convert the coordinate to text: [-5.7663 10.4305]: The authors propose an extension of persona-based dialogue to the multimodal domain and introduce a dataset, MPCHAT, which combines text and images to represent episodic memories in persona.", "target": "The authors propose an extension of persona-based dialogue to the multimodal domain and introduce a dataset, MPCHAT, which combines text and images to represent episodic memories in persona.", "example": "Convert the coordinate to text: [-5.7663 10.4305]:"}
{"text": "Convert the coordinate to text: [-15.7339  16.7901]: The study proposes a method to generate lyrics without utilizing any melody-lyric aligned data. It devises a hierarchical lyric generation framework that first generates a song outline and then the complete lyrics, thus separating the training process based on text from the inference process of melody-guided text generation.", "target": "The study proposes a method to generate lyrics without utilizing any melody-lyric aligned data. It devises a hierarchical lyric generation framework that first generates a song outline and then the complete lyrics, thus separating the training process based on text from the inference process of melody-guided text generation.", "example": "Convert the coordinate to text: [-15.7339  16.7901]:"}
{"text": "Convert the coordinate to text: [-4.4939  0.6234]: The authors propose a novel solution, One-ASQP, that detects aspect categories and identifies the aspect-opinion-sentiment (AOS) triplets simultaneously. They also introduce two larger, higher-density datasets for ASQP.", "target": "The authors propose a novel solution, One-ASQP, that detects aspect categories and identifies the aspect-opinion-sentiment (AOS) triplets simultaneously. They also introduce two larger, higher-density datasets for ASQP.", "example": "Convert the coordinate to text: [-4.4939  0.6234]:"}
{"text": "Convert the coordinate to text: [-1.9104 -5.3873]: The paper presents FLamE, a two-stage few-shot learning framework that generates explanations using GPT-3 and finetunes a smaller model with these generated explanations.", "target": "The paper presents FLamE, a two-stage few-shot learning framework that generates explanations using GPT-3 and finetunes a smaller model with these generated explanations.", "example": "Convert the coordinate to text: [-1.9104 -5.3873]:"}
{"text": "Convert the coordinate to text: [-4.5086 -2.4231]: This study argues that the operationalization of the neutral label in current NLI datasets has low validity, is interpreted inconsistently, and often ignores at least one important sense of neutrality.", "target": "This study argues that the operationalization of the neutral label in current NLI datasets has low validity, is interpreted inconsistently, and often ignores at least one important sense of neutrality.", "example": "Convert the coordinate to text: [-4.5086 -2.4231]:"}
{"text": "Convert the coordinate to text: [ 2.4414 -0.3173]: The paper proposes an adaptive ordered IE paradigm that can find the optimal element extraction order for different instances, aiming to achieve the best extraction results. It also introduces a co-training framework adapted to Reinforcement Learning (RL) to lessen the exposure bias during the extractor training phase.", "target": "The paper proposes an adaptive ordered IE paradigm that can find the optimal element extraction order for different instances, aiming to achieve the best extraction results. It also introduces a co-training framework adapted to Reinforcement Learning (RL) to lessen the exposure bias during the extractor training phase.", "example": "Convert the coordinate to text: [ 2.4414 -0.3173]:"}
{"text": "Convert the coordinate to text: [-1.0651 -4.8957]: The authors introduce a benchmark called CodeTask-CL for a wide range of tasks including code generation, translation, summarization, and refinement, in different programming languages. They also propose a method called Prompt Pooling with Teacher Forcing (PP-TF) to address the issue of catastrophic forgetting in continual learning scenarios.", "target": "The authors introduce a benchmark called CodeTask-CL for a wide range of tasks including code generation, translation, summarization, and refinement, in different programming languages. They also propose a method called Prompt Pooling with Teacher Forcing (PP-TF) to address the issue of catastrophic forgetting in continual learning scenarios.", "example": "Convert the coordinate to text: [-1.0651 -4.8957]:"}
{"text": "Convert the coordinate to text: [-4.1504 -6.4178]: The authors propose to augment existing datasets with disfluent user utterances by paraphrasing fluent utterances into disfluent ones, using a few-shot disfluent paraphraser guided by a disfluency classifier.", "target": "The authors propose to augment existing datasets with disfluent user utterances by paraphrasing fluent utterances into disfluent ones, using a few-shot disfluent paraphraser guided by a disfluency classifier.", "example": "Convert the coordinate to text: [-4.1504 -6.4178]:"}
{"text": "Convert the coordinate to text: [-2.3049 -6.104 ]: The researchers proposed a new approach of data augmentation for NER by combining various strategies of sequence generation for training, and fine-tuning a pre-trained language model.", "target": "The researchers proposed a new approach of data augmentation for NER by combining various strategies of sequence generation for training, and fine-tuning a pre-trained language model.", "example": "Convert the coordinate to text: [-2.3049 -6.104 ]:"}
{"text": "Convert the coordinate to text: [18.5422 -3.1894]: The key idea in the paper is to fine-tune pre-trained models to fit the spoiler classification task, which is part of the Clickbait Spoiling task.", "target": "The key idea in the paper is to fine-tune pre-trained models to fit the spoiler classification task, which is part of the Clickbait Spoiling task.", "example": "Convert the coordinate to text: [18.5422 -3.1894]:"}
{"text": "Convert the coordinate to text: [-3.5527  1.1065]: The paper proposes an XGBoost-based ensemble model trained on emoticon frequency-based features and the predictions of several statistical models such as SVMs, Logistic Regression, Random Forest, and BERT-based pre-trained language models such as AfriBERTa and AfroXLMR.", "target": "The paper proposes an XGBoost-based ensemble model trained on emoticon frequency-based features and the predictions of several statistical models such as SVMs, Logistic Regression, Random Forest, and BERT-based pre-trained language models such as AfriBERTa and AfroXLMR.", "example": "Convert the coordinate to text: [-3.5527  1.1065]:"}
{"text": "Convert the coordinate to text: [-1.3884 -3.6375]: This paper introduces the Hybrid Hierarchical Retrieval (HHR) to overcome the limitations in the existing models. HHR applies a sparse retriever, dense retriever, and a combination of both in both stages of document and passage retrieval, thus eliminating the need to solely rely on dense retrievers.", "target": "This paper introduces the Hybrid Hierarchical Retrieval (HHR) to overcome the limitations in the existing models. HHR applies a sparse retriever, dense retriever, and a combination of both in both stages of document and passage retrieval, thus eliminating the need to solely rely on dense retrievers.", "example": "Convert the coordinate to text: [-1.3884 -3.6375]:"}
{"text": "Convert the coordinate to text: [-0.9839 -5.1353]: The paper introduces a novel generative model enhanced by multimodal prompt retrieval (MPR), which merges retrieved prompts and multimodal features to produce answers in free text offering enhancement on data adaptability and handling open-set answer labels across datasets.", "target": "The paper introduces a novel generative model enhanced by multimodal prompt retrieval (MPR), which merges retrieved prompts and multimodal features to produce answers in free text offering enhancement on data adaptability and handling open-set answer labels across datasets.", "example": "Convert the coordinate to text: [-0.9839 -5.1353]:"}
{"text": "Convert the coordinate to text: [-4.3795 -6.0644]: The authors propose to enhance the NLU capabilities of Indic languages by creating the largest monolingual corpus (IndicCorp), a human-supervised benchmark (IndicXTREME), and a state-of-the-art model (IndicBERT v2) that supports all the Indic languages.", "target": "The authors propose to enhance the NLU capabilities of Indic languages by creating the largest monolingual corpus (IndicCorp), a human-supervised benchmark (IndicXTREME), and a state-of-the-art model (IndicBERT v2) that supports all the Indic languages.", "example": "Convert the coordinate to text: [-4.3795 -6.0644]:"}
{"text": "Convert the coordinate to text: [-1.2125 -3.2213]: In this study, the authors present KG-Roar, an interactive development and navigation environment for logical KGs that allows users to augment an input graph database and convert it into a KG by providing intensional definitions of new nodes and edges in the Vadalog language.", "target": "In this study, the authors present KG-Roar, an interactive development and navigation environment for logical KGs that allows users to augment an input graph database and convert it into a KG by providing intensional definitions of new nodes and edges in the Vadalog language.", "example": "Convert the coordinate to text: [-1.2125 -3.2213]:"}
{"text": "Convert the coordinate to text: [11.8138 -5.7032]: The authors propose a new purification strategy called PointDP, which uses diffusion models to defend against 3D adversarial attacks. Uniquely, PointDP does not rely on predefined adversarial examples for training and thus can counter a variety of threats.", "target": "The authors propose a new purification strategy called PointDP, which uses diffusion models to defend against 3D adversarial attacks. Uniquely, PointDP does not rely on predefined adversarial examples for training and thus can counter a variety of threats.", "example": "Convert the coordinate to text: [11.8138 -5.7032]:"}
{"text": "Convert the coordinate to text: [  6.9711 -20.4541]: This paper proposes a novel diffusion-based solution for unsupervised shadow removal, which separately models the shadow, non-shadow, and their boundary regions, and introduces a Shadow-Invariant Intrinsic Decomposition module to maintain structural consistency during the diffusive sampling.", "target": "This paper proposes a novel diffusion-based solution for unsupervised shadow removal, which separately models the shadow, non-shadow, and their boundary regions, and introduces a Shadow-Invariant Intrinsic Decomposition module to maintain structural consistency during the diffusive sampling.", "example": "Convert the coordinate to text: [  6.9711 -20.4541]:"}
{"text": "Convert the coordinate to text: [12.13   -5.0159]: The authors introduce TRM-UAP, a data-free universal attack that employs truncated ratio maximization to generate UAPs. This strategy deviates from previous models by optimizing the UAP generation based on the ratio of positive and negative activations, rather than just the positive activation.", "target": "The authors introduce TRM-UAP, a data-free universal attack that employs truncated ratio maximization to generate UAPs. This strategy deviates from previous models by optimizing the UAP generation based on the ratio of positive and negative activations, rather than just the positive activation.", "example": "Convert the coordinate to text: [12.13   -5.0159]:"}
{"text": "Convert the coordinate to text: [ 5.2205 -7.9101]: The authors propose a Trajectory Memory Retrieval Network (TMRN) that reconciles the inherent tension of spatial and temporal information to retrieve memory frame information along the object trajectory. This includes a spatial alignment module and a temporal aggregation module.", "target": "The authors propose a Trajectory Memory Retrieval Network (TMRN) that reconciles the inherent tension of spatial and temporal information to retrieve memory frame information along the object trajectory. This includes a spatial alignment module and a temporal aggregation module.", "example": "Convert the coordinate to text: [ 5.2205 -7.9101]:"}
{"text": "Convert the coordinate to text: [ 4.6684 -2.8314]: The authors propose a novel framework for TFCL that expands the architecture of a DEM model using a self-assessment mechanism, taking into account the diversity of knowledge among existing experts as expansion signals. They also propose a novelty-aware sample selection method to increase diversity among experts by making newly added experts learn novel information from data streams, reuse representing information from previous learning to learn new incoming data, which hasn't been explored before in TFCL.", "target": "The authors propose a novel framework for TFCL that expands the architecture of a DEM model using a self-assessment mechanism, taking into account the diversity of knowledge among existing experts as expansion signals. They also propose a novelty-aware sample selection method to increase diversity among experts by making newly added experts learn novel information from data streams, reuse representing information from previous learning to learn new incoming data, which hasn't been explored before in TFCL.", "example": "Convert the coordinate to text: [ 4.6684 -2.8314]:"}
{"text": "Convert the coordinate to text: [4.543  0.5622]: The authors introduce a new reset-based method that uses deep ensemble learning to address the limitations of the conventional reset method and to improve sample efficiency.", "target": "The authors introduce a new reset-based method that uses deep ensemble learning to address the limitations of the conventional reset method and to improve sample efficiency.", "example": "Convert the coordinate to text: [4.543  0.5622]:"}
{"text": "Convert the coordinate to text: [-2.2693 11.222 ]: The authors introduce the Reasoning Game, a cognition-oriented environment that encourages agents to reason and communicate high-level rules rather than perceived low-level contexts, and an unbiased dataset (rule-RAVEN) to avoid overfitting.", "target": "The authors introduce the Reasoning Game, a cognition-oriented environment that encourages agents to reason and communicate high-level rules rather than perceived low-level contexts, and an unbiased dataset (rule-RAVEN) to avoid overfitting.", "example": "Convert the coordinate to text: [-2.2693 11.222 ]:"}
{"text": "Convert the coordinate to text: [8.7871 5.1424]: This paper explores the use of polynomial approximations, specifically Taylor and Legendre, to the entropy of GMM. Motivated by the divergence of existing series under simple conditions, a novel Taylor series approximation to the entropy of any GMM that is provably convergent is proposed.", "target": "This paper explores the use of polynomial approximations, specifically Taylor and Legendre, to the entropy of GMM. Motivated by the divergence of existing series under simple conditions, a novel Taylor series approximation to the entropy of any GMM that is provably convergent is proposed.", "example": "Convert the coordinate to text: [8.7871 5.1424]:"}
{"text": "Convert the coordinate to text: [ 6.8884 -3.5464]: To deal with mixed-class scenarios in SSDG, the authors propose the Class-Wise Adaptive Exploration and Exploitation (CWAEE) method. This method leverages one-vs-rest classifiers and class-wise adaptive thresholds to distinguish known and unknown classes and uses consistency regularization on Fourier-transformed augmented samples for unseen domain generalization.", "target": "To deal with mixed-class scenarios in SSDG, the authors propose the Class-Wise Adaptive Exploration and Exploitation (CWAEE) method. This method leverages one-vs-rest classifiers and class-wise adaptive thresholds to distinguish known and unknown classes and uses consistency regularization on Fourier-transformed augmented samples for unseen domain generalization.", "example": "Convert the coordinate to text: [ 6.8884 -3.5464]:"}
{"text": "Convert the coordinate to text: [-7.2583 -6.3405]: The authors present a Multi-Word Tokenizer (MWT) that goes beyond word boundaries by representing frequent multi-word expressions as single tokens. This creates a more compact and efficient tokenization.", "target": "The authors present a Multi-Word Tokenizer (MWT) that goes beyond word boundaries by representing frequent multi-word expressions as single tokens. This creates a more compact and efficient tokenization.", "example": "Convert the coordinate to text: [-7.2583 -6.3405]:"}
{"text": "Convert the coordinate to text: [  9.7462 -19.1554]: The authors introduce a novel system, dubbed MSMD-Fusion, that optimizes utilization of depth information and ensures fine-grained cross-modal interaction between LiDAR and camera. This is achieved through the proposed Multi-Depth Unprojection (MDU) method and Gated Modality-Aware Convolution (GMA-Conv) block.", "target": "The authors introduce a novel system, dubbed MSMD-Fusion, that optimizes utilization of depth information and ensures fine-grained cross-modal interaction between LiDAR and camera. This is achieved through the proposed Multi-Depth Unprojection (MDU) method and Gated Modality-Aware Convolution (GMA-Conv) block.", "example": "Convert the coordinate to text: [  9.7462 -19.1554]:"}
{"text": "Convert the coordinate to text: [-2.092   4.2413]: The authors propose leveraging timestamps indicating the 'birth dates' of data, which are often overlooked, to develop a temporal threat model of data poisoning. They introduce two unique metrics, 'earliness' and 'duration', to measure the starting time and longevity of an attack.", "target": "The authors propose leveraging timestamps indicating the 'birth dates' of data, which are often overlooked, to develop a temporal threat model of data poisoning. They introduce two unique metrics, 'earliness' and 'duration', to measure the starting time and longevity of an attack.", "example": "Convert the coordinate to text: [-2.092   4.2413]:"}
{"text": "Convert the coordinate to text: [10.9986  7.0337]: The authors suggest a novel combination of three techniques significantly mitigating communication costs for resolving variational inequalities: using the similarity of local functions, compressing transmitted information, and performing local updates. Such an approach has not been used before for variational inequalities and saddle problems, nor for minimization problems.", "target": "The authors suggest a novel combination of three techniques significantly mitigating communication costs for resolving variational inequalities: using the similarity of local functions, compressing transmitted information, and performing local updates. Such an approach has not been used before for variational inequalities and saddle problems, nor for minimization problems.", "example": "Convert the coordinate to text: [10.9986  7.0337]:"}
{"text": "Convert the coordinate to text: [1.9143 8.8947]: The paper focuses on the CardMinSat problem, which investigates whether a given atom x is true in some cardinality-minimal model of a given formula F.", "target": "The paper focuses on the CardMinSat problem, which investigates whether a given atom x is true in some cardinality-minimal model of a given formula F.", "example": "Convert the coordinate to text: [1.9143 8.8947]:"}
{"text": "Convert the coordinate to text: [-3.18   -6.9455]: The authors propose a system that uses language-adaptive and task-adaptive pretraining on African texts and explores transfer learning with source language selection on top of an African language-centric pretrained language model.", "target": "The authors propose a system that uses language-adaptive and task-adaptive pretraining on African texts and explores transfer learning with source language selection on top of an African language-centric pretrained language model.", "example": "Convert the coordinate to text: [-3.18   -6.9455]:"}
{"text": "Convert the coordinate to text: [ 4.8147 14.8693]: This paper proposes a novel approach named InitLight, based on Adversarial Inverse Reinforcement Learning (AIRL), which generates an effective initial model to improve the initial performance in multi-intersection traffic signal control.", "target": "This paper proposes a novel approach named InitLight, based on Adversarial Inverse Reinforcement Learning (AIRL), which generates an effective initial model to improve the initial performance in multi-intersection traffic signal control.", "example": "Convert the coordinate to text: [ 4.8147 14.8693]:"}
{"text": "Convert the coordinate to text: [-2.2356 -5.3334]: The authors introduce a new technique for automatically generating summaries of lecture videos using advanced language models like GPT-3.", "target": "The authors introduce a new technique for automatically generating summaries of lecture videos using advanced language models like GPT-3.", "example": "Convert the coordinate to text: [-2.2356 -5.3334]:"}
{"text": "Convert the coordinate to text: [ 4.0549 -5.7737]: The authors propose a Relation-gated Heterogeneous Graph Network (RHGN) for entity alignment. RHGN distinguishes entities and relations in a KG using a relation-gated convolutional layer; it addresses the neighbor heterogeneity and relation heterogeneity between different KGs via a cross-graph embedding exchange module and a soft relation alignment module.", "target": "The authors propose a Relation-gated Heterogeneous Graph Network (RHGN) for entity alignment. RHGN distinguishes entities and relations in a KG using a relation-gated convolutional layer; it addresses the neighbor heterogeneity and relation heterogeneity between different KGs via a cross-graph embedding exchange module and a soft relation alignment module.", "example": "Convert the coordinate to text: [ 4.0549 -5.7737]:"}
{"text": "Convert the coordinate to text: [13.4272 -4.7122]: In opposition to the existing defense strategies, this paper presents a new approach where the backdoor attack is directly reversed by incorporating a maximum entropy loss in training to counteract the minimal cross-entropy loss fine-tuning done on poisoned data.", "target": "In opposition to the existing defense strategies, this paper presents a new approach where the backdoor attack is directly reversed by incorporating a maximum entropy loss in training to counteract the minimal cross-entropy loss fine-tuning done on poisoned data.", "example": "Convert the coordinate to text: [13.4272 -4.7122]:"}
{"text": "Convert the coordinate to text: [-3.9065 -4.9991]: The authors introduce a simplified approach to measure semantic change using contextual embeddings. This is achieved by relying only on the most probable substitutes for masked terms.", "target": "The authors introduce a simplified approach to measure semantic change using contextual embeddings. This is achieved by relying only on the most probable substitutes for masked terms.", "example": "Convert the coordinate to text: [-3.9065 -4.9991]:"}
{"text": "Convert the coordinate to text: [ 9.6379 -2.6389]: The authors propose to scale up the parameters of PLMs only during fine-tuning to benefit from over-parameterization, without increasing the inference latency. This is achieved by using a matrix product operator to factorize the parameter matrices of a relatively small PLM into a set of higher-dimensional tensors.", "target": "The authors propose to scale up the parameters of PLMs only during fine-tuning to benefit from over-parameterization, without increasing the inference latency. This is achieved by using a matrix product operator to factorize the parameter matrices of a relatively small PLM into a set of higher-dimensional tensors.", "example": "Convert the coordinate to text: [ 9.6379 -2.6389]:"}
{"text": "Convert the coordinate to text: [ 7.5098 -2.1703]: The authors propose a novel federated parameter propagation (FEDORA) framework for personalized federated learning. Their approach redefines federated learning as a privacy-preserving transfer learning problem, aiming to enhance the generalization performance for every individual client.", "target": "The authors propose a novel federated parameter propagation (FEDORA) framework for personalized federated learning. Their approach redefines federated learning as a privacy-preserving transfer learning problem, aiming to enhance the generalization performance for every individual client.", "example": "Convert the coordinate to text: [ 7.5098 -2.1703]:"}
{"text": "Convert the coordinate to text: [  5.1184 -14.18  ]: This paper proposes a novel model called Probabilistic Inter-Observer and iNtra-Observer variation NetwOrk (Pionono) that captures the labeling behavior of each rater with a multidimensional probability distribution and integrates this information with the feature maps of the image to produce probabilistic segmentation predictions.", "target": "This paper proposes a novel model called Probabilistic Inter-Observer and iNtra-Observer variation NetwOrk (Pionono) that captures the labeling behavior of each rater with a multidimensional probability distribution and integrates this information with the feature maps of the image to produce probabilistic segmentation predictions.", "example": "Convert the coordinate to text: [  5.1184 -14.18  ]:"}
{"text": "Convert the coordinate to text: [ 14.8108 -15.0775]: A novel neural representation, Strivec, is proposed which models a 3D scene as a radiance field with sparsely distributed and compactly factorized local tensor feature grids. Strivec differs from existing models by using a cloud of local tensors and apply CANDECOMP/PARAFAC (CP) decomposition to factorize each tensor into triple vectors.", "target": "A novel neural representation, Strivec, is proposed which models a 3D scene as a radiance field with sparsely distributed and compactly factorized local tensor feature grids. Strivec differs from existing models by using a cloud of local tensors and apply CANDECOMP/PARAFAC (CP) decomposition to factorize each tensor into triple vectors.", "example": "Convert the coordinate to text: [ 14.8108 -15.0775]:"}
{"text": "Convert the coordinate to text: [10.1749 -9.4365]: The authors address the challenge of low-light video enhancement by designing a camera system, collecting a high-quality low-light video dataset with multiple exposures and cameras, and proposing a novel Retinex-based method named Light Adjustable Network (LAN) for general low-light video enhancement.", "target": "The authors address the challenge of low-light video enhancement by designing a camera system, collecting a high-quality low-light video dataset with multiple exposures and cameras, and proposing a novel Retinex-based method named Light Adjustable Network (LAN) for general low-light video enhancement.", "example": "Convert the coordinate to text: [10.1749 -9.4365]:"}
{"text": "Convert the coordinate to text: [  8.8516 -16.6659]: The authors propose a new method for surface reconstruction that leverages only minimal supervision in the form of partial differential equations and properties of differential vector fields. Specifically, the $p$-Poisson equation is used to learn a signed distance function (SDF), with the reconstructed surface being implicitly represented by its zero-level set.", "target": "The authors propose a new method for surface reconstruction that leverages only minimal supervision in the form of partial differential equations and properties of differential vector fields. Specifically, the $p$-Poisson equation is used to learn a signed distance function (SDF), with the reconstructed surface being implicitly represented by its zero-level set.", "example": "Convert the coordinate to text: [  8.8516 -16.6659]:"}
{"text": "Convert the coordinate to text: [ 4.926  -2.3865]: The authors propose a novel SSL setting where unlabeled samples come from a mixed distribution that differs from the feature distribution of labeled samples, and present a solution \u2014 Self-Supervised Feature Adaptation (SSFA), a framework that adapts the feature extractor of the model to better suit the distribution of unlabeled data.", "target": "The authors propose a novel SSL setting where unlabeled samples come from a mixed distribution that differs from the feature distribution of labeled samples, and present a solution \u2014 Self-Supervised Feature Adaptation (SSFA), a framework that adapts the feature extractor of the model to better suit the distribution of unlabeled data.", "example": "Convert the coordinate to text: [ 4.926  -2.3865]:"}
{"text": "Convert the coordinate to text: [  9.6509 -16.5252]: The authors propose a generalized differentiable RANSAC ($ abla$-RANSAC) that allows learning the entire robust estimation pipeline, thus enabling better sampling distribution using relaxation techniques and marginalization over model scores to guide the network to learn accurate inlier probabilities.", "target": "The authors propose a generalized differentiable RANSAC ($ abla$-RANSAC) that allows learning the entire robust estimation pipeline, thus enabling better sampling distribution using relaxation techniques and marginalization over model scores to guide the network to learn accurate inlier probabilities.", "example": "Convert the coordinate to text: [  9.6509 -16.5252]:"}
{"text": "Convert the coordinate to text: [-4.1148 -5.6963]: The paper proposes a method to mine and generate self-supervised training data from a large-scale unlabeled corpus for better performance in multilingual retrieval tasks.", "target": "The paper proposes a method to mine and generate self-supervised training data from a large-scale unlabeled corpus for better performance in multilingual retrieval tasks.", "example": "Convert the coordinate to text: [-4.1148 -5.6963]:"}
{"text": "Convert the coordinate to text: [ 7.4166 -2.172 ]: The authors propose the framework FedAMD, which uses anchor sampling to split the participating clients into anchor and miner groups. Anchor clients aim for local optimality using large batch computations, while miner clients steer multiple near-optimal updates using small batches to update the global model.", "target": "The authors propose the framework FedAMD, which uses anchor sampling to split the participating clients into anchor and miner groups. Anchor clients aim for local optimality using large batch computations, while miner clients steer multiple near-optimal updates using small batches to update the global model.", "example": "Convert the coordinate to text: [ 7.4166 -2.172 ]:"}
{"text": "Convert the coordinate to text: [ 2.9874 -0.2058]: The authors illuminate the limitations and challenges that arise from treating pre-annotated datasets as the pool of unlabeled data in active learning (AL) simulations, and argue that such practices may only yield a lower bound estimation of the effectiveness of active learning algorithms in real life scenarios.", "target": "The authors illuminate the limitations and challenges that arise from treating pre-annotated datasets as the pool of unlabeled data in active learning (AL) simulations, and argue that such practices may only yield a lower bound estimation of the effectiveness of active learning algorithms in real life scenarios.", "example": "Convert the coordinate to text: [ 2.9874 -0.2058]:"}
{"text": "Convert the coordinate to text: [-9.8675 -5.2254]: The authors propose 'RSTformer', a novel summarization model that comprehensively includes both the types and uncertainty of rhetorical relations.", "target": "The authors propose 'RSTformer', a novel summarization model that comprehensively includes both the types and uncertainty of rhetorical relations.", "example": "Convert the coordinate to text: [-9.8675 -5.2254]:"}
{"text": "Convert the coordinate to text: [ 0.3262 -7.2558]: The authors argue that the inability of Transformers to generalize to longer sequences is due to positional encodings being out-of-distribution for those sequences. They introduce a new family of positional encodings that can address this problem.", "target": "The authors argue that the inability of Transformers to generalize to longer sequences is due to positional encodings being out-of-distribution for those sequences. They introduce a new family of positional encodings that can address this problem.", "example": "Convert the coordinate to text: [ 0.3262 -7.2558]:"}
{"text": "Convert the coordinate to text: [-10.2707   8.9701]: The study introduces TimelineQA, a benchmark for accelerating progress on querying lifelogs. These lifelogs contain various types of experiences, from major life events to daily occurrences, of imaginary individuals.", "target": "The study introduces TimelineQA, a benchmark for accelerating progress on querying lifelogs. These lifelogs contain various types of experiences, from major life events to daily occurrences, of imaginary individuals.", "example": "Convert the coordinate to text: [-10.2707   8.9701]:"}
{"text": "Convert the coordinate to text: [ 1.9931 -3.6735]: The authors propose an improved contrastive learning objective called 'contrastive loss with SAMe TOwer NEgatives' (SamToNe), which adds queries or documents from the same encoder towers to the negatives.", "target": "The authors propose an improved contrastive learning objective called 'contrastive loss with SAMe TOwer NEgatives' (SamToNe), which adds queries or documents from the same encoder towers to the negatives.", "example": "Convert the coordinate to text: [ 1.9931 -3.6735]:"}
{"text": "Convert the coordinate to text: [-7.0682 -1.0966]: In the SemEval-2023 Task 8, the authors introduce the task of identifying causal medical claims and extracting related Populations, Interventions, and Outcomes ('PIO') frames from social media text, intending to stimulate more research in this area.", "target": "In the SemEval-2023 Task 8, the authors introduce the task of identifying causal medical claims and extracting related Populations, Interventions, and Outcomes ('PIO') frames from social media text, intending to stimulate more research in this area.", "example": "Convert the coordinate to text: [-7.0682 -1.0966]:"}
{"text": "Convert the coordinate to text: [18.5374 -3.1861]: The authors propose an Information Condensation-based approach to prune unnecessary context and pinpoint the most relevant paragraphs corresponding to the clickbait. The selected information is then used for spoiler type classification and spoiler generation.", "target": "The authors propose an Information Condensation-based approach to prune unnecessary context and pinpoint the most relevant paragraphs corresponding to the clickbait. The selected information is then used for spoiler type classification and spoiler generation.", "example": "Convert the coordinate to text: [18.5374 -3.1861]:"}
{"text": "Convert the coordinate to text: [-3.2724 -8.5701]: This paper proposes a speech translation system that employs three strategies: data augmentation on both text and audio samples, an ensemble model that integrates models trained using various augmentation strategies, and post-processing techniques that utilize large language models to enhance sentence quality.", "target": "This paper proposes a speech translation system that employs three strategies: data augmentation on both text and audio samples, an ensemble model that integrates models trained using various augmentation strategies, and post-processing techniques that utilize large language models to enhance sentence quality.", "example": "Convert the coordinate to text: [-3.2724 -8.5701]:"}
{"text": "Convert the coordinate to text: [-7.0783 -6.2679]: The authors present a corpus of parallel German-language simplified newspaper articles, which are annotated according to the RST framework.", "target": "The authors present a corpus of parallel German-language simplified newspaper articles, which are annotated according to the RST framework.", "example": "Convert the coordinate to text: [-7.0783 -6.2679]:"}
{"text": "Convert the coordinate to text: [ 6.5817 -8.4349]: The paper proposes a Robust Addressee Recognition (RAR) method that discretizes addressees into a character codebook. Thus, it can represent open set addressees and enhance robustness in noisy environments.", "target": "The paper proposes a Robust Addressee Recognition (RAR) method that discretizes addressees into a character codebook. Thus, it can represent open set addressees and enhance robustness in noisy environments.", "example": "Convert the coordinate to text: [ 6.5817 -8.4349]:"}
{"text": "Convert the coordinate to text: [ 0.4718 -4.8012]: The authors introduce a sub-structure level compositional data augmentation method, Compo, to generate diverse and high-quality pairs of conversations and summaries by extracting basic units from conversation structures like topic splits and action triples and organizing them compositionally.", "target": "The authors introduce a sub-structure level compositional data augmentation method, Compo, to generate diverse and high-quality pairs of conversations and summaries by extracting basic units from conversation structures like topic splits and action triples and organizing them compositionally.", "example": "Convert the coordinate to text: [ 0.4718 -4.8012]:"}
{"text": "Convert the coordinate to text: [6.134  6.3456]: This paper extends the count-min sketch data structure to a higher-order sketch, which retains dense subgraph structure, and proposes four online algorithms that utilize this structure to simultaneously detect both edge and graph anomalies in constant memory and time.", "target": "This paper extends the count-min sketch data structure to a higher-order sketch, which retains dense subgraph structure, and proposes four online algorithms that utilize this structure to simultaneously detect both edge and graph anomalies in constant memory and time.", "example": "Convert the coordinate to text: [6.134  6.3456]:"}
{"text": "Convert the coordinate to text: [ 5.0023 -2.9406]: This study introduces a self-supervised learning (SSL) framework, which combines insights from coding theory, dynamical systems, function optimization, and supervised deep learning, to generate multi-modular grid cells without the need for supervised position information or engineered readout representations as required in previous methods.", "target": "This study introduces a self-supervised learning (SSL) framework, which combines insights from coding theory, dynamical systems, function optimization, and supervised deep learning, to generate multi-modular grid cells without the need for supervised position information or engineered readout representations as required in previous methods.", "example": "Convert the coordinate to text: [ 5.0023 -2.9406]:"}
{"text": "Convert the coordinate to text: [10.4421 -3.515 ]: The paper presents a novel Distributionally Robust Optimization (DRO) framework to create an ensemble of lottery tickets for calibrated network sparsification. This ensemble is designed to learn diverse and complementary sparse sub-networks (tickets) guided by uncertainty sets, which allows the tickets to capture different data distributions and complement each other.", "target": "The paper presents a novel Distributionally Robust Optimization (DRO) framework to create an ensemble of lottery tickets for calibrated network sparsification. This ensemble is designed to learn diverse and complementary sparse sub-networks (tickets) guided by uncertainty sets, which allows the tickets to capture different data distributions and complement each other.", "example": "Convert the coordinate to text: [10.4421 -3.515 ]:"}
{"text": "Convert the coordinate to text: [-1.1822 -2.7619]: The authors introduce two hierarchical contexts, namely perceptual context and spurious context, to describe the precise category boundary through automatic prompt tuning. They also introduce a novel application, CATegory-EXtensible OOD detection (CATEX), which enables the set of recognizable categories to be efficiently extended by simply merging the hierarchical contexts learned under different sub-task settings.", "target": "The authors introduce two hierarchical contexts, namely perceptual context and spurious context, to describe the precise category boundary through automatic prompt tuning. They also introduce a novel application, CATegory-EXtensible OOD detection (CATEX), which enables the set of recognizable categories to be efficiently extended by simply merging the hierarchical contexts learned under different sub-task settings.", "example": "Convert the coordinate to text: [-1.1822 -2.7619]:"}
{"text": "Convert the coordinate to text: [-2.4508 -4.9635]: The authors propose a graph-based method for encoding long sequences in NLP. This involves chunking the sequence into fixed lengths to model sentence-level information, and then utilizing graphs to model intra- and cross-sentence correlations with a new attention mechanism.", "target": "The authors propose a graph-based method for encoding long sequences in NLP. This involves chunking the sequence into fixed lengths to model sentence-level information, and then utilizing graphs to model intra- and cross-sentence correlations with a new attention mechanism.", "example": "Convert the coordinate to text: [-2.4508 -4.9635]:"}
{"text": "Convert the coordinate to text: [-1.056  -4.9986]: The paper proposes a new method which unifies entity locating and entity typing in prompt learning, designing a dual-slot multi-prompt template with the position slot and type slot to prompt locating and typing respectively. Multiple prompts can be fed into the model simultaneously and the model extracts all entities by parallel predictions on the slots.", "target": "The paper proposes a new method which unifies entity locating and entity typing in prompt learning, designing a dual-slot multi-prompt template with the position slot and type slot to prompt locating and typing respectively. Multiple prompts can be fed into the model simultaneously and the model extracts all entities by parallel predictions on the slots.", "example": "Convert the coordinate to text: [-1.056  -4.9986]:"}
{"text": "Convert the coordinate to text: [15.6756 -0.1134]: The paper proposes a novel 'quantize before fine-tuning' framework, PreQuant, which deviates from both quantization-aware training and post-training quantization. This approach leverages the over-parameterization nature of PLMs and is compatible with various quantization strategies.", "target": "The paper proposes a novel 'quantize before fine-tuning' framework, PreQuant, which deviates from both quantization-aware training and post-training quantization. This approach leverages the over-parameterization nature of PLMs and is compatible with various quantization strategies.", "example": "Convert the coordinate to text: [15.6756 -0.1134]:"}
{"text": "Convert the coordinate to text: [-3.933  -7.3182]: The authors propose multilingual parameter-efficient solutions that leverage robust pre-trained models to increase the quality of translation in low-resource settings.", "target": "The authors propose multilingual parameter-efficient solutions that leverage robust pre-trained models to increase the quality of translation in low-resource settings.", "example": "Convert the coordinate to text: [-3.933  -7.3182]:"}
{"text": "Convert the coordinate to text: [6.0008 2.4933]: The authors propose to analyze whether ignoring the marginalization in autoregressive language models is justified, by devising an importance-sampling-based algorithm that estimates marginal probabilities and comparing them to the default procedure.", "target": "The authors propose to analyze whether ignoring the marginalization in autoregressive language models is justified, by devising an importance-sampling-based algorithm that estimates marginal probabilities and comparing them to the default procedure.", "example": "Convert the coordinate to text: [6.0008 2.4933]:"}
{"text": "Convert the coordinate to text: [-5.8917 10.3537]: The authors introduce DIAGRAPH, an open-source graphical dialog flow editor built on the ADVISER toolkit. This allows users to create complex dialog systems without any coding knowledge, to support rapid prototyping of dialog system behavior and to provide a hands-on test bed for students learning about dialog systems.", "target": "The authors introduce DIAGRAPH, an open-source graphical dialog flow editor built on the ADVISER toolkit. This allows users to create complex dialog systems without any coding knowledge, to support rapid prototyping of dialog system behavior and to provide a hands-on test bed for students learning about dialog systems.", "example": "Convert the coordinate to text: [-5.8917 10.3537]:"}
{"text": "Convert the coordinate to text: [-3.2459 -3.7632]: The authors deploy NLI in CTRs to identify the inference relationship (entailment or contradiction) between pairs of clinical trial records and statements. They propose a model called 'Role-based Double Roberta-Large' to achieve this.", "target": "The authors deploy NLI in CTRs to identify the inference relationship (entailment or contradiction) between pairs of clinical trial records and statements. They propose a model called 'Role-based Double Roberta-Large' to achieve this.", "example": "Convert the coordinate to text: [-3.2459 -3.7632]:"}
{"text": "Convert the coordinate to text: [-6.948  -3.1715]: The paper investigates the effect of rare tokens on the evaluation of creative essays and presents five distinct extraction methods for these rare tokens.", "target": "The paper investigates the effect of rare tokens on the evaluation of creative essays and presents five distinct extraction methods for these rare tokens.", "example": "Convert the coordinate to text: [-6.948  -3.1715]:"}
{"text": "Convert the coordinate to text: [ 0.6275 -3.2621]: The authors propose a novel data generation framework tailored for HTC that can balance the controllability of multiple structural labels and text diversity by extracting high-quality semantic-level and phrase-level hierarchical label information.", "target": "The authors propose a novel data generation framework tailored for HTC that can balance the controllability of multiple structural labels and text diversity by extracting high-quality semantic-level and phrase-level hierarchical label information.", "example": "Convert the coordinate to text: [ 0.6275 -3.2621]:"}
{"text": "Convert the coordinate to text: [-5.0593 -1.1952]: The authors propose a novel model, DIVHSK, which has two components: KEYSELECT, which selects important keywords, and SEQGEN, which generates multiple diverse headlines. The KEYSELECT module clusters the self-attention heads of the pre-trained encoder to select the most attentive theme and general keywords from the source article.", "target": "The authors propose a novel model, DIVHSK, which has two components: KEYSELECT, which selects important keywords, and SEQGEN, which generates multiple diverse headlines. The KEYSELECT module clusters the self-attention heads of the pre-trained encoder to select the most attentive theme and general keywords from the source article.", "example": "Convert the coordinate to text: [-5.0593 -1.1952]:"}
{"text": "Convert the coordinate to text: [-3.2153 -8.2461]: The authors introduce a novel aligner for AMR graphs that scales cross-lingually and uses Transformer-based parsers which encode alignment information in their cross-attention weights to eliminate the need for language-specific rules or the EM algorithm.", "target": "The authors introduce a novel aligner for AMR graphs that scales cross-lingually and uses Transformer-based parsers which encode alignment information in their cross-attention weights to eliminate the need for language-specific rules or the EM algorithm.", "example": "Convert the coordinate to text: [-3.2153 -8.2461]:"}
{"text": "Convert the coordinate to text: [-4.1329 -4.6746]: This paper applies word embeddings to study the evolution of public associations, specifically in the context of Sweden\u2019s decision to apply for NATO membership in 2022.", "target": "This paper applies word embeddings to study the evolution of public associations, specifically in the context of Sweden\u2019s decision to apply for NATO membership in 2022.", "example": "Convert the coordinate to text: [-4.1329 -4.6746]:"}
{"text": "Convert the coordinate to text: [-3.5289 -1.7602]: The authors propose CHEER, a new DECI model that performs high-order reasoning while taking into account event centrality. They also introduce an Event Interaction Graph (EIG) to represent interactions among events and event pairs such as cause(A,B) and cause(B,C) leading to cause(A,C).", "target": "The authors propose CHEER, a new DECI model that performs high-order reasoning while taking into account event centrality. They also introduce an Event Interaction Graph (EIG) to represent interactions among events and event pairs such as cause(A,B) and cause(B,C) leading to cause(A,C).", "example": "Convert the coordinate to text: [-3.5289 -1.7602]:"}
{"text": "Convert the coordinate to text: [ 3.1714 -7.9841]: The authors put forth a hypothesis that the insensitivity to positional information in attention mechanisms is due to the weight sum operation and propose a novel weight concatenation operation to address this issue.", "target": "The authors put forth a hypothesis that the insensitivity to positional information in attention mechanisms is due to the weight sum operation and propose a novel weight concatenation operation to address this issue.", "example": "Convert the coordinate to text: [ 3.1714 -7.9841]:"}
{"text": "Convert the coordinate to text: [-4.286   6.4369]: The paper introduces 'Indexed Router', a novel method that categorizes experts into a structured hierarchy known as the indexed tree, facilitating real-time traffic speed prediction on road networks.", "target": "The paper introduces 'Indexed Router', a novel method that categorizes experts into a structured hierarchy known as the indexed tree, facilitating real-time traffic speed prediction on road networks.", "example": "Convert the coordinate to text: [-4.286   6.4369]:"}
{"text": "Convert the coordinate to text: [ 7.5487 -2.1506]: The authors introduce FedPseudo, a deep learning framework for FSA, based on pseudo values. It uses deep learning models to learn robust representations from non-linear survival data, employs pseudo values to handle non-uniform censoring, and employs federated learning algorithms such as FedAvg to learn model parameters. They also propose a novel method for estimating pseudo values for FSA and provide a theoretical proof that these values, termed as Federated Pseudo Values, are consistent.", "target": "The authors introduce FedPseudo, a deep learning framework for FSA, based on pseudo values. It uses deep learning models to learn robust representations from non-linear survival data, employs pseudo values to handle non-uniform censoring, and employs federated learning algorithms such as FedAvg to learn model parameters. They also propose a novel method for estimating pseudo values for FSA and provide a theoretical proof that these values, termed as Federated Pseudo Values, are consistent.", "example": "Convert the coordinate to text: [ 7.5487 -2.1506]:"}
{"text": "Convert the coordinate to text: [ 1.3912 -8.3156]: This paper proposes a more generalizable FAS approach by using a Vision Transformer model initialized with multimodal pre-trained weights (e.g., CLIP). They further enhance robustness by grounding visual representations with natural language, specifically aligning image representation with class descriptions, and use a multimodal contrastive learning strategy to further boost feature generalization.", "target": "This paper proposes a more generalizable FAS approach by using a Vision Transformer model initialized with multimodal pre-trained weights (e.g., CLIP). They further enhance robustness by grounding visual representations with natural language, specifically aligning image representation with class descriptions, and use a multimodal contrastive learning strategy to further boost feature generalization.", "example": "Convert the coordinate to text: [ 1.3912 -8.3156]:"}
{"text": "Convert the coordinate to text: [11.5931 -2.2405]: The paper introduces the exponential-increase hypothesis, positing that if a neural network is made to fit a discontinuous piecewise function to a certain small error, the time costs will exponentially increase. To address this problem, the authors introduce a partition mechanism to enhance INR methods for image reconstruction by dividing an image into sub-regions and assigning smaller networks for each.", "target": "The paper introduces the exponential-increase hypothesis, positing that if a neural network is made to fit a discontinuous piecewise function to a certain small error, the time costs will exponentially increase. To address this problem, the authors introduce a partition mechanism to enhance INR methods for image reconstruction by dividing an image into sub-regions and assigning smaller networks for each.", "example": "Convert the coordinate to text: [11.5931 -2.2405]:"}
{"text": "Convert the coordinate to text: [  7.8953 -15.2443]: An Improved Auto-regressive Model (ImAM) for 3D shape generation is proposed, it applies discrete representation learning based on a latent vector instead of volumetric grids, which not only reduces computational costs but also preserves geometric details.", "target": "An Improved Auto-regressive Model (ImAM) for 3D shape generation is proposed, it applies discrete representation learning based on a latent vector instead of volumetric grids, which not only reduces computational costs but also preserves geometric details.", "example": "Convert the coordinate to text: [  7.8953 -15.2443]:"}
{"text": "Convert the coordinate to text: [ 0.1359 -8.7358]: The authors propose a feature map distillation framework to mitigate differences between CLIP and MIM. The framework incorporates key elements of MIM, thus enhancing the fine-tuning performance of CLIP models.", "target": "The authors propose a feature map distillation framework to mitigate differences between CLIP and MIM. The framework incorporates key elements of MIM, thus enhancing the fine-tuning performance of CLIP models.", "example": "Convert the coordinate to text: [ 0.1359 -8.7358]:"}
{"text": "Convert the coordinate to text: [14.477   5.1869]: A novel approach to estimate the rate-distortion function from an optimal transport perspective is proposed. The approach relies on a Wasserstein gradient descent algorithm that learns the support of the optimal reproduction distribution by moving particles, rather than fixing the support as in previous methods.", "target": "A novel approach to estimate the rate-distortion function from an optimal transport perspective is proposed. The approach relies on a Wasserstein gradient descent algorithm that learns the support of the optimal reproduction distribution by moving particles, rather than fixing the support as in previous methods.", "example": "Convert the coordinate to text: [14.477   5.1869]:"}
{"text": "Convert the coordinate to text: [ 6.1719 -4.0228]: The authors introduce the Cluster Information Transfer (CIT) mechanism to improve the generalisation ability of GNNs by learning invariant representations when dealing with structure shift. It combines different cluster information with the nodes while preserving their cluster-independent information.", "target": "The authors introduce the Cluster Information Transfer (CIT) mechanism to improve the generalisation ability of GNNs by learning invariant representations when dealing with structure shift. It combines different cluster information with the nodes while preserving their cluster-independent information.", "example": "Convert the coordinate to text: [ 6.1719 -4.0228]:"}
{"text": "Convert the coordinate to text: [-0.8563 -7.4895]: The authors propose two scheduled masking approaches that adaptively tune the masking ratio and the content being masked during different training stages, aiming to improve the efficiency and effectiveness of pre-training.", "target": "The authors propose two scheduled masking approaches that adaptively tune the masking ratio and the content being masked during different training stages, aiming to improve the efficiency and effectiveness of pre-training.", "example": "Convert the coordinate to text: [-0.8563 -7.4895]:"}
{"text": "Convert the coordinate to text: [-5.9975  4.4044]: The authors propose a novel model, Hashtag-guided Tweet Classification model (HashTation), which automatically generates meaningful hashtags for tweets to provide auxiliary signals for classification. The authors posit that these generated hashtags can enrich short and ambiguous tweets with additional information such as topic, sentiment, and stance.", "target": "The authors propose a novel model, Hashtag-guided Tweet Classification model (HashTation), which automatically generates meaningful hashtags for tweets to provide auxiliary signals for classification. The authors posit that these generated hashtags can enrich short and ambiguous tweets with additional information such as topic, sentiment, and stance.", "example": "Convert the coordinate to text: [-5.9975  4.4044]:"}
{"text": "Convert the coordinate to text: [ 3.4963 -3.9156]: The authors propose a novel knowledge distillation method to learn a smaller, self-consistent CoT model from a larger teacher model. This includes eliciting rationales from the large model using contrastive decoding and teaching the smaller model with a counterfactual reasoning objective.", "target": "The authors propose a novel knowledge distillation method to learn a smaller, self-consistent CoT model from a larger teacher model. This includes eliciting rationales from the large model using contrastive decoding and teaching the smaller model with a counterfactual reasoning objective.", "example": "Convert the coordinate to text: [ 3.4963 -3.9156]:"}
{"text": "Convert the coordinate to text: [-0.2148  4.1185]: The authors propose to develop and compare different neural explainability methods to interpret the decision-making process of state-of-the-art fine-tuned neural metrics.", "target": "The authors propose to develop and compare different neural explainability methods to interpret the decision-making process of state-of-the-art fine-tuned neural metrics.", "example": "Convert the coordinate to text: [-0.2148  4.1185]:"}
{"text": "Convert the coordinate to text: [-1.8164 -2.9581]: The authors propose Direct Fact Retrieval (DiFaR), a knowledge retrieval framework that directly retrieves facts from KGs based on representational similarities. They embed all facts in KGs onto a dense embedding space using a language model trained only with pairs of input texts and facts. They refine the ranks of top-k retrieved facts with a reranker that contextualizes the input text and the fact jointly.", "target": "The authors propose Direct Fact Retrieval (DiFaR), a knowledge retrieval framework that directly retrieves facts from KGs based on representational similarities. They embed all facts in KGs onto a dense embedding space using a language model trained only with pairs of input texts and facts. They refine the ranks of top-k retrieved facts with a reranker that contextualizes the input text and the fact jointly.", "example": "Convert the coordinate to text: [-1.8164 -2.9581]:"}
{"text": "Convert the coordinate to text: [-8.9912 -7.1165]: The authors explore 'grammar prompting' as a simple method for enabling LLMs to incorporate external knowledge and domain-specific constraints expressed through a grammar in Backus-Naur Form (BNF) during in-context learning.", "target": "The authors explore 'grammar prompting' as a simple method for enabling LLMs to incorporate external knowledge and domain-specific constraints expressed through a grammar in Backus-Naur Form (BNF) during in-context learning.", "example": "Convert the coordinate to text: [-8.9912 -7.1165]:"}
{"text": "Convert the coordinate to text: [15.583 -4.966]: This paper develops a training-free NAS metric for recurrent neural network (RNN) and BERT-based transformer architectures, used for language modeling tasks. A new metric named 'hidden covariance' is proposed to predict the trained performance of an RNN architecture. Also, it's found that the current search space for transformer architectures is not optimized for training-free NAS, and suggest qualitative analysis could effectively shrink the search space to best performing architectures.", "target": "This paper develops a training-free NAS metric for recurrent neural network (RNN) and BERT-based transformer architectures, used for language modeling tasks. A new metric named 'hidden covariance' is proposed to predict the trained performance of an RNN architecture. Also, it's found that the current search space for transformer architectures is not optimized for training-free NAS, and suggest qualitative analysis could effectively shrink the search space to best performing architectures.", "example": "Convert the coordinate to text: [15.583 -4.966]:"}
{"text": "Convert the coordinate to text: [-0.1174 -7.0078]: The authors address this task with various Transformer-based approaches.", "target": "The authors address this task with various Transformer-based approaches.", "example": "Convert the coordinate to text: [-0.1174 -7.0078]:"}
{"text": "Convert the coordinate to text: [ 0.1823 -8.9265]: The authors propose using AltCLIP features in conjunction with a 3-layer standard transformer encoder to compare the cosine similarity between the given phrase and different images. They also use a subset of LAION-5B to improve the model's generalization.", "target": "The authors propose using AltCLIP features in conjunction with a 3-layer standard transformer encoder to compare the cosine similarity between the given phrase and different images. They also use a subset of LAION-5B to improve the model's generalization.", "example": "Convert the coordinate to text: [ 0.1823 -8.9265]:"}
{"text": "Convert the coordinate to text: [-6.4599 -1.1203]: This work explores the relationship between dataset extractivity and model performance, demonstrating that high extractivity negatively affects performance due to a greater tendency for the model to copy text from the source document. To counter this, the authors propose a new method for designing copy labels to adjust the model's copying behaviors.", "target": "This work explores the relationship between dataset extractivity and model performance, demonstrating that high extractivity negatively affects performance due to a greater tendency for the model to copy text from the source document. To counter this, the authors propose a new method for designing copy labels to adjust the model's copying behaviors.", "example": "Convert the coordinate to text: [-6.4599 -1.1203]:"}
{"text": "Convert the coordinate to text: [-7.5407 -6.9467]: The authors propose a new method for misleading relation classifiers by first analyzing the most important parts of speech (POSs) from syntax and morphology perspectives, and then substituting words labeled with these POS tags in the original samples with synonyms or hyponyms.", "target": "The authors propose a new method for misleading relation classifiers by first analyzing the most important parts of speech (POSs) from syntax and morphology perspectives, and then substituting words labeled with these POS tags in the original samples with synonyms or hyponyms.", "example": "Convert the coordinate to text: [-7.5407 -6.9467]:"}
{"text": "Convert the coordinate to text: [-5.6919 10.1651]: The study aims to analyze human behavior in knowledge-grounded dialogues by introducing a special annotation to the utterances in a dialogue corpus where each entity is marked by its information source: external knowledge or the speaker\u2019s own knowledge, experiences, and opinions.", "target": "The study aims to analyze human behavior in knowledge-grounded dialogues by introducing a special annotation to the utterances in a dialogue corpus where each entity is marked by its information source: external knowledge or the speaker\u2019s own knowledge, experiences, and opinions.", "example": "Convert the coordinate to text: [-5.6919 10.1651]:"}
{"text": "Convert the coordinate to text: [-3.5213 -7.6316]: This work presents a new approach of using multilingual transformers (MMTs, e.g., mBERT or XLM-R) alongside BabelNet's multilingual synsets, to create synonym pairs across 50 languages. The MMTs then undergo a lexical specialization procedure guided by a contrastive objective.", "target": "This work presents a new approach of using multilingual transformers (MMTs, e.g., mBERT or XLM-R) alongside BabelNet's multilingual synsets, to create synonym pairs across 50 languages. The MMTs then undergo a lexical specialization procedure guided by a contrastive objective.", "example": "Convert the coordinate to text: [-3.5213 -7.6316]:"}
{"text": "Convert the coordinate to text: [ 9.9183 11.4795]: The authors propose the Lasso Random Project Bandit (LRP-Bandit) algorithm, which integrates Lasso and Random Projection techniques for feature selection and dimension reduction in sparse linear bandit problems under high-dimensional settings.", "target": "The authors propose the Lasso Random Project Bandit (LRP-Bandit) algorithm, which integrates Lasso and Random Projection techniques for feature selection and dimension reduction in sparse linear bandit problems under high-dimensional settings.", "example": "Convert the coordinate to text: [ 9.9183 11.4795]:"}
{"text": "Convert the coordinate to text: [ 4.9057 -4.5607]: A new approach, the mutual information based dual level graph neural network (MIDLG), is proposed. It treats every complaint as a super-node involving individual identities, characterizes these individuals at the node-level as well as the super-node level, and uses a mutual information minimization objective based on a 'complaint verification-causal graph' to achieve stability against evolving fraud methods.", "target": "A new approach, the mutual information based dual level graph neural network (MIDLG), is proposed. It treats every complaint as a super-node involving individual identities, characterizes these individuals at the node-level as well as the super-node level, and uses a mutual information minimization objective based on a 'complaint verification-causal graph' to achieve stability against evolving fraud methods.", "example": "Convert the coordinate to text: [ 4.9057 -4.5607]:"}
{"text": "Convert the coordinate to text: [-1.4519  0.8876]: The author proposes to leverage probabilistic deep learning frameworks to streamline the adoption of SSM in biomedical research and practice.", "target": "The author proposes to leverage probabilistic deep learning frameworks to streamline the adoption of SSM in biomedical research and practice.", "example": "Convert the coordinate to text: [-1.4519  0.8876]:"}
{"text": "Convert the coordinate to text: [-1.7818 -5.3709]: A novel ChatGPT-based prompting approach, LLM4Vis, is proposed for visualization recommendation that provides human-like explanations using very few demonstration examples. The approach involves feature description, demonstration example selection, explanation generation, demonstration example construction, and inference steps.", "target": "A novel ChatGPT-based prompting approach, LLM4Vis, is proposed for visualization recommendation that provides human-like explanations using very few demonstration examples. The approach involves feature description, demonstration example selection, explanation generation, demonstration example construction, and inference steps.", "example": "Convert the coordinate to text: [-1.7818 -5.3709]:"}
{"text": "Convert the coordinate to text: [ 1.7299 -7.7791]: To address these problems, the authors propose MixSynthFormer, a transformer encoder-like model with MLP-based mixed synthetic attention that synthesizes spatial and temporal attentions, thereby accurately estimating human poses from sparsely sampled frames across an entire video sequence.", "target": "To address these problems, the authors propose MixSynthFormer, a transformer encoder-like model with MLP-based mixed synthetic attention that synthesizes spatial and temporal attentions, thereby accurately estimating human poses from sparsely sampled frames across an entire video sequence.", "example": "Convert the coordinate to text: [ 1.7299 -7.7791]:"}
{"text": "Convert the coordinate to text: [-7.1127 13.1437]: The authors propose a novel model called Affective Image Filter (AIF), which is capable of understanding visually-abstract emotions from text and reflecting these emotions into visually-concrete images through appropriate colors and textures.", "target": "The authors propose a novel model called Affective Image Filter (AIF), which is capable of understanding visually-abstract emotions from text and reflecting these emotions into visually-concrete images through appropriate colors and textures.", "example": "Convert the coordinate to text: [-7.1127 13.1437]:"}
{"text": "Convert the coordinate to text: [-3.2797 12.9966]: The authors propose a novel problem of role-aware interaction generation, where roles can be designated before generation. They also propose a model that learns to generate motions of the designated role that together form a mutually consistent interaction.", "target": "The authors propose a novel problem of role-aware interaction generation, where roles can be designated before generation. They also propose a model that learns to generate motions of the designated role that together form a mutually consistent interaction.", "example": "Convert the coordinate to text: [-3.2797 12.9966]:"}
{"text": "Convert the coordinate to text: [ 3.5906 -4.3533]: A pseudo-relation learning framework called Relation Teacher (RTea) is introduced, which exploits pixel relations to efficiently utilize unreliable pixels and learn generalized representations. Pseudo-relations are built on local grids and fused with low-level relations in image space, guided by reliable local relations and available low-level relations. A pseudo-relation learning strategy is also designed that optimizes class probabilities for consistent relations by finding the optimal sub-graph division.", "target": "A pseudo-relation learning framework called Relation Teacher (RTea) is introduced, which exploits pixel relations to efficiently utilize unreliable pixels and learn generalized representations. Pseudo-relations are built on local grids and fused with low-level relations in image space, guided by reliable local relations and available low-level relations. A pseudo-relation learning strategy is also designed that optimizes class probabilities for consistent relations by finding the optimal sub-graph division.", "example": "Convert the coordinate to text: [ 3.5906 -4.3533]:"}
{"text": "Convert the coordinate to text: [2.7737 2.5049]: The authors discover that learning invariant graph representations via environment augmentation is impossible without additional assumptions. They subsequently propose a set of minimal assumptions which includes variation sufficiency and variation consistency.", "target": "The authors discover that learning invariant graph representations via environment augmentation is impossible without additional assumptions. They subsequently propose a set of minimal assumptions which includes variation sufficiency and variation consistency.", "example": "Convert the coordinate to text: [2.7737 2.5049]:"}
{"text": "Convert the coordinate to text: [9.5266 3.6928]: The authors propose a Gaussian process regression technique that is capable of inferring implicit structure directly from data in a fully differentiable way, eliminating the need for explicitly provided manifold structure.", "target": "The authors propose a Gaussian process regression technique that is capable of inferring implicit structure directly from data in a fully differentiable way, eliminating the need for explicitly provided manifold structure.", "example": "Convert the coordinate to text: [9.5266 3.6928]:"}
{"text": "Convert the coordinate to text: [6.5695 1.7794]: The authors propose a novel data-driven strategy that restricts the separator selection space and introduces a learning-guided algorithm to predict instance-aware separator configurations that can dynamically adapt during the solve.", "target": "The authors propose a novel data-driven strategy that restricts the separator selection space and introduces a learning-guided algorithm to predict instance-aware separator configurations that can dynamically adapt during the solve.", "example": "Convert the coordinate to text: [6.5695 1.7794]:"}
{"text": "Convert the coordinate to text: [  8.0255 -12.9319]: The authors propose a new 3D object detection framework, referred to as CluB, which combines the strengths of BEV-based and cluster-based detectors. It includes an auxiliary cluster-based branch in the BEV-based detector, enriching the object representation at both feature and query levels.", "target": "The authors propose a new 3D object detection framework, referred to as CluB, which combines the strengths of BEV-based and cluster-based detectors. It includes an auxiliary cluster-based branch in the BEV-based detector, enriching the object representation at both feature and query levels.", "example": "Convert the coordinate to text: [  8.0255 -12.9319]:"}
{"text": "Convert the coordinate to text: [ 9.1539 10.6272]: This paper proposes a method to improve the regret rate of the GP-UCB algorithm by regularizing kernel ridge estimators in proportion to the smoothness of the underlying kernel.", "target": "This paper proposes a method to improve the regret rate of the GP-UCB algorithm by regularizing kernel ridge estimators in proportion to the smoothness of the underlying kernel.", "example": "Convert the coordinate to text: [ 9.1539 10.6272]:"}
{"text": "Convert the coordinate to text: [ 3.225  -3.9633]: The paper identifies learning-forgetting trade-off as a critical obstacle in progressive training and proposes a new method that combines knowledge distillation (KD) and consistency learning (CL) to improve data efficiency in speech translation.", "target": "The paper identifies learning-forgetting trade-off as a critical obstacle in progressive training and proposes a new method that combines knowledge distillation (KD) and consistency learning (CL) to improve data efficiency in speech translation.", "example": "Convert the coordinate to text: [ 3.225  -3.9633]:"}
{"text": "Convert the coordinate to text: [-7.8287 -4.2957]: The authors introduce MetaCLUE, a set of vision tasks on visual metaphor, which also includes the collection of high-quality and rich metaphor annotations.", "target": "The authors introduce MetaCLUE, a set of vision tasks on visual metaphor, which also includes the collection of high-quality and rich metaphor annotations.", "example": "Convert the coordinate to text: [-7.8287 -4.2957]:"}
{"text": "Convert the coordinate to text: [-2.8909  0.2386]: The authors focus on facilitating the fine-grained detection of Chinese toxic language by introducing a hierarchical taxonomy, Monitor Toxic Frame, to analyze toxic types and expressions. A new, more detailed dataset called ToxiCN is presented, covering both direct and indirect toxic samples. Furthermore, an insult lexicon containing implicit profanity is built and a benchmark tool, Toxic Knowledge Enhancement (TKE), is proposed.", "target": "The authors focus on facilitating the fine-grained detection of Chinese toxic language by introducing a hierarchical taxonomy, Monitor Toxic Frame, to analyze toxic types and expressions. A new, more detailed dataset called ToxiCN is presented, covering both direct and indirect toxic samples. Furthermore, an insult lexicon containing implicit profanity is built and a benchmark tool, Toxic Knowledge Enhancement (TKE), is proposed.", "example": "Convert the coordinate to text: [-2.8909  0.2386]:"}
{"text": "Convert the coordinate to text: [-1.6227 -7.2905]: The authors propose a soft erasure criterion that, instead of completely removing or retaining tokens, randomly masks parts of the token vector representations proportionately to their FA importance.", "target": "The authors propose a soft erasure criterion that, instead of completely removing or retaining tokens, randomly masks parts of the token vector representations proportionately to their FA importance.", "example": "Convert the coordinate to text: [-1.6227 -7.2905]:"}
{"text": "Convert the coordinate to text: [-0.2121 -8.2235]: The authors propose CLAPSpeech, a cross-modal contrastive pre-training framework that explicitly learns the prosody variance of the same text token under different contexts. This is done through a joint multi-modal space and a multi-scale pre-training pipeline to capture prosody patterns on multiple levels.", "target": "The authors propose CLAPSpeech, a cross-modal contrastive pre-training framework that explicitly learns the prosody variance of the same text token under different contexts. This is done through a joint multi-modal space and a multi-scale pre-training pipeline to capture prosody patterns on multiple levels.", "example": "Convert the coordinate to text: [-0.2121 -8.2235]:"}
{"text": "Convert the coordinate to text: [ 6.3317 -3.9733]: The authors propose MetaAdapt, a meta-learning-based approach for domain adaptive few-shot misinformation detection, that leverages limited target examples to guide knowledge transfer from the source to the target domain, learning how to adapt the misinformation detection model.", "target": "The authors propose MetaAdapt, a meta-learning-based approach for domain adaptive few-shot misinformation detection, that leverages limited target examples to guide knowledge transfer from the source to the target domain, learning how to adapt the misinformation detection model.", "example": "Convert the coordinate to text: [ 6.3317 -3.9733]:"}
{"text": "Convert the coordinate to text: [ 0.9742 -5.0354]: To overcome the challenge of multi-domain stance detection, the authors propose Topic Efficient Stance Detection (TESTED), a new method that comprises a topic-guided diversity sampling technique and a contrastive objective that fine-tunes a stance classifier.", "target": "To overcome the challenge of multi-domain stance detection, the authors propose Topic Efficient Stance Detection (TESTED), a new method that comprises a topic-guided diversity sampling technique and a contrastive objective that fine-tunes a stance classifier.", "example": "Convert the coordinate to text: [ 0.9742 -5.0354]:"}
{"text": "Convert the coordinate to text: [-6.361  -0.7895]: The study proposes a framework based on concept co-occurrence in academic papers to inspire new ideas. The authors innovate the concept of 'concept graphs' based on co-occurrence relationships and a temporal link prediction method to explore potential connections between different concepts, with a co-occurrence citation quintuple to verbalize these connections.", "target": "The study proposes a framework based on concept co-occurrence in academic papers to inspire new ideas. The authors innovate the concept of 'concept graphs' based on co-occurrence relationships and a temporal link prediction method to explore potential connections between different concepts, with a co-occurrence citation quintuple to verbalize these connections.", "example": "Convert the coordinate to text: [-6.361  -0.7895]:"}
{"text": "Convert the coordinate to text: [-3.1998  0.7612]: The authors propose a two-step process to tackle this issue: first, by creating a large dataset (SIGHT) containing math lecture transcripts and comments from the MIT OCW YouTube channel; second, by developing a rubric for categorizing feedback types using qualitative analysis and applying large language models to classify these comments at scale.", "target": "The authors propose a two-step process to tackle this issue: first, by creating a large dataset (SIGHT) containing math lecture transcripts and comments from the MIT OCW YouTube channel; second, by developing a rubric for categorizing feedback types using qualitative analysis and applying large language models to classify these comments at scale.", "example": "Convert the coordinate to text: [-3.1998  0.7612]:"}
{"text": "Convert the coordinate to text: [-3.294   0.1693]: The authors argue that the behaviour of annotation depends on more than just sociodemographics, and therefore aggregates like the behaviour of the average female annotator may not accurately predict individual behaviour\u2014a phenomenon known as the ecological fallacy.", "target": "The authors argue that the behaviour of annotation depends on more than just sociodemographics, and therefore aggregates like the behaviour of the average female annotator may not accurately predict individual behaviour\u2014a phenomenon known as the ecological fallacy.", "example": "Convert the coordinate to text: [-3.294   0.1693]:"}
{"text": "Convert the coordinate to text: [-3.5388 -3.8323]: The authors propose a novel graph-based relation mining method, called GRM, for OOV word embedding learning. They construct a Word Relationship Graph (WRG) based on word formation and associate OOV words with their semantically relevant words to mine the relational information within word structures.", "target": "The authors propose a novel graph-based relation mining method, called GRM, for OOV word embedding learning. They construct a Word Relationship Graph (WRG) based on word formation and associate OOV words with their semantically relevant words to mine the relational information within word structures.", "example": "Convert the coordinate to text: [-3.5388 -3.8323]:"}
{"text": "Convert the coordinate to text: [ 2.1392 -0.5457]: The paper introduces an approach for learning an adaptive propagation path to filter irrelevant entities while keeping promising ones. An incremental sampling mechanism with linear complexity is proposed along with a learning-based sampling distribution to identify semantically related entities.", "target": "The paper introduces an approach for learning an adaptive propagation path to filter irrelevant entities while keeping promising ones. An incremental sampling mechanism with linear complexity is proposed along with a learning-based sampling distribution to identify semantically related entities.", "example": "Convert the coordinate to text: [ 2.1392 -0.5457]:"}
{"text": "Convert the coordinate to text: [ 6.3155 -6.2007]: The authors propose a Progressive Neighborhood Aggregation (PNA) framework that refines semantic segmentation prediction. This process involves first presenting a neighborhood aggregation module, where the neighborhood similarity matrices for each pixel are estimated, and then progressively aggregating the high-level features for recovering spatial structure.", "target": "The authors propose a Progressive Neighborhood Aggregation (PNA) framework that refines semantic segmentation prediction. This process involves first presenting a neighborhood aggregation module, where the neighborhood similarity matrices for each pixel are estimated, and then progressively aggregating the high-level features for recovering spatial structure.", "example": "Convert the coordinate to text: [ 6.3155 -6.2007]:"}
{"text": "Convert the coordinate to text: [10.4579  6.6827]: The authors propose a new approach called Variance Suppression (VaSSO), which stabilizes the adversary in the Sharpness-aware Minimization through variance suppression, counteracting the 'over-friendly' behavior of the adversary.", "target": "The authors propose a new approach called Variance Suppression (VaSSO), which stabilizes the adversary in the Sharpness-aware Minimization through variance suppression, counteracting the 'over-friendly' behavior of the adversary.", "example": "Convert the coordinate to text: [10.4579  6.6827]:"}
{"text": "Convert the coordinate to text: [  6.4227 -13.1525]: The study proposes to improve the interpretability and generalization of part-based representations by introducing two innovative regularization methods: The first separates the generative process of foreground and background information, and the second ensures invariance of the learned parts to incidental background correlations.", "target": "The study proposes to improve the interpretability and generalization of part-based representations by introducing two innovative regularization methods: The first separates the generative process of foreground and background information, and the second ensures invariance of the learned parts to incidental background correlations.", "example": "Convert the coordinate to text: [  6.4227 -13.1525]:"}
{"text": "Convert the coordinate to text: [ 3.217  -7.3079]: This paper presents SubTree Attention (STA), a novel multi-hop graph attention mechanism designed to bridge the gap between fully-attentional structures and rooted subtrees, and solve the issues faced by existing graph attention mechanisms.", "target": "This paper presents SubTree Attention (STA), a novel multi-hop graph attention mechanism designed to bridge the gap between fully-attentional structures and rooted subtrees, and solve the issues faced by existing graph attention mechanisms.", "example": "Convert the coordinate to text: [ 3.217  -7.3079]:"}
{"text": "Convert the coordinate to text: [ 10.6358 -18.5785]: The authors propose a Deformable Convolution based on the Poincar\u00e9 Ball (DCPB), an analogy between the fisheye model and the Poincar\u00e9 ball, which helps to alleviate the issue of spatial distortion in images.", "target": "The authors propose a Deformable Convolution based on the Poincar\u00e9 Ball (DCPB), an analogy between the fisheye model and the Poincar\u00e9 ball, which helps to alleviate the issue of spatial distortion in images.", "example": "Convert the coordinate to text: [ 10.6358 -18.5785]:"}
{"text": "Convert the coordinate to text: [  9.6849 -19.8451]: The paper proposes a self-supervised deep learning method, USe-ReDI-Net, that uses both haze and geometry to improve the depth estimation from a single underwater image. The method also outputs the depth map and the restored image in real-time.", "target": "The paper proposes a self-supervised deep learning method, USe-ReDI-Net, that uses both haze and geometry to improve the depth estimation from a single underwater image. The method also outputs the depth map and the restored image in real-time.", "example": "Convert the coordinate to text: [  9.6849 -19.8451]:"}
{"text": "Convert the coordinate to text: [-0.8995 -6.9016]: The authors examine the extent to which transformer language models are sensitive to animacy, a phenomena that is indirectly expressed through language, despite not having direct access to extralinguistic animacy cues.", "target": "The authors examine the extent to which transformer language models are sensitive to animacy, a phenomena that is indirectly expressed through language, despite not having direct access to extralinguistic animacy cues.", "example": "Convert the coordinate to text: [-0.8995 -6.9016]:"}
{"text": "Convert the coordinate to text: [ 6.1321 14.5037]: The authors explore the benefits of meta-learning in solving multiple MARL tasks collectively, and propose to combine optimistic policy mirror descents with stage-based value updates.", "target": "The authors explore the benefits of meta-learning in solving multiple MARL tasks collectively, and propose to combine optimistic policy mirror descents with stage-based value updates.", "example": "Convert the coordinate to text: [ 6.1321 14.5037]:"}
{"text": "Convert the coordinate to text: [ 1.5138 -1.152 ]: The central insight of this paper is that real-world tabular datasets contain implicit sample relations, which can help obtain more accurate estimations. Therefore, a post-training confidence calibration framework, RECAL, is proposed to calibrate the predictive confidence of current machine learning models by employing graph neural networks to model these relations.", "target": "The central insight of this paper is that real-world tabular datasets contain implicit sample relations, which can help obtain more accurate estimations. Therefore, a post-training confidence calibration framework, RECAL, is proposed to calibrate the predictive confidence of current machine learning models by employing graph neural networks to model these relations.", "example": "Convert the coordinate to text: [ 1.5138 -1.152 ]:"}
{"text": "Convert the coordinate to text: [-1.8074 -4.9227]: This paper introduces a novel approach called low-resource comparative opinion quintuple extraction by Data Augmentation with Prompting (DAP), along with an end-to-end model architecture better suited to the data augmentation method from triplets to quintuples.", "target": "This paper introduces a novel approach called low-resource comparative opinion quintuple extraction by Data Augmentation with Prompting (DAP), along with an end-to-end model architecture better suited to the data augmentation method from triplets to quintuples.", "example": "Convert the coordinate to text: [-1.8074 -4.9227]:"}
{"text": "Convert the coordinate to text: [8.1028 6.0879]: The authors propose a method that combines multilevel MCMC approach and the delayed acceptance MCMC, extending it to use a hierarchy of models of arbitrary depth and allowing subchains of arbitrary length.", "target": "The authors propose a method that combines multilevel MCMC approach and the delayed acceptance MCMC, extending it to use a hierarchy of models of arbitrary depth and allowing subchains of arbitrary length.", "example": "Convert the coordinate to text: [8.1028 6.0879]:"}
{"text": "Convert the coordinate to text: [5.5037 9.001 ]: The authors propose a mathematical runtime analysis for NSGA-II demonstrating its feasibility and comparing it against other algorithms like SEMO and GSEMO on benchmark problems.", "target": "The authors propose a mathematical runtime analysis for NSGA-II demonstrating its feasibility and comparing it against other algorithms like SEMO and GSEMO on benchmark problems.", "example": "Convert the coordinate to text: [5.5037 9.001 ]:"}
{"text": "Convert the coordinate to text: [-16.6613  10.7214]: The Special Interest Group (SIG) will provide a platform to discuss topics concerning the development of participatory methods to assess the ethical implications of emerging technologies for children.", "target": "The Special Interest Group (SIG) will provide a platform to discuss topics concerning the development of participatory methods to assess the ethical implications of emerging technologies for children.", "example": "Convert the coordinate to text: [-16.6613  10.7214]:"}
{"text": "Convert the coordinate to text: [-3.5663  5.7676]: This paper proposes a new estimator ASAP (sAtisfaction eStimation via HAwkes Process) that considers user satisfaction across dialogue turns as an event sequence, using the Hawkes process to model the dynamics in this sequence.", "target": "This paper proposes a new estimator ASAP (sAtisfaction eStimation via HAwkes Process) that considers user satisfaction across dialogue turns as an event sequence, using the Hawkes process to model the dynamics in this sequence.", "example": "Convert the coordinate to text: [-3.5663  5.7676]:"}
{"text": "Convert the coordinate to text: [ 4.8223 -2.835 ]: A 'divide, conquer and combine' solution is presented which explicitly disentangles the semantics of seen data and leverages the performance and robustness using the mixture-of-experts mechanism. Exposure is divided into semantically independent subsets and corresponding experts are trained.", "target": "A 'divide, conquer and combine' solution is presented which explicitly disentangles the semantics of seen data and leverages the performance and robustness using the mixture-of-experts mechanism. Exposure is divided into semantically independent subsets and corresponding experts are trained.", "example": "Convert the coordinate to text: [ 4.8223 -2.835 ]:"}
{"text": "Convert the coordinate to text: [2.3426 3.9489]: The authors propose a dynamic causal space for DAG structure learning they call CASPER that brings in graph structure into the score function in order to faithfully reflect the causal distance between the estimated and grounded truth Directed Acyclic Graph (DAG). It revises the learning process and boosts DAG structure learning by paying adaptive attention to DAG-ness.", "target": "The authors propose a dynamic causal space for DAG structure learning they call CASPER that brings in graph structure into the score function in order to faithfully reflect the causal distance between the estimated and grounded truth Directed Acyclic Graph (DAG). It revises the learning process and boosts DAG structure learning by paying adaptive attention to DAG-ness.", "example": "Convert the coordinate to text: [2.3426 3.9489]:"}
{"text": "Convert the coordinate to text: [-4.2483 -8.2759]: This paper introduces a speech translation system for scientific conference talks with accented input and terminology-rich content, which also needs to be translated to 10 languages. The authors propose a retrieval-based approach (kNN-MT) for effective adaptation in the absence of training data from the target domain.", "target": "This paper introduces a speech translation system for scientific conference talks with accented input and terminology-rich content, which also needs to be translated to 10 languages. The authors propose a retrieval-based approach (kNN-MT) for effective adaptation in the absence of training data from the target domain.", "example": "Convert the coordinate to text: [-4.2483 -8.2759]:"}
{"text": "Convert the coordinate to text: [-3.0166 -4.8631]: The authors argue for the importance of running simple baselines, like linear classifiers on bag-of-words features, alongside advanced methods such as BERT, as they show competitive performance, high efficiency, and robustness for many text data.", "target": "The authors argue for the importance of running simple baselines, like linear classifiers on bag-of-words features, alongside advanced methods such as BERT, as they show competitive performance, high efficiency, and robustness for many text data.", "example": "Convert the coordinate to text: [-3.0166 -4.8631]:"}
{"text": "Convert the coordinate to text: [-1.0053 -4.1568]: The authors confront the question of which of these interaction attribution methods most faithfully reflects the inner workings of target models. They hypothesize that these interactions could be a starting point for investigating linguistic structure in language models.", "target": "The authors confront the question of which of these interaction attribution methods most faithfully reflects the inner workings of target models. They hypothesize that these interactions could be a starting point for investigating linguistic structure in language models.", "example": "Convert the coordinate to text: [-1.0053 -4.1568]:"}
{"text": "Convert the coordinate to text: [-0.9844  0.3117]: This work tackles the problem of gender bias in multilingual settings by creating a benchmark for evaluating gender biases. It extends DisCo to diverse Indian languages using human annotations and suggests mitigation techniques for the same.", "target": "This work tackles the problem of gender bias in multilingual settings by creating a benchmark for evaluating gender biases. It extends DisCo to diverse Indian languages using human annotations and suggests mitigation techniques for the same.", "example": "Convert the coordinate to text: [-0.9844  0.3117]:"}
{"text": "Convert the coordinate to text: [-3.7683 -3.7157]: In addition to using external knowledge bases for context, the authors propose a two-stage approach to the Named Entity Recognition (NER) task, consisting of a Span Extraction Step and an Entity Classification Step.", "target": "In addition to using external knowledge bases for context, the authors propose a two-stage approach to the Named Entity Recognition (NER) task, consisting of a Span Extraction Step and an Entity Classification Step.", "example": "Convert the coordinate to text: [-3.7683 -3.7157]:"}
{"text": "Convert the coordinate to text: [-4.7407 -3.0827]: The authors present their approaches to address all three sub-tasks in SemEval 2023's Legal-Eval, utilizing various deep learning-based models.", "target": "The authors present their approaches to address all three sub-tasks in SemEval 2023's Legal-Eval, utilizing various deep learning-based models.", "example": "Convert the coordinate to text: [-4.7407 -3.0827]:"}
{"text": "Convert the coordinate to text: [-2.1234 -5.5467]: The RIGA team introduces an approach that uses Large-scale Language Models (LLMs), specifically GPT-3, to gather additional contexts. These contexts are then used to fine-tune a pre-trained neural network.", "target": "The RIGA team introduces an approach that uses Large-scale Language Models (LLMs), specifically GPT-3, to gather additional contexts. These contexts are then used to fine-tune a pre-trained neural network.", "example": "Convert the coordinate to text: [-2.1234 -5.5467]:"}
{"text": "Convert the coordinate to text: [-5.1832 -1.4152]: The authors present a new approach that uses robust methods to extract structural information and character coreference clusters from full-length movie screenplays.", "target": "The authors present a new approach that uses robust methods to extract structural information and character coreference clusters from full-length movie screenplays.", "example": "Convert the coordinate to text: [-5.1832 -1.4152]:"}
{"text": "Convert the coordinate to text: [-1.3438 -3.9753]: The paper proposes the GRACE (Gradient-guided Controllable Retrieval) framework, which distills controlling information from natural texts for generating more fluent sentences while maintaining high controllability.", "target": "The paper proposes the GRACE (Gradient-guided Controllable Retrieval) framework, which distills controlling information from natural texts for generating more fluent sentences while maintaining high controllability.", "example": "Convert the coordinate to text: [-1.3438 -3.9753]:"}
{"text": "Convert the coordinate to text: [ 2.1969 13.703 ]: The authors propose a novel algorithm called CLUB-HG, which integrates a game-theoretic approach into clustering inference. The algorithm achieves Nash equilibrium at each inference step and discovers the underlying user clusters.", "target": "The authors propose a novel algorithm called CLUB-HG, which integrates a game-theoretic approach into clustering inference. The algorithm achieves Nash equilibrium at each inference step and discovers the underlying user clusters.", "example": "Convert the coordinate to text: [ 2.1969 13.703 ]:"}
{"text": "Convert the coordinate to text: [ 0.1889 -8.4149]: The authors propose a Cross-Modal Translation and Alignment (CMTA) framework to address these problems by exploring intrinsic cross-modal correlations and transferring potential complementary information.", "target": "The authors propose a Cross-Modal Translation and Alignment (CMTA) framework to address these problems by exploring intrinsic cross-modal correlations and transferring potential complementary information.", "example": "Convert the coordinate to text: [ 0.1889 -8.4149]:"}
{"text": "Convert the coordinate to text: [11.3484 -9.8914]: The authors propose using multi-source datasets with various resolution images to jointly learn a high-resolution human generative model, despite the datasets consisting of unaligned parts and different scales.", "target": "The authors propose using multi-source datasets with various resolution images to jointly learn a high-resolution human generative model, despite the datasets consisting of unaligned parts and different scales.", "example": "Convert the coordinate to text: [11.3484 -9.8914]:"}
{"text": "Convert the coordinate to text: [  0.9701 -10.4214]: The study proposes Curation in Training (CiT), an efficient vision-text learning algorithm that incorporates a data objective into training, thus automatically yielding quality data to hasten contrastive image-text training and lessening the need for an offline data filtering pipeline.", "target": "The study proposes Curation in Training (CiT), an efficient vision-text learning algorithm that incorporates a data objective into training, thus automatically yielding quality data to hasten contrastive image-text training and lessening the need for an offline data filtering pipeline.", "example": "Convert the coordinate to text: [  0.9701 -10.4214]:"}
{"text": "Convert the coordinate to text: [11.1078 -6.4965]: The authors present the Diffusion-augmented Generative model, DG3D, that generates high-fidelity 3D textured meshes incorporating a diffusion-based augmentation module into the min-max game between the 3D tetrahedral mesh generator and 2D renderings discriminators.", "target": "The authors present the Diffusion-augmented Generative model, DG3D, that generates high-fidelity 3D textured meshes incorporating a diffusion-based augmentation module into the min-max game between the 3D tetrahedral mesh generator and 2D renderings discriminators.", "example": "Convert the coordinate to text: [11.1078 -6.4965]:"}
{"text": "Convert the coordinate to text: [-3.6905 12.2521]: This paper introduces a formal definition of moral responsibility for AI systems, which incorporates both a causal condition and an epistemic condition within a framework of causal models.", "target": "This paper introduces a formal definition of moral responsibility for AI systems, which incorporates both a causal condition and an epistemic condition within a framework of causal models.", "example": "Convert the coordinate to text: [-3.6905 12.2521]:"}
{"text": "Convert the coordinate to text: [6.5862 8.681 ]: The authors suggest a probabilistic framework, the Multi Time Scale State Space (MTS3) model, to learn multi-time scale world models. This model provides an efficient inference scheme on multiple time scales for highly accurate long-horizon predictions and uncertainty estimates.", "target": "The authors suggest a probabilistic framework, the Multi Time Scale State Space (MTS3) model, to learn multi-time scale world models. This model provides an efficient inference scheme on multiple time scales for highly accurate long-horizon predictions and uncertainty estimates.", "example": "Convert the coordinate to text: [6.5862 8.681 ]:"}
{"text": "Convert the coordinate to text: [-0.7257 -6.6917]: The authors approach the few-shot experimental design problem as a conditional generation task. They introduce a model called Experiment Pretrained Transformers (ExPT), which leverages synthetic pretraining with in-context learning, and only requires a finite collection of unlabelled data points from the input domain.", "target": "The authors approach the few-shot experimental design problem as a conditional generation task. They introduce a model called Experiment Pretrained Transformers (ExPT), which leverages synthetic pretraining with in-context learning, and only requires a finite collection of unlabelled data points from the input domain.", "example": "Convert the coordinate to text: [-0.7257 -6.6917]:"}
{"text": "Convert the coordinate to text: [1.2416 2.5246]: The authors introduce Text-Transport, a method for estimating causal effects from natural language under any text distribution, leveraging the concept of distribution shift to describe an estimator that transports causal effects between domains, circumventing the need for strong assumptions in the target domain.", "target": "The authors introduce Text-Transport, a method for estimating causal effects from natural language under any text distribution, leveraging the concept of distribution shift to describe an estimator that transports causal effects between domains, circumventing the need for strong assumptions in the target domain.", "example": "Convert the coordinate to text: [1.2416 2.5246]:"}
{"text": "Convert the coordinate to text: [  5.4343 -13.7241]: The paper suggests reducing the spatial and temporal redundancy of feature grids by merging similar features for model compression, a method termed as 'dynamic codebook'. This approach compensates for any potential decline in rendering quality by implementing a set of dynamic codes.", "target": "The paper suggests reducing the spatial and temporal redundancy of feature grids by merging similar features for model compression, a method termed as 'dynamic codebook'. This approach compensates for any potential decline in rendering quality by implementing a set of dynamic codes.", "example": "Convert the coordinate to text: [  5.4343 -13.7241]:"}
{"text": "Convert the coordinate to text: [12.1955 -4.1026]: The work focuses on designing and analyzing a reliable learner which can provide optimal and provable guarantees in challenging environments including various adversarial test-time attacks and scenarios with natural distribution shifts.", "target": "The work focuses on designing and analyzing a reliable learner which can provide optimal and provable guarantees in challenging environments including various adversarial test-time attacks and scenarios with natural distribution shifts.", "example": "Convert the coordinate to text: [12.1955 -4.1026]:"}
{"text": "Convert the coordinate to text: [  4.9444 -11.1862]: This paper suggests a SOD algorithm fusing RGB image and eye tracking data, using the eye fixation points to better simulate the human visual selection attention mechanism and integrate high-level semantic information.", "target": "This paper suggests a SOD algorithm fusing RGB image and eye tracking data, using the eye fixation points to better simulate the human visual selection attention mechanism and integrate high-level semantic information.", "example": "Convert the coordinate to text: [  4.9444 -11.1862]:"}
{"text": "Convert the coordinate to text: [ 7.0854 -8.1871]: A learning-based encoder for fast and accurate concept customization is proposed. This encoder comprises global and local mapping networks, which separately project the hierarchical features of a given image into multiple 'new' words in the textual word embedding space, and inject encoded patch features into cross attention layers.", "target": "A learning-based encoder for fast and accurate concept customization is proposed. This encoder comprises global and local mapping networks, which separately project the hierarchical features of a given image into multiple 'new' words in the textual word embedding space, and inject encoded patch features into cross attention layers.", "example": "Convert the coordinate to text: [ 7.0854 -8.1871]:"}
{"text": "Convert the coordinate to text: [ 5.1432 -5.1043]: The authors propose a novel deep evolutionary graph mapping framework, GmapAD, which can adaptively map each graph into a new feature space based on its similarity to a set of representative nodes chosen from the graph set. It explores both intra- and inter-graph structural and attribute information.", "target": "The authors propose a novel deep evolutionary graph mapping framework, GmapAD, which can adaptively map each graph into a new feature space based on its similarity to a set of representative nodes chosen from the graph set. It explores both intra- and inter-graph structural and attribute information.", "example": "Convert the coordinate to text: [ 5.1432 -5.1043]:"}
{"text": "Convert the coordinate to text: [ 5.843  -4.0618]: The authors propose Conditional Adapter (CoDA), a novel transfer learning method that uses sparse activation and a small number of new parameters to improve inference efficiency without significantly sacrificing accuracy.", "target": "The authors propose Conditional Adapter (CoDA), a novel transfer learning method that uses sparse activation and a small number of new parameters to improve inference efficiency without significantly sacrificing accuracy.", "example": "Convert the coordinate to text: [ 5.843  -4.0618]:"}
{"text": "Convert the coordinate to text: [-2.5811 -6.3886]: The authors hypothesize that PreNorm may overfit supervised directions in Zero-shot Translation and thus it may have low generalizability for ZST.", "target": "The authors hypothesize that PreNorm may overfit supervised directions in Zero-shot Translation and thus it may have low generalizability for ZST.", "example": "Convert the coordinate to text: [-2.5811 -6.3886]:"}
{"text": "Convert the coordinate to text: [ 2.2005 -9.7793]: A novel method, LEMMA, is proposed, which explicitly models character regions to provide high-level, text-specific guidance for super-resolution. It includes a location enhancement module to extract character region features, a multimodal alignment module for bidirectional visual-semantic alignment, and an adaptive fusion module.", "target": "A novel method, LEMMA, is proposed, which explicitly models character regions to provide high-level, text-specific guidance for super-resolution. It includes a location enhancement module to extract character region features, a multimodal alignment module for bidirectional visual-semantic alignment, and an adaptive fusion module.", "example": "Convert the coordinate to text: [ 2.2005 -9.7793]:"}
{"text": "Convert the coordinate to text: [1.8532 5.4318]: The authors propose extending the $n$-th order H-index to temporal networks, and they also introduce corresponding temporal centrality measures and temporal core decompositions for these networks.", "target": "The authors propose extending the $n$-th order H-index to temporal networks, and they also introduce corresponding temporal centrality measures and temporal core decompositions for these networks.", "example": "Convert the coordinate to text: [1.8532 5.4318]:"}
{"text": "Convert the coordinate to text: [-6.6548 -9.8817]: The authors introduce NaSGEC, a new dataset for CGEC for native speaker texts from multiple domains, not just learner essays.", "target": "The authors introduce NaSGEC, a new dataset for CGEC for native speaker texts from multiple domains, not just learner essays.", "example": "Convert the coordinate to text: [-6.6548 -9.8817]:"}
{"text": "Convert the coordinate to text: [-1.7844 -4.9179]: This paper examines how LLMs leverage shortcuts or spurious correlations within prompts and found that LLMs tend to be 'lazy learners', exploiting shortcuts in prompts for downstream tasks.", "target": "This paper examines how LLMs leverage shortcuts or spurious correlations within prompts and found that LLMs tend to be 'lazy learners', exploiting shortcuts in prompts for downstream tasks.", "example": "Convert the coordinate to text: [-1.7844 -4.9179]:"}
{"text": "Convert the coordinate to text: [0.5126 1.6026]: The authors introduce a method using Causal Average Treatment Effect scores and counterfactual augmentation to control the attributes of Language Models, and propose the Causally Fair Language architecture for detoxifying pre-trained Language Models in a more mathematically transparent and efficient way.", "target": "The authors introduce a method using Causal Average Treatment Effect scores and counterfactual augmentation to control the attributes of Language Models, and propose the Causally Fair Language architecture for detoxifying pre-trained Language Models in a more mathematically transparent and efficient way.", "example": "Convert the coordinate to text: [0.5126 1.6026]:"}
{"text": "Convert the coordinate to text: [-1.875  -6.7759]: In this study, the authors introduce CamemBERTa, a data-efficient French DeBERTa model that builds upon the DeBERTaV3 architecture and training objective, improving upon the existing CamemBERT.", "target": "In this study, the authors introduce CamemBERTa, a data-efficient French DeBERTa model that builds upon the DeBERTaV3 architecture and training objective, improving upon the existing CamemBERT.", "example": "Convert the coordinate to text: [-1.875  -6.7759]:"}
{"text": "Convert the coordinate to text: [ 0.849  -3.3184]: The authors propose a novel method that combines a knowledge tracing model to estimate a student's evolving knowledge state, and a controlled text generation model to generate exercise sentences tailored to the student's current knowledge and instructor requirements.", "target": "The authors propose a novel method that combines a knowledge tracing model to estimate a student's evolving knowledge state, and a controlled text generation model to generate exercise sentences tailored to the student's current knowledge and instructor requirements.", "example": "Convert the coordinate to text: [ 0.849  -3.3184]:"}
{"text": "Convert the coordinate to text: [-2.8185 -7.3186]: The paper proposes the concept of \"target language-ready\" (TLR) adapters, which are task adapters fine-tuned for the target language(s). This maintains high transfer performance while preserving the modular design of MAD-X. The idea addresses the training-inference discrepancy of MAD-X by exposing the task adapter to the target language adapter during training.", "target": "The paper proposes the concept of \"target language-ready\" (TLR) adapters, which are task adapters fine-tuned for the target language(s). This maintains high transfer performance while preserving the modular design of MAD-X. The idea addresses the training-inference discrepancy of MAD-X by exposing the task adapter to the target language adapter during training.", "example": "Convert the coordinate to text: [-2.8185 -7.3186]:"}
{"text": "Convert the coordinate to text: [-0.0144 -7.2154]: The authors propose DecompX, a method that focuses on constructing decomposed token representations and propagating them throughout the model without mixing them in between layers. It also includes all encoder components (especially nonlinear feed-forward networks) and the classification head.", "target": "The authors propose DecompX, a method that focuses on constructing decomposed token representations and propagating them throughout the model without mixing them in between layers. It also includes all encoder components (especially nonlinear feed-forward networks) and the classification head.", "example": "Convert the coordinate to text: [-0.0144 -7.2154]:"}
{"text": "Convert the coordinate to text: [-0.8652  6.1567]: The authors propose a framework for MWP solvers based on the generation of linguistic variants of the problem text. The approach involves solving each of the variant problems and determining the predicted expression with the majority.", "target": "The authors propose a framework for MWP solvers based on the generation of linguistic variants of the problem text. The approach involves solving each of the variant problems and determining the predicted expression with the majority.", "example": "Convert the coordinate to text: [-0.8652  6.1567]:"}
{"text": "Convert the coordinate to text: [-0.9076 -3.7886]: The authors propose a novel framework for knowledge graph enhanced dialogue generation that involves the language model in feature aggregation in the graph at all steps by dynamically constructing a multi-hop knowledge graph with pseudo nodes.", "target": "The authors propose a novel framework for knowledge graph enhanced dialogue generation that involves the language model in feature aggregation in the graph at all steps by dynamically constructing a multi-hop knowledge graph with pseudo nodes.", "example": "Convert the coordinate to text: [-0.9076 -3.7886]:"}
{"text": "Convert the coordinate to text: [-1.9745 -6.221 ]: The authors propose a novel domain-specific model called BioNART, based on the encoder-decoder model, and compatible with the BERT architecture, allowing for the use of pre-trained biomedical language model checkpoints.", "target": "The authors propose a novel domain-specific model called BioNART, based on the encoder-decoder model, and compatible with the BERT architecture, allowing for the use of pre-trained biomedical language model checkpoints.", "example": "Convert the coordinate to text: [-1.9745 -6.221 ]:"}
{"text": "Convert the coordinate to text: [-7.5336 -7.3333]: The authors attempted to enhance NER by incorporating part-of-speech (POS) tags and dependency relation labels into a multitask model.", "target": "The authors attempted to enhance NER by incorporating part-of-speech (POS) tags and dependency relation labels into a multitask model.", "example": "Convert the coordinate to text: [-7.5336 -7.3333]:"}
{"text": "Convert the coordinate to text: [ 1.534  -7.6135]: The paper proposes a novel efficient Transformer model with adaptive attention, A2-Former, for long sequence modeling. A2-Former can select useful tokens automatically in sparse attention by learnable position vectors, which consist of meta position and offset position vectors.", "target": "The paper proposes a novel efficient Transformer model with adaptive attention, A2-Former, for long sequence modeling. A2-Former can select useful tokens automatically in sparse attention by learnable position vectors, which consist of meta position and offset position vectors.", "example": "Convert the coordinate to text: [ 1.534  -7.6135]:"}
{"text": "Convert the coordinate to text: [13.0701 -2.3723]: This paper proposes a novel extension of neural sequential models using path signatures from rough path theory, combined with contextual neural representations and recursive neural networks, to capture non-linearities and produce compact, time-sensitive user representations.", "target": "This paper proposes a novel extension of neural sequential models using path signatures from rough path theory, combined with contextual neural representations and recursive neural networks, to capture non-linearities and produce compact, time-sensitive user representations.", "example": "Convert the coordinate to text: [13.0701 -2.3723]:"}
{"text": "Convert the coordinate to text: [-10.5753  -1.8776]: The authors propose QGA-EE, a method which uses a Question Generation (QG) model to generate contextually rich questions, not relying on fixed templates. Dynamic templates are also introduced for the training of the QG model.", "target": "The authors propose QGA-EE, a method which uses a Question Generation (QG) model to generate contextually rich questions, not relying on fixed templates. Dynamic templates are also introduced for the training of the QG model.", "example": "Convert the coordinate to text: [-10.5753  -1.8776]:"}
{"text": "Convert the coordinate to text: [-3.3470e-03 -4.9275e+00]: The authors propose a Hierarchical Duality Learning for Dialogue (HDLD) which simulates this human cognitive ability through maximizing the mutual information between past and future utterances. The model is unique in that it estimates future information implicitly based on dialogue history.", "target": "The authors propose a Hierarchical Duality Learning for Dialogue (HDLD) which simulates this human cognitive ability through maximizing the mutual information between past and future utterances. The model is unique in that it estimates future information implicitly based on dialogue history.", "example": "Convert the coordinate to text: [-3.3470e-03 -4.9275e+00]:"}
{"text": "Convert the coordinate to text: [-5.3438  3.8209]: The paper proposes a novel framework that leverages user profiling to generate personalized headlines, using a learnable relevance function to assign personalized signature phrases to users based on their reading histories.", "target": "The paper proposes a novel framework that leverages user profiling to generate personalized headlines, using a learnable relevance function to assign personalized signature phrases to users based on their reading histories.", "example": "Convert the coordinate to text: [-5.3438  3.8209]:"}
{"text": "Convert the coordinate to text: [ 4.8634 14.1521]: The authors propose an Internal Logical Induction (ILI) framework that integrates deep RL and rule learning into one system. The ILI framework uses deep RL to process pixel inputs and rule learning algorithm to induce propositional logic knowledge from symbolic input.", "target": "The authors propose an Internal Logical Induction (ILI) framework that integrates deep RL and rule learning into one system. The ILI framework uses deep RL to process pixel inputs and rule learning algorithm to induce propositional logic knowledge from symbolic input.", "example": "Convert the coordinate to text: [ 4.8634 14.1521]:"}
{"text": "Convert the coordinate to text: [ 6.8538 -3.8698]: The authors propose a novel approach for source-free domain adaptation on time series data called MAsk and imPUte (MAPU), which uses a temporal imputer to recover the original signal from a masked version in the embedding space and guide the target model to produce target features that are temporally consistent with the source features.", "target": "The authors propose a novel approach for source-free domain adaptation on time series data called MAsk and imPUte (MAPU), which uses a temporal imputer to recover the original signal from a masked version in the embedding space and guide the target model to produce target features that are temporally consistent with the source features.", "example": "Convert the coordinate to text: [ 6.8538 -3.8698]:"}
{"text": "Convert the coordinate to text: [6.6668 7.1855]: The research proposes algorithms to select the optimal user contribution bound for histogram estimation in both bounded and unbounded domain settings to maintain privacy without discarding important data.", "target": "The research proposes algorithms to select the optimal user contribution bound for histogram estimation in both bounded and unbounded domain settings to maintain privacy without discarding important data.", "example": "Convert the coordinate to text: [6.6668 7.1855]:"}
{"text": "Convert the coordinate to text: [-1.9202 12.9453]: The authors propose the idea of using artificial intelligence to engineer cooperation and alleviate conflict in multiagent systems by providing improved algorithms and interaction paradigms.", "target": "The authors propose the idea of using artificial intelligence to engineer cooperation and alleviate conflict in multiagent systems by providing improved algorithms and interaction paradigms.", "example": "Convert the coordinate to text: [-1.9202 12.9453]:"}
{"text": "Convert the coordinate to text: [ 5.2382 -9.3669]: This paper introduces Multimodal alignmEnt aGgregation and distillAtion (MEGA), a method for cinematic long-video segmentation that harnesses multiple media modalities, and maintains temporal synchronization while reducing computation.", "target": "This paper introduces Multimodal alignmEnt aGgregation and distillAtion (MEGA), a method for cinematic long-video segmentation that harnesses multiple media modalities, and maintains temporal synchronization while reducing computation.", "example": "Convert the coordinate to text: [ 5.2382 -9.3669]:"}
{"text": "Convert the coordinate to text: [ 3.6733 -4.7009]: The authors propose the Task-aware Adaptive Network (TA2 -Net), which uses reinforcement learning to estimate the optimal task-specific parameter configuration for each task. This parameter configuration takes into consideration the level of domain shift between tasks.", "target": "The authors propose the Task-aware Adaptive Network (TA2 -Net), which uses reinforcement learning to estimate the optimal task-specific parameter configuration for each task. This parameter configuration takes into consideration the level of domain shift between tasks.", "example": "Convert the coordinate to text: [ 3.6733 -4.7009]:"}
{"text": "Convert the coordinate to text: [4.4821 4.3782]: This study introduces a process called scalable Hyperbolic Hierarchical Clustering (sHHC) that learns continuous hierarchies in hyperbolic space, overcoming the limitations of traditional hierarchical techniques.", "target": "This study introduces a process called scalable Hyperbolic Hierarchical Clustering (sHHC) that learns continuous hierarchies in hyperbolic space, overcoming the limitations of traditional hierarchical techniques.", "example": "Convert the coordinate to text: [4.4821 4.3782]:"}
{"text": "Convert the coordinate to text: [ 3.138  13.9405]: The study introduces a method using an oracle providing exact policy evaluation to improve the independent NPG method to eventually reach an $\\epsilon$-Nash Equilibrium (NE) faster.", "target": "The study introduces a method using an oracle providing exact policy evaluation to improve the independent NPG method to eventually reach an $\\epsilon$-Nash Equilibrium (NE) faster.", "example": "Convert the coordinate to text: [ 3.138  13.9405]:"}
{"text": "Convert the coordinate to text: [ 9.5691 -0.052 ]: The authors introduce a new training approach called Manifold Projection-Diffusion Recovery (MPDR) that perturbs a data point along a low-dimensional manifold approximating the training dataset. It optimises EBMs to maximize the probability of recovering the original data.", "target": "The authors introduce a new training approach called Manifold Projection-Diffusion Recovery (MPDR) that perturbs a data point along a low-dimensional manifold approximating the training dataset. It optimises EBMs to maximize the probability of recovering the original data.", "example": "Convert the coordinate to text: [ 9.5691 -0.052 ]:"}
{"text": "Convert the coordinate to text: [-0.9236 -4.5875]: The authors explore a solution to reduce the cost of VPG transfer, by investigating the VPG transferability across different LLM sizes and types.", "target": "The authors explore a solution to reduce the cost of VPG transfer, by investigating the VPG transferability across different LLM sizes and types.", "example": "Convert the coordinate to text: [-0.9236 -4.5875]:"}
{"text": "Convert the coordinate to text: [9.2967 2.9697]: The authors present a new kernel for time series analysis based on the established equivalence between reservoir dynamics and Nonlinear Vector AutoRegressive (NVAR) processes, utilizing a non-recurrent kernel that hinges on a small set of meaningful hyperparameters.", "target": "The authors present a new kernel for time series analysis based on the established equivalence between reservoir dynamics and Nonlinear Vector AutoRegressive (NVAR) processes, utilizing a non-recurrent kernel that hinges on a small set of meaningful hyperparameters.", "example": "Convert the coordinate to text: [9.2967 2.9697]:"}
{"text": "Convert the coordinate to text: [-0.4607  1.4114]: This paper investigates the commercial impact of publicly naming and disclosing performance results of biased AI systems - making use of the audit design and structured disclosure procedure used in the Gender Shades study that looked at gender- and skin-type performance disparities in commercial facial analysis models.", "target": "This paper investigates the commercial impact of publicly naming and disclosing performance results of biased AI systems - making use of the audit design and structured disclosure procedure used in the Gender Shades study that looked at gender- and skin-type performance disparities in commercial facial analysis models.", "example": "Convert the coordinate to text: [-0.4607  1.4114]:"}
{"text": "Convert the coordinate to text: [2.8477 8.9851]: The study proposes an improved method for generating explanations to CSPs that are provably optimal (with respect to the given cost metric) by developing a hitting set-based algorithm, a method for reusing information across multiple algorithm calls, and methods for exploiting domain-specific information.", "target": "The study proposes an improved method for generating explanations to CSPs that are provably optimal (with respect to the given cost metric) by developing a hitting set-based algorithm, a method for reusing information across multiple algorithm calls, and methods for exploiting domain-specific information.", "example": "Convert the coordinate to text: [2.8477 8.9851]:"}
{"text": "Convert the coordinate to text: [12.1102 -1.4557]: The authors propose a set of asymptotically exact equations to understand the generalisation dynamics of non-linear, shallow autoencoders trained with SGD in high-dimensional inputs, demonstrating that these autoencoders learn the leading principal components of their inputs sequentially.", "target": "The authors propose a set of asymptotically exact equations to understand the generalisation dynamics of non-linear, shallow autoencoders trained with SGD in high-dimensional inputs, demonstrating that these autoencoders learn the leading principal components of their inputs sequentially.", "example": "Convert the coordinate to text: [12.1102 -1.4557]:"}
{"text": "Convert the coordinate to text: [-7.3983 -8.0922]: This work proposes the K-UniMorph dataset, a Universal Morphological paradigm for the Korean language, detailing the extraction of inflected forms and the generation of morphological schemata.", "target": "This work proposes the K-UniMorph dataset, a Universal Morphological paradigm for the Korean language, detailing the extraction of inflected forms and the generation of morphological schemata.", "example": "Convert the coordinate to text: [-7.3983 -8.0922]:"}
{"text": "Convert the coordinate to text: [-2.9641  5.9271]: The paper proposes a method for curating and leveraging high-precision samples sourced from historical regression incident reports to validate, safe-guard, and improve policies prior to online deployment.", "target": "The paper proposes a method for curating and leveraging high-precision samples sourced from historical regression incident reports to validate, safe-guard, and improve policies prior to online deployment.", "example": "Convert the coordinate to text: [-2.9641  5.9271]:"}
{"text": "Convert the coordinate to text: [13.5756  0.313 ]: The authors introduce a novel parameterization framework for STPPs which effectively models complex spatio-temporal joint distributions through diffusion models. The learning process is decomposed into multiple steps that each can be accurately described by a Gaussian distribution, with an elaborate spatio-temporal co-attention module introduced to capture the interdependence between event time and space adaptively.", "target": "The authors introduce a novel parameterization framework for STPPs which effectively models complex spatio-temporal joint distributions through diffusion models. The learning process is decomposed into multiple steps that each can be accurately described by a Gaussian distribution, with an elaborate spatio-temporal co-attention module introduced to capture the interdependence between event time and space adaptively.", "example": "Convert the coordinate to text: [13.5756  0.313 ]:"}
{"text": "Convert the coordinate to text: [2.8595 1.3675]: The authors propose an algorithm that regularizes the learned effect of the features on the prediction to match the estimated effect of the feature on the label, to curb spurious correlations without dismissing causally relevant features.", "target": "The authors propose an algorithm that regularizes the learned effect of the features on the prediction to match the estimated effect of the feature on the label, to curb spurious correlations without dismissing causally relevant features.", "example": "Convert the coordinate to text: [2.8595 1.3675]:"}
{"text": "Convert the coordinate to text: [ 0.0978 -3.9303]: The authors propose a modularized zero-shot network that decomposes questions into sub reasoning steps. The sub reasoning tasks are converted into acceptable objectives for PTMs, which are then performed by fitting PTMs without adaptation.", "target": "The authors propose a modularized zero-shot network that decomposes questions into sub reasoning steps. The sub reasoning tasks are converted into acceptable objectives for PTMs, which are then performed by fitting PTMs without adaptation.", "example": "Convert the coordinate to text: [ 0.0978 -3.9303]:"}
{"text": "Convert the coordinate to text: [-7.3531  7.1548]: This study aims to address this challenge by integrating discourse information from various subreddit communities using embedding techniques to develop an effective recommendation system focused on mental health support groups.", "target": "This study aims to address this challenge by integrating discourse information from various subreddit communities using embedding techniques to develop an effective recommendation system focused on mental health support groups.", "example": "Convert the coordinate to text: [-7.3531  7.1548]:"}
{"text": "Convert the coordinate to text: [-3.3442 -6.6355]: The authors investigate WSD in a multimodal setting using pre-trained CLIP models and conduct an analysis of CLIP's zero-shot performance on monolingual and multilingual data.", "target": "The authors investigate WSD in a multimodal setting using pre-trained CLIP models and conduct an analysis of CLIP's zero-shot performance on monolingual and multilingual data.", "example": "Convert the coordinate to text: [-3.3442 -6.6355]:"}
{"text": "Convert the coordinate to text: [ 0.0593 -9.0919]: This paper proposes a solution for V-WSD using the state-of-the-art Image-Text Retrieval system, CLIP, and augments linguistic ambiguity across various domains and languages through text and image augmentation, powered by back-translation involving various auxiliary languages.", "target": "This paper proposes a solution for V-WSD using the state-of-the-art Image-Text Retrieval system, CLIP, and augments linguistic ambiguity across various domains and languages through text and image augmentation, powered by back-translation involving various auxiliary languages.", "example": "Convert the coordinate to text: [ 0.0593 -9.0919]:"}
{"text": "Convert the coordinate to text: [-0.8605 -5.1877]: The study proposes a new regularization method, CoRe, for gradient-based prompt tuning techniques, aiming to guide a prompt to produce a task context appropriately. It brings two regularization effects, context attuning and context filtering, to improve prediction performance in a zero-shot in-context learning setting without any demonstration examples.", "target": "The study proposes a new regularization method, CoRe, for gradient-based prompt tuning techniques, aiming to guide a prompt to produce a task context appropriately. It brings two regularization effects, context attuning and context filtering, to improve prediction performance in a zero-shot in-context learning setting without any demonstration examples.", "example": "Convert the coordinate to text: [-0.8605 -5.1877]:"}
{"text": "Convert the coordinate to text: [ 0.5158 -7.9524]: The authors propose a novel MUltimodal Structural Transformer (MUST) for web information extraction that incorporates multiple modalities, encoding the multimodal information based on the HTML structure of the web layout, with high-level DOM nodes, and low-level text and image tokens introduced to represent the entire page.", "target": "The authors propose a novel MUltimodal Structural Transformer (MUST) for web information extraction that incorporates multiple modalities, encoding the multimodal information based on the HTML structure of the web layout, with high-level DOM nodes, and low-level text and image tokens introduced to represent the entire page.", "example": "Convert the coordinate to text: [ 0.5158 -7.9524]:"}
{"text": "Convert the coordinate to text: [11.9664 -2.747 ]: The authors propose extending the Lipschitz analysis to graphs by establishing a systematic scheme to estimate the upper bounds of the Lipschitz constants of GNNs, even for commonly used GNN architectures including GCN, GraphSAGE and GAT.", "target": "The authors propose extending the Lipschitz analysis to graphs by establishing a systematic scheme to estimate the upper bounds of the Lipschitz constants of GNNs, even for commonly used GNN architectures including GCN, GraphSAGE and GAT.", "example": "Convert the coordinate to text: [11.9664 -2.747 ]:"}
{"text": "Convert the coordinate to text: [11.9746 -8.5331]: This paper introduces AdaTrans, an adaptive nonlinear latent transformation for conditional and disentangled face editing. It divides the manipulation process into finer steps and manipulates faces into target attributes while keeping others unchanged.", "target": "This paper introduces AdaTrans, an adaptive nonlinear latent transformation for conditional and disentangled face editing. It divides the manipulation process into finer steps and manipulates faces into target attributes while keeping others unchanged.", "example": "Convert the coordinate to text: [11.9746 -8.5331]:"}
{"text": "Convert the coordinate to text: [12.232  -5.4833]: The authors propose to establish a comprehensive point cloud adversarial robustness benchmark and propose a hybrid training augmentation method that considers various types of point cloud adversarial examples to adversarial training.", "target": "The authors propose to establish a comprehensive point cloud adversarial robustness benchmark and propose a hybrid training augmentation method that considers various types of point cloud adversarial examples to adversarial training.", "example": "Convert the coordinate to text: [12.232  -5.4833]:"}
{"text": "Convert the coordinate to text: [ 11.7047 -15.1381]: The authors propose MotionLM, a model that represents continuous trajectories as sequences of discrete motion tokens and treats multi-agent motion prediction as a language modeling task. The model does away with the need for anchors and explicit latent variable optimization and bypasses post-hoc interaction heuristics.", "target": "The authors propose MotionLM, a model that represents continuous trajectories as sequences of discrete motion tokens and treats multi-agent motion prediction as a language modeling task. The model does away with the need for anchors and explicit latent variable optimization and bypasses post-hoc interaction heuristics.", "example": "Convert the coordinate to text: [ 11.7047 -15.1381]:"}
{"text": "Convert the coordinate to text: [  9.7645 -19.3395]: The authors propose a real-time scene reconstruction method that uses a novel stereo-based depth prediction network to maintain the consistency of depth prediction in a sequence of images.", "target": "The authors propose a real-time scene reconstruction method that uses a novel stereo-based depth prediction network to maintain the consistency of depth prediction in a sequence of images.", "example": "Convert the coordinate to text: [  9.7645 -19.3395]:"}
{"text": "Convert the coordinate to text: [ 7.1941 12.4905]: The authors propose an improved policy, the improved knowledge gradient (iKG), which instead of the original KG approach, chooses the measurement for the greatest one-step improvement in the probability of choosing the best arm. ", "target": "The authors propose an improved policy, the improved knowledge gradient (iKG), which instead of the original KG approach, chooses the measurement for the greatest one-step improvement in the probability of choosing the best arm. ", "example": "Convert the coordinate to text: [ 7.1941 12.4905]:"}
{"text": "Convert the coordinate to text: [ 3.6518 -5.519 ]: The authors introduce Neural k-Opt (NeuOpt), a novel L2S solver that uses a customized recurrent dual-stream decoder to perform flexible k-opt exchanges. Additionally, they propose the Guided Infeasible Region Exploration (GIRE) scheme, which helps explore both feasible and infeasible regions.", "target": "The authors introduce Neural k-Opt (NeuOpt), a novel L2S solver that uses a customized recurrent dual-stream decoder to perform flexible k-opt exchanges. Additionally, they propose the Guided Infeasible Region Exploration (GIRE) scheme, which helps explore both feasible and infeasible regions.", "example": "Convert the coordinate to text: [ 3.6518 -5.519 ]:"}
{"text": "Convert the coordinate to text: [0.356  2.4118]: The authors focus on the concept of 'causal context' to join the dots between counterfactual fairness, robust prediction, and group fairness. They show that no fundamental trade-off exists between fairness and accuracy under certain conditions, suggesting that a counterfactually fair predictor could be accuracy-optimal.", "target": "The authors focus on the concept of 'causal context' to join the dots between counterfactual fairness, robust prediction, and group fairness. They show that no fundamental trade-off exists between fairness and accuracy under certain conditions, suggesting that a counterfactually fair predictor could be accuracy-optimal.", "example": "Convert the coordinate to text: [0.356  2.4118]:"}
{"text": "Convert the coordinate to text: [-1.4315 -4.5361]: A new decoding algorithm is proposed that integrates a stepwise self-evaluation mechanism to guide and calibrate the reasoning process of LLMs for handling uncertainty in multi-step reasoning.", "target": "A new decoding algorithm is proposed that integrates a stepwise self-evaluation mechanism to guide and calibrate the reasoning process of LLMs for handling uncertainty in multi-step reasoning.", "example": "Convert the coordinate to text: [-1.4315 -4.5361]:"}
{"text": "Convert the coordinate to text: [0.9471 1.7874]: The authors introduce a new framework to utilize counterfactual generative models for producing a large variety of counterfactuals, which are sourced from the regions of uncertainty, and then automatically labeled by an auxiliary classifier that has been learned.", "target": "The authors introduce a new framework to utilize counterfactual generative models for producing a large variety of counterfactuals, which are sourced from the regions of uncertainty, and then automatically labeled by an auxiliary classifier that has been learned.", "example": "Convert the coordinate to text: [0.9471 1.7874]:"}
{"text": "Convert the coordinate to text: [  0.1364 -15.4014]: The authors proposed the use of an experimental paradigm of imagination and observation, a EEG acquisition platform built using UNITY and MATLAB, and a Genetic Algorithm Extreme Learning Machine (GA-ELM) for pattern recognition and Hilbert Huang time and frequency domain characteristics.", "target": "The authors proposed the use of an experimental paradigm of imagination and observation, a EEG acquisition platform built using UNITY and MATLAB, and a Genetic Algorithm Extreme Learning Machine (GA-ELM) for pattern recognition and Hilbert Huang time and frequency domain characteristics.", "example": "Convert the coordinate to text: [  0.1364 -15.4014]:"}
{"text": "Convert the coordinate to text: [ 0.4652 -8.0163]: The authors propose a Unified Tumor Transformer (UniT) model, which can detect and diagnose eight major cancer-prevalent organs in CT scans. The model operates via a query-based Mask Transformer model with multi-organ and multi-tumor semantic segmentation.", "target": "The authors propose a Unified Tumor Transformer (UniT) model, which can detect and diagnose eight major cancer-prevalent organs in CT scans. The model operates via a query-based Mask Transformer model with multi-organ and multi-tumor semantic segmentation.", "example": "Convert the coordinate to text: [ 0.4652 -8.0163]:"}
{"text": "Convert the coordinate to text: [-10.352   -2.2773]: The authors propose to use a query generator as the teacher in a cross-lingual setting, which is less dependent on a sufficient number of training samples and high-quality negative samples.", "target": "The authors propose to use a query generator as the teacher in a cross-lingual setting, which is less dependent on a sufficient number of training samples and high-quality negative samples.", "example": "Convert the coordinate to text: [-10.352   -2.2773]:"}
{"text": "Convert the coordinate to text: [ 3.42   -0.0203]: The authors propose combining transfer learning and active learning solutions to tackle the issue of dissonance detection in rare class problems. They also propose a new acquisition strategy termed probability-of-rare-class (PRC).", "target": "The authors propose combining transfer learning and active learning solutions to tackle the issue of dissonance detection in rare class problems. They also propose a new acquisition strategy termed probability-of-rare-class (PRC).", "example": "Convert the coordinate to text: [ 3.42   -0.0203]:"}
{"text": "Convert the coordinate to text: [-8.0124 -1.2593]: The authors propose an easy-to-hard learning framework for Information Extraction that mimics the human learning process. The framework consists of three stages: easy, hard, and main stages, helping the model to acquire general IE task knowledge and improve its generalization ability.", "target": "The authors propose an easy-to-hard learning framework for Information Extraction that mimics the human learning process. The framework consists of three stages: easy, hard, and main stages, helping the model to acquire general IE task knowledge and improve its generalization ability.", "example": "Convert the coordinate to text: [-8.0124 -1.2593]:"}
{"text": "Convert the coordinate to text: [-2.8318 -5.4153]: The authors have found that large language models (LLMs) can follow human instructions to directly generate URLs for document retrieval, even when not explicitly trained to map questions to document identifiers. They can consider LLMs as built-in search engines.", "target": "The authors have found that large language models (LLMs) can follow human instructions to directly generate URLs for document retrieval, even when not explicitly trained to map questions to document identifiers. They can consider LLMs as built-in search engines.", "example": "Convert the coordinate to text: [-2.8318 -5.4153]:"}
{"text": "Convert the coordinate to text: [-5.2449 -0.6067]: This study proposes a new task of fine-grained inconsistency detection aimed at predicting the fine-grained types of factual errors in a summary. It introduces the model FineGrainFact, which uses semantic frames extracted through semantic role labeling to represent the facts in the documents and summaries and predict inconsistencies.", "target": "This study proposes a new task of fine-grained inconsistency detection aimed at predicting the fine-grained types of factual errors in a summary. It introduces the model FineGrainFact, which uses semantic frames extracted through semantic role labeling to represent the facts in the documents and summaries and predict inconsistencies.", "example": "Convert the coordinate to text: [-5.2449 -0.6067]:"}
{"text": "Convert the coordinate to text: [ 5.0708 -1.9692]: The authors introduce CoLaDa, a Collaborative Label Denoising Framework that addresses label noise problems. The proposed framework employs a model-collaboration-based denoising scheme for pseudo labels and an instance-collaboration-based strategy that takes into account label consistency in the representation space.", "target": "The authors introduce CoLaDa, a Collaborative Label Denoising Framework that addresses label noise problems. The proposed framework employs a model-collaboration-based denoising scheme for pseudo labels and an instance-collaboration-based strategy that takes into account label consistency in the representation space.", "example": "Convert the coordinate to text: [ 5.0708 -1.9692]:"}
{"text": "Convert the coordinate to text: [-6.1709 -8.72  ]: The authors propose both a Chinese-English TIT dataset named OCRMT30K and a TIT model with a multimodal codebook.", "target": "The authors propose both a Chinese-English TIT dataset named OCRMT30K and a TIT model with a multimodal codebook.", "example": "Convert the coordinate to text: [-6.1709 -8.72  ]:"}
{"text": "Convert the coordinate to text: [-4.9269 -1.9708]: The paper introduces a novel method to generate candidates for re-ranking that tackles the problem of redundancy and low-quality content. This method grounds each candidate's abstract on its own unique content plan generated by a standard language model (BART LM).", "target": "The paper introduces a novel method to generate candidates for re-ranking that tackles the problem of redundancy and low-quality content. This method grounds each candidate's abstract on its own unique content plan generated by a standard language model (BART LM).", "example": "Convert the coordinate to text: [-4.9269 -1.9708]:"}
{"text": "Convert the coordinate to text: [-6.1326 -5.8282]: The authors propose the SWiPE dataset, which offers a reconstruction of the document-level editing process from English Wikipedia articles to paired Simple Wikipedia articles. Unlike previous work, SWiPE utilises the entire revision history when pairing pages to better pinpoint simplification edits.", "target": "The authors propose the SWiPE dataset, which offers a reconstruction of the document-level editing process from English Wikipedia articles to paired Simple Wikipedia articles. Unlike previous work, SWiPE utilises the entire revision history when pairing pages to better pinpoint simplification edits.", "example": "Convert the coordinate to text: [-6.1326 -5.8282]:"}
{"text": "Convert the coordinate to text: [-5.501   1.2523]: The authors introduce a new approach to identify rhetorical features of stance in academic English writing with eight rhetorical stance categories and additional discourse elements.", "target": "The authors introduce a new approach to identify rhetorical features of stance in academic English writing with eight rhetorical stance categories and additional discourse elements.", "example": "Convert the coordinate to text: [-5.501   1.2523]:"}
{"text": "Convert the coordinate to text: [ 1.9851 -0.7803]: The authors propose a new method that uses a pseudo-labeling approach to annotate useful historical queries based on their impact on the retrieval results. A selection model is trained on this pseudo-labeled data.", "target": "The authors propose a new method that uses a pseudo-labeling approach to annotate useful historical queries based on their impact on the retrieval results. A selection model is trained on this pseudo-labeled data.", "example": "Convert the coordinate to text: [ 1.9851 -0.7803]:"}
{"text": "Convert the coordinate to text: [ 3.6613 -1.0732]: The authors address this issue by proposing a novel reasoning task, which they formulate as a noisy Positive-Unlabeled learning problem. They propose a variational framework, nPUGraph, that can jointly estimate the correctness of both collected and uncollected facts.", "target": "The authors address this issue by proposing a novel reasoning task, which they formulate as a noisy Positive-Unlabeled learning problem. They propose a variational framework, nPUGraph, that can jointly estimate the correctness of both collected and uncollected facts.", "example": "Convert the coordinate to text: [ 3.6613 -1.0732]:"}
{"text": "Convert the coordinate to text: [ 0.053  -9.2456]: The authors participated in Task 1 of SemEval-2023 and experimented with different methods, including the image captioning method and CLIP methods, for visual word sense disambiguation.", "target": "The authors participated in Task 1 of SemEval-2023 and experimented with different methods, including the image captioning method and CLIP methods, for visual word sense disambiguation.", "example": "Convert the coordinate to text: [ 0.053  -9.2456]:"}
{"text": "Convert the coordinate to text: [-1.5384 -6.4104]: The authors used pre-trained transformer models and fine-tuned these on task datasets to identify medical causal claims and extract PIO frames.", "target": "The authors used pre-trained transformer models and fine-tuned these on task datasets to identify medical causal claims and extract PIO frames.", "example": "Convert the coordinate to text: [-1.5384 -6.4104]:"}
{"text": "Convert the coordinate to text: [-0.2348 -4.6121]: The paper introduces an approach that uses frame knowledge as a conceptual semantic guide to bridge the gap between known intent representation learning and unknown intent clustering. In addition, a frame-guided data augmenter is proposed to capture intent-friendly semantic information.", "target": "The paper introduces an approach that uses frame knowledge as a conceptual semantic guide to bridge the gap between known intent representation learning and unknown intent clustering. In addition, a frame-guided data augmenter is proposed to capture intent-friendly semantic information.", "example": "Convert the coordinate to text: [-0.2348 -4.6121]:"}
{"text": "Convert the coordinate to text: [-6.2262 -9.9408]: The authors propose PTCSpell, a new pre-trained corrector for the CSC task under the detector-corrector architecture. PTCSpell captures pronunciation and shape information with two novel pre-training objectives, and introduces a new strategy to tackle misleads from detector\u2019s predictions by balancing loss of correct and wrong characters.", "target": "The authors propose PTCSpell, a new pre-trained corrector for the CSC task under the detector-corrector architecture. PTCSpell captures pronunciation and shape information with two novel pre-training objectives, and introduces a new strategy to tackle misleads from detector\u2019s predictions by balancing loss of correct and wrong characters.", "example": "Convert the coordinate to text: [-6.2262 -9.9408]:"}
{"text": "Convert the coordinate to text: [13.2426 -4.5956]: A novel proactive defense against model poisoning attacks, named RECESS, is proposed. RECESS proactively queries each participating client with a specially constructed aggregation gradient, detects malicious clients according to their response with higher accuracy, and uses a new trust scoring mechanism to robustly aggregate gradients.", "target": "A novel proactive defense against model poisoning attacks, named RECESS, is proposed. RECESS proactively queries each participating client with a specially constructed aggregation gradient, detects malicious clients according to their response with higher accuracy, and uses a new trust scoring mechanism to robustly aggregate gradients.", "example": "Convert the coordinate to text: [13.2426 -4.5956]:"}
{"text": "Convert the coordinate to text: [ 4.9563 -3.2501]: An adaptive MoE framework, AdaMV-MoE, is proposed for multi-task vision recognition that automatically determines the number of activated experts for each task, thereby avoiding manual tuning of the model size.", "target": "An adaptive MoE framework, AdaMV-MoE, is proposed for multi-task vision recognition that automatically determines the number of activated experts for each task, thereby avoiding manual tuning of the model size.", "example": "Convert the coordinate to text: [ 4.9563 -3.2501]:"}
{"text": "Convert the coordinate to text: [ 5.9242 -8.4187]: The authors propose a method called Social Diffusion that forecasts both the motion of multiple people and their social interactions, using a diffusion model conditioned on motion histories and causal temporal convolutional networks.", "target": "The authors propose a method called Social Diffusion that forecasts both the motion of multiple people and their social interactions, using a diffusion model conditioned on motion histories and causal temporal convolutional networks.", "example": "Convert the coordinate to text: [ 5.9242 -8.4187]:"}
{"text": "Convert the coordinate to text: [13.8502 -0.0714]: The authors propose a connection between DEQs and Neural ODEs using homotopy continuation, concluding that they are essentially two sides of the same coin. This insight leads to the proposition of a new implicit model called HomoODE.", "target": "The authors propose a connection between DEQs and Neural ODEs using homotopy continuation, concluding that they are essentially two sides of the same coin. This insight leads to the proposition of a new implicit model called HomoODE.", "example": "Convert the coordinate to text: [13.8502 -0.0714]:"}
{"text": "Convert the coordinate to text: [ -0.2984 -10.6284]: The authors explore a strategy for VQA that involves question decomposition, leveraging the capabilities of large vision-language models to both use human-written decompositions and to produce their own decompositions of visual questions.", "target": "The authors explore a strategy for VQA that involves question decomposition, leveraging the capabilities of large vision-language models to both use human-written decompositions and to produce their own decompositions of visual questions.", "example": "Convert the coordinate to text: [ -0.2984 -10.6284]:"}
{"text": "Convert the coordinate to text: [-1.0117  3.2314]: The paper proposes a framework named Propensity Estimation for Causality-based Recommendation (PropCare) that estimates propensity and exposure only from interaction data without the need for ground truth on exposure or propensity in training and inference.", "target": "The paper proposes a framework named Propensity Estimation for Causality-based Recommendation (PropCare) that estimates propensity and exposure only from interaction data without the need for ground truth on exposure or propensity in training and inference.", "example": "Convert the coordinate to text: [-1.0117  3.2314]:"}
{"text": "Convert the coordinate to text: [2.1436 3.5051]: This study focuses on improving experimental designs for non-stationary environments under linear trends, with dual objectives to estimate dynamic treatment effect and minimize loss within the experiment itself.", "target": "This study focuses on improving experimental designs for non-stationary environments under linear trends, with dual objectives to estimate dynamic treatment effect and minimize loss within the experiment itself.", "example": "Convert the coordinate to text: [2.1436 3.5051]:"}
{"text": "Convert the coordinate to text: [10.5744  2.0375]: The authors propose two novel strategies to improve spectral clustering on incomplete data: a kernel correction method that enhances the quality of the kernel matrix estimated with incomplete data, and a series of affinity learning methods that incorporate the self-expressive framework with the $\\ell_p$-norm.", "target": "The authors propose two novel strategies to improve spectral clustering on incomplete data: a kernel correction method that enhances the quality of the kernel matrix estimated with incomplete data, and a series of affinity learning methods that incorporate the self-expressive framework with the $\\ell_p$-norm.", "example": "Convert the coordinate to text: [10.5744  2.0375]:"}
{"text": "Convert the coordinate to text: [13.2643 -7.0555]: In order to facilitate the training of the discriminator in GANs, the authors propose a new method from a unique viewpoint of online continual learning where they suggest a discriminator model that can self-regulate according to its ability to adapt to the changes in newly generated data.", "target": "In order to facilitate the training of the discriminator in GANs, the authors propose a new method from a unique viewpoint of online continual learning where they suggest a discriminator model that can self-regulate according to its ability to adapt to the changes in newly generated data.", "example": "Convert the coordinate to text: [13.2643 -7.0555]:"}
{"text": "Convert the coordinate to text: [4.0421 0.201 ]: The paper proposes an approach called 'uncertainty-aware bootstrap learning', inspired by the idea that the higher uncertainty of an instance, the more likely the model confidence is inconsistent with the ground truths. This approach uses instance-level data uncertainty to create initial high-confident examples.", "target": "The paper proposes an approach called 'uncertainty-aware bootstrap learning', inspired by the idea that the higher uncertainty of an instance, the more likely the model confidence is inconsistent with the ground truths. This approach uses instance-level data uncertainty to create initial high-confident examples.", "example": "Convert the coordinate to text: [4.0421 0.201 ]:"}
{"text": "Convert the coordinate to text: [-2.0273 -8.7743]: This paper proposes AlignSTS, a model for STS conversion based on explicit cross-modal alignment. This approach treats variations in speech, such as pitch and content, as different modalities. The AlignSTS model uses a rhythm adaptor to predict the target rhythm representation and realign the content based on cross-attention for resynthesis.", "target": "This paper proposes AlignSTS, a model for STS conversion based on explicit cross-modal alignment. This approach treats variations in speech, such as pitch and content, as different modalities. The AlignSTS model uses a rhythm adaptor to predict the target rhythm representation and realign the content based on cross-attention for resynthesis.", "example": "Convert the coordinate to text: [-2.0273 -8.7743]:"}
{"text": "Convert the coordinate to text: [  4.5305 -13.4508]: The authors propose a new task setting, Group-wise Referring Expression Segmentation (GRES), which expands RES to a collection of related images, allowing the described objects to be present in a subset of input images.", "target": "The authors propose a new task setting, Group-wise Referring Expression Segmentation (GRES), which expands RES to a collection of related images, allowing the described objects to be present in a subset of input images.", "example": "Convert the coordinate to text: [  4.5305 -13.4508]:"}
{"text": "Convert the coordinate to text: [ 0.7534 -8.8408]: The aim of this paper is to patch the visual modality to textual-established attribute information extraction. The authors identify unique challenges in cross-modality integration and attempt to address these with the proposed PV2TEA, an encoder-decoder architecture equipped with techniques for reducing bias and improving cross-modality alignment.", "target": "The aim of this paper is to patch the visual modality to textual-established attribute information extraction. The authors identify unique challenges in cross-modality integration and attempt to address these with the proposed PV2TEA, an encoder-decoder architecture equipped with techniques for reducing bias and improving cross-modality alignment.", "example": "Convert the coordinate to text: [ 0.7534 -8.8408]:"}
{"text": "Convert the coordinate to text: [ 8.1515 -3.9334]: The authors propose that the critique of explainability robustness should consider both the faithfulness and the domain-specific plausibility, and argue for the necessity of an adaptation of current attribution robustness estimation methods to accommodate these attributes. In response, they propose the DomainAdaptiveAREstimator (DARE) attribution robustness estimator.", "target": "The authors propose that the critique of explainability robustness should consider both the faithfulness and the domain-specific plausibility, and argue for the necessity of an adaptation of current attribution robustness estimation methods to accommodate these attributes. In response, they propose the DomainAdaptiveAREstimator (DARE) attribution robustness estimator.", "example": "Convert the coordinate to text: [ 8.1515 -3.9334]:"}
{"text": "Convert the coordinate to text: [-0.6123  8.3353]: The authors explore a fundamental problem of developing attack models based on logic formalism and propose NatLogAttack, a framework for systematically attacking natural language inference models using natural logic, a classical logic formalism developed for natural language inference.", "target": "The authors explore a fundamental problem of developing attack models based on logic formalism and propose NatLogAttack, a framework for systematically attacking natural language inference models using natural logic, a classical logic formalism developed for natural language inference.", "example": "Convert the coordinate to text: [-0.6123  8.3353]:"}
{"text": "Convert the coordinate to text: [-4.945  -0.2006]: The authors propose an evaluation task, ValueEval\u201923, to explore the ability of automated systems to uncover the human values on which an argument draws. It involves identifying human values behind arguments.", "target": "The authors propose an evaluation task, ValueEval\u201923, to explore the ability of automated systems to uncover the human values on which an argument draws. It involves identifying human values behind arguments.", "example": "Convert the coordinate to text: [-4.945  -0.2006]:"}
{"text": "Convert the coordinate to text: [-2.9647 -2.1156]: The authors propose a novel approach to learning multi-relational probabilistic event embeddings based on contrastive learning, which consists of three major modules: a multi-relational event generation module, a probabilistic event encoding module, and a relation-aware projection module.", "target": "The authors propose a novel approach to learning multi-relational probabilistic event embeddings based on contrastive learning, which consists of three major modules: a multi-relational event generation module, a probabilistic event encoding module, and a relation-aware projection module.", "example": "Convert the coordinate to text: [-2.9647 -2.1156]:"}
{"text": "Convert the coordinate to text: [2.3171 5.7824]: This study proposes two new concepts to quantify node importance: the anchor power, which measures the engagement effect of node strengthening (i.e., overall coreness gain), and the collapse power, which measures the engagement effect of node weakening (i.e., overall coreness loss).", "target": "This study proposes two new concepts to quantify node importance: the anchor power, which measures the engagement effect of node strengthening (i.e., overall coreness gain), and the collapse power, which measures the engagement effect of node weakening (i.e., overall coreness loss).", "example": "Convert the coordinate to text: [2.3171 5.7824]:"}
{"text": "Convert the coordinate to text: [ 5.6618 -5.5257]: The authors address these challenges through Diga, a diffusion probabilistic model for graph anomaly detection. This is the first work to apply this model to such a problem, introducing novel techniques such as biased K-hop PageRank, semi-supervised guided diffusion, and a novel weight-sharing GNN layer.", "target": "The authors address these challenges through Diga, a diffusion probabilistic model for graph anomaly detection. This is the first work to apply this model to such a problem, introducing novel techniques such as biased K-hop PageRank, semi-supervised guided diffusion, and a novel weight-sharing GNN layer.", "example": "Convert the coordinate to text: [ 5.6618 -5.5257]:"}
{"text": "Convert the coordinate to text: [5.2971 4.0143]: A novel objective function concept, the density-connectivity distance (dc-dist), is proposed that effectively captures density-based clusters, unifying the concepts of DBSCAN, k-center, and spectral clustering.", "target": "A novel objective function concept, the density-connectivity distance (dc-dist), is proposed that effectively captures density-based clusters, unifying the concepts of DBSCAN, k-center, and spectral clustering.", "example": "Convert the coordinate to text: [5.2971 4.0143]:"}
{"text": "Convert the coordinate to text: [10.4758 -7.3809]: The paper proposes Selective Diffusion Distillation (SDD), a novel framework that maintains both fidelity and editability of images. The new approach involves training a feedforward image manipulation network under the guidance of the diffusion model.", "target": "The paper proposes Selective Diffusion Distillation (SDD), a novel framework that maintains both fidelity and editability of images. The new approach involves training a feedforward image manipulation network under the guidance of the diffusion model.", "example": "Convert the coordinate to text: [10.4758 -7.3809]:"}
{"text": "Convert the coordinate to text: [ -0.7484 -12.4579]: The authors propose a motion guided masking strategy, MGMAE, for video masked autoencoding. This approach emphasizes that motion is a unique and general priority in videos and should be considered in masked pre-training.", "target": "The authors propose a motion guided masking strategy, MGMAE, for video masked autoencoding. This approach emphasizes that motion is a unique and general priority in videos and should be considered in masked pre-training.", "example": "Convert the coordinate to text: [ -0.7484 -12.4579]:"}
{"text": "Convert the coordinate to text: [  5.4583 -15.1746]: The authors propose a new family of linear compressive representations of histogram tensors, that can be computed efficiently and in an online manner. These compressive representations consider the spatio-temporal information of each timestamp and can be implemented in-pixel.", "target": "The authors propose a new family of linear compressive representations of histogram tensors, that can be computed efficiently and in an online manner. These compressive representations consider the spatio-temporal information of each timestamp and can be implemented in-pixel.", "example": "Convert the coordinate to text: [  5.4583 -15.1746]:"}
{"text": "Convert the coordinate to text: [ 7.1853 -2.152 ]: The authors introduce a new federated multi-objective learning (FMOL) framework allowing multiple clients to collaboratively address an MOO problem while maintaining data privacy. This approach allows for different sets of objective functions across different clients to cater to a range of applications.", "target": "The authors introduce a new federated multi-objective learning (FMOL) framework allowing multiple clients to collaboratively address an MOO problem while maintaining data privacy. This approach allows for different sets of objective functions across different clients to cater to a range of applications.", "example": "Convert the coordinate to text: [ 7.1853 -2.152 ]:"}
{"text": "Convert the coordinate to text: [13.6751  5.0747]: The paper establishes a fundamental theory for the probability flow of discrete diffusion models by proving that the continuous probability flow is the Monge optimal transport map under certain conditions, and presents equivalent evidence for discrete cases.", "target": "The paper establishes a fundamental theory for the probability flow of discrete diffusion models by proving that the continuous probability flow is the Monge optimal transport map under certain conditions, and presents equivalent evidence for discrete cases.", "example": "Convert the coordinate to text: [13.6751  5.0747]:"}
{"text": "Convert the coordinate to text: [11.9134 -2.4452]: The authors aim to provide a detailed mathematical perspective on the classes of functions that a neural network with ReLU activations can represent, particularly investigating whether adding more layers increases the class of exactly representable functions.", "target": "The authors aim to provide a detailed mathematical perspective on the classes of functions that a neural network with ReLU activations can represent, particularly investigating whether adding more layers increases the class of exactly representable functions.", "example": "Convert the coordinate to text: [11.9134 -2.4452]:"}
{"text": "Convert the coordinate to text: [4.9769 1.8141]: The paper revisits the classical topic on discriminative vs. generative classifiers, specifically considering the use of naive Bayes for classifier selection in linear evaluation, inspired by its statistical efficiency.", "target": "The paper revisits the classical topic on discriminative vs. generative classifiers, specifically considering the use of naive Bayes for classifier selection in linear evaluation, inspired by its statistical efficiency.", "example": "Convert the coordinate to text: [4.9769 1.8141]:"}
{"text": "Convert the coordinate to text: [0.9303 1.9247]: This paper introduces the idea of using counterfactual explanations to elucidate a machine learning model's confidence scores.", "target": "This paper introduces the idea of using counterfactual explanations to elucidate a machine learning model's confidence scores.", "example": "Convert the coordinate to text: [0.9303 1.9247]:"}
{"text": "Convert the coordinate to text: [-1.166  -5.4212]: The authors propose to investigate the most efficient use of a fixed budget to build a compact model, comparing the strategy of distilling a large model to the strategy of manually labeling additional fine-tuning data.", "target": "The authors propose to investigate the most efficient use of a fixed budget to build a compact model, comparing the strategy of distilling a large model to the strategy of manually labeling additional fine-tuning data.", "example": "Convert the coordinate to text: [-1.166  -5.4212]:"}
{"text": "Convert the coordinate to text: [-1.5182 -2.9468]: The paper proposes CAT (Contextualized ConceptuAlization and InsTantiation), a semi-supervised learning framework that combines event conceptualization and instantiation to conceptualize commonsense knowledge bases at scale.", "target": "The paper proposes CAT (Contextualized ConceptuAlization and InsTantiation), a semi-supervised learning framework that combines event conceptualization and instantiation to conceptualize commonsense knowledge bases at scale.", "example": "Convert the coordinate to text: [-1.5182 -2.9468]:"}
{"text": "Convert the coordinate to text: [10.8498 -6.6087]: This study demonstrates the effectiveness of denoising diffusion probabilistic models in estimating optical flow and monocular depth, without requiring task-specific architectures or loss functions. These models allow for Monte Carlo inference and are combined with self-supervised pre-training, use of synthetic and real data, and infilling and step-unrolled denoising diffusion training for superior performance.", "target": "This study demonstrates the effectiveness of denoising diffusion probabilistic models in estimating optical flow and monocular depth, without requiring task-specific architectures or loss functions. These models allow for Monte Carlo inference and are combined with self-supervised pre-training, use of synthetic and real data, and infilling and step-unrolled denoising diffusion training for superior performance.", "example": "Convert the coordinate to text: [10.8498 -6.6087]:"}
{"text": "Convert the coordinate to text: [-6.4943 -6.2405]: The paper introduces two novel elements: a homograph disambiguation module to differentiate meanings of homographs, and PLUMCOT, an approach that incorporates contextually rich information from pre-trained language models about unseen lexical constraints and strengthens a copy mechanism of a pointer network via direct supervision of a copying score.", "target": "The paper introduces two novel elements: a homograph disambiguation module to differentiate meanings of homographs, and PLUMCOT, an approach that incorporates contextually rich information from pre-trained language models about unseen lexical constraints and strengthens a copy mechanism of a pointer network via direct supervision of a copying score.", "example": "Convert the coordinate to text: [-6.4943 -6.2405]:"}
{"text": "Convert the coordinate to text: [-0.0104 -5.1075]: The authors propose a novelty model using a graph convolutional neural network that considers dialogue user dynamics and the influence of public perception on conversation utterances.", "target": "The authors propose a novelty model using a graph convolutional neural network that considers dialogue user dynamics and the influence of public perception on conversation utterances.", "example": "Convert the coordinate to text: [-0.0104 -5.1075]:"}
{"text": "Convert the coordinate to text: [-3.2472  0.2196]: The authors hypothesize that NLP can process large collections of news articles to detect and summarize attacks on human rights defenders, and propose a new labeled dataset (HRDsAttack) to facilitate such work.", "target": "The authors hypothesize that NLP can process large collections of news articles to detect and summarize attacks on human rights defenders, and propose a new labeled dataset (HRDsAttack) to facilitate such work.", "example": "Convert the coordinate to text: [-3.2472  0.2196]:"}
{"text": "Convert the coordinate to text: [-5.2301  2.6253]: This study introduces a new approach to fake news detection using social graph refinement. The authors find degrees of news nodes having unique patterns indicative of news veracity. Hence, they put forward a new application of Degree-Corrected Stochastic Blockmodels for fake news detection, termed as DECOR.", "target": "This study introduces a new approach to fake news detection using social graph refinement. The authors find degrees of news nodes having unique patterns indicative of news veracity. Hence, they put forward a new application of Degree-Corrected Stochastic Blockmodels for fake news detection, termed as DECOR.", "example": "Convert the coordinate to text: [-5.2301  2.6253]:"}
{"text": "Convert the coordinate to text: [-4.6964  0.3161]: This study introduces a new general approach to quantitatively analyze word usage arcs for any word category using a combination of clustering and filtering and extends the exploration of narrative arcs in literature to eight different languages across multiple genres.", "target": "This study introduces a new general approach to quantitatively analyze word usage arcs for any word category using a combination of clustering and filtering and extends the exploration of narrative arcs in literature to eight different languages across multiple genres.", "example": "Convert the coordinate to text: [-4.6964  0.3161]:"}
{"text": "Convert the coordinate to text: [-2.293  -4.9055]: This paper probes whether PLMs store ontological knowledge, aiming to understand whether this knowledge is understood semantically or simply rote memorized. The authors investigate PLMs' memorization of entity types, hierarchical relationships, and domain and range constraints of properties.", "target": "This paper probes whether PLMs store ontological knowledge, aiming to understand whether this knowledge is understood semantically or simply rote memorized. The authors investigate PLMs' memorization of entity types, hierarchical relationships, and domain and range constraints of properties.", "example": "Convert the coordinate to text: [-2.293  -4.9055]:"}
{"text": "Convert the coordinate to text: [ 1.9163 -3.5837]: This paper proposes leveraging contrastive learning techniques to build improved representations and addresses the non-compositionality challenge. It also proposes a dynamic curriculum learning framework specifically designed to take advantage of the scarce available data for modeling non-compositionality.", "target": "This paper proposes leveraging contrastive learning techniques to build improved representations and addresses the non-compositionality challenge. It also proposes a dynamic curriculum learning framework specifically designed to take advantage of the scarce available data for modeling non-compositionality.", "example": "Convert the coordinate to text: [ 1.9163 -3.5837]:"}
{"text": "Convert the coordinate to text: [12.1685 -0.8412]: The authors introduce a novel family of methods, called neural network accelerated implicit filtering (NNAIF), that combines implicit filtering optimization methods with a neural network surrogate model of the objective function, aiming to accelerate derivative free methods for unconstrained optimization problems.", "target": "The authors introduce a novel family of methods, called neural network accelerated implicit filtering (NNAIF), that combines implicit filtering optimization methods with a neural network surrogate model of the objective function, aiming to accelerate derivative free methods for unconstrained optimization problems.", "example": "Convert the coordinate to text: [12.1685 -0.8412]:"}
{"text": "Convert the coordinate to text: [ 6.8183 -3.7832]: The paper addresses the Domain Generalization under Category Shift (DGCS) problem, which aims to detect unknown-class samples and classify known-class samples in target domains, with the introduction of 'Activate and Reject' (ART), a framework that reshapes the model's decision boundary to accommodate unknown classes.", "target": "The paper addresses the Domain Generalization under Category Shift (DGCS) problem, which aims to detect unknown-class samples and classify known-class samples in target domains, with the introduction of 'Activate and Reject' (ART), a framework that reshapes the model's decision boundary to accommodate unknown classes.", "example": "Convert the coordinate to text: [ 6.8183 -3.7832]:"}
{"text": "Convert the coordinate to text: [8.417  0.4206]: The proposal is for a Hyperbolic Chamfer Distance (HyperCD), a simple yet powerful metric for point cloud completion, which computes the Chamfer Distance in a hyperbolic space instead of the standard Euclidean space.", "target": "The proposal is for a Hyperbolic Chamfer Distance (HyperCD), a simple yet powerful metric for point cloud completion, which computes the Chamfer Distance in a hyperbolic space instead of the standard Euclidean space.", "example": "Convert the coordinate to text: [8.417  0.4206]:"}
{"text": "Convert the coordinate to text: [ 4.2431 -7.2094]: The authors propose a novel Frequency-Guided Few-shot Learning framework (FGFL) which leverages the task-specific frequency components to adaptively mask image information, while introducing a multi-level metric learning strategy including a triplet loss among original, masked and unmasked images along with a contrastive loss between masked and original support and query sets.", "target": "The authors propose a novel Frequency-Guided Few-shot Learning framework (FGFL) which leverages the task-specific frequency components to adaptively mask image information, while introducing a multi-level metric learning strategy including a triplet loss among original, masked and unmasked images along with a contrastive loss between masked and original support and query sets.", "example": "Convert the coordinate to text: [ 4.2431 -7.2094]:"}
{"text": "Convert the coordinate to text: [ 10.5434 -18.8509]: Dynamo-Depth is introduced as an approach that disambiguates dynamical motion in a scene by jointly learning monocular depth, 3D independent flow field, and motion segmentation from unlabeled monocular videos.", "target": "Dynamo-Depth is introduced as an approach that disambiguates dynamical motion in a scene by jointly learning monocular depth, 3D independent flow field, and motion segmentation from unlabeled monocular videos.", "example": "Convert the coordinate to text: [ 10.5434 -18.8509]:"}
{"text": "Convert the coordinate to text: [ 1.5223 -7.7411]: The authors introduce Reconstruction TRansformer (ReTR), a novel framework that utilizes transformer architecture to redesign the rendering process, thereby enabling complex render interaction modeling. It introduces a learnable meta-ray token and leverages the cross-attention mechanism to simulate the rendering process.", "target": "The authors introduce Reconstruction TRansformer (ReTR), a novel framework that utilizes transformer architecture to redesign the rendering process, thereby enabling complex render interaction modeling. It introduces a learnable meta-ray token and leverages the cross-attention mechanism to simulate the rendering process.", "example": "Convert the coordinate to text: [ 1.5223 -7.7411]:"}
{"text": "Convert the coordinate to text: [ 6.4715 -0.5447]: The authors propose a new class of theoretically robust passive loss functions, known as Normalized Negative Loss Functions (NNLFs), which focus more on memorized clean samples. They also introduce a new framework called Active Negative Loss (ANL) that utilizes NNLFs, providing improvements to the APL framework.", "target": "The authors propose a new class of theoretically robust passive loss functions, known as Normalized Negative Loss Functions (NNLFs), which focus more on memorized clean samples. They also introduce a new framework called Active Negative Loss (ANL) that utilizes NNLFs, providing improvements to the APL framework.", "example": "Convert the coordinate to text: [ 6.4715 -0.5447]:"}
{"text": "Convert the coordinate to text: [ 3.2113 -2.4076]: The paper addresses the balance issue by formulating the CML objective as controlling the average excess risk upper bound of the task sequence, which signifies the trade-off between forgetting and generalization. A novel algorithm is also proposed that adjusts the meta-parameter and its learning rate according to environment change.", "target": "The paper addresses the balance issue by formulating the CML objective as controlling the average excess risk upper bound of the task sequence, which signifies the trade-off between forgetting and generalization. A novel algorithm is also proposed that adjusts the meta-parameter and its learning rate according to environment change.", "example": "Convert the coordinate to text: [ 3.2113 -2.4076]:"}
{"text": "Convert the coordinate to text: [ 5.044  -3.1055]: The paper proposes the Re-parameterizing Mixture-of-Diverse-Experts (RepMode), a network that dynamically organizes its parameters with task-aware priors to handle specified single-label prediction tasks. It includes the Mixture-of-Diverse-Experts (MoDE) block for general parameters and gating re-parameterization (GatRep) for specialized parameters for each task, maintaining a compact practical network topology while achieving a powerful theoretical topology.", "target": "The paper proposes the Re-parameterizing Mixture-of-Diverse-Experts (RepMode), a network that dynamically organizes its parameters with task-aware priors to handle specified single-label prediction tasks. It includes the Mixture-of-Diverse-Experts (MoDE) block for general parameters and gating re-parameterization (GatRep) for specialized parameters for each task, maintaining a compact practical network topology while achieving a powerful theoretical topology.", "example": "Convert the coordinate to text: [ 5.044  -3.1055]:"}
{"text": "Convert the coordinate to text: [-8.3488 -1.8677]: The authors propose inline commentary as a natural vehicle for AI-based reading assistance, and present an open integrated platform, CARE, for the study of inline commentary and reading.", "target": "The authors propose inline commentary as a natural vehicle for AI-based reading assistance, and present an open integrated platform, CARE, for the study of inline commentary and reading.", "example": "Convert the coordinate to text: [-8.3488 -1.8677]:"}
{"text": "Convert the coordinate to text: [-0.7731  6.6402]: The authors propose a novel logic-based neural model for multimodal misinformation detection, inspired by NeuralSymbolic AI, which integrates interpretative logic clauses to express the reasoning process of the target task.", "target": "The authors propose a novel logic-based neural model for multimodal misinformation detection, inspired by NeuralSymbolic AI, which integrates interpretative logic clauses to express the reasoning process of the target task.", "example": "Convert the coordinate to text: [-0.7731  6.6402]:"}
{"text": "Convert the coordinate to text: [-6.4287 -9.6349]: The authors propose building clause-level edit models for automatic text-to-SQL error correction. The authors also propose a new representation for SQL queries and their edits, which adheres closely to the pre-training corpora of language models of code.", "target": "The authors propose building clause-level edit models for automatic text-to-SQL error correction. The authors also propose a new representation for SQL queries and their edits, which adheres closely to the pre-training corpora of language models of code.", "example": "Convert the coordinate to text: [-6.4287 -9.6349]:"}
{"text": "Convert the coordinate to text: [ 7.234  -6.1098]: The paper introduces a novel model called DCdetector, a multi-scale dual attention contrastive representation learning model. Unlike typical reconstruction methods, DCdetector uses contrastive learning to distinguish any instance from the others.", "target": "The paper introduces a novel model called DCdetector, a multi-scale dual attention contrastive representation learning model. Unlike typical reconstruction methods, DCdetector uses contrastive learning to distinguish any instance from the others.", "example": "Convert the coordinate to text: [ 7.234  -6.1098]:"}
{"text": "Convert the coordinate to text: [ 5.3912 12.949 ]: This study introduces a new alpha-mining framework that prioritizes mining a synergistic set of alphas, directly using the performance of the downstream combination model to optimize the alpha generator. This framework also leverages reinforcement learning to explore the vast search space of formulaic alphas.", "target": "This study introduces a new alpha-mining framework that prioritizes mining a synergistic set of alphas, directly using the performance of the downstream combination model to optimize the alpha generator. This framework also leverages reinforcement learning to explore the vast search space of formulaic alphas.", "example": "Convert the coordinate to text: [ 5.3912 12.949 ]:"}
{"text": "Convert the coordinate to text: [ 1.5149 -0.4385]: The authors propose an approach that posits disagreement between annotators can be captured by the uncertainty that a model, rooted on various linguistic characteristics, might have on predicting a specific gold label.", "target": "The authors propose an approach that posits disagreement between annotators can be captured by the uncertainty that a model, rooted on various linguistic characteristics, might have on predicting a specific gold label.", "example": "Convert the coordinate to text: [ 1.5149 -0.4385]:"}
{"text": "Convert the coordinate to text: [-3.6221 -9.0432]: The authors combine pre-trained ASR and MT models under the SATE framework, and propose an iterative dual-attention (IDA) method to improve MT model performance by generating pseudo ST data through MT systems.", "target": "The authors combine pre-trained ASR and MT models under the SATE framework, and propose an iterative dual-attention (IDA) method to improve MT model performance by generating pseudo ST data through MT systems.", "example": "Convert the coordinate to text: [-3.6221 -9.0432]:"}
{"text": "Convert the coordinate to text: [-10.6967   0.3508]: The authors introduce AnaMeta, a new dataset comprising 467k tables, offering derived supervision labels for frequently used field metadata including measure/dimension dichotomy, common field roles, semantic field type, and default aggregation function. They also propose KDF, a multi-encoder framework to boost metadata understanding of tabular models by integrating distribution and knowledge information.", "target": "The authors introduce AnaMeta, a new dataset comprising 467k tables, offering derived supervision labels for frequently used field metadata including measure/dimension dichotomy, common field roles, semantic field type, and default aggregation function. They also propose KDF, a multi-encoder framework to boost metadata understanding of tabular models by integrating distribution and knowledge information.", "example": "Convert the coordinate to text: [-10.6967   0.3508]:"}
{"text": "Convert the coordinate to text: [-2.9741  0.0573]: The authors fine-tune an NLI-based model on a task-specific dataset to benefit from both supervised and zero-shot approaches for classification tasks in emotion and hate speech detection.", "target": "The authors fine-tune an NLI-based model on a task-specific dataset to benefit from both supervised and zero-shot approaches for classification tasks in emotion and hate speech detection.", "example": "Convert the coordinate to text: [-2.9741  0.0573]:"}
{"text": "Convert the coordinate to text: [-2.4731 -7.7268]: This paper proposes Pretrained Bidirectional Distillation (PBD) for NMT, which efficiently transfers bidirectional language knowledge from masked language pretraining to NMT models through a globally defined and bidirectional context-aware distillation objective. Self-distilled masked language pretraining is proposed to obtain the PBD objective.", "target": "This paper proposes Pretrained Bidirectional Distillation (PBD) for NMT, which efficiently transfers bidirectional language knowledge from masked language pretraining to NMT models through a globally defined and bidirectional context-aware distillation objective. Self-distilled masked language pretraining is proposed to obtain the PBD objective.", "example": "Convert the coordinate to text: [-2.4731 -7.7268]:"}
{"text": "Convert the coordinate to text: [ 2.256  -5.6888]: The authors propose a generic MDLM framework that can embed one or more MMs in deep networks, addressing the issues of utilizing interconnections of multiple input examples, error bounding and ensembling multiple MMs. This framework is task-agnostic.", "target": "The authors propose a generic MDLM framework that can embed one or more MMs in deep networks, addressing the issues of utilizing interconnections of multiple input examples, error bounding and ensembling multiple MMs. This framework is task-agnostic.", "example": "Convert the coordinate to text: [ 2.256  -5.6888]:"}
{"text": "Convert the coordinate to text: [-2.1598  5.6107]: This paper seeks to quantify the lack of portability in tooling in the context of machine learning, especially analyzing the impact of hardware-software combinations on the performance and functionality of ML frameworks.", "target": "This paper seeks to quantify the lack of portability in tooling in the context of machine learning, especially analyzing the impact of hardware-software combinations on the performance and functionality of ML frameworks.", "example": "Convert the coordinate to text: [-2.1598  5.6107]:"}
{"text": "Convert the coordinate to text: [ 1.9664 11.2991]: The authors propose Skip-Plan, a condensed action space learning method that abstracts procedure planning as a chain model, skipping uncertain nodes and edges in action chains, transforming long, complex sequence functions into short but reliable ones.", "target": "The authors propose Skip-Plan, a condensed action space learning method that abstracts procedure planning as a chain model, skipping uncertain nodes and edges in action chains, transforming long, complex sequence functions into short but reliable ones.", "example": "Convert the coordinate to text: [ 1.9664 11.2991]:"}
{"text": "Convert the coordinate to text: [ 3.5099 -8.6155]: The paper introduces a novel attention mechanism based on cross-correlation and develops a relational classifier head based on the query and support video representations. Utilizing this cross-attention, the paper first transforms support videos into the query video's context to highlight relevant frames and suppress less relevant ones, and then uses the cross-attention to summarize sub-sequences of support video frames to represent temporal dynamics.", "target": "The paper introduces a novel attention mechanism based on cross-correlation and develops a relational classifier head based on the query and support video representations. Utilizing this cross-attention, the paper first transforms support videos into the query video's context to highlight relevant frames and suppress less relevant ones, and then uses the cross-attention to summarize sub-sequences of support video frames to represent temporal dynamics.", "example": "Convert the coordinate to text: [ 3.5099 -8.6155]:"}
{"text": "Convert the coordinate to text: [ 5.6566 -8.5773]: This paper introduces a new framework dubbed Spatio-Temporal Prompting Network (STPN) that dynamically adjusts the input features in the backbone network to efficiently extract robust and accurate video features by predicting video prompts that contain spatio-temporal information.", "target": "This paper introduces a new framework dubbed Spatio-Temporal Prompting Network (STPN) that dynamically adjusts the input features in the backbone network to efficiently extract robust and accurate video features by predicting video prompts that contain spatio-temporal information.", "example": "Convert the coordinate to text: [ 5.6566 -8.5773]:"}
{"text": "Convert the coordinate to text: [ 4.8219 -3.0192]: The authors propose a Global Balanced Multi-Expert (GBME) framework, optimizing a balanced global objective, which does not need further information outside the standard FL pipeline. They use a proxy derived from the accumulated gradients uploaded by clients after local training, shared by all clients for re-balance training, guiding client grouping and training a multi-expert model.", "target": "The authors propose a Global Balanced Multi-Expert (GBME) framework, optimizing a balanced global objective, which does not need further information outside the standard FL pipeline. They use a proxy derived from the accumulated gradients uploaded by clients after local training, shared by all clients for re-balance training, guiding client grouping and training a multi-expert model.", "example": "Convert the coordinate to text: [ 4.8219 -3.0192]:"}
{"text": "Convert the coordinate to text: [ 7.4555 -4.6776]: This paper proposes a fine-tuning approach, Feature Discrimination Alignment (FD-Align), which preserves the consistency of spurious features across the fine-tuning process, aiming to enhance the generalizability of pre-trained models.", "target": "This paper proposes a fine-tuning approach, Feature Discrimination Alignment (FD-Align), which preserves the consistency of spurious features across the fine-tuning process, aiming to enhance the generalizability of pre-trained models.", "example": "Convert the coordinate to text: [ 7.4555 -4.6776]:"}
{"text": "Convert the coordinate to text: [11.9745 -2.8479]: The authors propose a new framework that provides formal privacy guarantees for any arbitrarily trained neural network by linking the neural network's local Lipschitz constant with its local sensitivity. This is achieved by extending the Propose-Test-Release (PTR) framework to be tractable for neural network queries.", "target": "The authors propose a new framework that provides formal privacy guarantees for any arbitrarily trained neural network by linking the neural network's local Lipschitz constant with its local sensitivity. This is achieved by extending the Propose-Test-Release (PTR) framework to be tractable for neural network queries.", "example": "Convert the coordinate to text: [11.9745 -2.8479]:"}
{"text": "Convert the coordinate to text: [ 7.3816 10.3823]: A connection is made between Convolutional Neural Networks (CNN) and Proportional-Integral-Derivative (PID) controllers, and a parallel is drawn that a two-branch network is similar to a Proportional-Integral (PI) controller, which also has overshoot issues. To tackle this problem, the authors propose PIDNet, a three-branch network architecture that parses detailed, context and boundary information, and uses boundary attention to guide fusion of detail and context branches.", "target": "A connection is made between Convolutional Neural Networks (CNN) and Proportional-Integral-Derivative (PID) controllers, and a parallel is drawn that a two-branch network is similar to a Proportional-Integral (PI) controller, which also has overshoot issues. To tackle this problem, the authors propose PIDNet, a three-branch network architecture that parses detailed, context and boundary information, and uses boundary attention to guide fusion of detail and context branches.", "example": "Convert the coordinate to text: [ 7.3816 10.3823]:"}
{"text": "Convert the coordinate to text: [-10.9719   4.1201]: The paper introduces the concept of Dimensional alt text, a system that allows users to navigate image descriptions via three-dimensional layers: the foreground, middle ground, and background.", "target": "The paper introduces the concept of Dimensional alt text, a system that allows users to navigate image descriptions via three-dimensional layers: the foreground, middle ground, and background.", "example": "Convert the coordinate to text: [-10.9719   4.1201]:"}
{"text": "Convert the coordinate to text: [-1.6444 -0.1394]: This study proposes to investigate the influence of demographic attributes (race, ethnicity, and gender) and name tokenization length on the behavior of social commonsense reasoning models, by conducting a new series of first name substitution experiments controlling for these factors.", "target": "This study proposes to investigate the influence of demographic attributes (race, ethnicity, and gender) and name tokenization length on the behavior of social commonsense reasoning models, by conducting a new series of first name substitution experiments controlling for these factors.", "example": "Convert the coordinate to text: [-1.6444 -0.1394]:"}
{"text": "Convert the coordinate to text: [ 2.2088 -7.7774]: The authors suggest the use of position-based cross-attention combined with simple interpolation of the original and reversed encoded representations and relative attention to achieve length generalization.", "target": "The authors suggest the use of position-based cross-attention combined with simple interpolation of the original and reversed encoded representations and relative attention to achieve length generalization.", "example": "Convert the coordinate to text: [ 2.2088 -7.7774]:"}
{"text": "Convert the coordinate to text: [-9.9387 -7.9891]: The paper proposes two low-rank variants of Neural QCFG models that balance between efficiency and expressiveness. Additionally, the paper introduces two soft constraints over tree hierarchy and source coverage.", "target": "The paper proposes two low-rank variants of Neural QCFG models that balance between efficiency and expressiveness. Additionally, the paper introduces two soft constraints over tree hierarchy and source coverage.", "example": "Convert the coordinate to text: [-9.9387 -7.9891]:"}
{"text": "Convert the coordinate to text: [-5.3743 -6.3167]: This study introduces the novel task of Trans-Lingual Definition Generation (TLDG), which aims to generate definitions in a different language, specifically the native speaker's language.", "target": "This study introduces the novel task of Trans-Lingual Definition Generation (TLDG), which aims to generate definitions in a different language, specifically the native speaker's language.", "example": "Convert the coordinate to text: [-5.3743 -6.3167]:"}
{"text": "Convert the coordinate to text: [ 1.9132 -4.5983]: A novel three-stage framework, DS-MOCE, is proposed to automatically extract course concepts using a distantly supervised method, leveraging pre-trained language models and discipline-embedding models with a self-training strategy based on label generation refinement across different domains.", "target": "A novel three-stage framework, DS-MOCE, is proposed to automatically extract course concepts using a distantly supervised method, leveraging pre-trained language models and discipline-embedding models with a self-training strategy based on label generation refinement across different domains.", "example": "Convert the coordinate to text: [ 1.9132 -4.5983]:"}
{"text": "Convert the coordinate to text: [-4.3865 -6.912 ]: The authors propose using an alternative data source, specifically translationese (human-translated texts), due to its similarity in style to non-native texts and higher availability and quality comapred to non-native texts, for GEC data augmentation.", "target": "The authors propose using an alternative data source, specifically translationese (human-translated texts), due to its similarity in style to non-native texts and higher availability and quality comapred to non-native texts, for GEC data augmentation.", "example": "Convert the coordinate to text: [-4.3865 -6.912 ]:"}
{"text": "Convert the coordinate to text: [-2.1543 -5.4557]: This study proposes using large language models to augment the efficiency of aggregating results from RCTs at scale, and focuses on zero-shot prompt-based information extraction from a diverse set of RCTs.", "target": "This study proposes using large language models to augment the efficiency of aggregating results from RCTs at scale, and focuses on zero-shot prompt-based information extraction from a diverse set of RCTs.", "example": "Convert the coordinate to text: [-2.1543 -5.4557]:"}
{"text": "Convert the coordinate to text: [-3.9796 -3.3327]: This study focused on three subtasks: Legal Named Entity Recognition (L-NER) for Task-B, Legal Judgment Prediction (LJP) for Task-C1, and Court Judgment Prediction with Explanation (CJPE) for Task-C2.", "target": "This study focused on three subtasks: Legal Named Entity Recognition (L-NER) for Task-B, Legal Judgment Prediction (LJP) for Task-C1, and Court Judgment Prediction with Explanation (CJPE) for Task-C2.", "example": "Convert the coordinate to text: [-3.9796 -3.3327]:"}
{"text": "Convert the coordinate to text: [-5.3993  1.3665]: The authors propose an approach to categorize news genre by fine-tuning the POLITICO language model, pre-trained on a large-scale dataset of more than 3.6M English political news articles. A pre-processing step of translating all documents into English was added for the multi-lingual setup of the task.", "target": "The authors propose an approach to categorize news genre by fine-tuning the POLITICO language model, pre-trained on a large-scale dataset of more than 3.6M English political news articles. A pre-processing step of translating all documents into English was added for the multi-lingual setup of the task.", "example": "Convert the coordinate to text: [-5.3993  1.3665]:"}
{"text": "Convert the coordinate to text: [ 3.7637 -3.9008]: The paper proposes the use of knowledge distillation for stance detection, with a novel approach of dynamic temperature scaling to calibrate teacher predictions in each generation step. Additionally, knowledge is proposed to be distilled over multiple generations where a student becomes a new teacher to transfer knowledge to a new student.", "target": "The paper proposes the use of knowledge distillation for stance detection, with a novel approach of dynamic temperature scaling to calibrate teacher predictions in each generation step. Additionally, knowledge is proposed to be distilled over multiple generations where a student becomes a new teacher to transfer knowledge to a new student.", "example": "Convert the coordinate to text: [ 3.7637 -3.9008]:"}
{"text": "Convert the coordinate to text: [  3.4594 -10.1092]: The authors propose using YouTube house tour videos to create a large-scale dataset that provides meaningful path-instruction pairs. This is used to pretrain a model which utilizes this raw and unlabeled visual and linguistic data.", "target": "The authors propose using YouTube house tour videos to create a large-scale dataset that provides meaningful path-instruction pairs. This is used to pretrain a model which utilizes this raw and unlabeled visual and linguistic data.", "example": "Convert the coordinate to text: [  3.4594 -10.1092]:"}
{"text": "Convert the coordinate to text: [-0.8565 -3.5995]: The authors identified a gap regarding handling of multi-KB settings in EToDs, and have introduced a KB-over-KBHeterogeneous Graph Attention Network (KoK-HAN) designed to facilitate models to reason over multiple KBs.", "target": "The authors identified a gap regarding handling of multi-KB settings in EToDs, and have introduced a KB-over-KBHeterogeneous Graph Attention Network (KoK-HAN) designed to facilitate models to reason over multiple KBs.", "example": "Convert the coordinate to text: [-0.8565 -3.5995]:"}
{"text": "Convert the coordinate to text: [-2.0949 -4.1466]: This paper focuses on studying the phenomenon of geographical erasure in LLMs, where models under-predict or overlook certain countries, and attempts to mitigate it through a custom objective during the fine-tuning process.", "target": "This paper focuses on studying the phenomenon of geographical erasure in LLMs, where models under-predict or overlook certain countries, and attempts to mitigate it through a custom objective during the fine-tuning process.", "example": "Convert the coordinate to text: [-2.0949 -4.1466]:"}
{"text": "Convert the coordinate to text: [ 5.1849 13.918 ]: The authors propose a novel approach of learning intrinsic rewards through user interactions. They formulate intrinsic reward learning as a multi-objective bi-level optimization problem targeting maximizing success rate and minimizing conversational turns to reach successful recommendations.", "target": "The authors propose a novel approach of learning intrinsic rewards through user interactions. They formulate intrinsic reward learning as a multi-objective bi-level optimization problem targeting maximizing success rate and minimizing conversational turns to reach successful recommendations.", "example": "Convert the coordinate to text: [ 5.1849 13.918 ]:"}
{"text": "Convert the coordinate to text: [8.6218 2.0089]: The authors propose a new kernel, called the loss path kernel, that establishes a connection between the loss dynamics of gradient flow and general kernel machines. This kernel measures the similarity between two data points by evaluating the agreement between the loss gradients along the path determined by the gradient flow.", "target": "The authors propose a new kernel, called the loss path kernel, that establishes a connection between the loss dynamics of gradient flow and general kernel machines. This kernel measures the similarity between two data points by evaluating the agreement between the loss gradients along the path determined by the gradient flow.", "example": "Convert the coordinate to text: [8.6218 2.0089]:"}
{"text": "Convert the coordinate to text: [10.8776 -2.0197]: The authors propose that feature learning can actually perform worse than a lazy training approach (via the random feature kernel or the neural tangent kernel), as it can lead to a sparser neural representation.", "target": "The authors propose that feature learning can actually perform worse than a lazy training approach (via the random feature kernel or the neural tangent kernel), as it can lead to a sparser neural representation.", "example": "Convert the coordinate to text: [10.8776 -2.0197]:"}
{"text": "Convert the coordinate to text: [2.6912 1.2199]: The study introduces a new perspective based on the influence function for instance-wise feature selection. It proposes a solution (DIWIFT) for discovering instance-wise influential features in tabular data, where a self-attention network is used as a feature selection model and the value of the influence function is used as an optimization objective to guide the model.", "target": "The study introduces a new perspective based on the influence function for instance-wise feature selection. It proposes a solution (DIWIFT) for discovering instance-wise influential features in tabular data, where a self-attention network is used as a feature selection model and the value of the influence function is used as an optimization objective to guide the model.", "example": "Convert the coordinate to text: [2.6912 1.2199]:"}
{"text": "Convert the coordinate to text: [-11.2823  10.0514]: The authors conducted in-depth interviews with researchers, performed a SWOT analysis of remote conferences, and developed novel experimental conference functionalities for online academic conferences.", "target": "The authors conducted in-depth interviews with researchers, performed a SWOT analysis of remote conferences, and developed novel experimental conference functionalities for online academic conferences.", "example": "Convert the coordinate to text: [-11.2823  10.0514]:"}
{"text": "Convert the coordinate to text: [14.3321  5.3324]: The authors propose FGWEA, an unsupervised entity alignment framework that leverages the Fused Gromov-Wasserstein (FGW) distance to allow for a comprehensive comparison of entity semantics and KG structures within a joint optimization framework.", "target": "The authors propose FGWEA, an unsupervised entity alignment framework that leverages the Fused Gromov-Wasserstein (FGW) distance to allow for a comprehensive comparison of entity semantics and KG structures within a joint optimization framework.", "example": "Convert the coordinate to text: [14.3321  5.3324]:"}
{"text": "Convert the coordinate to text: [-2.9622 -4.1525]: The authors propose DiffusionNER, a novel approach to NER that formulates the task as a boundary-denoising diffusion process, allowing for progressive refinement and dynamic sampling of entities.", "target": "The authors propose DiffusionNER, a novel approach to NER that formulates the task as a boundary-denoising diffusion process, allowing for progressive refinement and dynamic sampling of entities.", "example": "Convert the coordinate to text: [-2.9622 -4.1525]:"}
{"text": "Convert the coordinate to text: [-2.9442 -1.7336]: The authors propose the Structured Prediction with Energy-based Event-Centric Hyperspheres (SPEECH) model to manage the complex dependency among event-structured components using energy-based modeling, and represent event classes with hyperspheres.", "target": "The authors propose the Structured Prediction with Energy-based Event-Centric Hyperspheres (SPEECH) model to manage the complex dependency among event-structured components using energy-based modeling, and represent event classes with hyperspheres.", "example": "Convert the coordinate to text: [-2.9442 -1.7336]:"}
{"text": "Convert the coordinate to text: [-8.335  -5.6563]: This study proposes a conjunct resolution task that works directly on the text using a split-and-rephrase paradigm to recover missing elements in the coordination structure. The study also proposes a pragmatic framework of verbal omissions that categorizes different types of omissions, and introduces an automatic scalable collection method.", "target": "This study proposes a conjunct resolution task that works directly on the text using a split-and-rephrase paradigm to recover missing elements in the coordination structure. The study also proposes a pragmatic framework of verbal omissions that categorizes different types of omissions, and introduces an automatic scalable collection method.", "example": "Convert the coordinate to text: [-8.335  -5.6563]:"}
{"text": "Convert the coordinate to text: [-1.2169 -3.675 ]: The study introduces the CConS (Counter-commonsense Contextual Size comparison) dataset which consists of both contexts that fit physical commonsense and those that do not, in order to test language models' ability to predict size relationships under various contexts.", "target": "The study introduces the CConS (Counter-commonsense Contextual Size comparison) dataset which consists of both contexts that fit physical commonsense and those that do not, in order to test language models' ability to predict size relationships under various contexts.", "example": "Convert the coordinate to text: [-1.2169 -3.675 ]:"}
{"text": "Convert the coordinate to text: [ 6.7632 -4.6006]: The authors propose a novel DAOD framework named Domain-Aware detection head with Prompt tuning (DA-Pro), which applies a learnable domain-adaptive prompt to generate a dynamic detection head according to each domain, leveraging the high generalization potential of vision-language models (VLMs).", "target": "The authors propose a novel DAOD framework named Domain-Aware detection head with Prompt tuning (DA-Pro), which applies a learnable domain-adaptive prompt to generate a dynamic detection head according to each domain, leveraging the high generalization potential of vision-language models (VLMs).", "example": "Convert the coordinate to text: [ 6.7632 -4.6006]:"}
{"text": "Convert the coordinate to text: [-2.3719 -6.2773]: The authors experimented with GloVe embeddings and fine-tuning BERT for this task and identified that an ensemble of BERT and GloVe (via Ridge Regression) produced the best results.", "target": "The authors experimented with GloVe embeddings and fine-tuning BERT for this task and identified that an ensemble of BERT and GloVe (via Ridge Regression) produced the best results.", "example": "Convert the coordinate to text: [-2.3719 -6.2773]:"}
{"text": "Convert the coordinate to text: [-1.8006 -6.5953]: The authors proposed the BERT-BiLSTM-RDrop model for Chinese Named Entity Recognition where fine-tuned BERT models are used, the output of BERT is taken as an input of the BiLSTM network, and R-Drop technology is employed to optimize the loss function.", "target": "The authors proposed the BERT-BiLSTM-RDrop model for Chinese Named Entity Recognition where fine-tuned BERT models are used, the output of BERT is taken as an input of the BiLSTM network, and R-Drop technology is employed to optimize the loss function.", "example": "Convert the coordinate to text: [-1.8006 -6.5953]:"}
{"text": "Convert the coordinate to text: [-4.0508  0.8419]: The authors propose a sentiment-guided Transformer model that merges the semantic and sentiment information from social media posts. In addition, the paper introduced a supervised severity-aware contrastive learning framework for better distinguishing between different severity levels.", "target": "The authors propose a sentiment-guided Transformer model that merges the semantic and sentiment information from social media posts. In addition, the paper introduced a supervised severity-aware contrastive learning framework for better distinguishing between different severity levels.", "example": "Convert the coordinate to text: [-4.0508  0.8419]:"}
{"text": "Convert the coordinate to text: [-1.7984 -5.6122]: The authors propose a novel framework to automatically generate labeled data for RE using pre-trained language model GPT-2 and a meta learning approach to optimize the generated samples.", "target": "The authors propose a novel framework to automatically generate labeled data for RE using pre-trained language model GPT-2 and a meta learning approach to optimize the generated samples.", "example": "Convert the coordinate to text: [-1.7984 -5.6122]:"}
{"text": "Convert the coordinate to text: [-8.1331 -5.8958]: The authors present a novel sentence ordering method by incorporating a coherence verifier (CoVer) into existing sentence ordering methods. In addition, a novel coherence model is proposed along with a graph formulation and data construction strategy for contrastive pre-training, separate from the sentence ordering task.", "target": "The authors present a novel sentence ordering method by incorporating a coherence verifier (CoVer) into existing sentence ordering methods. In addition, a novel coherence model is proposed along with a graph formulation and data construction strategy for contrastive pre-training, separate from the sentence ordering task.", "example": "Convert the coordinate to text: [-8.1331 -5.8958]:"}
{"text": "Convert the coordinate to text: [ 0.1158 -8.9254]: The paper introduces a simple yet efficient paradigm named XtremeCLIP for low-resource VLU, which minimizes trainable parameters to improve model generalization. It reformulates a series of VLU tasks as a unified open-book affinity-matching problem.", "target": "The paper introduces a simple yet efficient paradigm named XtremeCLIP for low-resource VLU, which minimizes trainable parameters to improve model generalization. It reformulates a series of VLU tasks as a unified open-book affinity-matching problem.", "example": "Convert the coordinate to text: [ 0.1158 -8.9254]:"}
{"text": "Convert the coordinate to text: [-0.5846  1.0964]: The authors propose a comprehensive evaluation of the impact of model compression techniques on the fairness of deep learning models, specifically language models.", "target": "The authors propose a comprehensive evaluation of the impact of model compression techniques on the fairness of deep learning models, specifically language models.", "example": "Convert the coordinate to text: [-0.5846  1.0964]:"}
{"text": "Convert the coordinate to text: [ 3.7498 -7.5123]: The authors propose sequence parallelism, a memory-efficient parallelism from a system perspective, which is compatible with most existing parallelisms, and does not require a single device to hold the whole sequence. They also propose Ring Self-Attention (RSA) that integrates ring-style communication with self-attention calculation.", "target": "The authors propose sequence parallelism, a memory-efficient parallelism from a system perspective, which is compatible with most existing parallelisms, and does not require a single device to hold the whole sequence. They also propose Ring Self-Attention (RSA) that integrates ring-style communication with self-attention calculation.", "example": "Convert the coordinate to text: [ 3.7498 -7.5123]:"}
{"text": "Convert the coordinate to text: [-2.76   -6.4748]: The author aims to detect intent dynamics, especially in the Indian multilingual context. MNID (Multiple Novel Intent Detection), a new cluster-based framework, is developed for identifying multiple novel intents while optimizing human annotation costs.", "target": "The author aims to detect intent dynamics, especially in the Indian multilingual context. MNID (Multiple Novel Intent Detection), a new cluster-based framework, is developed for identifying multiple novel intents while optimizing human annotation costs.", "example": "Convert the coordinate to text: [-2.76   -6.4748]:"}
{"text": "Convert the coordinate to text: [ 1.6189 13.4562]: The authors propose the use of game-theoretical modeling and online planning approaches to quantitively analyze the externalities associated with long-lasting humanitarian relief operations in conflict areas. The problems of humanitarian relief operations are modeled as an online multi-stage rescuer-and-attacker interdiction game with both single-source and multiple-source relief supply policies.", "target": "The authors propose the use of game-theoretical modeling and online planning approaches to quantitively analyze the externalities associated with long-lasting humanitarian relief operations in conflict areas. The problems of humanitarian relief operations are modeled as an online multi-stage rescuer-and-attacker interdiction game with both single-source and multiple-source relief supply policies.", "example": "Convert the coordinate to text: [ 1.6189 13.4562]:"}
{"text": "Convert the coordinate to text: [ 4.4145 12.3802]: The authors propose Fast and Forgetful Memory, an algorithm-agnostic memory model specifically designed for RL, which constrains the model search space via strong structural priors inspired by computational psychology.", "target": "The authors propose Fast and Forgetful Memory, an algorithm-agnostic memory model specifically designed for RL, which constrains the model search space via strong structural priors inspired by computational psychology.", "example": "Convert the coordinate to text: [ 4.4145 12.3802]:"}
{"text": "Convert the coordinate to text: [ 6.3184 -3.8924]: The authors propose SimPLE, a simple proxy-free method which doesn't need feature/proxy normalization or angular margin but can generalize well in open-set recognition.", "target": "The authors propose SimPLE, a simple proxy-free method which doesn't need feature/proxy normalization or angular margin but can generalize well in open-set recognition.", "example": "Convert the coordinate to text: [ 6.3184 -3.8924]:"}
{"text": "Convert the coordinate to text: [  4.0107 -12.5557]: The paper introduces an open corpus, composed of a set of external object concepts and clustered to several centroids, to improve the detection model's generalization ability. The authors propose the Generalized Objectness Assessment (GOAT) based on visual-text alignment and Category Expanding (CE) with open corpus in two training tasks.", "target": "The paper introduces an open corpus, composed of a set of external object concepts and clustered to several centroids, to improve the detection model's generalization ability. The authors propose the Generalized Objectness Assessment (GOAT) based on visual-text alignment and Category Expanding (CE) with open corpus in two training tasks.", "example": "Convert the coordinate to text: [  4.0107 -12.5557]:"}
{"text": "Convert the coordinate to text: [ 8.2888 -6.0186]: The authors present a straightforward and generic method for feature enhancement using partial channel shifting (PCS), which is inspired by the temporal shifting in video understanding and displplaces part of the channels along the spatial dimensions.", "target": "The authors present a straightforward and generic method for feature enhancement using partial channel shifting (PCS), which is inspired by the temporal shifting in video understanding and displplaces part of the channels along the spatial dimensions.", "example": "Convert the coordinate to text: [ 8.2888 -6.0186]:"}
{"text": "Convert the coordinate to text: [ 11.3282 -19.0475]: The authors introduce the Tangent Sampson error, a generalization of the classical Sampson error, which can handle arbitrary central camera models and requires only local gradients of the distortion map.", "target": "The authors introduce the Tangent Sampson error, a generalization of the classical Sampson error, which can handle arbitrary central camera models and requires only local gradients of the distortion map.", "example": "Convert the coordinate to text: [ 11.3282 -19.0475]:"}
{"text": "Convert the coordinate to text: [-9.3936 -1.5444]: The paper proposes to verify the output and the knowledge of knowledge-augmented LMs using a separate model called a verifier. The verifier is a small LM trained to identify errors in either the retrieval of relevant knowledge or its accurate reflection in the generated text, alerting the system to make corrections as needed.", "target": "The paper proposes to verify the output and the knowledge of knowledge-augmented LMs using a separate model called a verifier. The verifier is a small LM trained to identify errors in either the retrieval of relevant knowledge or its accurate reflection in the generated text, alerting the system to make corrections as needed.", "example": "Convert the coordinate to text: [-9.3936 -1.5444]:"}
{"text": "Convert the coordinate to text: [14.6355  4.8877]: The authors propose a principled approach named Entire Space CounterFactual Regression (ESCFR), which is a new take on optimal transport in the context of causality. The ESCFR approach includes a relaxed mass-preserving regularizer to address the mini-batch sampling effects issue and a proximal factual outcome regularizer to handle the unobserved confounder effects issue.", "target": "The authors propose a principled approach named Entire Space CounterFactual Regression (ESCFR), which is a new take on optimal transport in the context of causality. The ESCFR approach includes a relaxed mass-preserving regularizer to address the mini-batch sampling effects issue and a proximal factual outcome regularizer to handle the unobserved confounder effects issue.", "example": "Convert the coordinate to text: [14.6355  4.8877]:"}
{"text": "Convert the coordinate to text: [ 6.77   -6.0258]: The authors present ProtoConcepts, a method for interpretable image classification that combines deep learning and case-based reasoning using prototypical parts. This method modifies the architecture of prototype-based networks to learn prototypical concepts visualized using multiple image patches, facilitating the identification of the concept captured by that prototype.", "target": "The authors present ProtoConcepts, a method for interpretable image classification that combines deep learning and case-based reasoning using prototypical parts. This method modifies the architecture of prototype-based networks to learn prototypical concepts visualized using multiple image patches, facilitating the identification of the concept captured by that prototype.", "example": "Convert the coordinate to text: [ 6.77   -6.0258]:"}
{"text": "Convert the coordinate to text: [ 1.8534 -4.1493]: The authors propose a technique called CS-Isolate, which suggests that focusing solely on content factors such as semantic information, while ignoring style factors, can make hard examples more discriminable. The goal is to ensure the content factors of all examples in the same underlying clean class remain unchanged as their style information changes.", "target": "The authors propose a technique called CS-Isolate, which suggests that focusing solely on content factors such as semantic information, while ignoring style factors, can make hard examples more discriminable. The goal is to ensure the content factors of all examples in the same underlying clean class remain unchanged as their style information changes.", "example": "Convert the coordinate to text: [ 1.8534 -4.1493]:"}
{"text": "Convert the coordinate to text: [-0.1955 -1.9206]: The authors introduce TextReact, a method that enhances predictive chemistry by retrieving text descriptions relevant to a given chemical reaction and aligning them with the molecular representation of the reaction. This alignment is further strengthened by incorporating an auxiliary masked LM objective in the predictor training.", "target": "The authors introduce TextReact, a method that enhances predictive chemistry by retrieving text descriptions relevant to a given chemical reaction and aligning them with the molecular representation of the reaction. This alignment is further strengthened by incorporating an auxiliary masked LM objective in the predictor training.", "example": "Convert the coordinate to text: [-0.1955 -1.9206]:"}
{"text": "Convert the coordinate to text: [-4.3119  0.6837]: The study focuses on the document-level targeted sentiment analysis task, which aims to extract opinion targets consisting of multi-level entities from a review document and predict their sentiments. To address this, it introduces a Sequence-to-Structure (Seq2Struct) approach that can explicitly model the hierarchical structure among multiple opinion targets in a document and capture the long-distance dependencies among affiliated entities across sentences.", "target": "The study focuses on the document-level targeted sentiment analysis task, which aims to extract opinion targets consisting of multi-level entities from a review document and predict their sentiments. To address this, it introduces a Sequence-to-Structure (Seq2Struct) approach that can explicitly model the hierarchical structure among multiple opinion targets in a document and capture the long-distance dependencies among affiliated entities across sentences.", "example": "Convert the coordinate to text: [-4.3119  0.6837]:"}
{"text": "Convert the coordinate to text: [13.4792 -4.653 ]: The study explores three emerging security issues in NLP research: backdoor attacks, private data leakage, and imitation attacks.", "target": "The study explores three emerging security issues in NLP research: backdoor attacks, private data leakage, and imitation attacks.", "example": "Convert the coordinate to text: [13.4792 -4.653 ]:"}
{"text": "Convert the coordinate to text: [-5.8832  2.0282]: A novel sketch, BurstSketch, is proposed for accurate real-time burst detection. BurstSketch consists of two stages: Stage 1 uses the Running Track technique to efficiently select potential burst items, while Stage 2 monitors the potential burst items and captures key features of the burst pattern using a technique called Snapshotting. Dynamic Buckets, an optimization, is also proposed to improve Burstsketch's accuracy.", "target": "A novel sketch, BurstSketch, is proposed for accurate real-time burst detection. BurstSketch consists of two stages: Stage 1 uses the Running Track technique to efficiently select potential burst items, while Stage 2 monitors the potential burst items and captures key features of the burst pattern using a technique called Snapshotting. Dynamic Buckets, an optimization, is also proposed to improve Burstsketch's accuracy.", "example": "Convert the coordinate to text: [-5.8832  2.0282]:"}
{"text": "Convert the coordinate to text: [  8.382  -12.8684]: The authors propose LaserMix, a framework that mixes laser beams from different LiDAR scans to better exploit unlabeled data, and encourages the model to make consistent and confident predictions before and after mixing.", "target": "The authors propose LaserMix, a framework that mixes laser beams from different LiDAR scans to better exploit unlabeled data, and encourages the model to make consistent and confident predictions before and after mixing.", "example": "Convert the coordinate to text: [  8.382  -12.8684]:"}
{"text": "Convert the coordinate to text: [-6.0034 -7.249 ]: This paper assesses the alignment of top-p sets with their probabilistic meaning in different linguistic contexts, and proposes to use conformal prediction, a calibration procedure, to calibrate the parameter p as a function of the entropy of the next word distribution.", "target": "This paper assesses the alignment of top-p sets with their probabilistic meaning in different linguistic contexts, and proposes to use conformal prediction, a calibration procedure, to calibrate the parameter p as a function of the entropy of the next word distribution.", "example": "Convert the coordinate to text: [-6.0034 -7.249 ]:"}
{"text": "Convert the coordinate to text: [10.3505  8.0401]: The authors propose a new mechanism for SCO with user-level privacy that does not require any smoothness assumptions on the loss. The novel mechanism proposes that the optimizers of strongly convex losses have low local deletion sensitivity.", "target": "The authors propose a new mechanism for SCO with user-level privacy that does not require any smoothness assumptions on the loss. The novel mechanism proposes that the optimizers of strongly convex losses have low local deletion sensitivity.", "example": "Convert the coordinate to text: [10.3505  8.0401]:"}
{"text": "Convert the coordinate to text: [-0.2088 -1.1765]: NormMark, a probabilistic generative Markov model is proposed to carry the latent features throughout a dialogue. These features, captured by discrete and continuous latent variables conditioned on the conversation history, improve the model's ability in norm recognition.", "target": "NormMark, a probabilistic generative Markov model is proposed to carry the latent features throughout a dialogue. These features, captured by discrete and continuous latent variables conditioned on the conversation history, improve the model's ability in norm recognition.", "example": "Convert the coordinate to text: [-0.2088 -1.1765]:"}
{"text": "Convert the coordinate to text: [-2.6352 -5.7704]: This study empirically compares three different QAG methodologies that leverage sequence-to-sequence LM fine-tuning, establishing baselines for the field.", "target": "This study empirically compares three different QAG methodologies that leverage sequence-to-sequence LM fine-tuning, establishing baselines for the field.", "example": "Convert the coordinate to text: [-2.6352 -5.7704]:"}
{"text": "Convert the coordinate to text: [-8.1639 -7.3997]: The authors aim to improve generalization in semantic parsing with two techniques: a token preprocessing method to preserve the semantic boundaries of tokens produced by LM tokenizers, and the use of special tokens to mark the boundaries of components aligned between input and output.", "target": "The authors aim to improve generalization in semantic parsing with two techniques: a token preprocessing method to preserve the semantic boundaries of tokens produced by LM tokenizers, and the use of special tokens to mark the boundaries of components aligned between input and output.", "example": "Convert the coordinate to text: [-8.1639 -7.3997]:"}
{"text": "Convert the coordinate to text: [-6.068  -7.4782]: This work is the first exploration of compositional generalization in context-dependent Text-to-SQL scenarios and proposes a method named 'p-align' to improve the compositional generalization of Text-to-SQL models.", "target": "This work is the first exploration of compositional generalization in context-dependent Text-to-SQL scenarios and proposes a method named 'p-align' to improve the compositional generalization of Text-to-SQL models.", "example": "Convert the coordinate to text: [-6.068  -7.4782]:"}
{"text": "Convert the coordinate to text: [-1.2628 -5.4168]: The authors propose that continual pre-training may not be essential for few-shot intent detection. They find that directly fine-tuning PLMs on a few labeled examples yields comparable results to methods that use continual pre-training.", "target": "The authors propose that continual pre-training may not be essential for few-shot intent detection. They find that directly fine-tuning PLMs on a few labeled examples yields comparable results to methods that use continual pre-training.", "example": "Convert the coordinate to text: [-1.2628 -5.4168]:"}
{"text": "Convert the coordinate to text: [1.3781e+01 1.3548e-02]: The authors propose CounterFactual GraphODE (CF-GODE), a model for estimating continuous-time counterfactual outcomes in multi-agent dynamical systems, where units are inter-dependent and confounders are time-varying.", "target": "The authors propose CounterFactual GraphODE (CF-GODE), a model for estimating continuous-time counterfactual outcomes in multi-agent dynamical systems, where units are inter-dependent and confounders are time-varying.", "example": "Convert the coordinate to text: [1.3781e+01 1.3548e-02]:"}
{"text": "Convert the coordinate to text: [-5.0802 -6.3797]: The authors introduce PaRTE, a collection of 1,126 pairs of RTE examples, as a means to evaluate if model predictions are robust to paraphrasing.", "target": "The authors introduce PaRTE, a collection of 1,126 pairs of RTE examples, as a means to evaluate if model predictions are robust to paraphrasing.", "example": "Convert the coordinate to text: [-5.0802 -6.3797]:"}
{"text": "Convert the coordinate to text: [ 10.0014 -11.4181]: The authors propose a novel method that inputs a single image and outputs a full 360-degree 3D textured mesh in one feed-forward pass. This is done using a new view-conditioned 2D diffusion model, Zero123, and a novel 3D reconstruction module based on SDF-based generalizable neural surface reconstruction method.", "target": "The authors propose a novel method that inputs a single image and outputs a full 360-degree 3D textured mesh in one feed-forward pass. This is done using a new view-conditioned 2D diffusion model, Zero123, and a novel 3D reconstruction module based on SDF-based generalizable neural surface reconstruction method.", "example": "Convert the coordinate to text: [ 10.0014 -11.4181]:"}
{"text": "Convert the coordinate to text: [-1.2522 -1.5679]: The authors developed MDACE, the first publicly available code evidence dataset built from a subset of the MIMIC-III clinical records and annotated by professional medical coders, to support the development of systems that can provide evidence for coding decisions.", "target": "The authors developed MDACE, the first publicly available code evidence dataset built from a subset of the MIMIC-III clinical records and annotated by professional medical coders, to support the development of systems that can provide evidence for coding decisions.", "example": "Convert the coordinate to text: [-1.2522 -1.5679]:"}
{"text": "Convert the coordinate to text: [ 4.8765 -2.9457]: The authors propose a novel unsupervised AES approach, ULRA, which does not require groundtruth scores, but instead uses multiple heuristic quality signals as the pseudo-groundtruth. The AES task is viewed as a ranking problem, so a Deep Pairwise Rank Aggregation (DPRA) loss is designed for training.", "target": "The authors propose a novel unsupervised AES approach, ULRA, which does not require groundtruth scores, but instead uses multiple heuristic quality signals as the pseudo-groundtruth. The AES task is viewed as a ranking problem, so a Deep Pairwise Rank Aggregation (DPRA) loss is designed for training.", "example": "Convert the coordinate to text: [ 4.8765 -2.9457]:"}
{"text": "Convert the coordinate to text: [-4.4276 -9.249 ]: The authors propose SubAtt, a transformer-based OOV estimation model that uses attention mechanisms on both the context and the subwords, positioning it as a response to the lack of advanced architecture in past solutions. In addition to attention, pretraining subword representations is also suggested to lead to an improvement in OOV estimation.", "target": "The authors propose SubAtt, a transformer-based OOV estimation model that uses attention mechanisms on both the context and the subwords, positioning it as a response to the lack of advanced architecture in past solutions. In addition to attention, pretraining subword representations is also suggested to lead to an improvement in OOV estimation.", "example": "Convert the coordinate to text: [-4.4276 -9.249 ]:"}
{"text": "Convert the coordinate to text: [-1.2447  0.1601]: The study explores the effectiveness of five conventional machine learning techniques (Logistic Regression, Decision Tree, XGBoost, Support Vector Machines, and Random Forest) to detect sexist content in online texts.", "target": "The study explores the effectiveness of five conventional machine learning techniques (Logistic Regression, Decision Tree, XGBoost, Support Vector Machines, and Random Forest) to detect sexist content in online texts.", "example": "Convert the coordinate to text: [-1.2447  0.1601]:"}
{"text": "Convert the coordinate to text: [ 2.9651 -0.4036]: The authors propose an active learning approach called Disagreement Aware Active Learning (DAAL). This method focuses annotations on examples where model entropy and annotator entropy differ the most.", "target": "The authors propose an active learning approach called Disagreement Aware Active Learning (DAAL). This method focuses annotations on examples where model entropy and annotator entropy differ the most.", "example": "Convert the coordinate to text: [ 2.9651 -0.4036]:"}
{"text": "Convert the coordinate to text: [-2.0868  1.6988]: The authors aim to compare different instance-based and similarity-based methods on multiple datasets to examine the alleged advantages of the similarity-based approach, particularly in terms of data demand and cross-prompt performance.", "target": "The authors aim to compare different instance-based and similarity-based methods on multiple datasets to examine the alleged advantages of the similarity-based approach, particularly in terms of data demand and cross-prompt performance.", "example": "Convert the coordinate to text: [-2.0868  1.6988]:"}
{"text": "Convert the coordinate to text: [-0.3483  6.9818]: The authors propose a novel approach based on logic detection, logic mapping and hierarchical logical projections for constructing logic-aware input embeddings for transformer language models. They also introduce a new modeling paradigm, the logical transformer, to improve performance on NLU and NLG tasks.", "target": "The authors propose a novel approach based on logic detection, logic mapping and hierarchical logical projections for constructing logic-aware input embeddings for transformer language models. They also introduce a new modeling paradigm, the logical transformer, to improve performance on NLU and NLG tasks.", "example": "Convert the coordinate to text: [-0.3483  6.9818]:"}
{"text": "Convert the coordinate to text: [-10.0468   2.9237]: The authors propose OpenTIPE, a flexible and extensible framework aimed at supporting research on interactive post-editing, which allows for exploration of human-centered approaches for post-editing tasks.", "target": "The authors propose OpenTIPE, a flexible and extensible framework aimed at supporting research on interactive post-editing, which allows for exploration of human-centered approaches for post-editing tasks.", "example": "Convert the coordinate to text: [-10.0468   2.9237]:"}
{"text": "Convert the coordinate to text: [-10.1371  -0.8401]: The authors propose the concept of query refinement prompts, which urge LLMs to explicitly express the complexities and various facets in questions, and then generate comprehensive long-form answers covering these facets.", "target": "The authors propose the concept of query refinement prompts, which urge LLMs to explicitly express the complexities and various facets in questions, and then generate comprehensive long-form answers covering these facets.", "example": "Convert the coordinate to text: [-10.1371  -0.8401]:"}
{"text": "Convert the coordinate to text: [ 2.2882 -8.3484]: The authors propose a new cross-modal affinity (CMA) module based on Transformer architecture to quickly learn new semantic information with few samples and to adapt to different scenarios, and reframe the problem as few-shot referring video object segmentation (FS-RVOS).", "target": "The authors propose a new cross-modal affinity (CMA) module based on Transformer architecture to quickly learn new semantic information with few samples and to adapt to different scenarios, and reframe the problem as few-shot referring video object segmentation (FS-RVOS).", "example": "Convert the coordinate to text: [ 2.2882 -8.3484]:"}
{"text": "Convert the coordinate to text: [0.3435 2.6621]: The authors propose a fairness framework that minimizes the correlation disparity error by ensuring that global projection matrices learned from all data points provide comparable correlations to those of group-specific projection matrices.", "target": "The authors propose a fairness framework that minimizes the correlation disparity error by ensuring that global projection matrices learned from all data points provide comparable correlations to those of group-specific projection matrices.", "example": "Convert the coordinate to text: [0.3435 2.6621]:"}
{"text": "Convert the coordinate to text: [ 9.791  12.2267]: The authors propose the problem of clustering of bandits with misspecified user models (CBMUM), and introduce two robust CB algorithms, RCLUMB and RSCLUMB, which can handle inaccurate user preference estimations and improper clustering caused by model misspecifications.", "target": "The authors propose the problem of clustering of bandits with misspecified user models (CBMUM), and introduce two robust CB algorithms, RCLUMB and RSCLUMB, which can handle inaccurate user preference estimations and improper clustering caused by model misspecifications.", "example": "Convert the coordinate to text: [ 9.791  12.2267]:"}
{"text": "Convert the coordinate to text: [  0.0228 -10.3664]: The paper introduces a novel task, IntentQA, focused on video intent reasoning, and establishes a large-scale VideoQA dataset for this purpose. The authors also propose a context-aware Video Intent Reasoning model (CaVIR) made up of a Video Query Language (VQL), a Contrastive Learning module, and a Commonsense Reasoning module.", "target": "The paper introduces a novel task, IntentQA, focused on video intent reasoning, and establishes a large-scale VideoQA dataset for this purpose. The authors also propose a context-aware Video Intent Reasoning model (CaVIR) made up of a Video Query Language (VQL), a Contrastive Learning module, and a Commonsense Reasoning module.", "example": "Convert the coordinate to text: [  0.0228 -10.3664]:"}
{"text": "Convert the coordinate to text: [-0.9737 -6.241 ]: The authors discover that during the pre-training process, models trained for shorter periods (middle epochs), which are not fully trained, can perform better than fully trained models when used as feature extractors (FE) while fine-tuning (FT) performance still grows with source performance.", "target": "The authors discover that during the pre-training process, models trained for shorter periods (middle epochs), which are not fully trained, can perform better than fully trained models when used as feature extractors (FE) while fine-tuning (FT) performance still grows with source performance.", "example": "Convert the coordinate to text: [-0.9737 -6.241 ]:"}
{"text": "Convert the coordinate to text: [13.0591  0.0325]: The paper introduces BCDiff, a Bi-directional Consistent Diffusion framework tailored for instantaneous trajectory prediction. BCDiff utilizes two coupled diffusion models with a mutual guidance mechanism to generate unobserved historical trajectories and future trajectories bidirectionally and consistently.", "target": "The paper introduces BCDiff, a Bi-directional Consistent Diffusion framework tailored for instantaneous trajectory prediction. BCDiff utilizes two coupled diffusion models with a mutual guidance mechanism to generate unobserved historical trajectories and future trajectories bidirectionally and consistently.", "example": "Convert the coordinate to text: [13.0591  0.0325]:"}
{"text": "Convert the coordinate to text: [ 12.0264 -13.973 ]: The authors introduce MoFusion, a new denoising-diffusion-based framework for high-quality conditional human motion synthesis that can synthesise long, temporally plausible, and semantically accurate motions based on a range of conditioning contexts such as music and text.", "target": "The authors introduce MoFusion, a new denoising-diffusion-based framework for high-quality conditional human motion synthesis that can synthesise long, temporally plausible, and semantically accurate motions based on a range of conditioning contexts such as music and text.", "example": "Convert the coordinate to text: [ 12.0264 -13.973 ]:"}
{"text": "Convert the coordinate to text: [ 5.5412 -4.9678]: The authors propose the graph active learning problem as a generative process called GFlowGNN, which generates samples proportionate to a predefined reward function. They also propose the concept of flow nodes and flow features to efficiently model graphs as flows based on generative flow networks.", "target": "The authors propose the graph active learning problem as a generative process called GFlowGNN, which generates samples proportionate to a predefined reward function. They also propose the concept of flow nodes and flow features to efficiently model graphs as flows based on generative flow networks.", "example": "Convert the coordinate to text: [ 5.5412 -4.9678]:"}
{"text": "Convert the coordinate to text: [  0.8291 -13.3031]: The authors propose the problem of automatically generating CAD for RE tasks from an entity-centric viewpoint and develop a new approach to derive contextual counterfactuals for entities using two topological properties, centrality and shortest path, in syntactic and semantic dependency graphs.", "target": "The authors propose the problem of automatically generating CAD for RE tasks from an entity-centric viewpoint and develop a new approach to derive contextual counterfactuals for entities using two topological properties, centrality and shortest path, in syntactic and semantic dependency graphs.", "example": "Convert the coordinate to text: [  0.8291 -13.3031]:"}
{"text": "Convert the coordinate to text: [-7.5552  0.4244]: The authors propose a new method called Hybrid and Collaborative Passage Reranking (HybRank), which appreciates the substantial similarity measurements of upstream retrievers for passage collaboration and also considers the lexical and semantic properties of both sparse and dense retrievers for reranking. Moreover, HybRank is a plug-in reranker that enhances arbitrary passage lists including already reranked ones.", "target": "The authors propose a new method called Hybrid and Collaborative Passage Reranking (HybRank), which appreciates the substantial similarity measurements of upstream retrievers for passage collaboration and also considers the lexical and semantic properties of both sparse and dense retrievers for reranking. Moreover, HybRank is a plug-in reranker that enhances arbitrary passage lists including already reranked ones.", "example": "Convert the coordinate to text: [-7.5552  0.4244]:"}
{"text": "Convert the coordinate to text: [ 1.6075 13.5053]: The authors introduce a soft quota setting in which every post is associated with two values \u2014 a lower and upper target which denote a range for the intended number of applicants in any assignment. They allow the number of applicants assigned to fall outside this range, creating assignments with deviation.", "target": "The authors introduce a soft quota setting in which every post is associated with two values \u2014 a lower and upper target which denote a range for the intended number of applicants in any assignment. They allow the number of applicants assigned to fall outside this range, creating assignments with deviation.", "example": "Convert the coordinate to text: [ 1.6075 13.5053]:"}
{"text": "Convert the coordinate to text: [-2.3203 -7.0474]: The authors present AxomiyaBERTa, a novel BERT model for Assamese, that is trained solely on the masked language modeling (MLM) task without the typical additional next sentence prediction (NSP) objective, suggesting that MLM alone can be successfully leveraged for a range of tasks in resource-scarce settings.", "target": "The authors present AxomiyaBERTa, a novel BERT model for Assamese, that is trained solely on the masked language modeling (MLM) task without the typical additional next sentence prediction (NSP) objective, suggesting that MLM alone can be successfully leveraged for a range of tasks in resource-scarce settings.", "example": "Convert the coordinate to text: [-2.3203 -7.0474]:"}
{"text": "Convert the coordinate to text: [-10.2082  -1.4346]: A Semantic Question Reformulation (SURF) model is proposed which utilizes three linguistically-grounded operations (repair, syntactic reshaping, generalization) to rewrite users' questions in order to improve answering efficiency.", "target": "A Semantic Question Reformulation (SURF) model is proposed which utilizes three linguistically-grounded operations (repair, syntactic reshaping, generalization) to rewrite users' questions in order to improve answering efficiency.", "example": "Convert the coordinate to text: [-10.2082  -1.4346]:"}
{"text": "Convert the coordinate to text: [-3.1394 -4.2978]: The authors compare the SEQ, SeqCRF, and SpanPred approaches for NER on 4 biomedical tasks, and also propose simple ways of combining these three approaches to improve performance.", "target": "The authors compare the SEQ, SeqCRF, and SpanPred approaches for NER on 4 biomedical tasks, and also propose simple ways of combining these three approaches to improve performance.", "example": "Convert the coordinate to text: [-3.1394 -4.2978]:"}
{"text": "Convert the coordinate to text: [2.4918 5.767 ]: The authors propose to modify the FwdPush algorithm, by leveraging the linear invariant property and demonstrating FwdPush is a variant of Gauss-Seidel. They present a Successive Over-Relaxation based method, FwdPushSOR, and a new local heuristic push method to enhance computing efficiency.", "target": "The authors propose to modify the FwdPush algorithm, by leveraging the linear invariant property and demonstrating FwdPush is a variant of Gauss-Seidel. They present a Successive Over-Relaxation based method, FwdPushSOR, and a new local heuristic push method to enhance computing efficiency.", "example": "Convert the coordinate to text: [2.4918 5.767 ]:"}
{"text": "Convert the coordinate to text: [-4.1397 -6.8595]: The authors challenge the assumption that aligned representations significantly benefit cross-lingual transfer, providing evidence that alignment is actually significantly correlated with cross-lingual transfer across different parameters such as languages, models, and random seeds.", "target": "The authors challenge the assumption that aligned representations significantly benefit cross-lingual transfer, providing evidence that alignment is actually significantly correlated with cross-lingual transfer across different parameters such as languages, models, and random seeds.", "example": "Convert the coordinate to text: [-4.1397 -6.8595]:"}
{"text": "Convert the coordinate to text: [-3.4861 -5.5588]: The authors propose a novel tokenization method that factorizes subwords onto discrete triplets using a VQ-VAE model, referred to as the Factorizer.", "target": "The authors propose a novel tokenization method that factorizes subwords onto discrete triplets using a VQ-VAE model, referred to as the Factorizer.", "example": "Convert the coordinate to text: [-3.4861 -5.5588]:"}
{"text": "Convert the coordinate to text: [-2.1493 -5.3714]: This study aims to conduct a systematic inspection of ChatGPT's performance in two controllable generation tasks, specifically its capability to adapt its output to different target audiences (expert vs. layman) and writing styles (formal vs. informal).", "target": "This study aims to conduct a systematic inspection of ChatGPT's performance in two controllable generation tasks, specifically its capability to adapt its output to different target audiences (expert vs. layman) and writing styles (formal vs. informal).", "example": "Convert the coordinate to text: [-2.1493 -5.3714]:"}
{"text": "Convert the coordinate to text: [ -3.2775 -10.206 ]: The study proposes an unsupervised speech-to-sign-language recognition system, speech2sign-U, that learns to translate between spoken and sign languages by observing only non-parallel speech and sign-language corpora.", "target": "The study proposes an unsupervised speech-to-sign-language recognition system, speech2sign-U, that learns to translate between spoken and sign languages by observing only non-parallel speech and sign-language corpora.", "example": "Convert the coordinate to text: [ -3.2775 -10.206 ]:"}
{"text": "Convert the coordinate to text: [3.6354 1.9215]: This study introduces the use of four machine-learning algorithms: Decision Trees, Random Forest, Logistic Regression, and Support Vector Classifier (SVC) in detecting these subtle themes.", "target": "This study introduces the use of four machine-learning algorithms: Decision Trees, Random Forest, Logistic Regression, and Support Vector Classifier (SVC) in detecting these subtle themes.", "example": "Convert the coordinate to text: [3.6354 1.9215]:"}
{"text": "Convert the coordinate to text: [-3.8195 -8.9431]: UM-DFKI presents a cascade solution that uses fine-tuned XLS-R models for Maltese ASR, and the mBART model for English machine translation purposes.", "target": "UM-DFKI presents a cascade solution that uses fine-tuned XLS-R models for Maltese ASR, and the mBART model for English machine translation purposes.", "example": "Convert the coordinate to text: [-3.8195 -8.9431]:"}
{"text": "Convert the coordinate to text: [ 3.1002 -1.3584]: The authors propose overcoming the challenge of limited annotations by using semi-supervised learning from unlabeled news texts. They include a self-supervised sequence labeling approach and a second model for disambiguating signal candidates.", "target": "The authors propose overcoming the challenge of limited annotations by using semi-supervised learning from unlabeled news texts. They include a self-supervised sequence labeling approach and a second model for disambiguating signal candidates.", "example": "Convert the coordinate to text: [ 3.1002 -1.3584]:"}
{"text": "Convert the coordinate to text: [-5.1639 10.6858]: The authors propose Mars, an end-to-end task-oriented dialog system that uses two contrastive learning strategies to model the relationship between dialog context and belief/action state representations.", "target": "The authors propose Mars, an end-to-end task-oriented dialog system that uses two contrastive learning strategies to model the relationship between dialog context and belief/action state representations.", "example": "Convert the coordinate to text: [-5.1639 10.6858]:"}
{"text": "Convert the coordinate to text: [-2.7736 -3.0761]: This study introduces a new method to harvest massive KGs of arbitrary relations from pretrained language models, with minimal input of a relation definition. The approach efficiently searches in the entity pair space to extract diverse accurate knowledge of the desired relation, supported by an effective search-and-rescore mechanism for improved efficiency and accuracy.", "target": "This study introduces a new method to harvest massive KGs of arbitrary relations from pretrained language models, with minimal input of a relation definition. The approach efficiently searches in the entity pair space to extract diverse accurate knowledge of the desired relation, supported by an effective search-and-rescore mechanism for improved efficiency and accuracy.", "example": "Convert the coordinate to text: [-2.7736 -3.0761]:"}
{"text": "Convert the coordinate to text: [0.7254 1.8037]: In response to this, the paper proposes counterfactual reasoning, which explicitly estimates the influence of context keywords and event pairs in training to eliminate biases in inference.", "target": "In response to this, the paper proposes counterfactual reasoning, which explicitly estimates the influence of context keywords and event pairs in training to eliminate biases in inference.", "example": "Convert the coordinate to text: [0.7254 1.8037]:"}
{"text": "Convert the coordinate to text: [ 0.7321 -4.087 ]: The authors propose self-adaptive in-context learning, a new principle for ICL. They introduce a self-adaption mechanism that helps each sample find an in-context example organization (selection and permutation), thereby maximizing performance.", "target": "The authors propose self-adaptive in-context learning, a new principle for ICL. They introduce a self-adaption mechanism that helps each sample find an in-context example organization (selection and permutation), thereby maximizing performance.", "example": "Convert the coordinate to text: [ 0.7321 -4.087 ]:"}
{"text": "Convert the coordinate to text: [5.8566 6.0843]: The authors propose a testing procedure for detecting interference in A/B testing with increasing allocation. The approach does not demand a predefined interference mechanism and can be supplemented to an existing A/B testing platform.", "target": "The authors propose a testing procedure for detecting interference in A/B testing with increasing allocation. The approach does not demand a predefined interference mechanism and can be supplemented to an existing A/B testing platform.", "example": "Convert the coordinate to text: [5.8566 6.0843]:"}
{"text": "Convert the coordinate to text: [-3.8618 -1.278 ]: The paper proposes a novel mechanism called Automatic Temporal Relation (AutoTR) that can directly learn the temporal relation from any dataset. It also demonstrates that the temporal relation between tasks can be asymmetrical, contradicting the assumptions in previous works.", "target": "The paper proposes a novel mechanism called Automatic Temporal Relation (AutoTR) that can directly learn the temporal relation from any dataset. It also demonstrates that the temporal relation between tasks can be asymmetrical, contradicting the assumptions in previous works.", "example": "Convert the coordinate to text: [-3.8618 -1.278 ]:"}
{"text": "Convert the coordinate to text: [ 4.0794 -3.7417]: The authors introduce DreamTeacher, a self-supervised representation learning framework that uses generative networks for pre-training downstream image backbones. It distills knowledge from a trained generative model into these backbones and distills labels obtained from generative networks onto logits of target backbones.", "target": "The authors introduce DreamTeacher, a self-supervised representation learning framework that uses generative networks for pre-training downstream image backbones. It distills knowledge from a trained generative model into these backbones and distills labels obtained from generative networks onto logits of target backbones.", "example": "Convert the coordinate to text: [ 4.0794 -3.7417]:"}
{"text": "Convert the coordinate to text: [ 0.7374 -2.0742]: The authors propose FABind, an end-to-end model that combines pocket prediction and docking for fast and accurate protein-ligand binding. The model incorporates a ligand-informed pocket prediction module leveraged for docking pose estimation and incrementally integrates the predicted pocket to optimize protein-ligand binding.", "target": "The authors propose FABind, an end-to-end model that combines pocket prediction and docking for fast and accurate protein-ligand binding. The model incorporates a ligand-informed pocket prediction module leveraged for docking pose estimation and incrementally integrates the predicted pocket to optimize protein-ligand binding.", "example": "Convert the coordinate to text: [ 0.7374 -2.0742]:"}
{"text": "Convert the coordinate to text: [ 14.8223 -15.0258]: The paper introduces ClimateNeRF, a novel NeRF-editing procedure that fuses physical simulations with NeRF models of scenes, enabling realistic rendering of extreme weather effects in response to climate change.", "target": "The paper introduces ClimateNeRF, a novel NeRF-editing procedure that fuses physical simulations with NeRF models of scenes, enabling realistic rendering of extreme weather effects in response to climate change.", "example": "Convert the coordinate to text: [ 14.8223 -15.0258]:"}
{"text": "Convert the coordinate to text: [ 7.05   12.9174]: The authors propose to tackle the delayed feedback challenge in RL with linear function approximation by employing posterior sampling, introducing an algorithm called Delayed-PSVI. They also suggest improving computational efficiency and applicability in high-dimensional RL problems by incorporating a gradient-based approximate sampling scheme via Langevin dynamics for Delayed-LPSVI.", "target": "The authors propose to tackle the delayed feedback challenge in RL with linear function approximation by employing posterior sampling, introducing an algorithm called Delayed-PSVI. They also suggest improving computational efficiency and applicability in high-dimensional RL problems by incorporating a gradient-based approximate sampling scheme via Langevin dynamics for Delayed-LPSVI.", "example": "Convert the coordinate to text: [ 7.05   12.9174]:"}
{"text": "Convert the coordinate to text: [10.9255 -2.8696]: A novel approach is proposed for learning generative neural fields using linear combinations of implicit basis networks. This approach increases capacity by increasing the number of basis networks, but keeps inference size small through weighted model averaging.", "target": "A novel approach is proposed for learning generative neural fields using linear combinations of implicit basis networks. This approach increases capacity by increasing the number of basis networks, but keeps inference size small through weighted model averaging.", "example": "Convert the coordinate to text: [10.9255 -2.8696]:"}
{"text": "Convert the coordinate to text: [ 6.1607 -1.1017]: The authors propose a method, called Loss Decoupling (LODE), that separates the two objectives for a new task by decoupling the loss of the new task, hence providing a way to obtain a better trade-off between stability and plasticity.", "target": "The authors propose a method, called Loss Decoupling (LODE), that separates the two objectives for a new task by decoupling the loss of the new task, hence providing a way to obtain a better trade-off between stability and plasticity.", "example": "Convert the coordinate to text: [ 6.1607 -1.1017]:"}
{"text": "Convert the coordinate to text: [-2.136  -5.7544]: The authors propose monitor-guided decoding (MGD), a method where a monitor uses static analysis to guide the decoding process in LMs, extending the assistance of integrated development environments (IDEs) to LMs.", "target": "The authors propose monitor-guided decoding (MGD), a method where a monitor uses static analysis to guide the decoding process in LMs, extending the assistance of integrated development environments (IDEs) to LMs.", "example": "Convert the coordinate to text: [-2.136  -5.7544]:"}
{"text": "Convert the coordinate to text: [ 4.3354 -8.4762]: A new two-stream architecture known as Cross-Attention in Space and Time (CAST) is proposed. It uses a novel bottleneck cross-attention mechanism for a better spatial and temporal understanding of videos using only RGB input.", "target": "A new two-stream architecture known as Cross-Attention in Space and Time (CAST) is proposed. It uses a novel bottleneck cross-attention mechanism for a better spatial and temporal understanding of videos using only RGB input.", "example": "Convert the coordinate to text: [ 4.3354 -8.4762]:"}
{"text": "Convert the coordinate to text: [-3.0861 -7.7211]: The authors propose to use large language models (LLMs) to estimate the amount of redundant information between prosody and the words themselves by extracting prosodic features aligned to individual words and testing how well they can be predicted from LLM embeddings.", "target": "The authors propose to use large language models (LLMs) to estimate the amount of redundant information between prosody and the words themselves by extracting prosodic features aligned to individual words and testing how well they can be predicted from LLM embeddings.", "example": "Convert the coordinate to text: [-3.0861 -7.7211]:"}
{"text": "Convert the coordinate to text: [-3.2286 -4.0397]: The authors formulate a new few-shot multimodal named entity recognition (FewMNER) task, which aims to effectively locate and identify named entities for a text-image pair using only a small number of labeled examples. They propose a novel framework taking into consideration of converting visual modality, selecting useful examples, and designing an effective task demonstration.", "target": "The authors formulate a new few-shot multimodal named entity recognition (FewMNER) task, which aims to effectively locate and identify named entities for a text-image pair using only a small number of labeled examples. They propose a novel framework taking into consideration of converting visual modality, selecting useful examples, and designing an effective task demonstration.", "example": "Convert the coordinate to text: [-3.2286 -4.0397]:"}
{"text": "Convert the coordinate to text: [ 6.8312 -1.5083]: The paper proposes a general multi-modal mutual information formula as a unified optimization target, aiming to integrate all pre-training strategies into a single-stage system, named Maximizing Multi-modal Mutual Information Pre-training (M3I Pretraining).", "target": "The paper proposes a general multi-modal mutual information formula as a unified optimization target, aiming to integrate all pre-training strategies into a single-stage system, named Maximizing Multi-modal Mutual Information Pre-training (M3I Pretraining).", "example": "Convert the coordinate to text: [ 6.8312 -1.5083]:"}
{"text": "Convert the coordinate to text: [-3.0262  7.0081]: A new multi-task framework named MTDiag is proposed to address the above issues. The framework reformulates symptom checking as a multi-label classification task, converts each medical dialogue into multiple samples for classification as a solution to the issue of data scarcity, and also devises a multi-task learning strategy that leverages disease information in symptom checking and uses contrastive learning to discriminate symptoms between diseases.", "target": "A new multi-task framework named MTDiag is proposed to address the above issues. The framework reformulates symptom checking as a multi-label classification task, converts each medical dialogue into multiple samples for classification as a solution to the issue of data scarcity, and also devises a multi-task learning strategy that leverages disease information in symptom checking and uses contrastive learning to discriminate symptoms between diseases.", "example": "Convert the coordinate to text: [-3.0262  7.0081]:"}
{"text": "Convert the coordinate to text: [-1.4258 -4.1548]: The authors present InstructCTG, a controlled text generation framework that incorporates different constraints using natural language descriptions and demonstrations of the constraints.", "target": "The authors present InstructCTG, a controlled text generation framework that incorporates different constraints using natural language descriptions and demonstrations of the constraints.", "example": "Convert the coordinate to text: [-1.4258 -4.1548]:"}
{"text": "Convert the coordinate to text: [-5.3578 -0.8476]: This work aims to uncover the underlying characteristics of effective sets for training summarization models by systematically varying the subsets used for calibration fine-tuning, targeting distinct aspects of the sets such as lexical diversity or the size of the gap between positives and negatives.", "target": "This work aims to uncover the underlying characteristics of effective sets for training summarization models by systematically varying the subsets used for calibration fine-tuning, targeting distinct aspects of the sets such as lexical diversity or the size of the gap between positives and negatives.", "example": "Convert the coordinate to text: [-5.3578 -0.8476]:"}
{"text": "Convert the coordinate to text: [12.6354  6.7459]: This paper studies the convergence and implicit bias of constant-stepsize GD for logistic regression on linearly separable data in the EoS regime.", "target": "This paper studies the convergence and implicit bias of constant-stepsize GD for logistic regression on linearly separable data in the EoS regime.", "example": "Convert the coordinate to text: [12.6354  6.7459]:"}
{"text": "Convert the coordinate to text: [-1.8898 -7.0459]: This study introduces a PretrAining on TexT-Rich NetwOrk framework dubbed Patton that includes two pretraining strategies: network-contextualized masked language modeling and masked node prediction, which maximize the inherent dependency between textual attributes and network structure.", "target": "This study introduces a PretrAining on TexT-Rich NetwOrk framework dubbed Patton that includes two pretraining strategies: network-contextualized masked language modeling and masked node prediction, which maximize the inherent dependency between textual attributes and network structure.", "example": "Convert the coordinate to text: [-1.8898 -7.0459]:"}
{"text": "Convert the coordinate to text: [16.2545  1.8285]: The authors investigate the efficacy of directly leveraging pre-trained language models for OOD detection, without any model fine-tuning on the ID data. They also question the necessity of fine-tuning in OOD detection.", "target": "The authors investigate the efficacy of directly leveraging pre-trained language models for OOD detection, without any model fine-tuning on the ID data. They also question the necessity of fine-tuning in OOD detection.", "example": "Convert the coordinate to text: [16.2545  1.8285]:"}
{"text": "Convert the coordinate to text: [-4.4862 -7.0683]: The authors introduce ParaAMR, a large-scale, syntactically diverse paraphrase dataset, created using abstract meaning representation back-translation.", "target": "The authors introduce ParaAMR, a large-scale, syntactically diverse paraphrase dataset, created using abstract meaning representation back-translation.", "example": "Convert the coordinate to text: [-4.4862 -7.0683]:"}
{"text": "Convert the coordinate to text: [-0.5908 -3.3253]: The authors propose a new tabular-format CoT prompting method called Tab-CoT that allows complex reasoning processes to be explicitly modeled in a highly structured way.", "target": "The authors propose a new tabular-format CoT prompting method called Tab-CoT that allows complex reasoning processes to be explicitly modeled in a highly structured way.", "example": "Convert the coordinate to text: [-0.5908 -3.3253]:"}
{"text": "Convert the coordinate to text: [ 5.5096 -3.793 ]: The paper introduces Orthogonal Finetuning (OFT), a finetuning method aimed at adapting text-to-image diffusion models to downstream tasks. OFT can provably preserve hyperspherical energy, crucial for preserving the semantic generation ability of these models. The authors further propose Constrained Orthogonal Finetuning (COFT) that imposes an additional radius constraint to the hypersphere.", "target": "The paper introduces Orthogonal Finetuning (OFT), a finetuning method aimed at adapting text-to-image diffusion models to downstream tasks. OFT can provably preserve hyperspherical energy, crucial for preserving the semantic generation ability of these models. The authors further propose Constrained Orthogonal Finetuning (COFT) that imposes an additional radius constraint to the hypersphere.", "example": "Convert the coordinate to text: [ 5.5096 -3.793 ]:"}
{"text": "Convert the coordinate to text: [ 4.6998 -4.8191]: The authors propose that homophily, or the principle that 'like attracts like', plays a key role in the success of graph contrastive learning. To leverage this, they introduce HomoGCL, a model-agnostic framework that expands the positive set using neighbor nodes with neighbor-specific significances.", "target": "The authors propose that homophily, or the principle that 'like attracts like', plays a key role in the success of graph contrastive learning. To leverage this, they introduce HomoGCL, a model-agnostic framework that expands the positive set using neighbor nodes with neighbor-specific significances.", "example": "Convert the coordinate to text: [ 4.6998 -4.8191]:"}
{"text": "Convert the coordinate to text: [-10.5583  -1.6578]: The authors propose an alternative approach which transforms images and tables into unified language representations, simplifying the complex task into a simpler textual Question and Answering (QA) problem. This approach is implemented in a framework called Solar.", "target": "The authors propose an alternative approach which transforms images and tables into unified language representations, simplifying the complex task into a simpler textual Question and Answering (QA) problem. This approach is implemented in a framework called Solar.", "example": "Convert the coordinate to text: [-10.5583  -1.6578]:"}
{"text": "Convert the coordinate to text: [-3.0837 -4.008 ]: The authors propose a two-level system for inference classification in clinical trials; first level involves identifying relevant evidence-statement pairs using a BERT-based classifier along with contextual data augmentation, second level involves analyzing these identified evidence-statements to classify whether the relation is entailment or contradiction.", "target": "The authors propose a two-level system for inference classification in clinical trials; first level involves identifying relevant evidence-statement pairs using a BERT-based classifier along with contextual data augmentation, second level involves analyzing these identified evidence-statements to classify whether the relation is entailment or contradiction.", "example": "Convert the coordinate to text: [-3.0837 -4.008 ]:"}
{"text": "Convert the coordinate to text: [-3.4991 -9.4543]: The key idea is a cascaded system including Conformer and S2T-Transformer-based ASR models, a Transformer-based MT model, and a DTS (Diffusion-based TTS model), which takes raw text and generates waveform through iterative denoising on pure Gaussian noise, performing well in code-switching scenarios.", "target": "The key idea is a cascaded system including Conformer and S2T-Transformer-based ASR models, a Transformer-based MT model, and a DTS (Diffusion-based TTS model), which takes raw text and generates waveform through iterative denoising on pure Gaussian noise, performing well in code-switching scenarios.", "example": "Convert the coordinate to text: [-3.4991 -9.4543]:"}
{"text": "Convert the coordinate to text: [-1.1733 -5.1108]: The authors propose a straightforward data construction method to de-bias a given prompt template, which is expected to improve performance in sentiment analysis tasks widely.", "target": "The authors propose a straightforward data construction method to de-bias a given prompt template, which is expected to improve performance in sentiment analysis tasks widely.", "example": "Convert the coordinate to text: [-1.1733 -5.1108]:"}
{"text": "Convert the coordinate to text: [ 1.3776 -3.7432]: The authors propose a novel method to mitigate the bias of the QE model and improve estimation performance using contrastive learning between clean and noisy sentence pairs.", "target": "The authors propose a novel method to mitigate the bias of the QE model and improve estimation performance using contrastive learning between clean and noisy sentence pairs.", "example": "Convert the coordinate to text: [ 1.3776 -3.7432]:"}
{"text": "Convert the coordinate to text: [8.3832 7.9026]: The authors present a key finding that classes of functions with finite fat-shattering dimensions are PAC learnable in both the realizable and agnostic settings. Moreover, for convex function classes, they propose they are even properly learnable.", "target": "The authors present a key finding that classes of functions with finite fat-shattering dimensions are PAC learnable in both the realizable and agnostic settings. Moreover, for convex function classes, they propose they are even properly learnable.", "example": "Convert the coordinate to text: [8.3832 7.9026]:"}
{"text": "Convert the coordinate to text: [  8.8745 -11.5997]: The authors propose a one-stage framework called 3D Relative Position-aware Network (3DRP-Net) that effectively captures the relative spatial relationships between objects and enhances object attributes.", "target": "The authors propose a one-stage framework called 3D Relative Position-aware Network (3DRP-Net) that effectively captures the relative spatial relationships between objects and enhances object attributes.", "example": "Convert the coordinate to text: [  8.8745 -11.5997]:"}
{"text": "Convert the coordinate to text: [ 1.5001 -6.4173]: Authors propose a model with a reasoning module containing a multi-head self-attention unit that models four common reasoning patterns to cover more relational triples, and a self-distillation training framework to model the process of relational reasoning.", "target": "Authors propose a model with a reasoning module containing a multi-head self-attention unit that models four common reasoning patterns to cover more relational triples, and a self-distillation training framework to model the process of relational reasoning.", "example": "Convert the coordinate to text: [ 1.5001 -6.4173]:"}
{"text": "Convert the coordinate to text: [2.2741 4.6364]: The authors propose Epidemic Learning (EL), a DL algorithm with changing communication topologies where each node sends its model updates to a random sample of s other nodes in a system of n nodes, to improve model convergence speed.", "target": "The authors propose Epidemic Learning (EL), a DL algorithm with changing communication topologies where each node sends its model updates to a random sample of s other nodes in a system of n nodes, to improve model convergence speed.", "example": "Convert the coordinate to text: [2.2741 4.6364]:"}
{"text": "Convert the coordinate to text: [11.3066 -2.5116]: The authors propose a spectrally-normalized robust generalization bound for deep neural networks that does not depend on additional assumptions.", "target": "The authors propose a spectrally-normalized robust generalization bound for deep neural networks that does not depend on additional assumptions.", "example": "Convert the coordinate to text: [11.3066 -2.5116]:"}
{"text": "Convert the coordinate to text: [ 0.4867 -8.8317]: The authors propose a novel method leveraging modality-specific autoencoders trained on large-scale unpaired portraits and parametric avatars. An alignment module is then used to map between both modalities.", "target": "The authors propose a novel method leveraging modality-specific autoencoders trained on large-scale unpaired portraits and parametric avatars. An alignment module is then used to map between both modalities.", "example": "Convert the coordinate to text: [ 0.4867 -8.8317]:"}
{"text": "Convert the coordinate to text: [15.0806  0.3928]: This study looks at learning deep discrete representations from the generative viewpoint by endowing distributions over sequences of codewords and developing a deterministic decoder that transports the distribution over the sequences of codewords to the data distribution via minimizing a WS distance between them.", "target": "This study looks at learning deep discrete representations from the generative viewpoint by endowing distributions over sequences of codewords and developing a deterministic decoder that transports the distribution over the sequences of codewords to the data distribution via minimizing a WS distance between them.", "example": "Convert the coordinate to text: [15.0806  0.3928]:"}
{"text": "Convert the coordinate to text: [-3.9789 -1.4773]: The authors argue that the quality of a human-annotated explanation can be measured based on its helpfulness (or impairment) to the ML models' performance for the desired NLP tasks for which the annotations were collected. They propose a new metric that takes into consideration the helpfulness of an explanation for model performance at both fine-tuning and inference stages.", "target": "The authors argue that the quality of a human-annotated explanation can be measured based on its helpfulness (or impairment) to the ML models' performance for the desired NLP tasks for which the annotations were collected. They propose a new metric that takes into consideration the helpfulness of an explanation for model performance at both fine-tuning and inference stages.", "example": "Convert the coordinate to text: [-3.9789 -1.4773]:"}
{"text": "Convert the coordinate to text: [-2.9855 -6.8675]: LLM-RM proposes an approach leveraging cross-lingual representation by fine-tuning the XLM-RoBERTa base model on datasets of 12 different languages.", "target": "LLM-RM proposes an approach leveraging cross-lingual representation by fine-tuning the XLM-RoBERTa base model on datasets of 12 different languages.", "example": "Convert the coordinate to text: [-2.9855 -6.8675]:"}
{"text": "Convert the coordinate to text: [13.0086 -6.5749]: The authors propose a novel training method for generative models, like Generative Adversarial Networks and Normalizing Flows, which explicitly optimizes a user-defined trade-off between precision and recall. They introduce the concept of PR-divergences.", "target": "The authors propose a novel training method for generative models, like Generative Adversarial Networks and Normalizing Flows, which explicitly optimizes a user-defined trade-off between precision and recall. They introduce the concept of PR-divergences.", "example": "Convert the coordinate to text: [13.0086 -6.5749]:"}
{"text": "Convert the coordinate to text: [-6.7542 -6.8413]: The authors propose an extension of the Cross-lingual Natural Language Inference (XNLI) corpus to include Croatian, with the train set translated using Facebook's 1.2B parameter m2m_100 model.", "target": "The authors propose an extension of the Cross-lingual Natural Language Inference (XNLI) corpus to include Croatian, with the train set translated using Facebook's 1.2B parameter m2m_100 model.", "example": "Convert the coordinate to text: [-6.7542 -6.8413]:"}
{"text": "Convert the coordinate to text: [-5.9732 -7.1627]: The study introduces PMI-Align, a new approach for word alignment that computes the point-wise mutual information between source and target tokens instead of relying on cosine similarity or dot product.", "target": "The study introduces PMI-Align, a new approach for word alignment that computes the point-wise mutual information between source and target tokens instead of relying on cosine similarity or dot product.", "example": "Convert the coordinate to text: [-5.9732 -7.1627]:"}
{"text": "Convert the coordinate to text: [-4.5348  0.8651]: This paper investigates the potential of sentiment arcs coupled with topical-semantic profiling of literary narratives as indicators of their literary quality.", "target": "This paper investigates the potential of sentiment arcs coupled with topical-semantic profiling of literary narratives as indicators of their literary quality.", "example": "Convert the coordinate to text: [-4.5348  0.8651]:"}
{"text": "Convert the coordinate to text: [-3.5934 -9.3838]: The main solution presented is a cascaded incremental decoding system, comprising an Automatic Speech Recognition (ASR) model, a Machine Translation (MT) model, and a Text to Speech (TTS) model. The authors use the strategies from the Speech-to-Text track to generate more confident target text for each audio segment input.", "target": "The main solution presented is a cascaded incremental decoding system, comprising an Automatic Speech Recognition (ASR) model, a Machine Translation (MT) model, and a Text to Speech (TTS) model. The authors use the strategies from the Speech-to-Text track to generate more confident target text for each audio segment input.", "example": "Convert the coordinate to text: [-3.5934 -9.3838]:"}
{"text": "Convert the coordinate to text: [ 1.2269 -4.4423]: The authors propose a contrastive learning-based self-supervised approach (SSCon) for classroom dialogue act recognition that leverages limited labeled data. The approach uses two independent models that iteratively improve one another's performance by increasing dialogue act recognition accuracy and reducing the embedding distance between similar dialogue acts.", "target": "The authors propose a contrastive learning-based self-supervised approach (SSCon) for classroom dialogue act recognition that leverages limited labeled data. The approach uses two independent models that iteratively improve one another's performance by increasing dialogue act recognition accuracy and reducing the embedding distance between similar dialogue acts.", "example": "Convert the coordinate to text: [ 1.2269 -4.4423]:"}
{"text": "Convert the coordinate to text: [-10.4642  -1.9629]: The authors introduce FORK, a small, manually-curated set of CommonsenseQA-style questions designed to probe the cultural biases and assumptions, specifically regarding food-related customs, present in commonsense reasoning systems.", "target": "The authors introduce FORK, a small, manually-curated set of CommonsenseQA-style questions designed to probe the cultural biases and assumptions, specifically regarding food-related customs, present in commonsense reasoning systems.", "example": "Convert the coordinate to text: [-10.4642  -1.9629]:"}
{"text": "Convert the coordinate to text: [-6.1946 -6.293 ]: The authors attempt to replicate the earlier study's findings on a new and more interrelated corpus with a larger set of native languages.", "target": "The authors attempt to replicate the earlier study's findings on a new and more interrelated corpus with a larger set of native languages.", "example": "Convert the coordinate to text: [-6.1946 -6.293 ]:"}
{"text": "Convert the coordinate to text: [-1.3439 -3.1276]: In this paper, an approach is proposed to build Dense-ATOMIC, a variant of ATOMIC, which aims to achieve higher knowledge coverage and multiple multi-hop paths. To establish Dense-ATOMIC, events in ATOMIC are first normalized, and then a commonsense knowledge graph completion method, called Rel-CSKGC, is introduced.", "target": "In this paper, an approach is proposed to build Dense-ATOMIC, a variant of ATOMIC, which aims to achieve higher knowledge coverage and multiple multi-hop paths. To establish Dense-ATOMIC, events in ATOMIC are first normalized, and then a commonsense knowledge graph completion method, called Rel-CSKGC, is introduced.", "example": "Convert the coordinate to text: [-1.3439 -3.1276]:"}
{"text": "Convert the coordinate to text: [ 1.389  -9.4915]: The authors introduce the task of Stylized Visual Storytelling (SVST), aiming to create stylized narratives, and propose a multitasking memory-augmented framework called StyleVSG that is trained on factual visual storytelling data and an unpaired style corpus.", "target": "The authors introduce the task of Stylized Visual Storytelling (SVST), aiming to create stylized narratives, and propose a multitasking memory-augmented framework called StyleVSG that is trained on factual visual storytelling data and an unpaired style corpus.", "example": "Convert the coordinate to text: [ 1.389  -9.4915]:"}
{"text": "Convert the coordinate to text: [-4.0232 -4.5387]: To address this issue, a novel statistical model is proposed. It decomposes document embeddings into a linear superposition of two vectors; a latent neutral context vector that is independent of ideology, and a latent position vector that aligns with the ideology.", "target": "To address this issue, a novel statistical model is proposed. It decomposes document embeddings into a linear superposition of two vectors; a latent neutral context vector that is independent of ideology, and a latent position vector that aligns with the ideology.", "example": "Convert the coordinate to text: [-4.0232 -4.5387]:"}
{"text": "Convert the coordinate to text: [ 5.4638 13.5077]: The authors propose a method using unsupervised model-based RL for pre-training the agent, and a task-aware fine-tuning strategy along with a new proposed hybrid planner, Dyna-MPC, for adapting the agent for downstream tasks.", "target": "The authors propose a method using unsupervised model-based RL for pre-training the agent, and a task-aware fine-tuning strategy along with a new proposed hybrid planner, Dyna-MPC, for adapting the agent for downstream tasks.", "example": "Convert the coordinate to text: [ 5.4638 13.5077]:"}
{"text": "Convert the coordinate to text: [ 13.9453 -13.3981]: The authors propose FineDance, a large music-dance paired dataset covering 14.6 hours of material, fine-grained hand motions, 22 dance genres, and accurate posture, and FineNet, a full-body dance generation network which incorporates the diverse generation capabilities of diffusion models and expert nets.", "target": "The authors propose FineDance, a large music-dance paired dataset covering 14.6 hours of material, fine-grained hand motions, 22 dance genres, and accurate posture, and FineNet, a full-body dance generation network which incorporates the diverse generation capabilities of diffusion models and expert nets.", "example": "Convert the coordinate to text: [ 13.9453 -13.3981]:"}
{"text": "Convert the coordinate to text: [-6.369  -8.6473]: This paper presents a new methodology for extracting linguistic features, specifically syllabifying words in multiple languages including English, French, and Spanish with compatibility to MFA. The method also extracts features such as phonetic transcriptions from text, stress marks, and performs unified automatic syllabification in text and phonetic domains.", "target": "This paper presents a new methodology for extracting linguistic features, specifically syllabifying words in multiple languages including English, French, and Spanish with compatibility to MFA. The method also extracts features such as phonetic transcriptions from text, stress marks, and performs unified automatic syllabification in text and phonetic domains.", "example": "Convert the coordinate to text: [-6.369  -8.6473]:"}
{"text": "Convert the coordinate to text: [  9.2674 -20.7557]: The authors introduce MACO, a method that optimizes an image's phase spectrum while keeping its magnitude constant to generate explanations that lie within the space of natural images.", "target": "The authors introduce MACO, a method that optimizes an image's phase spectrum while keeping its magnitude constant to generate explanations that lie within the space of natural images.", "example": "Convert the coordinate to text: [  9.2674 -20.7557]:"}
{"text": "Convert the coordinate to text: [8.9062 3.7451]: The authors develop an identifiability theory that accommodates Gaussian sources by relying on second-order statistics, without imposing further preconditions on the distribution of sources, and introduce new assumptions on the connective structure from sources to observed variables.", "target": "The authors develop an identifiability theory that accommodates Gaussian sources by relying on second-order statistics, without imposing further preconditions on the distribution of sources, and introduce new assumptions on the connective structure from sources to observed variables.", "example": "Convert the coordinate to text: [8.9062 3.7451]:"}
{"text": "Convert the coordinate to text: [ 5.3639 13.8334]: This study derives a lower bound on the sample complexity for a class of goal-conditioned Hierarchical Reinforcement Learning (HRL) algorithms, allowing quantification of hierarchical decomposition's benefits and leading to the design of a simple Q-learning-type algorithm leveraging hierarchical decompositions.", "target": "This study derives a lower bound on the sample complexity for a class of goal-conditioned Hierarchical Reinforcement Learning (HRL) algorithms, allowing quantification of hierarchical decomposition's benefits and leading to the design of a simple Q-learning-type algorithm leveraging hierarchical decompositions.", "example": "Convert the coordinate to text: [ 5.3639 13.8334]:"}
{"text": "Convert the coordinate to text: [ 0.91   -9.0671]: The authors introduce EVA, a vision-centric foundation model trained to reconstruct the masked-out image-text aligned vision features conditioned on visible image patches. EVA represents a new direction for scaling up and accelerating the costly training of multi-modal foundation models.", "target": "The authors introduce EVA, a vision-centric foundation model trained to reconstruct the masked-out image-text aligned vision features conditioned on visible image patches. EVA represents a new direction for scaling up and accelerating the costly training of multi-modal foundation models.", "example": "Convert the coordinate to text: [ 0.91   -9.0671]:"}
{"text": "Convert the coordinate to text: [ 6.8676 -1.2897]: The authors approach this issue from the perspective of Mutual Information (MI) optimization, theoretically proving that MI involving negatives also matters in cases where noises commonly exist. They propose a contrastive learning strategy, regulated by progressively refined cross-modal similarity, to more accurately optimize MI.", "target": "The authors approach this issue from the perspective of Mutual Information (MI) optimization, theoretically proving that MI involving negatives also matters in cases where noises commonly exist. They propose a contrastive learning strategy, regulated by progressively refined cross-modal similarity, to more accurately optimize MI.", "example": "Convert the coordinate to text: [ 6.8676 -1.2897]:"}
{"text": "Convert the coordinate to text: [7.5827 4.8757]: The authors propose an Expectation-Maximization (EM) approach, which iteratively generates addressee labels and optimizes a response generation model to address the problem of lack of annotated addressee labels in multi-party dialogue datasets.", "target": "The authors propose an Expectation-Maximization (EM) approach, which iteratively generates addressee labels and optimizes a response generation model to address the problem of lack of annotated addressee labels in multi-party dialogue datasets.", "example": "Convert the coordinate to text: [7.5827 4.8757]:"}
{"text": "Convert the coordinate to text: [-7.5055  3.4193]: The authors propose to learn from collaborative editing behaviors in online debates, to capture implicit revision patterns and develop approaches to guide writers in improving their arguments. They also propose a new sampling strategy based on revision distance that can be done without additional annotations and judgments.", "target": "The authors propose to learn from collaborative editing behaviors in online debates, to capture implicit revision patterns and develop approaches to guide writers in improving their arguments. They also propose a new sampling strategy based on revision distance that can be done without additional annotations and judgments.", "example": "Convert the coordinate to text: [-7.5055  3.4193]:"}
{"text": "Convert the coordinate to text: [10.1041 -3.9433]: The authors propose a new dynamic sparse training method, Channel-aware dynamic sparse (Chase), which for the first time translates the promise of unstructured dynamic sparsity to GPU-friendly channel-level sparsity during one end-to-end training process, without requiring any specialized operations.", "target": "The authors propose a new dynamic sparse training method, Channel-aware dynamic sparse (Chase), which for the first time translates the promise of unstructured dynamic sparsity to GPU-friendly channel-level sparsity during one end-to-end training process, without requiring any specialized operations.", "example": "Convert the coordinate to text: [10.1041 -3.9433]:"}
{"text": "Convert the coordinate to text: [-2.0429 -4.8117]: The authors propose MetaRetriever, a system to retrieve task-specific knowledge from pretrained language models (PLMs) to improve universal Information Extraction (IE). Different IE tasks require different knowledge, so they propose Meta-Pretraining Algorithm to optimize MetaRetriever's task-specific retrieval performance in downstream IE tasks.", "target": "The authors propose MetaRetriever, a system to retrieve task-specific knowledge from pretrained language models (PLMs) to improve universal Information Extraction (IE). Different IE tasks require different knowledge, so they propose Meta-Pretraining Algorithm to optimize MetaRetriever's task-specific retrieval performance in downstream IE tasks.", "example": "Convert the coordinate to text: [-2.0429 -4.8117]:"}
{"text": "Convert the coordinate to text: [-7.3447 -8.1805]: The paper presents two methods that give morphological models access to subcharacter phonological features that are the targets of morphological processes: one that manipulates the data to include features instead of characters, and another that manipulates models to consider phonological features when building representations for phonemes.", "target": "The paper presents two methods that give morphological models access to subcharacter phonological features that are the targets of morphological processes: one that manipulates the data to include features instead of characters, and another that manipulates models to consider phonological features when building representations for phonemes.", "example": "Convert the coordinate to text: [-7.3447 -8.1805]:"}
{"text": "Convert the coordinate to text: [-7.3208 -4.8405]: The authors introduce a taxonomy that clarifies the connection between several problems in lexical semantics, including both monolingual and cross-lingual variants, based on the hypothesis of the equivalence of concept and meaning distinctions.", "target": "The authors introduce a taxonomy that clarifies the connection between several problems in lexical semantics, including both monolingual and cross-lingual variants, based on the hypothesis of the equivalence of concept and meaning distinctions.", "example": "Convert the coordinate to text: [-7.3208 -4.8405]:"}
{"text": "Convert the coordinate to text: [-9.0562 -4.8847]: The authors propose the Span-trigger-based Contextual Pooling and latent Role Guidance (SCPRG) model, which includes new modules that account for non-argument contextual clue information (through the Span-Trigger-based Contextual Pooling - STCP) and the relevance among argument roles (through Role-based Latent Information Guidance - RLIG).", "target": "The authors propose the Span-trigger-based Contextual Pooling and latent Role Guidance (SCPRG) model, which includes new modules that account for non-argument contextual clue information (through the Span-Trigger-based Contextual Pooling - STCP) and the relevance among argument roles (through Role-based Latent Information Guidance - RLIG).", "example": "Convert the coordinate to text: [-9.0562 -4.8847]:"}
{"text": "Convert the coordinate to text: [-3.7714 -3.1434]: The authors introduce TAGPRIME, a unified framework for relational structure extraction tasks. It is a sequence tagging model that appends priming words about the given condition to the input text, improving contextualized representations through the use of a self-attention mechanism in pre-trained language models.", "target": "The authors introduce TAGPRIME, a unified framework for relational structure extraction tasks. It is a sequence tagging model that appends priming words about the given condition to the input text, improving contextualized representations through the use of a self-attention mechanism in pre-trained language models.", "example": "Convert the coordinate to text: [-3.7714 -3.1434]:"}
{"text": "Convert the coordinate to text: [-6.032   4.3661]: Rather than treating SVHR as a classification or ranking problem, this study reformulates it as a generation task to better reflect the natural process of hashtag creation, and introduces the Guided Generative Model (GGM) which uses retrieved relevant hashtags from a large-scale hashtag pool as extra guidance signals.", "target": "Rather than treating SVHR as a classification or ranking problem, this study reformulates it as a generation task to better reflect the natural process of hashtag creation, and introduces the Guided Generative Model (GGM) which uses retrieved relevant hashtags from a large-scale hashtag pool as extra guidance signals.", "example": "Convert the coordinate to text: [-6.032   4.3661]:"}
{"text": "Convert the coordinate to text: [ 7.0457 -3.7188]: The authors propose a Distribution Free Domain Generalization (DFDG) procedure for classification that reformulates the cross domain/class discrepancy by conducting a pairwise two-sample test, which weight their importance or the covariance structures equally to avoid domain/class dominance.", "target": "The authors propose a Distribution Free Domain Generalization (DFDG) procedure for classification that reformulates the cross domain/class discrepancy by conducting a pairwise two-sample test, which weight their importance or the covariance structures equally to avoid domain/class dominance.", "example": "Convert the coordinate to text: [ 7.0457 -3.7188]:"}
{"text": "Convert the coordinate to text: [  9.4652 -14.5386]: The authors present TrackFlow, an approach that extends tracking-by-detection to multi-modal settings by leveraging a deep density estimator to model the conditional joint probability distribution of correct associations, considering the cost of a candidate association as its negative log-likelihood.", "target": "The authors present TrackFlow, an approach that extends tracking-by-detection to multi-modal settings by leveraging a deep density estimator to model the conditional joint probability distribution of correct associations, considering the cost of a candidate association as its negative log-likelihood.", "example": "Convert the coordinate to text: [  9.4652 -14.5386]:"}
{"text": "Convert the coordinate to text: [ 3.5543 -6.8692]: The authors propose the Dynamic Hyperbolic Attention Network (DHANet), the first precise method for hand-object reconstruction in hyperbolic space. Unlike the Euclidean space, hyperbolic space better preserves the geometric properties of meshes, thus allowing the method to learn representative features using intrinsic properties of hyperbolic space.", "target": "The authors propose the Dynamic Hyperbolic Attention Network (DHANet), the first precise method for hand-object reconstruction in hyperbolic space. Unlike the Euclidean space, hyperbolic space better preserves the geometric properties of meshes, thus allowing the method to learn representative features using intrinsic properties of hyperbolic space.", "example": "Convert the coordinate to text: [ 3.5543 -6.8692]:"}
{"text": "Convert the coordinate to text: [ 4.1882 -4.4292]: The authors propose DFKD-FGVC, a novel approach that extends DFKD to fine-grained visual categorization (FGVC) tasks. This involves an adversarial distillation framework, attention generator, mixed high-order attention distillation, and semantic feature contrast learning.", "target": "The authors propose DFKD-FGVC, a novel approach that extends DFKD to fine-grained visual categorization (FGVC) tasks. This involves an adversarial distillation framework, attention generator, mixed high-order attention distillation, and semantic feature contrast learning.", "example": "Convert the coordinate to text: [ 4.1882 -4.4292]:"}
{"text": "Convert the coordinate to text: [ 0.1723 -7.46  ]: This paper introduces a new model, the Continuously Masked Transformer (CMT), which uses a continuous mask to represent the amounts of errors in tokens and facilitates self-attention with overlapping tokens.", "target": "This paper introduces a new model, the Continuously Masked Transformer (CMT), which uses a continuous mask to represent the amounts of errors in tokens and facilitates self-attention with overlapping tokens.", "example": "Convert the coordinate to text: [ 0.1723 -7.46  ]:"}
{"text": "Convert the coordinate to text: [4.2126 6.0866]: This paper introduces the Best Order Score Search (BOSS) and Grow-Shrink Trees (GSTs) as a novel method for learning directed acyclic graphs (DAGs) in machine learning and causal discovery.", "target": "This paper introduces the Best Order Score Search (BOSS) and Grow-Shrink Trees (GSTs) as a novel method for learning directed acyclic graphs (DAGs) in machine learning and causal discovery.", "example": "Convert the coordinate to text: [4.2126 6.0866]:"}
{"text": "Convert the coordinate to text: [-2.8653 -6.0047]: The authors introduce a pretrained small scorer, Cappy, designed to enhance the efficiency and performance of multi-task LLMs. It can work either independently or serve as an auxiliary for LLMs, and it does not require finetuning or access to the LLM parameters.", "target": "The authors introduce a pretrained small scorer, Cappy, designed to enhance the efficiency and performance of multi-task LLMs. It can work either independently or serve as an auxiliary for LLMs, and it does not require finetuning or access to the LLM parameters.", "example": "Convert the coordinate to text: [-2.8653 -6.0047]:"}
{"text": "Convert the coordinate to text: [-12.2515   5.4638]: JarviX is introduced as a data analytics framework. It employs large language models to automatically guide and execute data analytics on tabular datasets, emphasizing the significance of varying column types, providing concise data insight summaries, proposing relevant analysis inquiries, visualizing data effectively, and explaining results. It also integrates an AutoML pipeline for predictive modeling.", "target": "JarviX is introduced as a data analytics framework. It employs large language models to automatically guide and execute data analytics on tabular datasets, emphasizing the significance of varying column types, providing concise data insight summaries, proposing relevant analysis inquiries, visualizing data effectively, and explaining results. It also integrates an AutoML pipeline for predictive modeling.", "example": "Convert the coordinate to text: [-12.2515   5.4638]:"}
{"text": "Convert the coordinate to text: [2.7777 5.0844]: This paper argues that for node distinguishability, it is ideal to have smaller intra-class ND than inter-class ND. To study ND deeply and formulate this idea, the authors propose a Contextual Stochastic Block Model for Homophily (CSBM-H) and define two metrics, the Probabilistic Bayes Error (PBE) and negative generalized Jeffreys divergence.", "target": "This paper argues that for node distinguishability, it is ideal to have smaller intra-class ND than inter-class ND. To study ND deeply and formulate this idea, the authors propose a Contextual Stochastic Block Model for Homophily (CSBM-H) and define two metrics, the Probabilistic Bayes Error (PBE) and negative generalized Jeffreys divergence.", "example": "Convert the coordinate to text: [2.7777 5.0844]:"}
{"text": "Convert the coordinate to text: [-2.4014 -3.2711]: In this study, the authors propose a new framework known as RE-KBQA, which uses relations in the knowledge base to not only enhance entity representation but also to introduce additional supervision.", "target": "In this study, the authors propose a new framework known as RE-KBQA, which uses relations in the knowledge base to not only enhance entity representation but also to introduce additional supervision.", "example": "Convert the coordinate to text: [-2.4014 -3.2711]:"}
{"text": "Convert the coordinate to text: [-0.9888 -4.3125]: A Unified Demonstration Retriever (UDR) is proposed, which is a single model designed to retrieve demonstrations for a wide range of tasks. To train UDR, a unified list-wise ranking formulation is used, incorporating feedback from a language model across multiple tasks.", "target": "A Unified Demonstration Retriever (UDR) is proposed, which is a single model designed to retrieve demonstrations for a wide range of tasks. To train UDR, a unified list-wise ranking formulation is used, incorporating feedback from a language model across multiple tasks.", "example": "Convert the coordinate to text: [-0.9888 -4.3125]:"}
{"text": "Convert the coordinate to text: [ 5.9268 13.4589]: The paper proposes using reinforcement learning techniques for topic modeling by replacing the variational autoencoder in ProdLDA with a continuous action space reinforcement learning policy trained with a policy gradient algorithm REINFORCE.", "target": "The paper proposes using reinforcement learning techniques for topic modeling by replacing the variational autoencoder in ProdLDA with a continuous action space reinforcement learning policy trained with a policy gradient algorithm REINFORCE.", "example": "Convert the coordinate to text: [ 5.9268 13.4589]:"}
{"text": "Convert the coordinate to text: [-3.3574 -6.7811]: The authors conduct a detailed analysis of ICL for cross-lingual text classification and find that the random selection of input-label pairs has limitations due to lack of alignment in the input and output spaces. To mitigate this, they propose a new prompt construction strategy -- Cross-lingual In-context Source-Target Alignment (X-InSTA).", "target": "The authors conduct a detailed analysis of ICL for cross-lingual text classification and find that the random selection of input-label pairs has limitations due to lack of alignment in the input and output spaces. To mitigate this, they propose a new prompt construction strategy -- Cross-lingual In-context Source-Target Alignment (X-InSTA).", "example": "Convert the coordinate to text: [-3.3574 -6.7811]:"}
{"text": "Convert the coordinate to text: [ 9.9801 -8.0281]: To address the mentioned problems, a novel approach named FLIGHT-Net is proposed. FLIGHT-Net uses a sequence of neural architecture blocks, first block for scene dependent illumination adjustment and the second block for channel attention and denoising.", "target": "To address the mentioned problems, a novel approach named FLIGHT-Net is proposed. FLIGHT-Net uses a sequence of neural architecture blocks, first block for scene dependent illumination adjustment and the second block for channel attention and denoising.", "example": "Convert the coordinate to text: [ 9.9801 -8.0281]:"}
{"text": "Convert the coordinate to text: [-3.4906 14.9378]: The authors propose using two robots to measure the acoustics of an environment by actively moving and emitting/receiving sweep signals, and introduce a collaborative multi-agent policy where the robots are trained to explore the environment's acoustics while being rewarded for wide exploration and accurate prediction.", "target": "The authors propose using two robots to measure the acoustics of an environment by actively moving and emitting/receiving sweep signals, and introduce a collaborative multi-agent policy where the robots are trained to explore the environment's acoustics while being rewarded for wide exploration and accurate prediction.", "example": "Convert the coordinate to text: [-3.4906 14.9378]:"}
{"text": "Convert the coordinate to text: [3.652  1.2022]: The authors investigate how classifier drift leads to forgetting and propose four novel solutions: Individual Classifiers with Frozen Feature Extractor (ICE) and three variants, ICE-PL, ICE-O, and ICE-PL&O. These solutions aim to mitigate classifier drift by using individual classifiers for each learning session and additional constraints derived from previously learned classes or a constant logit of an 'Other' class.", "target": "The authors investigate how classifier drift leads to forgetting and propose four novel solutions: Individual Classifiers with Frozen Feature Extractor (ICE) and three variants, ICE-PL, ICE-O, and ICE-PL&O. These solutions aim to mitigate classifier drift by using individual classifiers for each learning session and additional constraints derived from previously learned classes or a constant logit of an 'Other' class.", "example": "Convert the coordinate to text: [3.652  1.2022]:"}
{"text": "Convert the coordinate to text: [9.266  5.5942]: The authors provide the first example of a natural exponential family of distributions where the score matching loss is computationally efficient to optimize and offers similar statistical efficiency to ML, when the ML loss is intractable to optimize using a gradient-based method.", "target": "The authors provide the first example of a natural exponential family of distributions where the score matching loss is computationally efficient to optimize and offers similar statistical efficiency to ML, when the ML loss is intractable to optimize using a gradient-based method.", "example": "Convert the coordinate to text: [9.266  5.5942]:"}
{"text": "Convert the coordinate to text: [-10.0052  -0.924 ]: The authors propose an intent-aware FAQ retrieval system consisting of an intent classifier that predicts when a user's information need can be answered by an FAQ and a reformulation model that rewrites a query into a natural question.", "target": "The authors propose an intent-aware FAQ retrieval system consisting of an intent classifier that predicts when a user's information need can be answered by an FAQ and a reformulation model that rewrites a query into a natural question.", "example": "Convert the coordinate to text: [-10.0052  -0.924 ]:"}
{"text": "Convert the coordinate to text: [-2.0378 -7.8972]: The paper proposes an adversarially-trained sequence-tagging model for DC, which utilizes a small amount of labeled real disfluent data along with a large amount of unlabeled data, banking on synthetically generated disfluent data.", "target": "The paper proposes an adversarially-trained sequence-tagging model for DC, which utilizes a small amount of labeled real disfluent data along with a large amount of unlabeled data, banking on synthetically generated disfluent data.", "example": "Convert the coordinate to text: [-2.0378 -7.8972]:"}
{"text": "Convert the coordinate to text: [-0.9833 -3.5175]: The authors propose a new model called History Semantic Graph Enhanced KBQA model (HSGE) which can effectively model long-range semantic dependencies in a conversation history while maintaining a low computational cost. This is achieved by incorporating a context-aware encoder which uses a dynamic memory decay mechanism and models context at various levels of detail.", "target": "The authors propose a new model called History Semantic Graph Enhanced KBQA model (HSGE) which can effectively model long-range semantic dependencies in a conversation history while maintaining a low computational cost. This is achieved by incorporating a context-aware encoder which uses a dynamic memory decay mechanism and models context at various levels of detail.", "example": "Convert the coordinate to text: [-0.9833 -3.5175]:"}
{"text": "Convert the coordinate to text: [-3.9191 -5.0359]: Introducing novel training objectives that utilize semantic similarity of the predicted tokens to reference can help address these issues, as this strategy avoids the common assumption of there being a single correct prediction, thereby fighting against the catastrophic forgetting seen in adaptation.", "target": "Introducing novel training objectives that utilize semantic similarity of the predicted tokens to reference can help address these issues, as this strategy avoids the common assumption of there being a single correct prediction, thereby fighting against the catastrophic forgetting seen in adaptation.", "example": "Convert the coordinate to text: [-3.9191 -5.0359]:"}
{"text": "Convert the coordinate to text: [-1.1109 -3.5695]: The authors propose a novel multilingual KGC framework with language-sensitive multi-graph attention, which allows for the inference of missing links on all given KGs through a universal knowledge completion model.", "target": "The authors propose a novel multilingual KGC framework with language-sensitive multi-graph attention, which allows for the inference of missing links on all given KGs through a universal knowledge completion model.", "example": "Convert the coordinate to text: [-1.1109 -3.5695]:"}
{"text": "Convert the coordinate to text: [ 0.7215 -3.2911]: The paper explores and extends the Label Confusion Model for learning a representation for discourse relation labels, proposing alternative ways of informing the model about the similarities between relations, by representing relations in terms of their names, their typical markers, or in terms of CCR features that describe the relations.", "target": "The paper explores and extends the Label Confusion Model for learning a representation for discourse relation labels, proposing alternative ways of informing the model about the similarities between relations, by representing relations in terms of their names, their typical markers, or in terms of CCR features that describe the relations.", "example": "Convert the coordinate to text: [ 0.7215 -3.2911]:"}
{"text": "Convert the coordinate to text: [  1.0357 -10.1578]: The authors propose a solution for vWSD by deriving quasi-symbolic semantic categories from the hidden representations of multi-modal text-image encoders.", "target": "The authors propose a solution for vWSD by deriving quasi-symbolic semantic categories from the hidden representations of multi-modal text-image encoders.", "example": "Convert the coordinate to text: [  1.0357 -10.1578]:"}
{"text": "Convert the coordinate to text: [-1.4553  0.1187]: This paper aims to create more nuanced models for the detection and classification of online sexism through fine-grained categorizations, experimenting with language model finetuning, class-specific adapters, and pseudo-labelling.", "target": "This paper aims to create more nuanced models for the detection and classification of online sexism through fine-grained categorizations, experimenting with language model finetuning, class-specific adapters, and pseudo-labelling.", "example": "Convert the coordinate to text: [-1.4553  0.1187]:"}
{"text": "Convert the coordinate to text: [-3.4193 -9.3836]: To improve the performance of the cascaded models, Whisper is introduced to reduce intermediate source language errors. For end-to-end models, a Stacked Acoustic-and-Textual Encoding extension (SATE-ex) is proposed that feeds the output of the acoustic decoder into the textual decoder to fuse information and prevent error propagation.", "target": "To improve the performance of the cascaded models, Whisper is introduced to reduce intermediate source language errors. For end-to-end models, a Stacked Acoustic-and-Textual Encoding extension (SATE-ex) is proposed that feeds the output of the acoustic decoder into the textual decoder to fuse information and prevent error propagation.", "example": "Convert the coordinate to text: [-3.4193 -9.3836]:"}
{"text": "Convert the coordinate to text: [-10.4099   1.901 ]: The authors propose an automatic pipeline for building an educational resource discovery system for new domains, involving three main steps: resource searching, feature extraction, and resource classification.", "target": "The authors propose an automatic pipeline for building an educational resource discovery system for new domains, involving three main steps: resource searching, feature extraction, and resource classification.", "example": "Convert the coordinate to text: [-10.4099   1.901 ]:"}
{"text": "Convert the coordinate to text: [-1.6526 -6.366 ]: The authors approach cloze distractor generation as a Text2Text task, introduce pseudo Kullback-Leibler Divergence for regulating the generation and consider the item discrimination index in education evaluation. Additionally, they propose a candidate augmentation strategy and multi-tasking training with cloze-related tasks.", "target": "The authors approach cloze distractor generation as a Text2Text task, introduce pseudo Kullback-Leibler Divergence for regulating the generation and consider the item discrimination index in education evaluation. Additionally, they propose a candidate augmentation strategy and multi-tasking training with cloze-related tasks.", "example": "Convert the coordinate to text: [-1.6526 -6.366 ]:"}
{"text": "Convert the coordinate to text: [ 5.1985 -3.222 ]: The authors propose CoAug, a co-augmentation framework that improves upon few-shot models and rule-augmentation models by bootstrapping predictions from each model and leveraging rules and neural model predictions.", "target": "The authors propose CoAug, a co-augmentation framework that improves upon few-shot models and rule-augmentation models by bootstrapping predictions from each model and leveraging rules and neural model predictions.", "example": "Convert the coordinate to text: [ 5.1985 -3.222 ]:"}
{"text": "Convert the coordinate to text: [-5.3209 -0.3928]: The authors propose NonFactS, a data generation model, to synthesize nonfactual summaries given a context document and a human-annotated factual summary, which are more abstractive and more similar to their corresponding factual samples.", "target": "The authors propose NonFactS, a data generation model, to synthesize nonfactual summaries given a context document and a human-annotated factual summary, which are more abstractive and more similar to their corresponding factual samples.", "example": "Convert the coordinate to text: [-5.3209 -0.3928]:"}
{"text": "Convert the coordinate to text: [-1.8574 -3.598 ]: The authors put forward a new approach to learn a more semantically structured entity representation space in text-based KGC by applying a sequence-to-sequence architecture to generate high-quality hard negatives that are semantically close to the correct entity.", "target": "The authors put forward a new approach to learn a more semantically structured entity representation space in text-based KGC by applying a sequence-to-sequence architecture to generate high-quality hard negatives that are semantically close to the correct entity.", "example": "Convert the coordinate to text: [-1.8574 -3.598 ]:"}
{"text": "Convert the coordinate to text: [-9.0673 -7.2196]: The authors propose a new model for inducing a basic categorial grammar. In contrast to earlier categorial grammar induction systems, this model learns from raw data without any part-of-speech information.", "target": "The authors propose a new model for inducing a basic categorial grammar. In contrast to earlier categorial grammar induction systems, this model learns from raw data without any part-of-speech information.", "example": "Convert the coordinate to text: [-9.0673 -7.2196]:"}
{"text": "Convert the coordinate to text: [-4.1075 -1.3212]: The paper introduces a proxy task to identify the distinct sets of aligned story actors responsible for sustaining issue-specific narratives. By discovering aligned actors and the groups they form, we can estimate the narrative each group represents. This is accomplished by introducing a novel two-step graph-based framework that identifies alignment between actors (INCANT) and extracts aligned actor groups using the network structure (TAMPA).", "target": "The paper introduces a proxy task to identify the distinct sets of aligned story actors responsible for sustaining issue-specific narratives. By discovering aligned actors and the groups they form, we can estimate the narrative each group represents. This is accomplished by introducing a novel two-step graph-based framework that identifies alignment between actors (INCANT) and extracts aligned actor groups using the network structure (TAMPA).", "example": "Convert the coordinate to text: [-4.1075 -1.3212]:"}
{"text": "Convert the coordinate to text: [-8.3794 -3.8388]: The authors introduce a new evaluative framework, Symbolism Analysis (SymbA), to assess the ability of LMs to recognize and interpret symbolic meaning in text.", "target": "The authors introduce a new evaluative framework, Symbolism Analysis (SymbA), to assess the ability of LMs to recognize and interpret symbolic meaning in text.", "example": "Convert the coordinate to text: [-8.3794 -3.8388]:"}
{"text": "Convert the coordinate to text: [ 3.8577 -0.9629]: The authors propose a robust PU learning method where a unique 'hardness' measure is used to determine unlabeled samples that are likely to be negative and samples with significant label noise.", "target": "The authors propose a robust PU learning method where a unique 'hardness' measure is used to determine unlabeled samples that are likely to be negative and samples with significant label noise.", "example": "Convert the coordinate to text: [ 3.8577 -0.9629]:"}
{"text": "Convert the coordinate to text: [2.3179 1.6514]: The paper proposes a new framework for probabilistic anomaly attribution enabling the computation of attribution scores along with quantifying the uncertainty in those scores. Instead of explaining the black-box model itself, this approach aims to explain the anomalous deviation from a black-box prediction.", "target": "The paper proposes a new framework for probabilistic anomaly attribution enabling the computation of attribution scores along with quantifying the uncertainty in those scores. Instead of explaining the black-box model itself, this approach aims to explain the anomalous deviation from a black-box prediction.", "example": "Convert the coordinate to text: [2.3179 1.6514]:"}
{"text": "Convert the coordinate to text: [  6.2228 -11.675 ]: The authors propose a continually semantic segmentation (CSS) learning framework to learn a single deep segmentation model for segmenting a total of 143 whole-body organs. The approach continually trains an encoder and incrementally adds decoders, thereby avoiding catastrophic forgetting in CSS.", "target": "The authors propose a continually semantic segmentation (CSS) learning framework to learn a single deep segmentation model for segmenting a total of 143 whole-body organs. The approach continually trains an encoder and incrementally adds decoders, thereby avoiding catastrophic forgetting in CSS.", "example": "Convert the coordinate to text: [  6.2228 -11.675 ]:"}
{"text": "Convert the coordinate to text: [13.5064 -2.4961]: The paper introduces the Stabilized Spiking Flow (SSF), a method designed to speed up the training of SG-based SNNs. The key idea is to average the neuron's input and output activations over time and then propagate the auxiliary gradient from the stabilized output to the input via a devised relationship mapping.", "target": "The paper introduces the Stabilized Spiking Flow (SSF), a method designed to speed up the training of SG-based SNNs. The key idea is to average the neuron's input and output activations over time and then propagate the auxiliary gradient from the stabilized output to the input via a devised relationship mapping.", "example": "Convert the coordinate to text: [13.5064 -2.4961]:"}
{"text": "Convert the coordinate to text: [10.8409 -2.6434]: The authors propose Dual Bank Normalization (DBNorm), a framework that leverages two banks constructed from the query and gallery samples in an attempt to reduce the occurrence of hubs during inference. Further, they introduce dual inverted softmax and dual dynamic inverted softmax methods for normalizing similarity based on the two banks.", "target": "The authors propose Dual Bank Normalization (DBNorm), a framework that leverages two banks constructed from the query and gallery samples in an attempt to reduce the occurrence of hubs during inference. Further, they introduce dual inverted softmax and dual dynamic inverted softmax methods for normalizing similarity based on the two banks.", "example": "Convert the coordinate to text: [10.8409 -2.6434]:"}
{"text": "Convert the coordinate to text: [8.9986 3.9784]: This paper introduces conditions for identifying the generator of linear SDEs with additive noise and multiplicative noise, facilitating causal inference.", "target": "This paper introduces conditions for identifying the generator of linear SDEs with additive noise and multiplicative noise, facilitating causal inference.", "example": "Convert the coordinate to text: [8.9986 3.9784]:"}
{"text": "Convert the coordinate to text: [-6.3058 -5.1771]: The authors aim to study uncertainty estimation (UE) in the context of word sense disambiguation (WSD) by comparing different uncertainty scores for a state-of-the-art WSD model and exploring the effect of lexical properties on data uncertainty.", "target": "The authors aim to study uncertainty estimation (UE) in the context of word sense disambiguation (WSD) by comparing different uncertainty scores for a state-of-the-art WSD model and exploring the effect of lexical properties on data uncertainty.", "example": "Convert the coordinate to text: [-6.3058 -5.1771]:"}
{"text": "Convert the coordinate to text: [-1.9684 -4.9081]: An efficient LLM inference pipeline is presented in this paper, wherein LLMs are leveraged to accurately perceive and predict the response length with minimal overhead. An efficient sequence scheduling technique is introduced which groups queries with similar response lengths into micro-batches.", "target": "An efficient LLM inference pipeline is presented in this paper, wherein LLMs are leveraged to accurately perceive and predict the response length with minimal overhead. An efficient sequence scheduling technique is introduced which groups queries with similar response lengths into micro-batches.", "example": "Convert the coordinate to text: [-1.9684 -4.9081]:"}
{"text": "Convert the coordinate to text: [-1.428  -4.5938]: The authors propose TAGREAL, which automatically generates quality query prompts and retrieves support information from large text corpora to probe knowledge from PLM for KG completion.", "target": "The authors propose TAGREAL, which automatically generates quality query prompts and retrieves support information from large text corpora to probe knowledge from PLM for KG completion.", "example": "Convert the coordinate to text: [-1.428  -4.5938]:"}
{"text": "Convert the coordinate to text: [-4.9466  3.7701]: Journey Ranker, a new multi-task deep learning model architecture, is introduced in this paper. The model uses intermediate guest actions as milestones to direct guests towards successful bookings and balances guest and host preferences using guest states and search queries.", "target": "Journey Ranker, a new multi-task deep learning model architecture, is introduced in this paper. The model uses intermediate guest actions as milestones to direct guests towards successful bookings and balances guest and host preferences using guest states and search queries.", "example": "Convert the coordinate to text: [-4.9466  3.7701]:"}
{"text": "Convert the coordinate to text: [-5.2314  4.4538]: The paper introduces Pinterest's ranking architecture for Homefeed and proposes TransAct, a sequential model that extracts short-term preferences from users' real-time activities. A hybrid approach to ranking is also described, which combines end-to-end sequential modeling via TransAct with batch-generated user embeddings.", "target": "The paper introduces Pinterest's ranking architecture for Homefeed and proposes TransAct, a sequential model that extracts short-term preferences from users' real-time activities. A hybrid approach to ranking is also described, which combines end-to-end sequential modeling via TransAct with batch-generated user embeddings.", "example": "Convert the coordinate to text: [-5.2314  4.4538]:"}
{"text": "Convert the coordinate to text: [ 10.5635 -14.7429]: The authors propose a novel 3D object detection model, Predict to Detect (P2D), that integrates a prediction scheme into a detection framework to explicitly extract and leverage motion features. The P2D model predicts object information in the current frame using only past frames to learn temporal motion features.", "target": "The authors propose a novel 3D object detection model, Predict to Detect (P2D), that integrates a prediction scheme into a detection framework to explicitly extract and leverage motion features. The P2D model predicts object information in the current frame using only past frames to learn temporal motion features.", "example": "Convert the coordinate to text: [ 10.5635 -14.7429]:"}
{"text": "Convert the coordinate to text: [-1.9239 -6.6433]: The authors describe their participation in this shared task with a system that's an ensemble of different variants of fine-tuned DeBERTa models that uses a k-fold cross-validation technique.", "target": "The authors describe their participation in this shared task with a system that's an ensemble of different variants of fine-tuned DeBERTa models that uses a k-fold cross-validation technique.", "example": "Convert the coordinate to text: [-1.9239 -6.6433]:"}
{"text": "Convert the coordinate to text: [-5.6901  1.9631]: The paper presents a novel strategy for categorizing news articles based on 'Lexical Weirdness', which helps ascertain whether a given article constitutes an opinion piece, reports factual news, or is satirical in nature.", "target": "The paper presents a novel strategy for categorizing news articles based on 'Lexical Weirdness', which helps ascertain whether a given article constitutes an opinion piece, reports factual news, or is satirical in nature.", "example": "Convert the coordinate to text: [-5.6901  1.9631]:"}
{"text": "Convert the coordinate to text: [-1.9303 -5.0746]: The authors propose a methodology that includes a language-specific data-driven approach and the generation of synthetic data through the employment of large-scale language models and empirically-grounded prompt engineering.", "target": "The authors propose a methodology that includes a language-specific data-driven approach and the generation of synthetic data through the employment of large-scale language models and empirically-grounded prompt engineering.", "example": "Convert the coordinate to text: [-1.9303 -5.0746]:"}
{"text": "Convert the coordinate to text: [-3.4364 -6.8709]: The authors propose the Prototype-based Representation Alignment Model (PRAM), which models cross-lingual (CL) NER task and transfers knowledge from source to target languages in a unified neural network. This model uses attribution-prediction consistency (APC) to align entity representations and predictions across languages using prototypes.", "target": "The authors propose the Prototype-based Representation Alignment Model (PRAM), which models cross-lingual (CL) NER task and transfers knowledge from source to target languages in a unified neural network. This model uses attribution-prediction consistency (APC) to align entity representations and predictions across languages using prototypes.", "example": "Convert the coordinate to text: [-3.4364 -6.8709]:"}
{"text": "Convert the coordinate to text: [-2.7523 -4.5322]: The authors propose a unified non-autoregressive generation (NAG) framework for NER tasks, termed NAG-NER, which treats entities as a set rather than a sequence to prevent error propagation. It also incorporates non-autoregressive generation in NER tasks for efficient decoding.", "target": "The authors propose a unified non-autoregressive generation (NAG) framework for NER tasks, termed NAG-NER, which treats entities as a set rather than a sequence to prevent error propagation. It also incorporates non-autoregressive generation in NER tasks for efficient decoding.", "example": "Convert the coordinate to text: [-2.7523 -4.5322]:"}
{"text": "Convert the coordinate to text: [9.1017 1.8863]: The authors propose a new infinite width limit, the Bayesian representation learning limit, that demonstrates representation learning that mirrors finite-width models. They also introduce deep kernel machines (DKMs), a deep generalization of kernel methods, and a sparse DKM that scales linearly with the number of data points.", "target": "The authors propose a new infinite width limit, the Bayesian representation learning limit, that demonstrates representation learning that mirrors finite-width models. They also introduce deep kernel machines (DKMs), a deep generalization of kernel methods, and a sparse DKM that scales linearly with the number of data points.", "example": "Convert the coordinate to text: [9.1017 1.8863]:"}
{"text": "Convert the coordinate to text: [13.9781 -2.3194]: The authors propose an approach to deal with the issue of quantization error in SNNs, which is a regularizing membrane potential loss (RMP-Loss) to adjust the distribution related to the error so it's closer to the spikes.", "target": "The authors propose an approach to deal with the issue of quantization error in SNNs, which is a regularizing membrane potential loss (RMP-Loss) to adjust the distribution related to the error so it's closer to the spikes.", "example": "Convert the coordinate to text: [13.9781 -2.3194]:"}
{"text": "Convert the coordinate to text: [  9.1806 -12.5038]: The authors introduce Pixel-Aligned Recurrent Queries (PARQ), a multi-view 3D object detector that uses transformer and pixel-aligned recurrent queries initialized from reference points in 3D space. The model incorporates pixel-aligned features and cross attention to handle 3D-to-2D correspondences and capture global contextual information.", "target": "The authors introduce Pixel-Aligned Recurrent Queries (PARQ), a multi-view 3D object detector that uses transformer and pixel-aligned recurrent queries initialized from reference points in 3D space. The model incorporates pixel-aligned features and cross attention to handle 3D-to-2D correspondences and capture global contextual information.", "example": "Convert the coordinate to text: [  9.1806 -12.5038]:"}
{"text": "Convert the coordinate to text: [ 1.9932 -7.7054]: The authors introduce an innovative module called Affine-Consistent Transformer (AC-Former), which incorporates two sub-networks (global and local), facilitates direct calculation of a sequence of nucleus positions, and also an Adaptive Affine Transformer (AAT) module that can learn crucial spatial transformations for local network training.", "target": "The authors introduce an innovative module called Affine-Consistent Transformer (AC-Former), which incorporates two sub-networks (global and local), facilitates direct calculation of a sequence of nucleus positions, and also an Adaptive Affine Transformer (AAT) module that can learn crucial spatial transformations for local network training.", "example": "Convert the coordinate to text: [ 1.9932 -7.7054]:"}
{"text": "Convert the coordinate to text: [  9.3269 -16.3431]: The authors propose a novel center-based decoupled point cloud registration framework that separately predicts the object center and estimates the rotation in a center-aware way, overcoming the issues with constructing correspondences.", "target": "The authors propose a novel center-based decoupled point cloud registration framework that separately predicts the object center and estimates the rotation in a center-aware way, overcoming the issues with constructing correspondences.", "example": "Convert the coordinate to text: [  9.3269 -16.3431]:"}
{"text": "Convert the coordinate to text: [ 10.2729 -15.7882]: The authors propose a new method for 3D reconstruction that leverages differentiable physics simulation in combination with differentiable rendering via coordinate descent for end-to-end optimization of 3D reconstructions and physical system parameters.", "target": "The authors propose a new method for 3D reconstruction that leverages differentiable physics simulation in combination with differentiable rendering via coordinate descent for end-to-end optimization of 3D reconstructions and physical system parameters.", "example": "Convert the coordinate to text: [ 10.2729 -15.7882]:"}
{"text": "Convert the coordinate to text: [ 1.3648 -2.9755]: The paper investigates compositional generalization in conditional diffusion models in a synthetic setting, examining the impacts of the training data's attributes on the models' abilities to generate out-of-distribution samples.", "target": "The paper investigates compositional generalization in conditional diffusion models in a synthetic setting, examining the impacts of the training data's attributes on the models' abilities to generate out-of-distribution samples.", "example": "Convert the coordinate to text: [ 1.3648 -2.9755]:"}
{"text": "Convert the coordinate to text: [11.9543 -2.2504]: The authors prove mathematically for a particular class of ReLU-based RNNs that certain bifurcations are associated with loss gradients tending toward infinity or zero. They also propose a new heuristic algorithm for detecting all fixed points and k-cycles in ReLU-based RNNs and their existence, stability regions, and bifurcation manifolds in parameter space.", "target": "The authors prove mathematically for a particular class of ReLU-based RNNs that certain bifurcations are associated with loss gradients tending toward infinity or zero. They also propose a new heuristic algorithm for detecting all fixed points and k-cycles in ReLU-based RNNs and their existence, stability regions, and bifurcation manifolds in parameter space.", "example": "Convert the coordinate to text: [11.9543 -2.2504]:"}
{"text": "Convert the coordinate to text: [10.3525 -3.8439]: This study introduces a novel model-based perspective on MU: model sparsification via weight pruning, which can reduce the gap between exact unlearning and approximate unlearning. A new MU paradigm, termed 'prune first, then unlearn', is proposed, which infuses a sparse model prior into the unlearning process.", "target": "This study introduces a novel model-based perspective on MU: model sparsification via weight pruning, which can reduce the gap between exact unlearning and approximate unlearning. A new MU paradigm, termed 'prune first, then unlearn', is proposed, which infuses a sparse model prior into the unlearning process.", "example": "Convert the coordinate to text: [10.3525 -3.8439]:"}
{"text": "Convert the coordinate to text: [-8.9533 -2.5134]: The authors provide an overview of key considerations and effective approaches to study interactions between humans and NLP models. This focuses on scenarios where end users, who are less familiar with NLP techniques but have access to models, use or collaborate with deployed models.", "target": "The authors provide an overview of key considerations and effective approaches to study interactions between humans and NLP models. This focuses on scenarios where end users, who are less familiar with NLP techniques but have access to models, use or collaborate with deployed models.", "example": "Convert the coordinate to text: [-8.9533 -2.5134]:"}
{"text": "Convert the coordinate to text: [-0.8713 -4.6228]: The authors break down the development of Flan 2022, such as task balancing and enrichment techniques, and reasons why training with mixed prompt settings yields stronger performance.", "target": "The authors break down the development of Flan 2022, such as task balancing and enrichment techniques, and reasons why training with mixed prompt settings yields stronger performance.", "example": "Convert the coordinate to text: [-0.8713 -4.6228]:"}
{"text": "Convert the coordinate to text: [-3.7511 -3.4947]: The paper proposes GenRet, a document tokenization learning method that defines document identifiers for generative retrieval. GenRet tokenizes documents into short discrete representations (docids) via a discrete auto-encoding approach with a tokenization, reconstruction, and sequence-to-sequence retrieval model.", "target": "The paper proposes GenRet, a document tokenization learning method that defines document identifiers for generative retrieval. GenRet tokenizes documents into short discrete representations (docids) via a discrete auto-encoding approach with a tokenization, reconstruction, and sequence-to-sequence retrieval model.", "example": "Convert the coordinate to text: [-3.7511 -3.4947]:"}
{"text": "Convert the coordinate to text: [ 4.9704 -5.7098]: This paper presents xGCN, a novel model for large-scale network embedding, aimed at improving the accuracy, efficiency, and scalability of link predictions. Unlike typical GNNs which assign a learnable embedding vector to each node, xGCN treats node embeddings as static features and iteratively refines them using a Refinement neural Network (RefNet).", "target": "This paper presents xGCN, a novel model for large-scale network embedding, aimed at improving the accuracy, efficiency, and scalability of link predictions. Unlike typical GNNs which assign a learnable embedding vector to each node, xGCN treats node embeddings as static features and iteratively refines them using a Refinement neural Network (RefNet).", "example": "Convert the coordinate to text: [ 4.9704 -5.7098]:"}
{"text": "Convert the coordinate to text: [-13.2631   5.3297]: The paper proposes a new approach to measure potential performance gains of upgraded Python web applications, using an interactive service that assists developers with optimizing their Python code through changes to the system infrastructure.", "target": "The paper proposes a new approach to measure potential performance gains of upgraded Python web applications, using an interactive service that assists developers with optimizing their Python code through changes to the system infrastructure.", "example": "Convert the coordinate to text: [-13.2631   5.3297]:"}
{"text": "Convert the coordinate to text: [ 6.6106 13.8743]: The authors propose a new paradigm called semi-offline RL, which smoothly transits from offline to online settings, balancing exploration capability and training cost.", "target": "The authors propose a new paradigm called semi-offline RL, which smoothly transits from offline to online settings, balancing exploration capability and training cost.", "example": "Convert the coordinate to text: [ 6.6106 13.8743]:"}
{"text": "Convert the coordinate to text: [ 7.6955 11.3612]: The authors propose a more general formulation that accounts for diverse user behavior which can vary according to the user context. The result of this formulation is a new estimator, Adaptive IPS (AIPS), which can be unbiased under any complexity of user behavior.", "target": "The authors propose a more general formulation that accounts for diverse user behavior which can vary according to the user context. The result of this formulation is a new estimator, Adaptive IPS (AIPS), which can be unbiased under any complexity of user behavior.", "example": "Convert the coordinate to text: [ 7.6955 11.3612]:"}
{"text": "Convert the coordinate to text: [-8.9808 -7.2873]: The authors propose the use of Cambridge Grammar of the English Language (CGEL) along with developed guidelines as a more comprehensive and accessible annotation scheme for English syntax.", "target": "The authors propose the use of Cambridge Grammar of the English Language (CGEL) along with developed guidelines as a more comprehensive and accessible annotation scheme for English syntax.", "example": "Convert the coordinate to text: [-8.9808 -7.2873]:"}
{"text": "Convert the coordinate to text: [-2.8047 -5.867 ]: The study proposes the usage of a large language model, Galactica, to automatically extract biological information, which can be potentially beneficial in life science research.", "target": "The study proposes the usage of a large language model, Galactica, to automatically extract biological information, which can be potentially beneficial in life science research.", "example": "Convert the coordinate to text: [-2.8047 -5.867 ]:"}
{"text": "Convert the coordinate to text: [ 4.7313 13.7597]: The authors propose a novel, end-to-end, skill-centric reinforcement learning framework that can learn more disentangled skills via abstracting actions.", "target": "The authors propose a novel, end-to-end, skill-centric reinforcement learning framework that can learn more disentangled skills via abstracting actions.", "example": "Convert the coordinate to text: [ 4.7313 13.7597]:"}
{"text": "Convert the coordinate to text: [  5.7136 -12.4347]: This work introduces an exploratory inference learning (EIL) framework designed to foster efficient probing on unlabeled pixels and encourage selecting confident candidates to boost the evolved segmentation.", "target": "This work introduces an exploratory inference learning (EIL) framework designed to foster efficient probing on unlabeled pixels and encourage selecting confident candidates to boost the evolved segmentation.", "example": "Convert the coordinate to text: [  5.7136 -12.4347]:"}
{"text": "Convert the coordinate to text: [13.5104 -4.728 ]: The authors propose a distributed backdoor attack method, named Cerberus Poisoning (CerP), which jointly tunes the backdoor trigger and controls the poisoned model changes on each malicious participant. This strategy aims to achieve a stealthy yet successful backdoor attack against the defensive mechanisms of federated learning techniques.", "target": "The authors propose a distributed backdoor attack method, named Cerberus Poisoning (CerP), which jointly tunes the backdoor trigger and controls the poisoned model changes on each malicious participant. This strategy aims to achieve a stealthy yet successful backdoor attack against the defensive mechanisms of federated learning techniques.", "example": "Convert the coordinate to text: [13.5104 -4.728 ]:"}
{"text": "Convert the coordinate to text: [ 3.64   10.6222]: The authors propose that graph-search-based planning can be used to efficiently generate solutions for multi-robot coordination problems with guarantees on correctness, completeness, and solution quality. They delve into both theoretical and application perspectives to address the MAPF problem using artificial intelligence and optimization technologies.", "target": "The authors propose that graph-search-based planning can be used to efficiently generate solutions for multi-robot coordination problems with guarantees on correctness, completeness, and solution quality. They delve into both theoretical and application perspectives to address the MAPF problem using artificial intelligence and optimization technologies.", "example": "Convert the coordinate to text: [ 3.64   10.6222]:"}
{"text": "Convert the coordinate to text: [  8.5807 -12.5559]: The authors introduced FUS3D, a lightweight system that integrates the stages of 3D object detection and multi-object-tracking into a single, end-to-end trainable model. The system is optimized for edge devices, for sensitive applications, and relies exclusively on less privacy-intrusive 3D depth imaging.", "target": "The authors introduced FUS3D, a lightweight system that integrates the stages of 3D object detection and multi-object-tracking into a single, end-to-end trainable model. The system is optimized for edge devices, for sensitive applications, and relies exclusively on less privacy-intrusive 3D depth imaging.", "example": "Convert the coordinate to text: [  8.5807 -12.5559]:"}
{"text": "Convert the coordinate to text: [ 5.1047 -2.2872]: The authors propose the Simple but Strong Baseline (SSB) for open-set SSL, an approach that improves inlier classification performance by integrating high-confidence pseudo-labeled data, and leverages non-linear transformations and pseudo-negative mining to boost outlier detection.", "target": "The authors propose the Simple but Strong Baseline (SSB) for open-set SSL, an approach that improves inlier classification performance by integrating high-confidence pseudo-labeled data, and leverages non-linear transformations and pseudo-negative mining to boost outlier detection.", "example": "Convert the coordinate to text: [ 5.1047 -2.2872]:"}
{"text": "Convert the coordinate to text: [  3.099  -11.6256]: The authors propose to deconstruct this abstraction in relational representations by expressing them as interpretable graphs over image views. They introduce a graph-space search algorithm called Transitivity Recovering Decompositions (TRD) that identifies interpretable equivalents of abstract emergent relationships at both instance and class levels, without any post-hoc computations.", "target": "The authors propose to deconstruct this abstraction in relational representations by expressing them as interpretable graphs over image views. They introduce a graph-space search algorithm called Transitivity Recovering Decompositions (TRD) that identifies interpretable equivalents of abstract emergent relationships at both instance and class levels, without any post-hoc computations.", "example": "Convert the coordinate to text: [  3.099  -11.6256]:"}
{"text": "Convert the coordinate to text: [ 8.7017 -3.1303]: This paper introduces the Robustness-Constrained Learning (RCL) algorithm, which combines questionable ML predictions with a trustable online expert algorithm via constrained projection, aiming to strengthen the ML prediction.", "target": "This paper introduces the Robustness-Constrained Learning (RCL) algorithm, which combines questionable ML predictions with a trustable online expert algorithm via constrained projection, aiming to strengthen the ML prediction.", "example": "Convert the coordinate to text: [ 8.7017 -3.1303]:"}
{"text": "Convert the coordinate to text: [3.9298 4.9592]: This study introduces a method for exact recovery of community labels by jointly leveraging both network information and node attribute information in network clustering. It also presents a new iterative clustering algorithm that maximizes the joint likelihood, assuming that the probability distribution of network interactions and node attributes belong to exponential families.", "target": "This study introduces a method for exact recovery of community labels by jointly leveraging both network information and node attribute information in network clustering. It also presents a new iterative clustering algorithm that maximizes the joint likelihood, assuming that the probability distribution of network interactions and node attributes belong to exponential families.", "example": "Convert the coordinate to text: [3.9298 4.9592]:"}
{"text": "Convert the coordinate to text: [ 0.1366 -8.7515]: The authors propose a lightweight, residual-style adapter named Meta-Adapter that refines the CLIP features guided by few-shot samples in an online manner without the need for additional fine-tuning.", "target": "The authors propose a lightweight, residual-style adapter named Meta-Adapter that refines the CLIP features guided by few-shot samples in an online manner without the need for additional fine-tuning.", "example": "Convert the coordinate to text: [ 0.1366 -8.7515]:"}
{"text": "Convert the coordinate to text: [13.8599 -4.2996]: The paper proposes a Structure-Aware Shapley-based Multipiece Explanation (SAME) method that addresses the challenge of structure-aware feature interactions for GNN explanation. It leverages an expansion-based Monte Carlo tree search to explore multi-grained structure-aware connected substructures.", "target": "The paper proposes a Structure-Aware Shapley-based Multipiece Explanation (SAME) method that addresses the challenge of structure-aware feature interactions for GNN explanation. It leverages an expansion-based Monte Carlo tree search to explore multi-grained structure-aware connected substructures.", "example": "Convert the coordinate to text: [13.8599 -4.2996]:"}
{"text": "Convert the coordinate to text: [-3.2962 -9.7577]: A new model, P-Flow, is proposed which uses speech prompts for speaker adaptation and comprises a speech-prompted text encoder and a flow matching generative decoder for efficient and high-quality speech synthesis.", "target": "A new model, P-Flow, is proposed which uses speech prompts for speaker adaptation and comprises a speech-prompted text encoder and a flow matching generative decoder for efficient and high-quality speech synthesis.", "example": "Convert the coordinate to text: [-3.2962 -9.7577]:"}
{"text": "Convert the coordinate to text: [ 2.3592 15.7882]: The authors explore the efficiency gains of voting rules that add a simple randomization step to a deterministic rule, retaining explainability. They focus on two families of rules: randomized positional scoring rules and random committee member rules.", "target": "The authors explore the efficiency gains of voting rules that add a simple randomization step to a deterministic rule, retaining explainability. They focus on two families of rules: randomized positional scoring rules and random committee member rules.", "example": "Convert the coordinate to text: [ 2.3592 15.7882]:"}
{"text": "Convert the coordinate to text: [ 6.7714 -9.5426]: To address these limitations, this paper proposes a novel Siamese Sampling and Reasoning Network (SSRN) for TSG, introducing a siamese sampling mechanism to generate additional contextual frames to refine the new boundaries.", "target": "To address these limitations, this paper proposes a novel Siamese Sampling and Reasoning Network (SSRN) for TSG, introducing a siamese sampling mechanism to generate additional contextual frames to refine the new boundaries.", "example": "Convert the coordinate to text: [ 6.7714 -9.5426]:"}
{"text": "Convert the coordinate to text: [ 2.1872 -8.3353]: In this paper, the authors present Dynamic Sparse Voxel Transformer (DSVT), a single-stride window-based voxel transformer backbone for outdoor 3D perception. The key features include Dynamic Sparse Window Attention, rotated set partitioning and an attention-style 3D pooling module on sparse points.", "target": "In this paper, the authors present Dynamic Sparse Voxel Transformer (DSVT), a single-stride window-based voxel transformer backbone for outdoor 3D perception. The key features include Dynamic Sparse Window Attention, rotated set partitioning and an attention-style 3D pooling module on sparse points.", "example": "Convert the coordinate to text: [ 2.1872 -8.3353]:"}
{"text": "Convert the coordinate to text: [ 14.8137 -15.0582]: This study introduces Language Embedded Radiance Fields (LERFs), a method to ground language embeddings from generic models such as CLIP into NeRF (Neural Radiance Fields), thereby enabling open-ended language queries in 3D spaces.", "target": "This study introduces Language Embedded Radiance Fields (LERFs), a method to ground language embeddings from generic models such as CLIP into NeRF (Neural Radiance Fields), thereby enabling open-ended language queries in 3D spaces.", "example": "Convert the coordinate to text: [ 14.8137 -15.0582]:"}
{"text": "Convert the coordinate to text: [ 2.0895 -2.907 ]: This paper investigates the phenomenon of catastrophic forgetting in LLMs and proposes a novel framework for injecting non-linguistic skills into LLMs. The framework is based on information theoretic interventions and skill-specific losses that facilitate the learning of strict arithmetic reasoning.", "target": "This paper investigates the phenomenon of catastrophic forgetting in LLMs and proposes a novel framework for injecting non-linguistic skills into LLMs. The framework is based on information theoretic interventions and skill-specific losses that facilitate the learning of strict arithmetic reasoning.", "example": "Convert the coordinate to text: [ 2.0895 -2.907 ]:"}
{"text": "Convert the coordinate to text: [1.4336 3.9497]: The authors present a new constraint-based algorithm that gradually refines a causal graph by learning long-term temporal relations before short-term ones, with contemporaneous relations being learned last.", "target": "The authors present a new constraint-based algorithm that gradually refines a causal graph by learning long-term temporal relations before short-term ones, with contemporaneous relations being learned last.", "example": "Convert the coordinate to text: [1.4336 3.9497]:"}
{"text": "Convert the coordinate to text: [-9.1698  0.492 ]: The authors propose a new large benchmark for the PCR task - the IL-PCR (Indian Legal Prior Case Retrieval) corpus, and also develop a new unsupervised retrieval method-based pipeline, Unsupervised Case Retrieval using Events Extraction (U-CREAT), to explore the role of events in legal case retrieval.", "target": "The authors propose a new large benchmark for the PCR task - the IL-PCR (Indian Legal Prior Case Retrieval) corpus, and also develop a new unsupervised retrieval method-based pipeline, Unsupervised Case Retrieval using Events Extraction (U-CREAT), to explore the role of events in legal case retrieval.", "example": "Convert the coordinate to text: [-9.1698  0.492 ]:"}
{"text": "Convert the coordinate to text: [-7.4913 -2.8212]: This study introduces the CoRRPUS system, which leverages state-of-the-art Code-LLMs like Codex to bootstrap the use of symbolic methods for tracking the state of stories and improving story understanding.", "target": "This study introduces the CoRRPUS system, which leverages state-of-the-art Code-LLMs like Codex to bootstrap the use of symbolic methods for tracking the state of stories and improving story understanding.", "example": "Convert the coordinate to text: [-7.4913 -2.8212]:"}
{"text": "Convert the coordinate to text: [-0.4167 -4.3357]: The study investigates response generation in inquiry conversation by proposing the Focus-aware Response Generation (FRG) method which takes the focus of conversation into consideration.", "target": "The study investigates response generation in inquiry conversation by proposing the Focus-aware Response Generation (FRG) method which takes the focus of conversation into consideration.", "example": "Convert the coordinate to text: [-0.4167 -4.3357]:"}
{"text": "Convert the coordinate to text: [-7.6825 -1.4419]: To address the lack of attention towards event-based OA, the authors construct an Event Ontology Alignment (EventOA) dataset derived from FrameNet and Wikidata and propose a new multi-view event ontology alignment (MEOA) method.", "target": "To address the lack of attention towards event-based OA, the authors construct an Event Ontology Alignment (EventOA) dataset derived from FrameNet and Wikidata and propose a new multi-view event ontology alignment (MEOA) method.", "example": "Convert the coordinate to text: [-7.6825 -1.4419]:"}
{"text": "Convert the coordinate to text: [-7.3325 -7.4888]: The authors introduce KWJA, a unified high-performance Japanese text analyzer based on foundation models, capable of managing a wide array of tasks such as typo correction, word segmentation, normalization, morphological analysis, among others.", "target": "The authors introduce KWJA, a unified high-performance Japanese text analyzer based on foundation models, capable of managing a wide array of tasks such as typo correction, word segmentation, normalization, morphological analysis, among others.", "example": "Convert the coordinate to text: [-7.3325 -7.4888]:"}
{"text": "Convert the coordinate to text: [9.9029 5.0946]: The authors propose a variance decomposition-based method to assess the generalizability of large pretrained neural models when fine-tuned, and a two-stage fine-tuning algorithm which first reduces bias and variance iteratively, then further diminishes variance due to optimization by ensembling a fixed-bias model.", "target": "The authors propose a variance decomposition-based method to assess the generalizability of large pretrained neural models when fine-tuned, and a two-stage fine-tuning algorithm which first reduces bias and variance iteratively, then further diminishes variance due to optimization by ensembling a fixed-bias model.", "example": "Convert the coordinate to text: [9.9029 5.0946]:"}
{"text": "Convert the coordinate to text: [-0.3327 -8.5595]: The authors propose the importance of maintaining modality independence for improving model performance in multi-modal emotion recognition. Accordingly, they devise a multi-modal transformer model and construct a dataset, CHERMA, with uni-modal labels for each individual modality and multi-modal labels for all joint modalities.", "target": "The authors propose the importance of maintaining modality independence for improving model performance in multi-modal emotion recognition. Accordingly, they devise a multi-modal transformer model and construct a dataset, CHERMA, with uni-modal labels for each individual modality and multi-modal labels for all joint modalities.", "example": "Convert the coordinate to text: [-0.3327 -8.5595]:"}
{"text": "Convert the coordinate to text: [-5.6819  4.6125]: This paper proposes the Diverse Counterfactual Evidence framework for Rumor Detection (DCE-RD). The DCE-RD intuitively uses the diverse counterfactual evidence of an event graph as multi-view interpretations, which are aggregated for robust rumor detection results.", "target": "This paper proposes the Diverse Counterfactual Evidence framework for Rumor Detection (DCE-RD). The DCE-RD intuitively uses the diverse counterfactual evidence of an event graph as multi-view interpretations, which are aggregated for robust rumor detection results.", "example": "Convert the coordinate to text: [-5.6819  4.6125]:"}
{"text": "Convert the coordinate to text: [10.9988 -9.9622]: The authors propose two solutions for one-shot video inpainting: curricular inactivation for reliable target indication in long-term video inpainting, and an online residue removal method for partially inpainted artifacts.", "target": "The authors propose two solutions for one-shot video inpainting: curricular inactivation for reliable target indication in long-term video inpainting, and an online residue removal method for partially inpainted artifacts.", "example": "Convert the coordinate to text: [10.9988 -9.9622]:"}
{"text": "Convert the coordinate to text: [-1.3293 -4.5183]: The authors propose a new framework for adaptation with self-evaluation to improve the selective prediction performance of LLMs, which uses parameter-efficient tuning to adapt the LLM to the specific task while enhancing its self-evaluation ability.", "target": "The authors propose a new framework for adaptation with self-evaluation to improve the selective prediction performance of LLMs, which uses parameter-efficient tuning to adapt the LLM to the specific task while enhancing its self-evaluation ability.", "example": "Convert the coordinate to text: [-1.3293 -4.5183]:"}
{"text": "Convert the coordinate to text: [ 6.2215 13.3725]: The authors propose a novel distributional reinforcement learning algorithm that selects actions by randomizing risk criterion as a way to avoid this one-sided risk tendency.", "target": "The authors propose a novel distributional reinforcement learning algorithm that selects actions by randomizing risk criterion as a way to avoid this one-sided risk tendency.", "example": "Convert the coordinate to text: [ 6.2215 13.3725]:"}
{"text": "Convert the coordinate to text: [ 4.9727 11.0916]: The authors identify a significant limitation in MENTS where the optimal actions for the maximum entropy objective do not necessarily correspond to optimal actions for the original objective. They propose two new algorithms, Boltzmann Tree Search (BTS) and Decaying ENtropy Tree-Search (DENTS), to rectify this limitation and maintain the advantages of Boltzmann policies.", "target": "The authors identify a significant limitation in MENTS where the optimal actions for the maximum entropy objective do not necessarily correspond to optimal actions for the original objective. They propose two new algorithms, Boltzmann Tree Search (BTS) and Decaying ENtropy Tree-Search (DENTS), to rectify this limitation and maintain the advantages of Boltzmann policies.", "example": "Convert the coordinate to text: [ 4.9727 11.0916]:"}
{"text": "Convert the coordinate to text: [-5.7007  4.8746]: The authors propose Crowd Intelligence and ChatGPT-Assisted Network (CICAN) for rumor classification. The approach uses a crowd intelligence-based semantic feature learning module, a knowledge-based semantic structural mining module that leverages ChatGPT for knowledge enhancement, and an entity-sentence heterogeneous graph with Entity-Aware Heterogeneous Attention to integrate diverse structural information meta-paths.", "target": "The authors propose Crowd Intelligence and ChatGPT-Assisted Network (CICAN) for rumor classification. The approach uses a crowd intelligence-based semantic feature learning module, a knowledge-based semantic structural mining module that leverages ChatGPT for knowledge enhancement, and an entity-sentence heterogeneous graph with Entity-Aware Heterogeneous Attention to integrate diverse structural information meta-paths.", "example": "Convert the coordinate to text: [-5.7007  4.8746]:"}
{"text": "Convert the coordinate to text: [-10.5416  -1.9032]: The authors introduce PQQ, an innovative approach for question data augmentation in low-resource question-answering tasks which consists of Prompt Answer, Question Generation, and Question Filter.", "target": "The authors introduce PQQ, an innovative approach for question data augmentation in low-resource question-answering tasks which consists of Prompt Answer, Question Generation, and Question Filter.", "example": "Convert the coordinate to text: [-10.5416  -1.9032]:"}
{"text": "Convert the coordinate to text: [ 5.1868 -5.8074]: The paper introduces ClenshawGCN, a Graph Neural Network model that uses the Clenshaw Summation Algorithm to increase the expressivity of the GCN model. The model utilizes two straightforward residual modules, the adaptive initial residual connection and the negative second-order residual connection, for this purpose.", "target": "The paper introduces ClenshawGCN, a Graph Neural Network model that uses the Clenshaw Summation Algorithm to increase the expressivity of the GCN model. The model utilizes two straightforward residual modules, the adaptive initial residual connection and the negative second-order residual connection, for this purpose.", "example": "Convert the coordinate to text: [ 5.1868 -5.8074]:"}
{"text": "Convert the coordinate to text: [ 2.7803 -7.9774]: This study proposes GAGA, a novel Group AGgregation enhanced TrAnsformer, to address issues with low homophily. It introduces group aggregation that integrates label information to generate distinguishable neighborhood information and proposes an end-to-end trainable group encoding that augments original features with class labels.", "target": "This study proposes GAGA, a novel Group AGgregation enhanced TrAnsformer, to address issues with low homophily. It introduces group aggregation that integrates label information to generate distinguishable neighborhood information and proposes an end-to-end trainable group encoding that augments original features with class labels.", "example": "Convert the coordinate to text: [ 2.7803 -7.9774]:"}
{"text": "Convert the coordinate to text: [-1.8337 -6.7963]: The authors propose a system that uses a multi-label contrastive loss for fine-tuning large pre-trained language models in a multi-lingual setting for Framing Detection.", "target": "The authors propose a system that uses a multi-label contrastive loss for fine-tuning large pre-trained language models in a multi-lingual setting for Framing Detection.", "example": "Convert the coordinate to text: [-1.8337 -6.7963]:"}
{"text": "Convert the coordinate to text: [-5.408   9.9325]: This paper proposes a novel method of implementing dual learning in task-oriented dialogues to exploit the correlation of heterogeneous data, and converting the one-to-one duality into a multijugate duality to reduce the influences of spurious correlations in dual training for improved generalization.", "target": "This paper proposes a novel method of implementing dual learning in task-oriented dialogues to exploit the correlation of heterogeneous data, and converting the one-to-one duality into a multijugate duality to reduce the influences of spurious correlations in dual training for improved generalization.", "example": "Convert the coordinate to text: [-5.408   9.9325]:"}
{"text": "Convert the coordinate to text: [-4.8509 -3.1144]: The authors propose a model-in-the-loop annotation approach for event coreference resolution that suggests likely corefering event pairs, potentially reducing manual workload.", "target": "The authors propose a model-in-the-loop annotation approach for event coreference resolution that suggests likely corefering event pairs, potentially reducing manual workload.", "example": "Convert the coordinate to text: [-4.8509 -3.1144]:"}
{"text": "Convert the coordinate to text: [-0.6155 -3.3856]: The authors propose CoT-KA, a Chain-of-Thought-based method for augmenting knowledge for deep learning models, which negates the need for additional standalone knowledge retrieval or knowledge reasoning models.", "target": "The authors propose CoT-KA, a Chain-of-Thought-based method for augmenting knowledge for deep learning models, which negates the need for additional standalone knowledge retrieval or knowledge reasoning models.", "example": "Convert the coordinate to text: [-0.6155 -3.3856]:"}
{"text": "Convert the coordinate to text: [-1.188  -4.8818]: This paper proposes to use prompting, a method that injects task-specific knowledge into a model without relying on labeled data, in combination with zero-shot learning, to detect hate speech across 3 different languages with limited labeled data.", "target": "This paper proposes to use prompting, a method that injects task-specific knowledge into a model without relying on labeled data, in combination with zero-shot learning, to detect hate speech across 3 different languages with limited labeled data.", "example": "Convert the coordinate to text: [-1.188  -4.8818]:"}
{"text": "Convert the coordinate to text: [-7.1672  0.8732]: The authors propose new unsupervised evaluation metrics to assess the quality and flow of knowledge in technical problem-solving documents and to suggest possible improvements.", "target": "The authors propose new unsupervised evaluation metrics to assess the quality and flow of knowledge in technical problem-solving documents and to suggest possible improvements.", "example": "Convert the coordinate to text: [-7.1672  0.8732]:"}
{"text": "Convert the coordinate to text: [-3.1145 -3.6672]: The authors leverage an explanations-driven Natural Language Inference (NLI) approach to handle these tasks. They first identify relevant evidence from target CTRs, perform evidence level inferences, and then ensemble them for the final inference.", "target": "The authors leverage an explanations-driven Natural Language Inference (NLI) approach to handle these tasks. They first identify relevant evidence from target CTRs, perform evidence level inferences, and then ensemble them for the final inference.", "example": "Convert the coordinate to text: [-3.1145 -3.6672]:"}
{"text": "Convert the coordinate to text: [-5.6153 -1.1611]: The authors develop two distinct approaches: one is a rule-based summarization model which exploits the Unified Medical Language System (UMLS) and a negation detector to create the summary; the other employs fine-tuning of three pre-trained language models (BART, T5 and GPT2).", "target": "The authors develop two distinct approaches: one is a rule-based summarization model which exploits the Unified Medical Language System (UMLS) and a negation detector to create the summary; the other employs fine-tuning of three pre-trained language models (BART, T5 and GPT2).", "example": "Convert the coordinate to text: [-5.6153 -1.1611]:"}
{"text": "Convert the coordinate to text: [-4.995  -8.9768]: A deterministic decoding scheme, Local Temperature Beam Search, is proposed. It is a simple variant of beam search that addresses the problem of repetition while maintaining output coherence.", "target": "A deterministic decoding scheme, Local Temperature Beam Search, is proposed. It is a simple variant of beam search that addresses the problem of repetition while maintaining output coherence.", "example": "Convert the coordinate to text: [-4.995  -8.9768]:"}
{"text": "Convert the coordinate to text: [-3.0557 -5.8529]: A light add-on network called EmbedTextNet is proposed, capable of generating compact embeddings without requiring changes in the architecture or training procedure of any arbitrary language model. The approach introduces a correlation penalty added to the weighted reconstruction loss to improve text embedding efficiency.", "target": "A light add-on network called EmbedTextNet is proposed, capable of generating compact embeddings without requiring changes in the architecture or training procedure of any arbitrary language model. The approach introduces a correlation penalty added to the weighted reconstruction loss to improve text embedding efficiency.", "example": "Convert the coordinate to text: [-3.0557 -5.8529]:"}
{"text": "Convert the coordinate to text: [-0.9721 -5.9228]: The authors propose a novel contrastive data augmentation method for AD detection that simulates the cognitive impairment of a patient by randomly deleting a proportion of text from the transcript to create negative samples.", "target": "The authors propose a novel contrastive data augmentation method for AD detection that simulates the cognitive impairment of a patient by randomly deleting a proportion of text from the transcript to create negative samples.", "example": "Convert the coordinate to text: [-0.9721 -5.9228]:"}
{"text": "Convert the coordinate to text: [14.9398  0.1399]: The authors propose a differentiable quantum architecture search (QAS) algorithm based on Gumbel-Softmax to automatically design PQCs for VQA. They introduced two versions of their algorithm: the macro search, which directly searches for the whole circuit, and the micro search, a novel approach to infer the sub-circuit structure from a small-scale problem and transfer it to a large-scale problem.", "target": "The authors propose a differentiable quantum architecture search (QAS) algorithm based on Gumbel-Softmax to automatically design PQCs for VQA. They introduced two versions of their algorithm: the macro search, which directly searches for the whole circuit, and the micro search, a novel approach to infer the sub-circuit structure from a small-scale problem and transfer it to a large-scale problem.", "example": "Convert the coordinate to text: [14.9398  0.1399]:"}
{"text": "Convert the coordinate to text: [-5.7923  2.5777]: This research involves characterizing and predicting how prominent news outlets make edits to news frames, specifically around geopolitical relationships and attitudes.", "target": "This research involves characterizing and predicting how prominent news outlets make edits to news frames, specifically around geopolitical relationships and attitudes.", "example": "Convert the coordinate to text: [-5.7923  2.5777]:"}
{"text": "Convert the coordinate to text: [ 11.1132 -13.0912]: Click-Pose, an end-to-end neural interactive keypoint detection framework, is proposed. This solution enhances the self-correction ability of the model through a pose error modeling strategy and includes an interactive human-feedback loop that allows users' clicks to correct predicted keypoints, iterating towards the correct pose.", "target": "Click-Pose, an end-to-end neural interactive keypoint detection framework, is proposed. This solution enhances the self-correction ability of the model through a pose error modeling strategy and includes an interactive human-feedback loop that allows users' clicks to correct predicted keypoints, iterating towards the correct pose.", "example": "Convert the coordinate to text: [ 11.1132 -13.0912]:"}
{"text": "Convert the coordinate to text: [ 5.9576 13.7978]: The authors propose an adjustable robust reinforcement learning (AR2L) framework that allows efficient adjustment of robustness weights. The objective function is formulated as a weighted sum of expected and worst-case returns to provide a balance of the policy's performance in average and worst-case environments.", "target": "The authors propose an adjustable robust reinforcement learning (AR2L) framework that allows efficient adjustment of robustness weights. The objective function is formulated as a weighted sum of expected and worst-case returns to provide a balance of the policy's performance in average and worst-case environments.", "example": "Convert the coordinate to text: [ 5.9576 13.7978]:"}
{"text": "Convert the coordinate to text: [ 4.3963 -2.8553]: The authors propose to replace the contrastive learning task with a new pretext task: Augmentation-Adaptive Self-Supervised Ranking (AdaptSSR), which does not require the same level of semantic consistency between the changed views while still pre-training a discriminative user model. Their unique approach includes a multiple pairwise ranking loss and an augmentation-adaptive fusion mechanism.", "target": "The authors propose to replace the contrastive learning task with a new pretext task: Augmentation-Adaptive Self-Supervised Ranking (AdaptSSR), which does not require the same level of semantic consistency between the changed views while still pre-training a discriminative user model. Their unique approach includes a multiple pairwise ranking loss and an augmentation-adaptive fusion mechanism.", "example": "Convert the coordinate to text: [ 4.3963 -2.8553]:"}
{"text": "Convert the coordinate to text: [ 4.3785 13.8854]: The authors present Knowledge-Grounded RL (KGRL), an RL paradigm that fuses multiple knowledge policies, aiming for human-like efficiency and flexibility. They propose a new actor architecture for KGRL, Knowledge-Inclusive Attention Network (KIAN), which allows free knowledge rearrangement owing to embedding-based attentive action prediction.", "target": "The authors present Knowledge-Grounded RL (KGRL), an RL paradigm that fuses multiple knowledge policies, aiming for human-like efficiency and flexibility. They propose a new actor architecture for KGRL, Knowledge-Inclusive Attention Network (KIAN), which allows free knowledge rearrangement owing to embedding-based attentive action prediction.", "example": "Convert the coordinate to text: [ 4.3785 13.8854]:"}
{"text": "Convert the coordinate to text: [ 5.9276 11.54  ]: The study introduces predictable MDP abstraction (PMA), a method that trains a model on a transformed MDP with a learned action space that only permits predictable, easy-to-model actions. This process ideally covers the original state-action space as much as possible to make model learning easier and more accurate.", "target": "The study introduces predictable MDP abstraction (PMA), a method that trains a model on a transformed MDP with a learned action space that only permits predictable, easy-to-model actions. This process ideally covers the original state-action space as much as possible to make model learning easier and more accurate.", "example": "Convert the coordinate to text: [ 5.9276 11.54  ]:"}
{"text": "Convert the coordinate to text: [10.1698 -3.9833]: The authors propose a method called LLM-Pruner that adopts structural pruning that selectively removes non-critical coupled structures based on gradient information, thus preserving the functionality of LLMs in a task-agnostic manner.", "target": "The authors propose a method called LLM-Pruner that adopts structural pruning that selectively removes non-critical coupled structures based on gradient information, thus preserving the functionality of LLMs in a task-agnostic manner.", "example": "Convert the coordinate to text: [10.1698 -3.9833]:"}
{"text": "Convert the coordinate to text: [-10.2064  -1.8422]: The paper introduces a new benchmark named KoRC, which offers broad knowledge coverage and a flexible answer format by using massive knowledge bases to guide annotators or large language models to construct knowledgable questions, and labels from knowledge bases as the final answers, instead of spans or choices.", "target": "The paper introduces a new benchmark named KoRC, which offers broad knowledge coverage and a flexible answer format by using massive knowledge bases to guide annotators or large language models to construct knowledgable questions, and labels from knowledge bases as the final answers, instead of spans or choices.", "example": "Convert the coordinate to text: [-10.2064  -1.8422]:"}
{"text": "Convert the coordinate to text: [ 6.0347 14.8318]: The authors present a multi-agent reinforcement learning (MARL) method for multi-order execution that treats each agent as an individual operator for one specific order, communicating and collaborating with others to maximize overall profits. This includes a new learnable multi-round communication protocol for transmitting intended actions among agents.", "target": "The authors present a multi-agent reinforcement learning (MARL) method for multi-order execution that treats each agent as an individual operator for one specific order, communicating and collaborating with others to maximize overall profits. This includes a new learnable multi-round communication protocol for transmitting intended actions among agents.", "example": "Convert the coordinate to text: [ 6.0347 14.8318]:"}
{"text": "Convert the coordinate to text: [-5.2691 -6.2629]: The authors propose a normalization strategy, implemented through NormNet, a pretrained language model-based network, to eliminate the false features caused by the textual surfaces of noun phrases. NormNet learns to replace as many noun phrases in the input sentence as possible with pre-defined base forms. The motivation behind this strategy is that the exact forms of noun phrases are often not as important for performing the final task.", "target": "The authors propose a normalization strategy, implemented through NormNet, a pretrained language model-based network, to eliminate the false features caused by the textual surfaces of noun phrases. NormNet learns to replace as many noun phrases in the input sentence as possible with pre-defined base forms. The motivation behind this strategy is that the exact forms of noun phrases are often not as important for performing the final task.", "example": "Convert the coordinate to text: [-5.2691 -6.2629]:"}
{"text": "Convert the coordinate to text: [ 2.1061 -0.6801]: In this paper, the authors propose two heuristic functions - AnnoHard and AnnoSoft, to compute the annotator ranking scores based on the hard (aggregative) labels and soft (cross-entropy) labels respectively. Introducing these scores allows them to adjust the weights of the training instances and improve learning when disagreements arise among annotators.", "target": "In this paper, the authors propose two heuristic functions - AnnoHard and AnnoSoft, to compute the annotator ranking scores based on the hard (aggregative) labels and soft (cross-entropy) labels respectively. Introducing these scores allows them to adjust the weights of the training instances and improve learning when disagreements arise among annotators.", "example": "Convert the coordinate to text: [ 2.1061 -0.6801]:"}
{"text": "Convert the coordinate to text: [-1.4238  0.1428]: The authors propose systems that use classical models, deep learning models, and transformer-based models for detecting online sexism. The intricate online language is addressed by utilizing TF-IDF with classical models, bidirectional models with embedding, and pre-trained transformer models.", "target": "The authors propose systems that use classical models, deep learning models, and transformer-based models for detecting online sexism. The intricate online language is addressed by utilizing TF-IDF with classical models, bidirectional models with embedding, and pre-trained transformer models.", "example": "Convert the coordinate to text: [-1.4238  0.1428]:"}
{"text": "Convert the coordinate to text: [-4.9462 -4.1257]: The authors propose an ensemble-based framework which combines various transfer learning techniques to overcome the challenges faced in multilingual coreference resolution. Moreover, they introduce a low-cost transfer learning method utilizing Wikipedia anchor texts, which naturally contain coreferential links.", "target": "The authors propose an ensemble-based framework which combines various transfer learning techniques to overcome the challenges faced in multilingual coreference resolution. Moreover, they introduce a low-cost transfer learning method utilizing Wikipedia anchor texts, which naturally contain coreferential links.", "example": "Convert the coordinate to text: [-4.9462 -4.1257]:"}
{"text": "Convert the coordinate to text: [-1.2596 -7.7279]: The authors introduce a two-stage fine-tuning approach for using knowledge learnt from different datasets in generative language models for radiology report summarization.", "target": "The authors introduce a two-stage fine-tuning approach for using knowledge learnt from different datasets in generative language models for radiology report summarization.", "example": "Convert the coordinate to text: [-1.2596 -7.7279]:"}
{"text": "Convert the coordinate to text: [ 0.233  -8.0699]: The authors propose a new, transferable framework called Contrastive Token-Wise Meta-learning (CtoML). This framework is designed to improve the generalization ability of visual temporal-aligned translation and applies meta-learning strategies directly in the image domain.", "target": "The authors propose a new, transferable framework called Contrastive Token-Wise Meta-learning (CtoML). This framework is designed to improve the generalization ability of visual temporal-aligned translation and applies meta-learning strategies directly in the image domain.", "example": "Convert the coordinate to text: [ 0.233  -8.0699]:"}
{"text": "Convert the coordinate to text: [-3.1091 -5.8455]: This paper proposes using random-word-substitution and random-label-matching as control tasks to reduce the biases present in traditional probing methods, thereby enhancing the robustness and accuracy of syntactic probing methods.", "target": "This paper proposes using random-word-substitution and random-label-matching as control tasks to reduce the biases present in traditional probing methods, thereby enhancing the robustness and accuracy of syntactic probing methods.", "example": "Convert the coordinate to text: [-3.1091 -5.8455]:"}
{"text": "Convert the coordinate to text: [-1.1312  0.2348]: The authors complement existing work by bridging the connection between language model predictions and people's social attitudes, particularly focusing on how the language model BERT reflects social attitudes about gender.", "target": "The authors complement existing work by bridging the connection between language model predictions and people's social attitudes, particularly focusing on how the language model BERT reflects social attitudes about gender.", "example": "Convert the coordinate to text: [-1.1312  0.2348]:"}
{"text": "Convert the coordinate to text: [-15.315    2.4254]: The authors propose a new framework called Anser, which enhances the design of traditional distributed data warehouses by embedding a new information sharing mechanism. This allows for the efficient management of the production and consumption of various dynamic information across the system.", "target": "The authors propose a new framework called Anser, which enhances the design of traditional distributed data warehouses by embedding a new information sharing mechanism. This allows for the efficient management of the production and consumption of various dynamic information across the system.", "example": "Convert the coordinate to text: [-15.315    2.4254]:"}
{"text": "Convert the coordinate to text: [3.727  3.8034]: The authors propose a method to alleviate this scalability problem by concentrating on improving predictive accuracy of significant properties or regions of dynamic systems, while comparatively reducing emphasis on the remaining aspects. They employ a two-stage prediction model that utilizes graph learning schemes and custom-designed modules, that operates in a reduced-dimensional mesh space.", "target": "The authors propose a method to alleviate this scalability problem by concentrating on improving predictive accuracy of significant properties or regions of dynamic systems, while comparatively reducing emphasis on the remaining aspects. They employ a two-stage prediction model that utilizes graph learning schemes and custom-designed modules, that operates in a reduced-dimensional mesh space.", "example": "Convert the coordinate to text: [3.727  3.8034]:"}
{"text": "Convert the coordinate to text: [ 4.6273 -9.751 ]: The authors introduce the 'Ordered Atomic Activity', a novel representation that decomposes a traffic scenario into a set of ordered atomic activities, each consisting of an action and the corresponding actors, with the order representing the temporal development of the scenario. They also collect a new dataset, OATS (Ordered Atomic Activities in interactive Traffic Scenarios).", "target": "The authors introduce the 'Ordered Atomic Activity', a novel representation that decomposes a traffic scenario into a set of ordered atomic activities, each consisting of an action and the corresponding actors, with the order representing the temporal development of the scenario. They also collect a new dataset, OATS (Ordered Atomic Activities in interactive Traffic Scenarios).", "example": "Convert the coordinate to text: [ 4.6273 -9.751 ]:"}
{"text": "Convert the coordinate to text: [2.8193 1.9813]: The paper proposes the use of textual outliers, replacing visual outliers with textual equivalents, for OoD detection and suggests various methods for generating preferable textual outliers.", "target": "The paper proposes the use of textual outliers, replacing visual outliers with textual equivalents, for OoD detection and suggests various methods for generating preferable textual outliers.", "example": "Convert the coordinate to text: [2.8193 1.9813]:"}
{"text": "Convert the coordinate to text: [ 7.6339 11.9968]: The proposes a semi-offline evaluation framework, where human users annotate unobserved counterfactual trajectories. Moreover, they design a family of OPE estimators based on importance sampling (IS) and a new weighting scheme which seamlessly incorporates these counterfactual annotations without introducing additional bias.", "target": "The proposes a semi-offline evaluation framework, where human users annotate unobserved counterfactual trajectories. Moreover, they design a family of OPE estimators based on importance sampling (IS) and a new weighting scheme which seamlessly incorporates these counterfactual annotations without introducing additional bias.", "example": "Convert the coordinate to text: [ 7.6339 11.9968]:"}
{"text": "Convert the coordinate to text: [11.8676  6.2714]: The authors have introduced the concept of 'virtual particles' to create novel stochastic approximations of population-limit SVGD dynamics in the probability measures space that can be realized using finite particles, leading to the development of two efficient SVGD variants, VP-SVGD and GB-SVGD, with provable fast finite-particle convergence rates.", "target": "The authors have introduced the concept of 'virtual particles' to create novel stochastic approximations of population-limit SVGD dynamics in the probability measures space that can be realized using finite particles, leading to the development of two efficient SVGD variants, VP-SVGD and GB-SVGD, with provable fast finite-particle convergence rates.", "example": "Convert the coordinate to text: [11.8676  6.2714]:"}
{"text": "Convert the coordinate to text: [4.4289 0.7602]: The authors propose the Generative Boosting Training (GBT) approach for PI which designs a boosting learning method for a single model based on the human learning process and utilizes a seq2seq model for dance augmentation on misclassified instances periodically.", "target": "The authors propose the Generative Boosting Training (GBT) approach for PI which designs a boosting learning method for a single model based on the human learning process and utilizes a seq2seq model for dance augmentation on misclassified instances periodically.", "example": "Convert the coordinate to text: [4.4289 0.7602]:"}
{"text": "Convert the coordinate to text: [-4.4406 -2.9798]: The paper investigates the disconnect between the performance of KBE models of WordNet on link prediction and their ability to encode semantic information, and questions the effectiveness of current evaluation protocols.", "target": "The paper investigates the disconnect between the performance of KBE models of WordNet on link prediction and their ability to encode semantic information, and questions the effectiveness of current evaluation protocols.", "example": "Convert the coordinate to text: [-4.4406 -2.9798]:"}
{"text": "Convert the coordinate to text: [-4.5422 -5.5286]: The paper introduces an annotation-free method for cultural-concept adaptation and a new multimodal data augmentation, CultureMixup, which leverages high-resource cultures to aid in comprehending low-resource cultures, thus addressing the issues of data scarcity and annotation costs.", "target": "The paper introduces an annotation-free method for cultural-concept adaptation and a new multimodal data augmentation, CultureMixup, which leverages high-resource cultures to aid in comprehending low-resource cultures, thus addressing the issues of data scarcity and annotation costs.", "example": "Convert the coordinate to text: [-4.5422 -5.5286]:"}
{"text": "Convert the coordinate to text: [8.9005 4.6839]: The paper proposes an alternative approach for Bayesian inference in neural networks by inferring a posterior distribution over functions, instead of parameters. This new method, called function-space variational inference, allows for incorporating prior information and leads to reliable predictive uncertainty estimates.", "target": "The paper proposes an alternative approach for Bayesian inference in neural networks by inferring a posterior distribution over functions, instead of parameters. This new method, called function-space variational inference, allows for incorporating prior information and leads to reliable predictive uncertainty estimates.", "example": "Convert the coordinate to text: [8.9005 4.6839]:"}
{"text": "Convert the coordinate to text: [10.9258  2.0269]: The paper introduces the concept of Latent Autoregressive Source Separation (LASS), a method to perform vector-quantized source separation without requiring additional gradient-based optimization or modifications to existing models.", "target": "The paper introduces the concept of Latent Autoregressive Source Separation (LASS), a method to perform vector-quantized source separation without requiring additional gradient-based optimization or modifications to existing models.", "example": "Convert the coordinate to text: [10.9258  2.0269]:"}
{"text": "Convert the coordinate to text: [-14.1084  11.1515]: The authors introduce the concept of 'integrative object', inspired by the work of philosopher Anne-Fran\u00e7oise Schmid, as a mean to align interdisciplinary collaboration with the requirements of the object of research itself.", "target": "The authors introduce the concept of 'integrative object', inspired by the work of philosopher Anne-Fran\u00e7oise Schmid, as a mean to align interdisciplinary collaboration with the requirements of the object of research itself.", "example": "Convert the coordinate to text: [-14.1084  11.1515]:"}
{"text": "Convert the coordinate to text: [-1.1083 -7.7894]: The authors introduce the Masked Trajectory Models (MTM), a versatile model designed to reconstruct trajectories based on randomly chosen subsets of the same trajectory, enabling it to function as either a forward dynamics model, inverse dynamics model, or offline RL agent by simply choosing appropriate masks.", "target": "The authors introduce the Masked Trajectory Models (MTM), a versatile model designed to reconstruct trajectories based on randomly chosen subsets of the same trajectory, enabling it to function as either a forward dynamics model, inverse dynamics model, or offline RL agent by simply choosing appropriate masks.", "example": "Convert the coordinate to text: [-1.1083 -7.7894]:"}
{"text": "Convert the coordinate to text: [ 0.7344 -3.773 ]: The paper characterizes two ways in which ICL leverages demonstrations, namely: Task Recognition (TR) which measures the extent that LLMs can recognize a task through demonstrations and apply their pre-trained priors; and Task Learning (TL), which is the ability to capture new input-label mappings that were not seen in pre-training.", "target": "The paper characterizes two ways in which ICL leverages demonstrations, namely: Task Recognition (TR) which measures the extent that LLMs can recognize a task through demonstrations and apply their pre-trained priors; and Task Learning (TL), which is the ability to capture new input-label mappings that were not seen in pre-training.", "example": "Convert the coordinate to text: [ 0.7344 -3.773 ]:"}
{"text": "Convert the coordinate to text: [ 5.9445 10.9928]: A novel method is proposed to construct an optimal policy for SiMT during online operation employing binary search.", "target": "A novel method is proposed to construct an optimal policy for SiMT during online operation employing binary search.", "example": "Convert the coordinate to text: [ 5.9445 10.9928]:"}
{"text": "Convert the coordinate to text: [-6.4243 -6.5739]: The authors present a new dataset, DEplain, of professionally written and manually aligned simplifications in plain German. It includes a news domain, a web-domain corpus, and a web harvester, and they are experimenting with automatic alignment methods to incorporate non-aligned and forthcoming parallel documents.", "target": "The authors present a new dataset, DEplain, of professionally written and manually aligned simplifications in plain German. It includes a news domain, a web-domain corpus, and a web harvester, and they are experimenting with automatic alignment methods to incorporate non-aligned and forthcoming parallel documents.", "example": "Convert the coordinate to text: [-6.4243 -6.5739]:"}
{"text": "Convert the coordinate to text: [ 0.1675 -9.4596]: The authors propose 'Conceptual Coverage Across Languages' (CoCo-CroLa), a benchmarking technique which assesses the 'conceptual coverage' of a text-to-image model in a target language relative to a source language.", "target": "The authors propose 'Conceptual Coverage Across Languages' (CoCo-CroLa), a benchmarking technique which assesses the 'conceptual coverage' of a text-to-image model in a target language relative to a source language.", "example": "Convert the coordinate to text: [ 0.1675 -9.4596]:"}
{"text": "Convert the coordinate to text: [-3.4521 -1.7126]: The authors propose treating event schemas as commonsense knowledge that can be derived from large language models, thus simplifying schema induction and enabling direct handling of hierarchical and temporal relations between events. A novel incremental prompting and verification method is introduced for constructing complex event graphs.", "target": "The authors propose treating event schemas as commonsense knowledge that can be derived from large language models, thus simplifying schema induction and enabling direct handling of hierarchical and temporal relations between events. A novel incremental prompting and verification method is introduced for constructing complex event graphs.", "example": "Convert the coordinate to text: [-3.4521 -1.7126]:"}
{"text": "Convert the coordinate to text: [-3.733  -6.6369]: The authors present the first study on automatic sentence polishing by adding modifiers. They propose a fine-tuned LongLM to reconstruct original sentences from 'corrupted' ones and a retrieval augmentation algorithm to prompt the model to add suitable modifiers.", "target": "The authors present the first study on automatic sentence polishing by adding modifiers. They propose a fine-tuned LongLM to reconstruct original sentences from 'corrupted' ones and a retrieval augmentation algorithm to prompt the model to add suitable modifiers.", "example": "Convert the coordinate to text: [-3.733  -6.6369]:"}
{"text": "Convert the coordinate to text: [ 1.3156 -8.3045]: The authors propose a Multi-View Calibration Network (MVCN) that aims to mitigate issues arising from modality heterogeneity in sentiment detection from multimodal posts. The network uses a text-guided fusion module with sparse attention, a sentiment-based congruity constraint task, and an adaptive loss calibration strategy.", "target": "The authors propose a Multi-View Calibration Network (MVCN) that aims to mitigate issues arising from modality heterogeneity in sentiment detection from multimodal posts. The network uses a text-guided fusion module with sparse attention, a sentiment-based congruity constraint task, and an adaptive loss calibration strategy.", "example": "Convert the coordinate to text: [ 1.3156 -8.3045]:"}
{"text": "Convert the coordinate to text: [8.7738 1.185 ]: The paper proposes to improve the effectiveness of RKME specification for Matching models and tasks in terms of heterogeneous label spaces by considering a class-specific model specification and a class-wise learnware identification method.", "target": "The paper proposes to improve the effectiveness of RKME specification for Matching models and tasks in terms of heterogeneous label spaces by considering a class-specific model specification and a class-wise learnware identification method.", "example": "Convert the coordinate to text: [8.7738 1.185 ]:"}
{"text": "Convert the coordinate to text: [ 2.3093 15.8948]: The authors examine perpetual voting rules from an axiomatic perspective, define two classes of perpetual voting rules that are easy to explain to voters, and explore the bounds imposed by simplicity. They also identify two rules with strong proportionality guarantees, although these are incompatible with each other.", "target": "The authors examine perpetual voting rules from an axiomatic perspective, define two classes of perpetual voting rules that are easy to explain to voters, and explore the bounds imposed by simplicity. They also identify two rules with strong proportionality guarantees, although these are incompatible with each other.", "example": "Convert the coordinate to text: [ 2.3093 15.8948]:"}
{"text": "Convert the coordinate to text: [  7.5658 -14.7245]: The authors introduce a new approach to image harmonization that uses global information to guide the transformation of foreground features and transfers foreground-background relationships from real to composite images for more effective adjustment.", "target": "The authors introduce a new approach to image harmonization that uses global information to guide the transformation of foreground features and transfers foreground-background relationships from real to composite images for more effective adjustment.", "example": "Convert the coordinate to text: [  7.5658 -14.7245]:"}
{"text": "Convert the coordinate to text: [  2.5167 -10.94  ]: The authors address the challenge by proposing a new problem of Panoptic Scene Graph Generation from Textual Descriptions (Caption-to-PSG), capitalizing on the large collection of freely available image-caption data on the web to generate these graphs.", "target": "The authors address the challenge by proposing a new problem of Panoptic Scene Graph Generation from Textual Descriptions (Caption-to-PSG), capitalizing on the large collection of freely available image-caption data on the web to generate these graphs.", "example": "Convert the coordinate to text: [  2.5167 -10.94  ]:"}
{"text": "Convert the coordinate to text: [7.468 7.16 ]: A series of DP-SignRP algorithms are proposed that leverage the robustness of the sign flipping probability of random projections for better utility. The concept of 'smooth flipping probability' is introduced.", "target": "A series of DP-SignRP algorithms are proposed that leverage the robustness of the sign flipping probability of random projections for better utility. The concept of 'smooth flipping probability' is introduced.", "example": "Convert the coordinate to text: [7.468 7.16 ]:"}
{"text": "Convert the coordinate to text: [13.3119  5.9907]: This paper introduces Riemannian SAM, a generalization of the conventional Euclidean SAM to Riemannian manifolds, enabling sharpness-aware minimization on such manifolds. This leads to a novel instantiation, Lorentz SAM, and the paper shows that past SAM variants can be derived as special examples within this framework.", "target": "This paper introduces Riemannian SAM, a generalization of the conventional Euclidean SAM to Riemannian manifolds, enabling sharpness-aware minimization on such manifolds. This leads to a novel instantiation, Lorentz SAM, and the paper shows that past SAM variants can be derived as special examples within this framework.", "example": "Convert the coordinate to text: [13.3119  5.9907]:"}
{"text": "Convert the coordinate to text: [ 6.4633 13.7225]: The authors propose a novel RL algorithm, HYbrid Policy Optimization (HYPO), which uses imperfect demonstrations to accelerate an agent's online learning process. This is done by training an offline 'guider' policy via imitation learning that instructs the online agent policy to explore efficiently.", "target": "The authors propose a novel RL algorithm, HYbrid Policy Optimization (HYPO), which uses imperfect demonstrations to accelerate an agent's online learning process. This is done by training an offline 'guider' policy via imitation learning that instructs the online agent policy to explore efficiently.", "example": "Convert the coordinate to text: [ 6.4633 13.7225]:"}
{"text": "Convert the coordinate to text: [11.8159 -2.3996]: This study aims to characterize the functions realized by shallow ReLU neural network denoisers in an interpolation setting with minimal representation cost. The authors study denoisers for both univariate and multivariate data under various geometric assumptions.", "target": "This study aims to characterize the functions realized by shallow ReLU neural network denoisers in an interpolation setting with minimal representation cost. The authors study denoisers for both univariate and multivariate data under various geometric assumptions.", "example": "Convert the coordinate to text: [11.8159 -2.3996]:"}
{"text": "Convert the coordinate to text: [-0.7971  6.8636]: The paper proposes 'MathPrompter', a technique designed to improve the performance of LLMs in arithmetic problem solving while increasing reliance on the predictions.", "target": "The paper proposes 'MathPrompter', a technique designed to improve the performance of LLMs in arithmetic problem solving while increasing reliance on the predictions.", "example": "Convert the coordinate to text: [-0.7971  6.8636]:"}
{"text": "Convert the coordinate to text: [ 2.1792 -9.8411]: A shift from solely discriminative models towards conceptualizing the text-video retrieval task from a generative viewpoint is proposed through the means of a diffusion-based text-video retrieval framework called DiffusionRet. The correlation between text and video is modeled as their joint probability as opposed to simply conditioning on the query.", "target": "A shift from solely discriminative models towards conceptualizing the text-video retrieval task from a generative viewpoint is proposed through the means of a diffusion-based text-video retrieval framework called DiffusionRet. The correlation between text and video is modeled as their joint probability as opposed to simply conditioning on the query.", "example": "Convert the coordinate to text: [ 2.1792 -9.8411]:"}
{"text": "Convert the coordinate to text: [ 0.2142 -6.8421]: The paper proposes a new approach called ReMask, a domain obfuscation method that operates in three steps: frequency and attention norm-based masking to obscure domain-specific cues and unmasking to regain the domain generic context.", "target": "The paper proposes a new approach called ReMask, a domain obfuscation method that operates in three steps: frequency and attention norm-based masking to obscure domain-specific cues and unmasking to regain the domain generic context.", "example": "Convert the coordinate to text: [ 0.2142 -6.8421]:"}
{"text": "Convert the coordinate to text: [-13.1209   1.0358]: The authors introduce a new interaction mechanism that allows users to directly edit a step-by-step explanation of a SQL query, enabling them to correct errors.", "target": "The authors introduce a new interaction mechanism that allows users to directly edit a step-by-step explanation of a SQL query, enabling them to correct errors.", "example": "Convert the coordinate to text: [-13.1209   1.0358]:"}
{"text": "Convert the coordinate to text: [-1.887  -6.5409]: The authors propose DarkBERT, a language model specifically pre-trained on Dark Web language data with steps taken to filter and compile the text to minimize the impact of extreme lexical and structural diversity of the Dark Web.", "target": "The authors propose DarkBERT, a language model specifically pre-trained on Dark Web language data with steps taken to filter and compile the text to minimize the impact of extreme lexical and structural diversity of the Dark Web.", "example": "Convert the coordinate to text: [-1.887  -6.5409]:"}
{"text": "Convert the coordinate to text: [-1.672  -6.4522]: The authors present an approach for the SemEval task that utilizes transformer-based models for training until they reach their loss minimum or f1-score maximum and an ensembling method using one global decision threshold to maximize the f1-score.", "target": "The authors present an approach for the SemEval task that utilizes transformer-based models for training until they reach their loss minimum or f1-score maximum and an ensembling method using one global decision threshold to maximize the f1-score.", "example": "Convert the coordinate to text: [-1.672  -6.4522]:"}
{"text": "Convert the coordinate to text: [12.6873 -5.1152]: The authors propose ATINTER, a language model that learns to rewrite adversarial inputs to make them non-adversarial for a downstream text classifier and does not require retraining for new task settings.", "target": "The authors propose ATINTER, a language model that learns to rewrite adversarial inputs to make them non-adversarial for a downstream text classifier and does not require retraining for new task settings.", "example": "Convert the coordinate to text: [12.6873 -5.1152]:"}
{"text": "Convert the coordinate to text: [-9.2698  0.0471]: The authors introduce a novel QE system called Event-Centric Query Expansion (EQE) that aims to mine the best expansion from a significant amount of potential events rapidly and accurately, resolving issues with slow updates and sub-par performance in news searches.", "target": "The authors introduce a novel QE system called Event-Centric Query Expansion (EQE) that aims to mine the best expansion from a significant amount of potential events rapidly and accurately, resolving issues with slow updates and sub-par performance in news searches.", "example": "Convert the coordinate to text: [-9.2698  0.0471]:"}
{"text": "Convert the coordinate to text: [ 0.8678 -5.1743]: The stance detection task is decomposed from a linguistic perspective, and the relationship between explicit and implicit objects is characterized in an expansion of the previously proposed stance triangle linguistic framework. The expanded framework guides the task completion by extending a single training corpus with additional annotation.", "target": "The stance detection task is decomposed from a linguistic perspective, and the relationship between explicit and implicit objects is characterized in an expansion of the previously proposed stance triangle linguistic framework. The expanded framework guides the task completion by extending a single training corpus with additional annotation.", "example": "Convert the coordinate to text: [ 0.8678 -5.1743]:"}
{"text": "Convert the coordinate to text: [-2.2134 11.8141]: The authors introduce SymbolicToM, a plug-and-play approach that enhances the theory of mind capacities of 'off-the-shelf' neural language models without the need for explicit supervision. This is achieved by employing a symbolic representation to reason about the belief states of multiple characters in reading comprehension tasks.", "target": "The authors introduce SymbolicToM, a plug-and-play approach that enhances the theory of mind capacities of 'off-the-shelf' neural language models without the need for explicit supervision. This is achieved by employing a symbolic representation to reason about the belief states of multiple characters in reading comprehension tasks.", "example": "Convert the coordinate to text: [-2.2134 11.8141]:"}
{"text": "Convert the coordinate to text: [ 4.5752 -4.6463]: This paper proposes a similarity-preserving adversarial graph contrastive learning (SP-AGCL) framework. The key idea is to contrast the clean graph with two auxiliary views of different properties, specifically the node similarity-preserving view and the adversarial view.", "target": "This paper proposes a similarity-preserving adversarial graph contrastive learning (SP-AGCL) framework. The key idea is to contrast the clean graph with two auxiliary views of different properties, specifically the node similarity-preserving view and the adversarial view.", "example": "Convert the coordinate to text: [ 4.5752 -4.6463]:"}
{"text": "Convert the coordinate to text: [  0.5683 -15.078 ]: The authors propose fMRI2text, the first open-vocabulary task that creates a bridge between fMRI time series and human language. Additionally, they present a baseline solution named UniCoRN (Unified Cognitive Signal ReconstructioN for Brain Decoding), which reconstructs both individual time-points and time series, establishing a robust encoder for cognitive signals (fMRI & EEG).", "target": "The authors propose fMRI2text, the first open-vocabulary task that creates a bridge between fMRI time series and human language. Additionally, they present a baseline solution named UniCoRN (Unified Cognitive Signal ReconstructioN for Brain Decoding), which reconstructs both individual time-points and time series, establishing a robust encoder for cognitive signals (fMRI & EEG).", "example": "Convert the coordinate to text: [  0.5683 -15.078 ]:"}
{"text": "Convert the coordinate to text: [-1.8062 -6.4216]: The authors propose an approach that integrates well-known models - BERT, ERNIE2.0, RoBERTA and XLNet, and applies fine tuning, to enhance the detection of human values behind arguments.", "target": "The authors propose an approach that integrates well-known models - BERT, ERNIE2.0, RoBERTA and XLNet, and applies fine tuning, to enhance the detection of human values behind arguments.", "example": "Convert the coordinate to text: [-1.8062 -6.4216]:"}
{"text": "Convert the coordinate to text: [-2.3158 -5.5043]: The authors investigate the effectiveness of existing pre-trained language models in generating lay summaries.", "target": "The authors investigate the effectiveness of existing pre-trained language models in generating lay summaries.", "example": "Convert the coordinate to text: [-2.3158 -5.5043]:"}
{"text": "Convert the coordinate to text: [-6.2788 -9.9516]: The authors propose an end-to-end framework that Leverages Error Type (LET) information in the generation process.", "target": "The authors propose an end-to-end framework that Leverages Error Type (LET) information in the generation process.", "example": "Convert the coordinate to text: [-6.2788 -9.9516]:"}
{"text": "Convert the coordinate to text: [-2.3163 -4.5054]: The paper introduces Tab-Cleaner, a model designed to handle error detection over text-rich tabular data following a pre-training / fine-tuning paradigm.", "target": "The paper introduces Tab-Cleaner, a model designed to handle error detection over text-rich tabular data following a pre-training / fine-tuning paradigm.", "example": "Convert the coordinate to text: [-2.3163 -4.5054]:"}
{"text": "Convert the coordinate to text: [-5.6729  0.8477]: The paper introduces the task of environmental claim detection and releases an expert-annotated dataset for this task.", "target": "The paper introduces the task of environmental claim detection and releases an expert-annotated dataset for this task.", "example": "Convert the coordinate to text: [-5.6729  0.8477]:"}
{"text": "Convert the coordinate to text: [-5.9686 -0.806 ]: The authors introduce CSJ as a downstream task of text simplification and cross-lingual scientific summarization, and propose combining three components - SELECT, SIMPLIFY and REWRITE (SSR) - to produce cross-lingual, simplified science summaries for non-expert readers.", "target": "The authors introduce CSJ as a downstream task of text simplification and cross-lingual scientific summarization, and propose combining three components - SELECT, SIMPLIFY and REWRITE (SSR) - to produce cross-lingual, simplified science summaries for non-expert readers.", "example": "Convert the coordinate to text: [-5.9686 -0.806 ]:"}
{"text": "Convert the coordinate to text: [-13.4735   0.2233]: The authors propose a novel system, QueryBooster, to support SQL query rewriting as a cloud service. It allows users to formulate rewriting rules via a language or express rewriting intentions by providing example query pairs, share rewriting knowledge among multiple users, and requires no modifications to applications or databases.", "target": "The authors propose a novel system, QueryBooster, to support SQL query rewriting as a cloud service. It allows users to formulate rewriting rules via a language or express rewriting intentions by providing example query pairs, share rewriting knowledge among multiple users, and requires no modifications to applications or databases.", "example": "Convert the coordinate to text: [-13.4735   0.2233]:"}
{"text": "Convert the coordinate to text: [ 11.3938 -13.2944]: The authors propose TEMPO, a multi-view pose estimation model that learns robust spatiotemporal representation to improve pose estimation accuracy, track and forecast human pose.", "target": "The authors propose TEMPO, a multi-view pose estimation model that learns robust spatiotemporal representation to improve pose estimation accuracy, track and forecast human pose.", "example": "Convert the coordinate to text: [ 11.3938 -13.2944]:"}
{"text": "Convert the coordinate to text: [ 3.9369 -3.9591]: The authors introduce the concept of distillation space and propose the idea of few-shot dataset distillation, where a distilled dataset is synthesized with only a few or even a single network. The synthetic data optimized only in the distillation space can achieve the effect of those optimized through numerous neural networks, reducing training time and computational costs.", "target": "The authors introduce the concept of distillation space and propose the idea of few-shot dataset distillation, where a distilled dataset is synthesized with only a few or even a single network. The synthetic data optimized only in the distillation space can achieve the effect of those optimized through numerous neural networks, reducing training time and computational costs.", "example": "Convert the coordinate to text: [ 3.9369 -3.9591]:"}
{"text": "Convert the coordinate to text: [ 12.8183 -18.4622]: The authors propose the first Non-coaxial Event-guided Image Deblurring (NEID) method which utilizes the camera setup composed of a standard frame-based camera with a non-coaxial single event camera. This new approach allows per-pixel alignment between the image and event without additional devices.", "target": "The authors propose the first Non-coaxial Event-guided Image Deblurring (NEID) method which utilizes the camera setup composed of a standard frame-based camera with a non-coaxial single event camera. This new approach allows per-pixel alignment between the image and event without additional devices.", "example": "Convert the coordinate to text: [ 12.8183 -18.4622]:"}
{"text": "Convert the coordinate to text: [-2.599  -5.6093]: To mitigate these issues, the authors propose an open-source ecosystem for developing and testing LLMs, aiming to boost open alternatives to closed-source approaches. They release a family of fine-tuned LLMs, h2oGPT, ranging from 7 to 70 Billion parameters.", "target": "To mitigate these issues, the authors propose an open-source ecosystem for developing and testing LLMs, aiming to boost open alternatives to closed-source approaches. They release a family of fine-tuned LLMs, h2oGPT, ranging from 7 to 70 Billion parameters.", "example": "Convert the coordinate to text: [-2.599  -5.6093]:"}
{"text": "Convert the coordinate to text: [ 6.76   13.6095]: A new framework called Family Offline-to-Online RL (FamO2O) is presented that empowers existing algorithms to determine state-adaptive improvement-constraint balances and utilizes a universal model to train a family of policies with different improvement/constraint intensities.", "target": "A new framework called Family Offline-to-Online RL (FamO2O) is presented that empowers existing algorithms to determine state-adaptive improvement-constraint balances and utilizes a universal model to train a family of policies with different improvement/constraint intensities.", "example": "Convert the coordinate to text: [ 6.76   13.6095]:"}
{"text": "Convert the coordinate to text: [ 14.8165 -15.0434]: The authors propose UP-NeRF (Unconstrained Pose-prior-free Neural Radiance Fields), designed to optimize NeRF with unconstrained image collections without camera pose prior. UP-NeRF uses surrogate tasks and a separate module for transient occluders, alongside a candidate head for robust pose estimation and transient-aware depth supervision.", "target": "The authors propose UP-NeRF (Unconstrained Pose-prior-free Neural Radiance Fields), designed to optimize NeRF with unconstrained image collections without camera pose prior. UP-NeRF uses surrogate tasks and a separate module for transient occluders, alongside a candidate head for robust pose estimation and transient-aware depth supervision.", "example": "Convert the coordinate to text: [ 14.8165 -15.0434]:"}
{"text": "Convert the coordinate to text: [ 5.4016 -9.0169]: This paper proposes STREAMER, an architecture for hierarchical representation learning and segmentation of perceptual inputs in a streaming fashion. It is trained layer-by-layer and its primary objectives are to make accurate predictions into the future and provide necessary information to other levels for achieving the same objective.", "target": "This paper proposes STREAMER, an architecture for hierarchical representation learning and segmentation of perceptual inputs in a streaming fashion. It is trained layer-by-layer and its primary objectives are to make accurate predictions into the future and provide necessary information to other levels for achieving the same objective.", "example": "Convert the coordinate to text: [ 5.4016 -9.0169]:"}
{"text": "Convert the coordinate to text: [ 12.7097 -16.5806]: The authors propose continuous parametric optical flow, a representation of dense and continuous motion over arbitrary time intervals, employing B-splines to fit point trajectories and a neural ordinary differential equation (ODE) to represent features associated with specific times.", "target": "The authors propose continuous parametric optical flow, a representation of dense and continuous motion over arbitrary time intervals, employing B-splines to fit point trajectories and a neural ordinary differential equation (ODE) to represent features associated with specific times.", "example": "Convert the coordinate to text: [ 12.7097 -16.5806]:"}
{"text": "Convert the coordinate to text: [ 7.6649 -0.9257]: The paper seeks to understand the intrinsic relationships between competing sampling strategies in network embedding and identifies two properties - discrimination and monotonicity - that node embeddings should embrace.", "target": "The paper seeks to understand the intrinsic relationships between competing sampling strategies in network embedding and identifies two properties - discrimination and monotonicity - that node embeddings should embrace.", "example": "Convert the coordinate to text: [ 7.6649 -0.9257]:"}
{"text": "Convert the coordinate to text: [ -0.9809 -12.9337]: This paper proposes the Implicit AutoEncoder (IAE), a self-supervised 3D representation learning method that addresses the sampling variation issue by replacing the point-cloud decoder with an implicit decoder. This decoder reconstructs a continuous representation of the 3D shape, independent of any imperfections in the discrete samples.", "target": "This paper proposes the Implicit AutoEncoder (IAE), a self-supervised 3D representation learning method that addresses the sampling variation issue by replacing the point-cloud decoder with an implicit decoder. This decoder reconstructs a continuous representation of the 3D shape, independent of any imperfections in the discrete samples.", "example": "Convert the coordinate to text: [ -0.9809 -12.9337]:"}
{"text": "Convert the coordinate to text: [ 5.916  -9.9309]: The authors introduce Spatio-temporal Crop Aggregation for video representation LEarning (SCALE), a scalable method that builds long-range video features from sets of video clip-level features extracted with a pre-trained backbone. They implement a self-supervised objective consisting of masked clip feature prediction.", "target": "The authors introduce Spatio-temporal Crop Aggregation for video representation LEarning (SCALE), a scalable method that builds long-range video features from sets of video clip-level features extracted with a pre-trained backbone. They implement a self-supervised objective consisting of masked clip feature prediction.", "example": "Convert the coordinate to text: [ 5.916  -9.9309]:"}
{"text": "Convert the coordinate to text: [12.1359 -6.5605]: The authors introduce a new adversarial training framework for image inpainting entailing segmentation confusion adversarial training (SCAT) and contrastive learning. SCAT creates an adversarial dynamic between an inpainting generator and a segmentation network.", "target": "The authors introduce a new adversarial training framework for image inpainting entailing segmentation confusion adversarial training (SCAT) and contrastive learning. SCAT creates an adversarial dynamic between an inpainting generator and a segmentation network.", "example": "Convert the coordinate to text: [12.1359 -6.5605]:"}
{"text": "Convert the coordinate to text: [11.3955  6.1979]: The authors propose ReinMax, a novel method that approximates the gradient of parameters in discrete latent variables by leveraging Heun's Method, a second-order numerical method for solving ODEs.", "target": "The authors propose ReinMax, a novel method that approximates the gradient of parameters in discrete latent variables by leveraging Heun's Method, a second-order numerical method for solving ODEs.", "example": "Convert the coordinate to text: [11.3955  6.1979]:"}
{"text": "Convert the coordinate to text: [-1.5926 -8.5447]: The authors propose a new model that combines the strengths of both Transducer and Attention based Encoder-Decoder (TAED) models for speech-to-text tasks, replacing the predictor in the Transducer with the decoder in the AED model and conditioning the outputs of the decoder on the speech inputs.", "target": "The authors propose a new model that combines the strengths of both Transducer and Attention based Encoder-Decoder (TAED) models for speech-to-text tasks, replacing the predictor in the Transducer with the decoder in the AED model and conditioning the outputs of the decoder on the speech inputs.", "example": "Convert the coordinate to text: [-1.5926 -8.5447]:"}
{"text": "Convert the coordinate to text: [-1.291  -3.0699]: The authors propose Decker, a model for commonsense fact verification that leverages both structured and unstructured knowledge by revealing latent relationships between the two.", "target": "The authors propose Decker, a model for commonsense fact verification that leverages both structured and unstructured knowledge by revealing latent relationships between the two.", "example": "Convert the coordinate to text: [-1.291  -3.0699]:"}
{"text": "Convert the coordinate to text: [-3.5458 -9.1418]: The authors propose a novel approach to SLT, the Gloss-Free End-to-End sign language translation framework (GloFE), which improves the result by leveraging the underlying semantics of signs and their spoken translations, instead of using gloss annotations.", "target": "The authors propose a novel approach to SLT, the Gloss-Free End-to-End sign language translation framework (GloFE), which improves the result by leveraging the underlying semantics of signs and their spoken translations, instead of using gloss annotations.", "example": "Convert the coordinate to text: [-3.5458 -9.1418]:"}
{"text": "Convert the coordinate to text: [-1.6095 -4.7072]: The authors propose a new paradigm of plug-and-play knowledge injection, where knowledge bases are injected into existing, unmodified downstream models using a knowledge plugin, and they introduce a plug-and-play injection method called map-tuning.", "target": "The authors propose a new paradigm of plug-and-play knowledge injection, where knowledge bases are injected into existing, unmodified downstream models using a knowledge plugin, and they introduce a plug-and-play injection method called map-tuning.", "example": "Convert the coordinate to text: [-1.6095 -4.7072]:"}
{"text": "Convert the coordinate to text: [-5.7202 10.4832]: The authors identify the challenge of helping patients clarify their medical consultation goals, and propose a new task along with a human-to-human mixed-type medical consultation dialogue corpus, MidMed. They also introduce a medical dialogue generation framework, InsMed, to tackle this task.", "target": "The authors identify the challenge of helping patients clarify their medical consultation goals, and propose a new task along with a human-to-human mixed-type medical consultation dialogue corpus, MidMed. They also introduce a medical dialogue generation framework, InsMed, to tackle this task.", "example": "Convert the coordinate to text: [-5.7202 10.4832]:"}
{"text": "Convert the coordinate to text: [-2.5609 -8.184 ]: This paper presents LeakDistill, a model and method that modifies the Transformer architecture by using structural adapters to explicitly incorporate graph information into the learned representations to improve AMR parsing performance.", "target": "This paper presents LeakDistill, a model and method that modifies the Transformer architecture by using structural adapters to explicitly incorporate graph information into the learned representations to improve AMR parsing performance.", "example": "Convert the coordinate to text: [-2.5609 -8.184 ]:"}
{"text": "Convert the coordinate to text: [-8.3231 -5.4034]: The authors propose a syntactic approach for handling deverbal nouns that maps the arguments of deverbal nouns to the universal-dependency relations of the corresponding verbal construction.", "target": "The authors propose a syntactic approach for handling deverbal nouns that maps the arguments of deverbal nouns to the universal-dependency relations of the corresponding verbal construction.", "example": "Convert the coordinate to text: [-8.3231 -5.4034]:"}
{"text": "Convert the coordinate to text: [-1.3902  0.0806]: The authors use a multi-task learning approach where models share representations for all three tasks of sexism detection, allowing knowledge to be shared across tasks. They incorporate inter-annotator agreement information into the multi-task architecture, estimating it using a 5-classifier ensemble.", "target": "The authors use a multi-task learning approach where models share representations for all three tasks of sexism detection, allowing knowledge to be shared across tasks. They incorporate inter-annotator agreement information into the multi-task architecture, estimating it using a 5-classifier ensemble.", "example": "Convert the coordinate to text: [-1.3902  0.0806]:"}
{"text": "Convert the coordinate to text: [-9.843  -1.9076]: The authors propose a new approach based on prompt-based learning to handle the task's complications. They tackle the problem as a ranking problem using a seq2seq framework, and as an extractive question-answering task.", "target": "The authors propose a new approach based on prompt-based learning to handle the task's complications. They tackle the problem as a ranking problem using a seq2seq framework, and as an extractive question-answering task.", "example": "Convert the coordinate to text: [-9.843  -1.9076]:"}
{"text": "Convert the coordinate to text: [-3.6987 -9.0753]: The authors' submissions to the IWSLT use cascaded architectures models in all three conditions (constrained training, constrained with large language models training, and unconstrained training). They use data enhancement, pre-training models and other means to improve the ASR quality, and use R-Drop, deep model, domain data selection, etc. to improve the translation quality.", "target": "The authors' submissions to the IWSLT use cascaded architectures models in all three conditions (constrained training, constrained with large language models training, and unconstrained training). They use data enhancement, pre-training models and other means to improve the ASR quality, and use R-Drop, deep model, domain data selection, etc. to improve the translation quality.", "example": "Convert the coordinate to text: [-3.6987 -9.0753]:"}
{"text": "Convert the coordinate to text: [-0.3075 -4.7537]: The authors present a schema-aware end-to-end neural network model for handling task-oriented dialogues that can address a dynamic set of slots within different types of schemas, enabling better generalizability among services and domains.", "target": "The authors present a schema-aware end-to-end neural network model for handling task-oriented dialogues that can address a dynamic set of slots within different types of schemas, enabling better generalizability among services and domains.", "example": "Convert the coordinate to text: [-0.3075 -4.7537]:"}
{"text": "Convert the coordinate to text: [  1.4063 -12.0294]: The authors introduce pixel retrieval, an extension of image retrieval that helps users quickly identify the query object in true positive images and exclude false positive images by marking the correlated pixels.", "target": "The authors introduce pixel retrieval, an extension of image retrieval that helps users quickly identify the query object in true positive images and exclude false positive images by marking the correlated pixels.", "example": "Convert the coordinate to text: [  1.4063 -12.0294]:"}
{"text": "Convert the coordinate to text: [ 11.4616 -18.5138]: The authors introduce a concept of the 'quintessential matrix', a 4x4 matrix embedded from a 3x3 essential matrix, and propose a novel method to estimate this matrix using semidefinite relaxations, bringing into play relations with 4-D rotations, quaternions and the twisted-pair ambiguity in two-view SfM.", "target": "The authors introduce a concept of the 'quintessential matrix', a 4x4 matrix embedded from a 3x3 essential matrix, and propose a novel method to estimate this matrix using semidefinite relaxations, bringing into play relations with 4-D rotations, quaternions and the twisted-pair ambiguity in two-view SfM.", "example": "Convert the coordinate to text: [ 11.4616 -18.5138]:"}
{"text": "Convert the coordinate to text: [-3.4839 -6.4065]: The paper introduces a novel contrastive unlikelihood objective (COUNT) for text detoxification, which contrasts the reference rephrase with the direct input-to-output mapping to emphasis learning on non-toxic style transfer.", "target": "The paper introduces a novel contrastive unlikelihood objective (COUNT) for text detoxification, which contrasts the reference rephrase with the direct input-to-output mapping to emphasis learning on non-toxic style transfer.", "example": "Convert the coordinate to text: [-3.4839 -6.4065]:"}
{"text": "Convert the coordinate to text: [4.6449 7.988 ]: The study proposes a new method to significantly improve the asymptotic bounds of the state-of-the-art evaluation algorithms for threshold queries.", "target": "The study proposes a new method to significantly improve the asymptotic bounds of the state-of-the-art evaluation algorithms for threshold queries.", "example": "Convert the coordinate to text: [4.6449 7.988 ]:"}
{"text": "Convert the coordinate to text: [ 8.8815 -6.7177]: The authors find that in state-of-the-art convolutional neural networks, when the last hidden representation is sufficiently wide, its neurons tend to form groups carrying identical information, differing only by statistically independent noise. The occurrence of these groups is noted to increase linearly with the width of the layer, beyond a critical value.", "target": "The authors find that in state-of-the-art convolutional neural networks, when the last hidden representation is sufficiently wide, its neurons tend to form groups carrying identical information, differing only by statistically independent noise. The occurrence of these groups is noted to increase linearly with the width of the layer, beyond a critical value.", "example": "Convert the coordinate to text: [ 8.8815 -6.7177]:"}
{"text": "Convert the coordinate to text: [11.8882 -2.4377]: The research delves into a setting where the data consists of clusters and the correlations between cluster means are small and explores how in two-layer ReLU networks gradient flow is biased towards solutions that generalize well, but are highly vulnerable to adversarial examples.", "target": "The research delves into a setting where the data consists of clusters and the correlations between cluster means are small and explores how in two-layer ReLU networks gradient flow is biased towards solutions that generalize well, but are highly vulnerable to adversarial examples.", "example": "Convert the coordinate to text: [11.8882 -2.4377]:"}
{"text": "Convert the coordinate to text: [-8.7299 -2.7058]: The authors aim to quantify and characterize the presence and impact of industry, particularly big tech companies, in the NLP community over time.", "target": "The authors aim to quantify and characterize the presence and impact of industry, particularly big tech companies, in the NLP community over time.", "example": "Convert the coordinate to text: [-8.7299 -2.7058]:"}
{"text": "Convert the coordinate to text: [-4.5396 12.5333]: The study focuses on the teachers' perspective on implementing an AI education curriculum, particularly emphasizing on fostering inclusion and accessibility in disadvantaged areas of Europe.", "target": "The study focuses on the teachers' perspective on implementing an AI education curriculum, particularly emphasizing on fostering inclusion and accessibility in disadvantaged areas of Europe.", "example": "Convert the coordinate to text: [-4.5396 12.5333]:"}
{"text": "Convert the coordinate to text: [-2.9083 -5.7476]: The study introduces LIMA, a 65B parameter LLaMa language model that is trained only with 1,000 carefully curated prompts and responses using a standard supervised loss, completely bypassing reinforcement learning or human preference modeling.", "target": "The study introduces LIMA, a 65B parameter LLaMa language model that is trained only with 1,000 carefully curated prompts and responses using a standard supervised loss, completely bypassing reinforcement learning or human preference modeling.", "example": "Convert the coordinate to text: [-2.9083 -5.7476]:"}
{"text": "Convert the coordinate to text: [-3.5404 -5.1788]: The paper introduces an open-vocabulary language model that uses a hierarchical two-level approach: one at the word level, another at the sequence level. This model directly operates on character sequences with explicit awareness of word boundaries, without the need for biased sub-word or word-level vocabulary.", "target": "The paper introduces an open-vocabulary language model that uses a hierarchical two-level approach: one at the word level, another at the sequence level. This model directly operates on character sequences with explicit awareness of word boundaries, without the need for biased sub-word or word-level vocabulary.", "example": "Convert the coordinate to text: [-3.5404 -5.1788]:"}
{"text": "Convert the coordinate to text: [ 4.4067 -1.0098]: To enhance data diversity and maintain accuracy in LLM-based text data generation, this study proposes two different human interventions: label replacement (LR), which corrects misaligned labels, and out-of-scope filtering (OOSF), which removes instances that fall out of the target domain.", "target": "To enhance data diversity and maintain accuracy in LLM-based text data generation, this study proposes two different human interventions: label replacement (LR), which corrects misaligned labels, and out-of-scope filtering (OOSF), which removes instances that fall out of the target domain.", "example": "Convert the coordinate to text: [ 4.4067 -1.0098]:"}
{"text": "Convert the coordinate to text: [-9.0236  6.8746]: The authors aim to evaluate the level of evidence supporting the aforementioned observation by surveying over 30 studies that explore this relation using various datasets and metrics.", "target": "The authors aim to evaluate the level of evidence supporting the aforementioned observation by surveying over 30 studies that explore this relation using various datasets and metrics.", "example": "Convert the coordinate to text: [-9.0236  6.8746]:"}
{"text": "Convert the coordinate to text: [-8.6671 -5.0849]: The authors propose a new PropBank dataset that includes a wide coverage of multiple predicate types and present a novel, manually-annotated challenge set designed to give equal importance to verbal, nominal and adjectival predicate-argument structures.", "target": "The authors propose a new PropBank dataset that includes a wide coverage of multiple predicate types and present a novel, manually-annotated challenge set designed to give equal importance to verbal, nominal and adjectival predicate-argument structures.", "example": "Convert the coordinate to text: [-8.6671 -5.0849]:"}
{"text": "Convert the coordinate to text: [-6.4872 10.7584]: This study addresses the feasibility of users interrupting their dictation with spoken editing commands in open-ended natural language and introduces a new task and dataset, TERTiUS, to experiment with such systems.", "target": "This study addresses the feasibility of users interrupting their dictation with spoken editing commands in open-ended natural language and introduces a new task and dataset, TERTiUS, to experiment with such systems.", "example": "Convert the coordinate to text: [-6.4872 10.7584]:"}
{"text": "Convert the coordinate to text: [-2.3103 -7.5932]: The authors propose to use pre-trained masked language models (MLMs) in combination with an iterative non-autoregressive (NAR) decoding strategy to improve the inference efficiency in Open-LTG. They introduce two strategies, dynamic sliding window attention (DSWA) and linear temperature decay (LTD), to boost the long text generation capabilities of MLMs.", "target": "The authors propose to use pre-trained masked language models (MLMs) in combination with an iterative non-autoregressive (NAR) decoding strategy to improve the inference efficiency in Open-LTG. They introduce two strategies, dynamic sliding window attention (DSWA) and linear temperature decay (LTD), to boost the long text generation capabilities of MLMs.", "example": "Convert the coordinate to text: [-2.3103 -7.5932]:"}
{"text": "Convert the coordinate to text: [-1.8146 -6.7729]: The authors discovered that pre-processing techniques do not improve learning performance for multilingual intimacy analysis, and fine-tuning a transformer-based model does not provide advantages over using the pre-trained model to generate text embeddings and using them to train simpler and more efficient models such as MLPs.", "target": "The authors discovered that pre-processing techniques do not improve learning performance for multilingual intimacy analysis, and fine-tuning a transformer-based model does not provide advantages over using the pre-trained model to generate text embeddings and using them to train simpler and more efficient models such as MLPs.", "example": "Convert the coordinate to text: [-1.8146 -6.7729]:"}
{"text": "Convert the coordinate to text: [-2.7681 -0.9892]: The authors propose SeededNTM, a neural topic model enhanced with supervisions from seed words at both word and document levels, introducing a context-dependency assumption to deal with ambiguities, an auto-adaptation mechanism to balance multi-level information, and an intra-sample consistency regularizer to manage noisy supervisions.", "target": "The authors propose SeededNTM, a neural topic model enhanced with supervisions from seed words at both word and document levels, introducing a context-dependency assumption to deal with ambiguities, an auto-adaptation mechanism to balance multi-level information, and an intra-sample consistency regularizer to manage noisy supervisions.", "example": "Convert the coordinate to text: [-2.7681 -0.9892]:"}
{"text": "Convert the coordinate to text: [-4.255  -6.0629]: The authors propose a novel neural-network-based reference-free TS metric BETS, leveraging pre-trained contextualized language representation models and large-scale paraphrasing datasets to evaluate simplicity and meaning preservation.", "target": "The authors propose a novel neural-network-based reference-free TS metric BETS, leveraging pre-trained contextualized language representation models and large-scale paraphrasing datasets to evaluate simplicity and meaning preservation.", "example": "Convert the coordinate to text: [-4.255  -6.0629]:"}
{"text": "Convert the coordinate to text: [ 0.8111 -3.8545]: The paper introduces PLAT, a novel framework for EWS that creates weak labels by utilizing recent developments in zero-shot text classification. Notably, PLAT adopts models trained for other sub-tasks to label documents and avoids assigning overly confident weak labels.", "target": "The paper introduces PLAT, a novel framework for EWS that creates weak labels by utilizing recent developments in zero-shot text classification. Notably, PLAT adopts models trained for other sub-tasks to label documents and avoids assigning overly confident weak labels.", "example": "Convert the coordinate to text: [ 0.8111 -3.8545]:"}
{"text": "Convert the coordinate to text: [-7.8167 -1.9864]: An annotation approach is proposed that captures the structured components and arguments in legal case solutions of German students, based on the appraisal style of writing in German law.", "target": "An annotation approach is proposed that captures the structured components and arguments in legal case solutions of German students, based on the appraisal style of writing in German law.", "example": "Convert the coordinate to text: [-7.8167 -1.9864]:"}
{"text": "Convert the coordinate to text: [-2.4103 -4.7516]: To tackle these challenges, the authors propose a multi-span extraction model that incorporates continual pre-training and multi-task learning schemes for improved performance on conversation-based QAs.", "target": "To tackle these challenges, the authors propose a multi-span extraction model that incorporates continual pre-training and multi-task learning schemes for improved performance on conversation-based QAs.", "example": "Convert the coordinate to text: [-2.4103 -4.7516]:"}
{"text": "Convert the coordinate to text: [ 6.9488 -3.6879]: The authors define domain generalization recommendation symbolically and propose corresponding models for it, which include a hierarchical invariant learning approach to find common patterns in generalization space, a learnable environment assignment method, and an adversarial environment refinement method.", "target": "The authors define domain generalization recommendation symbolically and propose corresponding models for it, which include a hierarchical invariant learning approach to find common patterns in generalization space, a learnable environment assignment method, and an adversarial environment refinement method.", "example": "Convert the coordinate to text: [ 6.9488 -3.6879]:"}
{"text": "Convert the coordinate to text: [ 1.0225 -6.7587]: SMURF-THP, a score-based method for training Transformer Hawkes Processes and quantifying the uncertainty of its predictions, is proposed to tackle the absence of uncertainty quantification in current methods and the difficulty experienced in computing complex, intractable integrals.", "target": "SMURF-THP, a score-based method for training Transformer Hawkes Processes and quantifying the uncertainty of its predictions, is proposed to tackle the absence of uncertainty quantification in current methods and the difficulty experienced in computing complex, intractable integrals.", "example": "Convert the coordinate to text: [ 1.0225 -6.7587]:"}
{"text": "Convert the coordinate to text: [  9.1701 -14.3763]: The challenge is divided into two tracks: Track 1 aims to achieve the best FID while maintaining or improving the baseline method in terms of temporal consistency, and Track 2 aims to get the best CDC result while maintaining or improving over the baseline method in terms of FID.", "target": "The challenge is divided into two tracks: Track 1 aims to achieve the best FID while maintaining or improving the baseline method in terms of temporal consistency, and Track 2 aims to get the best CDC result while maintaining or improving over the baseline method in terms of FID.", "example": "Convert the coordinate to text: [  9.1701 -14.3763]:"}
{"text": "Convert the coordinate to text: [-11.5108  -0.7539]: The proposed solution, Query Refinement Transformer or QueryFormer, optimizes the initialization process for the query distribution with a high coverage and low repetition rate. It also uses an affiliated transformer decoder that suppresses the interference of noise background queries.", "target": "The proposed solution, Query Refinement Transformer or QueryFormer, optimizes the initialization process for the query distribution with a high coverage and low repetition rate. It also uses an affiliated transformer decoder that suppresses the interference of noise background queries.", "example": "Convert the coordinate to text: [-11.5108  -0.7539]:"}
{"text": "Convert the coordinate to text: [ 3.9075 12.401 ]: This paper proposes an approach that augments a subgoal search method to achieve completeness in discrete action spaces, known as hybrid search, which combines high-level search with low-level actions to execute a multi-level (complete subgoal) search.", "target": "This paper proposes an approach that augments a subgoal search method to achieve completeness in discrete action spaces, known as hybrid search, which combines high-level search with low-level actions to execute a multi-level (complete subgoal) search.", "example": "Convert the coordinate to text: [ 3.9075 12.401 ]:"}
{"text": "Convert the coordinate to text: [  8.9648 -12.4883]: The authors propose CoBEVFlow, an asynchrony-robust collaborative perception system based on bird's eye view (BEV) flow. The system compensates motions to align asynchronous collaboration messages sent by multiple agents, and models the motion in a scene by using BEV flow, a collection of the motion vector corresponding to each spatial location.", "target": "The authors propose CoBEVFlow, an asynchrony-robust collaborative perception system based on bird's eye view (BEV) flow. The system compensates motions to align asynchronous collaboration messages sent by multiple agents, and models the motion in a scene by using BEV flow, a collection of the motion vector corresponding to each spatial location.", "example": "Convert the coordinate to text: [  8.9648 -12.4883]:"}
{"text": "Convert the coordinate to text: [ 2.7404 -3.8525]: The authors introduce a novel concept of color-separating sets to completely resolve the issue of what class of attributed graphs PH can recognize. They also propose RePHINE, a method for learning topological features on graphs which combines vertex- and edge-level PH.", "target": "The authors introduce a novel concept of color-separating sets to completely resolve the issue of what class of attributed graphs PH can recognize. They also propose RePHINE, a method for learning topological features on graphs which combines vertex- and edge-level PH.", "example": "Convert the coordinate to text: [ 2.7404 -3.8525]:"}
{"text": "Convert the coordinate to text: [12.2746  7.3067]: A variant of stochastic MGDA named Multi-objective gradient with Double sampling (MoDo) is then developed, which aims to study its own generalization performance and the correlation with optimization through algorithm stability.", "target": "A variant of stochastic MGDA named Multi-objective gradient with Double sampling (MoDo) is then developed, which aims to study its own generalization performance and the correlation with optimization through algorithm stability.", "example": "Convert the coordinate to text: [12.2746  7.3067]:"}
{"text": "Convert the coordinate to text: [5.825  7.0743]: The paper proposes Adaptive-Consistency, a cost-efficient technique that is model-agnostic and dynamically adjusts the number of samples per question using a lightweight stopping criterion.", "target": "The paper proposes Adaptive-Consistency, a cost-efficient technique that is model-agnostic and dynamically adjusts the number of samples per question using a lightweight stopping criterion.", "example": "Convert the coordinate to text: [5.825  7.0743]:"}
{"text": "Convert the coordinate to text: [ -0.1721 -15.3864]: The authors developed a 10-command SSVEP-BCI system in mixed reality using Hololens2 and explored the system\u2019s performance with two stimulus colors (white and red) against four monochrome backgrounds (green, blue, white, and black).", "target": "The authors developed a 10-command SSVEP-BCI system in mixed reality using Hololens2 and explored the system\u2019s performance with two stimulus colors (white and red) against four monochrome backgrounds (green, blue, white, and black).", "example": "Convert the coordinate to text: [ -0.1721 -15.3864]:"}
{"text": "Convert the coordinate to text: [9.3398 7.9147]: The authors propose a framework for smoothed analysis for sequential probability assignment, developing a general-purpose reduction from minimax rates for smoothed adversaries to minimax rates for transductive learning.", "target": "The authors propose a framework for smoothed analysis for sequential probability assignment, developing a general-purpose reduction from minimax rates for smoothed adversaries to minimax rates for transductive learning.", "example": "Convert the coordinate to text: [9.3398 7.9147]:"}
{"text": "Convert the coordinate to text: [16.1427  1.9281]: The authors propose a method for retraining agents to identify when they are in out-of-distribution states and to self-navigate back to in-distribution states, essentially recovering from OOD situations in a self-supervised manner.", "target": "The authors propose a method for retraining agents to identify when they are in out-of-distribution states and to self-navigate back to in-distribution states, essentially recovering from OOD situations in a self-supervised manner.", "example": "Convert the coordinate to text: [16.1427  1.9281]:"}
{"text": "Convert the coordinate to text: [-7.5692 11.0097]: The authors propose an initial study that evaluates the use of intra-episodic feedback given in a collaborative setting using a referential language game, where a teacher monitors a follower's actions and intervenes with feedback.", "target": "The authors propose an initial study that evaluates the use of intra-episodic feedback given in a collaborative setting using a referential language game, where a teacher monitors a follower's actions and intervenes with feedback.", "example": "Convert the coordinate to text: [-7.5692 11.0097]:"}
{"text": "Convert the coordinate to text: [ 1.7607 -3.9009]: Rather than using direct supervision, this work proposes an approach that uses posterior regularization to enforce a mutual exclusion constraint, allowing the model to discern between fluent and plausible explanations for abductive commonsense reasoning.", "target": "Rather than using direct supervision, this work proposes an approach that uses posterior regularization to enforce a mutual exclusion constraint, allowing the model to discern between fluent and plausible explanations for abductive commonsense reasoning.", "example": "Convert the coordinate to text: [ 1.7607 -3.9009]:"}
{"text": "Convert the coordinate to text: [ 0.0173 -7.2154]: The authors propose a unified local- and global-attention Transformer encoder to better model two-level contexts of user history. Additionally, they propose a framework, UniTRec, which leverages Transformer decoders to estimate the language perplexity of candidate text items, serving as a significant contrastive signal for user-item text matching.", "target": "The authors propose a unified local- and global-attention Transformer encoder to better model two-level contexts of user history. Additionally, they propose a framework, UniTRec, which leverages Transformer decoders to estimate the language perplexity of candidate text items, serving as a significant contrastive signal for user-item text matching.", "example": "Convert the coordinate to text: [ 0.0173 -7.2154]:"}
{"text": "Convert the coordinate to text: [-6.9286  0.4915]: The authors propose SciLit, a pipeline that automatically recommends relevant papers, extracts highlights, and suggests a reference sentence as a citation all considering the user-provided context and keywords. It uses a two-stage pre-fetching and re-ranking literature search system for efficient recommendation from large paper databases.", "target": "The authors propose SciLit, a pipeline that automatically recommends relevant papers, extracts highlights, and suggests a reference sentence as a citation all considering the user-provided context and keywords. It uses a two-stage pre-fetching and re-ranking literature search system for efficient recommendation from large paper databases.", "example": "Convert the coordinate to text: [-6.9286  0.4915]:"}
{"text": "Convert the coordinate to text: [-5.8017  9.7525]: The authors adapt a system of DRs for written language to spontaneous dialogue using crowdsourced annotations from novice annotators and test whether discourse relations are used differently across several types of multi-utterance contexts.", "target": "The authors adapt a system of DRs for written language to spontaneous dialogue using crowdsourced annotations from novice annotators and test whether discourse relations are used differently across several types of multi-utterance contexts.", "example": "Convert the coordinate to text: [-5.8017  9.7525]:"}
{"text": "Convert the coordinate to text: [-4.2061 -3.0996]: The authors have developed specific deep-learning models for each sub-task of the LegalEval challenge. These include a multi-task learning model for RR, a hybrid model with a rule-based system for L-NER, and a hierarchical approach for the CJPE task.", "target": "The authors have developed specific deep-learning models for each sub-task of the LegalEval challenge. These include a multi-task learning model for RR, a hybrid model with a rule-based system for L-NER, and a hierarchical approach for the CJPE task.", "example": "Convert the coordinate to text: [-4.2061 -3.0996]:"}
{"text": "Convert the coordinate to text: [-3.0945 -6.7537]: The YNU-HPCC team developed a system based on the BioBERT model, integrating supervised contrastive learning for classification improvement, and back-translation for enhancing the training data.", "target": "The YNU-HPCC team developed a system based on the BioBERT model, integrating supervised contrastive learning for classification improvement, and back-translation for enhancing the training data.", "example": "Convert the coordinate to text: [-3.0945 -6.7537]:"}
{"text": "Convert the coordinate to text: [-2.2542 -5.3979]: The authors propose an ensemble solution based on various pre-trained language models (PLMs) that are fine-tuned on a propaganda dataset for detecting persuasion techniques in text across multiple languages.", "target": "The authors propose an ensemble solution based on various pre-trained language models (PLMs) that are fine-tuned on a propaganda dataset for detecting persuasion techniques in text across multiple languages.", "example": "Convert the coordinate to text: [-2.2542 -5.3979]:"}
{"text": "Convert the coordinate to text: [-10.6231  -1.9917]: The paper introduces ADEQA, a question-answer-based approach that uses quasi supervised labeled data and sequence-to-sequence transformers for extracting ADEs, drug suspects, and relationships between them.", "target": "The paper introduces ADEQA, a question-answer-based approach that uses quasi supervised labeled data and sequence-to-sequence transformers for extracting ADEs, drug suspects, and relationships between them.", "example": "Convert the coordinate to text: [-10.6231  -1.9917]:"}
{"text": "Convert the coordinate to text: [-2.7732 -8.4471]: The authors propose a novel algorithm that transforms complete dialogues into topic-segment-level Abstract Meaning Representation (AMR) graphs which capture the dialogue structure and preserve crucial information, along with a new text-graph attention system that leverages both graph semantics and a pre-trained LLM's text.", "target": "The authors propose a novel algorithm that transforms complete dialogues into topic-segment-level Abstract Meaning Representation (AMR) graphs which capture the dialogue structure and preserve crucial information, along with a new text-graph attention system that leverages both graph semantics and a pre-trained LLM's text.", "example": "Convert the coordinate to text: [-2.7732 -8.4471]:"}
{"text": "Convert the coordinate to text: [-5.856  -4.6851]: A new method to evaluate semantic distance is proposed, called Neighboring Distribution Divergence (NDD), which uses a mask-and-predict strategy with Masked Language Modeling (MLM) to predict word distributions in the longest common sequence (LCS) of paired texts.", "target": "A new method to evaluate semantic distance is proposed, called Neighboring Distribution Divergence (NDD), which uses a mask-and-predict strategy with Masked Language Modeling (MLM) to predict word distributions in the longest common sequence (LCS) of paired texts.", "example": "Convert the coordinate to text: [-5.856  -4.6851]:"}
{"text": "Convert the coordinate to text: [-12.3734  -0.4311]: The authors present a framework called G3R which consists of a graph-guided SQL generator and a knowledge-enhanced re-ranking mechanism to address the limitations of current approaches to Text-to-SQL generation.", "target": "The authors present a framework called G3R which consists of a graph-guided SQL generator and a knowledge-enhanced re-ranking mechanism to address the limitations of current approaches to Text-to-SQL generation.", "example": "Convert the coordinate to text: [-12.3734  -0.4311]:"}
{"text": "Convert the coordinate to text: [-3.2868 -0.784 ]: This study proposes the task of discriminative dynamic topic discovery aiming to discover topic evolutions from temporal corpora that distinctly align with a set of user-provided category names and uniquely capture topics at each time step. To solve this task, the authors develop DynaMiTE, a framework that combines semantic similarity, category indicative, and time indicative scores to produce informative topic evolutions.", "target": "This study proposes the task of discriminative dynamic topic discovery aiming to discover topic evolutions from temporal corpora that distinctly align with a set of user-provided category names and uniquely capture topics at each time step. To solve this task, the authors develop DynaMiTE, a framework that combines semantic similarity, category indicative, and time indicative scores to produce informative topic evolutions.", "example": "Convert the coordinate to text: [-3.2868 -0.784 ]:"}
{"text": "Convert the coordinate to text: [-2.9028  0.3783]: The authors introduce the new task of node placement, which is about suggesting candidate nodes as parents for a new contribution in an argument map.", "target": "The authors introduce the new task of node placement, which is about suggesting candidate nodes as parents for a new contribution in an argument map.", "example": "Convert the coordinate to text: [-2.9028  0.3783]:"}
{"text": "Convert the coordinate to text: [-1.8502 -3.0122]: The authors propose TREA, a novel Tree structure Reasoning schemA, that constructs a multi-hierarchical scalable tree as the reasoning structure to reveal the causal relationships between mentioned entities. TREA also fully utilizes historical conversations to generate more reasonable responses for recommended results.", "target": "The authors propose TREA, a novel Tree structure Reasoning schemA, that constructs a multi-hierarchical scalable tree as the reasoning structure to reveal the causal relationships between mentioned entities. TREA also fully utilizes historical conversations to generate more reasonable responses for recommended results.", "example": "Convert the coordinate to text: [-1.8502 -3.0122]:"}
{"text": "Convert the coordinate to text: [ 8.3067 -3.143 ]: A two-stage explanation strategy is proposed where explainers are first pretrained in a task-agnostic fashion in the representation space and then further fine-tuned in the task-specific label space and representation space if downstream tasks are accessible, and an explanation framework based on the Information Bottleneck principle is introduced, named Explainable Graph Information Bottleneck (EGIB).", "target": "A two-stage explanation strategy is proposed where explainers are first pretrained in a task-agnostic fashion in the representation space and then further fine-tuned in the task-specific label space and representation space if downstream tasks are accessible, and an explanation framework based on the Information Bottleneck principle is introduced, named Explainable Graph Information Bottleneck (EGIB).", "example": "Convert the coordinate to text: [ 8.3067 -3.143 ]:"}
{"text": "Convert the coordinate to text: [12.8293  7.1154]: The paper investigates the relationship between batch size and the number of steps needed to train GANs with TTURs based on constant learning rates. The authors posit that there exists a critical batch size for minimization of the stochastic first-order oracle (SFO) complexity.", "target": "The paper investigates the relationship between batch size and the number of steps needed to train GANs with TTURs based on constant learning rates. The authors posit that there exists a critical batch size for minimization of the stochastic first-order oracle (SFO) complexity.", "example": "Convert the coordinate to text: [12.8293  7.1154]:"}
{"text": "Convert the coordinate to text: [-6.7866  6.3596]: This study presents a solution, BiRDy, a fully web-based platform that performs participant role detection in chat groups. It leverages the pre-trained language model mBERT to classify messages according to the author's involvement in cyberbullying.", "target": "This study presents a solution, BiRDy, a fully web-based platform that performs participant role detection in chat groups. It leverages the pre-trained language model mBERT to classify messages according to the author's involvement in cyberbullying.", "example": "Convert the coordinate to text: [-6.7866  6.3596]:"}
{"text": "Convert the coordinate to text: [ 7.4171 12.3292]: The paper introduces an Off-Policy Evaluation for Human Feedback (OPEHF) framework that improves existing OPE methods to more accurately evaluate human feedback signals. They do this through an immediate human reward (IHR) reconstruction approach, which is regularized by environmental knowledge distilled in a latent space that captures underlying state transition dynamics and human feedback signal generation.", "target": "The paper introduces an Off-Policy Evaluation for Human Feedback (OPEHF) framework that improves existing OPE methods to more accurately evaluate human feedback signals. They do this through an immediate human reward (IHR) reconstruction approach, which is regularized by environmental knowledge distilled in a latent space that captures underlying state transition dynamics and human feedback signal generation.", "example": "Convert the coordinate to text: [ 7.4171 12.3292]:"}
{"text": "Convert the coordinate to text: [13.4148 -4.6933]: The authors propose a novel dual-network training framework, known as The Victim and The Beneficiary (V&B), to exploit a poisoned model to train a clean model without requiring extra benign samples. An observation that the poisoned samples can be distinguished from benign samples using prediction entropy forms the basis for the framework.", "target": "The authors propose a novel dual-network training framework, known as The Victim and The Beneficiary (V&B), to exploit a poisoned model to train a clean model without requiring extra benign samples. An observation that the poisoned samples can be distinguished from benign samples using prediction entropy forms the basis for the framework.", "example": "Convert the coordinate to text: [13.4148 -4.6933]:"}
{"text": "Convert the coordinate to text: [ 8.9478 -8.6727]: The authors propose an approach focused more on important areas for reconstruction in a corrupted image, introducing a dual-domain selection mechanism to spotlight crucial information such as edge signals and hard regions. They also propose splitting high-resolution features to insert multi-scale receptive fields into the network, improving both efficiency and performance. This all resulted in a U-shaped backbone network called FocalNet.", "target": "The authors propose an approach focused more on important areas for reconstruction in a corrupted image, introducing a dual-domain selection mechanism to spotlight crucial information such as edge signals and hard regions. They also propose splitting high-resolution features to insert multi-scale receptive fields into the network, improving both efficiency and performance. This all resulted in a U-shaped backbone network called FocalNet.", "example": "Convert the coordinate to text: [ 8.9478 -8.6727]:"}
{"text": "Convert the coordinate to text: [ 6.3051 -6.5842]: The paper investigates the inferior performance of RNNs compared to transformer-based algorithms in OAD tasks. The authors find that the disparity between training and inference hinders the effective training of RNNs, so they propose applying non-uniform weights to the loss computed at each time step to tackle this issue.", "target": "The paper investigates the inferior performance of RNNs compared to transformer-based algorithms in OAD tasks. The authors find that the disparity between training and inference hinders the effective training of RNNs, so they propose applying non-uniform weights to the loss computed at each time step to tackle this issue.", "example": "Convert the coordinate to text: [ 6.3051 -6.5842]:"}
{"text": "Convert the coordinate to text: [ 2.4239 -3.0828]: The authors propose Catastrophic Forgetting Measurement (CFM) to adjust the learning rate, avoiding excessive training and mitigating catastrophic forgetting. They then formulate a Pseudo-labeling setting with Adaptive Debiasing in CLIP (PADCLIP), which uses CLIP\u2019s zero-shot prediction, adjusts it with causal inference, momentum, and CFM.", "target": "The authors propose Catastrophic Forgetting Measurement (CFM) to adjust the learning rate, avoiding excessive training and mitigating catastrophic forgetting. They then formulate a Pseudo-labeling setting with Adaptive Debiasing in CLIP (PADCLIP), which uses CLIP\u2019s zero-shot prediction, adjusts it with causal inference, momentum, and CFM.", "example": "Convert the coordinate to text: [ 2.4239 -3.0828]:"}
{"text": "Convert the coordinate to text: [10.1938 -4.1458]: The paper proposes a novel channel pruning method where a target sub-network is first learned during the model training process and then used to guide the learning of model weights through partial regularization, mitigating the gap caused by pruning.", "target": "The paper proposes a novel channel pruning method where a target sub-network is first learned during the model training process and then used to guide the learning of model weights through partial regularization, mitigating the gap caused by pruning.", "example": "Convert the coordinate to text: [10.1938 -4.1458]:"}
{"text": "Convert the coordinate to text: [ 7.5005 -2.1346]: The authors propose a novel federated learning method with Dynamic Fisher Personalization and Adaptive Constraint (FedDPA) which leverages Fisher information values as an effective measure for estimating the information content of parameters and uses layer-wise Fisher information to measure the information content of local parameters.", "target": "The authors propose a novel federated learning method with Dynamic Fisher Personalization and Adaptive Constraint (FedDPA) which leverages Fisher information values as an effective measure for estimating the information content of parameters and uses layer-wise Fisher information to measure the information content of local parameters.", "example": "Convert the coordinate to text: [ 7.5005 -2.1346]:"}
{"text": "Convert the coordinate to text: [ 6.765  -6.3081]: This paper proposes a density-aware prototypical network (D-Proto) that treats various instances distinctly, with unique training objectives separating known instances and isolating NOTA instances for an ideal instance distribution.", "target": "This paper proposes a density-aware prototypical network (D-Proto) that treats various instances distinctly, with unique training objectives separating known instances and isolating NOTA instances for an ideal instance distribution.", "example": "Convert the coordinate to text: [ 6.765  -6.3081]:"}
{"text": "Convert the coordinate to text: [-0.6031 -3.0593]: The authors propose a simple yet effective approach for TKG reasoning, named SiMFy, which uses a multilayer perceptron (MLP) to model structural dependencies of events and a fixed-frequency strategy to incorporate historical frequency during inference.", "target": "The authors propose a simple yet effective approach for TKG reasoning, named SiMFy, which uses a multilayer perceptron (MLP) to model structural dependencies of events and a fixed-frequency strategy to incorporate historical frequency during inference.", "example": "Convert the coordinate to text: [-0.6031 -3.0593]:"}
{"text": "Convert the coordinate to text: [6.3448 3.8717]: The authors propose scalable algorithms, DistEB and DistMS, for two balancing approaches: entropy balancing and MicroSynth, for causal inference on large scale datasets. These algorithms have linear time complexity and can be implemented in distributed computing frameworks.", "target": "The authors propose scalable algorithms, DistEB and DistMS, for two balancing approaches: entropy balancing and MicroSynth, for causal inference on large scale datasets. These algorithms have linear time complexity and can be implemented in distributed computing frameworks.", "example": "Convert the coordinate to text: [6.3448 3.8717]:"}
{"text": "Convert the coordinate to text: [-12.0607  11.9795]: This study uses an autobiographical design approach to examine the integration of precision techniques with ritual cooking practices using a developed open-source hardware toolkit. They apply the toolkit to three recipes: flour skin, rice wine, and doufu.", "target": "This study uses an autobiographical design approach to examine the integration of precision techniques with ritual cooking practices using a developed open-source hardware toolkit. They apply the toolkit to three recipes: flour skin, rice wine, and doufu.", "example": "Convert the coordinate to text: [-12.0607  11.9795]:"}
{"text": "Convert the coordinate to text: [-12.6272  15.1089]: The authors present LYDSPOR, a site-specific sound experience comprising of two physical installations and an app-based soundwalk. This project is notable for its use of soma design methods, affective interaction design, and an emphasis on physical sensation in conveying aspects of the history of Elsinore, Denmark.", "target": "The authors present LYDSPOR, a site-specific sound experience comprising of two physical installations and an app-based soundwalk. This project is notable for its use of soma design methods, affective interaction design, and an emphasis on physical sensation in conveying aspects of the history of Elsinore, Denmark.", "example": "Convert the coordinate to text: [-12.6272  15.1089]:"}
{"text": "Convert the coordinate to text: [-2.0155 10.1768]: The authors introduce ArgU, a neural argument generator capable of producing factual arguments based on input facts and real-world concepts. It also introduces control over stance and argument structure using Walton's argument scheme-based control codes.", "target": "The authors introduce ArgU, a neural argument generator capable of producing factual arguments based on input facts and real-world concepts. It also introduces control over stance and argument structure using Walton's argument scheme-based control codes.", "example": "Convert the coordinate to text: [-2.0155 10.1768]:"}
{"text": "Convert the coordinate to text: [-1.5637  1.7118]: The paper proposes a workflow for estimating policy domain aware party similarity to improve on existing methods that only consider global party (dis)-similarity without providing insights into domain-specific disagreements.", "target": "The paper proposes a workflow for estimating policy domain aware party similarity to improve on existing methods that only consider global party (dis)-similarity without providing insights into domain-specific disagreements.", "example": "Convert the coordinate to text: [-1.5637  1.7118]:"}
{"text": "Convert the coordinate to text: [ 0.1635 -9.0168]: The authors propose the first empirical study of image ad understanding through the lens of pre-trained VLMs, and suggest a simple feature adaptation strategy for effectively fusing multimodal information for image ads and further enhancing it with knowledge of real-world entities.", "target": "The authors propose the first empirical study of image ad understanding through the lens of pre-trained VLMs, and suggest a simple feature adaptation strategy for effectively fusing multimodal information for image ads and further enhancing it with knowledge of real-world entities.", "example": "Convert the coordinate to text: [ 0.1635 -9.0168]:"}
{"text": "Convert the coordinate to text: [2.695  5.5909]: This paper introduces axioms for necessary characteristics of hypergraph transitivity measures. It presents a principled hypergraph transitivity measure, named HyperTrans, that satisfies the proposed axioms, alongside a fast computation algorithm Fast-HyperTrans. The authors also propose a scalable hypergraph generator, called THera, for reproducing observed transitivity patterns through community structures.", "target": "This paper introduces axioms for necessary characteristics of hypergraph transitivity measures. It presents a principled hypergraph transitivity measure, named HyperTrans, that satisfies the proposed axioms, alongside a fast computation algorithm Fast-HyperTrans. The authors also propose a scalable hypergraph generator, called THera, for reproducing observed transitivity patterns through community structures.", "example": "Convert the coordinate to text: [2.695  5.5909]:"}
{"text": "Convert the coordinate to text: [-1.5916 -6.6311]: The paper is based on the author's participation in the task, which involved fine-tuning different layer representations of Transformer-based pre-trained language models including BERT, AlBERT and RoBERTa, and employing ensemble learning through majority voting of the best performing models.", "target": "The paper is based on the author's participation in the task, which involved fine-tuning different layer representations of Transformer-based pre-trained language models including BERT, AlBERT and RoBERTa, and employing ensemble learning through majority voting of the best performing models.", "example": "Convert the coordinate to text: [-1.5916 -6.6311]:"}
{"text": "Convert the coordinate to text: [-4.1773 -3.4766]: HITS used a framework that employs different pre-trained models depending on the target language for Discourse Segmentation and Connective Detection. For Relation Classification, a joint model was designed for languages with small corpora and separate models for large corpora, with an adversarial training strategy to enhance the robustness of relation classifiers.", "target": "HITS used a framework that employs different pre-trained models depending on the target language for Discourse Segmentation and Connective Detection. For Relation Classification, a joint model was designed for languages with small corpora and separate models for large corpora, with an adversarial training strategy to enhance the robustness of relation classifiers.", "example": "Convert the coordinate to text: [-4.1773 -3.4766]:"}
{"text": "Convert the coordinate to text: [-2.1495 -5.7774]: This paper proposes a novel span-level ABSA model named Table Filling BERT (TF-BERT), which considers the consistency of multi-word opinion expressions at the span-level, through a table filling method.", "target": "This paper proposes a novel span-level ABSA model named Table Filling BERT (TF-BERT), which considers the consistency of multi-word opinion expressions at the span-level, through a table filling method.", "example": "Convert the coordinate to text: [-2.1495 -5.7774]:"}
{"text": "Convert the coordinate to text: [8.7543 2.5769]: The authors propose Kernel QuantTree (KQT), a non-parametric change detection algorithm that constructs a histogram through a nonlinear partition of the input space, aligning with the target probabilities and promoting compact bins that adhere to the data distribution.", "target": "The authors propose Kernel QuantTree (KQT), a non-parametric change detection algorithm that constructs a histogram through a nonlinear partition of the input space, aligning with the target probabilities and promoting compact bins that adhere to the data distribution.", "example": "Convert the coordinate to text: [8.7543 2.5769]:"}
{"text": "Convert the coordinate to text: [10.0402 -1.1888]: The authors propose the energy objective, an alternative sample-based loss based on proper scoring rules, which does not require the calculation of determinants, and a novel model family, named Semi-Autoregressive Energy Flows, which interpolates between fully autoregressive and non-autoregressive models.", "target": "The authors propose the energy objective, an alternative sample-based loss based on proper scoring rules, which does not require the calculation of determinants, and a novel model family, named Semi-Autoregressive Energy Flows, which interpolates between fully autoregressive and non-autoregressive models.", "example": "Convert the coordinate to text: [10.0402 -1.1888]:"}
{"text": "Convert the coordinate to text: [  6.754  -15.2528]: The authors propose a dynamic scale perception framework named GeoAgent that adaptively captures appropriate scale context information outside the image patch based on the different geo-objects.", "target": "The authors propose a dynamic scale perception framework named GeoAgent that adaptively captures appropriate scale context information outside the image patch based on the different geo-objects.", "example": "Convert the coordinate to text: [  6.754  -15.2528]:"}
{"text": "Convert the coordinate to text: [-0.8933  6.4692]: The authors introduce a model of inductive learning that mimics human-like learning capabilities. It is based on a Bayesian reasoning process where a language model first suggests candidate hypotheses expressed in natural language, which are then re-weighed by a prior and a likelihood.", "target": "The authors introduce a model of inductive learning that mimics human-like learning capabilities. It is based on a Bayesian reasoning process where a language model first suggests candidate hypotheses expressed in natural language, which are then re-weighed by a prior and a likelihood.", "example": "Convert the coordinate to text: [-0.8933  6.4692]:"}
{"text": "Convert the coordinate to text: [2.0966 3.3279]: The authors propose to tackle this challenge by considering a class of non-stationary time series problems and designing a constraint-based, non-parametric algorithm for discovering causal relations in this setting.", "target": "The authors propose to tackle this challenge by considering a class of non-stationary time series problems and designing a constraint-based, non-parametric algorithm for discovering causal relations in this setting.", "example": "Convert the coordinate to text: [2.0966 3.3279]:"}
{"text": "Convert the coordinate to text: [-10.3211  17.7374]: The paper demonstrates a wearable ICI that trains the user's tongue muscles using a gamified form of myofunctional therapy, a method that can reduce snoring and mild sleep apnea.", "target": "The paper demonstrates a wearable ICI that trains the user's tongue muscles using a gamified form of myofunctional therapy, a method that can reduce snoring and mild sleep apnea.", "example": "Convert the coordinate to text: [-10.3211  17.7374]:"}
{"text": "Convert the coordinate to text: [-3.5541 -6.3781]: An unbiased UD-based XRE transfer is proposed by constructing a code-mixed UD forest, which merges the source and target-side UD structures as a unified entity.", "target": "An unbiased UD-based XRE transfer is proposed by constructing a code-mixed UD forest, which merges the source and target-side UD structures as a unified entity.", "example": "Convert the coordinate to text: [-3.5541 -6.3781]:"}
{"text": "Convert the coordinate to text: [-6.9425 -1.3284]: The authors propose revisiting the sentence union generation task as a well-defined testbed for assessing text consolidation capabilities, thus separating the consolidation challenge from subjective content selection.", "target": "The authors propose revisiting the sentence union generation task as a well-defined testbed for assessing text consolidation capabilities, thus separating the consolidation challenge from subjective content selection.", "example": "Convert the coordinate to text: [-6.9425 -1.3284]:"}
{"text": "Convert the coordinate to text: [-5.9262  1.7018]: This paper presents an overview of existing research into automated scientific fact-checking based on Natural Language Processing (NLP), illustrating its potential to address the spread of misinformation and facilitate scientific understanding.", "target": "This paper presents an overview of existing research into automated scientific fact-checking based on Natural Language Processing (NLP), illustrating its potential to address the spread of misinformation and facilitate scientific understanding.", "example": "Convert the coordinate to text: [-5.9262  1.7018]:"}
{"text": "Convert the coordinate to text: [-0.9689 -5.4365]: The authors propose 'focused prefix tuning' (FPT), a method designed to mitigate the issues caused by unannotated attributes and enable control to focus on the desired attribute.", "target": "The authors propose 'focused prefix tuning' (FPT), a method designed to mitigate the issues caused by unannotated attributes and enable control to focus on the desired attribute.", "example": "Convert the coordinate to text: [-0.9689 -5.4365]:"}
{"text": "Convert the coordinate to text: [ 7.2747 -1.5862]: In this paper, the authors propose a novel approach called Diverse and Discriminative representation Learning (DDLearn) for generalizable low-resource HAR, which simultaneously considers diversity and discrimination learning. DDLearn enlarges the data diversity, explores the latent activity properties, preserves the diversity of learned features, and enhances semantic discrimination.", "target": "In this paper, the authors propose a novel approach called Diverse and Discriminative representation Learning (DDLearn) for generalizable low-resource HAR, which simultaneously considers diversity and discrimination learning. DDLearn enlarges the data diversity, explores the latent activity properties, preserves the diversity of learned features, and enhances semantic discrimination.", "example": "Convert the coordinate to text: [ 7.2747 -1.5862]:"}
{"text": "Convert the coordinate to text: [-0.3761 -9.4669]: The authors aim to bridge the gap in AVSR by learning shared representations across modalities, focusing on temporal contextual dependencies due to the sequence-to-sequence task setting, and propose an adversarial network to refine frame-level modality-invariant representations (MIR-GAN).", "target": "The authors aim to bridge the gap in AVSR by learning shared representations across modalities, focusing on temporal contextual dependencies due to the sequence-to-sequence task setting, and propose an adversarial network to refine frame-level modality-invariant representations (MIR-GAN).", "example": "Convert the coordinate to text: [-0.3761 -9.4669]:"}
{"text": "Convert the coordinate to text: [  4.9858 -12.6987]: The authors propose ZestGuide, a zero-shot segmentation guidance approach. It can be plugged into pre-trained text-to-image diffusion models and does not require additional training. It leverages implicit segmentation maps from cross-attention layers to align generation with input masks.", "target": "The authors propose ZestGuide, a zero-shot segmentation guidance approach. It can be plugged into pre-trained text-to-image diffusion models and does not require additional training. It leverages implicit segmentation maps from cross-attention layers to align generation with input masks.", "example": "Convert the coordinate to text: [  4.9858 -12.6987]:"}
{"text": "Convert the coordinate to text: [-4.2649 -1.5048]: The authors annotated 6315 sentences from different mythological contexts, such as Ancient Greece, Rome, and Mesopotamia, into four categories; single-point events, durative-constant, durative-initial, and durative-resultativ.", "target": "The authors annotated 6315 sentences from different mythological contexts, such as Ancient Greece, Rome, and Mesopotamia, into four categories; single-point events, durative-constant, durative-initial, and durative-resultativ.", "example": "Convert the coordinate to text: [-4.2649 -1.5048]:"}
{"text": "Convert the coordinate to text: [-1.9433  8.5775]: The paper introduces a dependency-aware symbolic reasoning framework that reasons out each entity in the table description with a custom designed table-compatible programming language and an entity scheduling mechanism.", "target": "The paper introduces a dependency-aware symbolic reasoning framework that reasons out each entity in the table description with a custom designed table-compatible programming language and an entity scheduling mechanism.", "example": "Convert the coordinate to text: [-1.9433  8.5775]:"}
{"text": "Convert the coordinate to text: [-0.303  -5.7628]: The paper critically investigates the chaining approach, particularly transformer guided chaining, on a multi-hop First-Order Logic (FOL) reasoning benchmark. The authors also introduce an implementation known as Chainformer.", "target": "The paper critically investigates the chaining approach, particularly transformer guided chaining, on a multi-hop First-Order Logic (FOL) reasoning benchmark. The authors also introduce an implementation known as Chainformer.", "example": "Convert the coordinate to text: [-0.303  -5.7628]:"}
{"text": "Convert the coordinate to text: [-4.2853 -6.5631]: The authors propose EVALM, an entropy-based vocabulary augmented language model that uses a new task-cognizant measurement to detect vulnerable low-resource language words with undesirable wordpiece segmentations, and provides improved initializations of their embeddings.", "target": "The authors propose EVALM, an entropy-based vocabulary augmented language model that uses a new task-cognizant measurement to detect vulnerable low-resource language words with undesirable wordpiece segmentations, and provides improved initializations of their embeddings.", "example": "Convert the coordinate to text: [-4.2853 -6.5631]:"}
{"text": "Convert the coordinate to text: [ 3.404  -3.9351]: The authors propose a knowledge distillation approach, Socratic CoT, to leverage the CoT reasoning capabilities of larger models and distill these abilities into smaller models. The system consists of problem decomposer and a subproblem solver, which, in practice, work together to decompose and solve complex problems.", "target": "The authors propose a knowledge distillation approach, Socratic CoT, to leverage the CoT reasoning capabilities of larger models and distill these abilities into smaller models. The system consists of problem decomposer and a subproblem solver, which, in practice, work together to decompose and solve complex problems.", "example": "Convert the coordinate to text: [ 3.404  -3.9351]:"}
{"text": "Convert the coordinate to text: [-1.3099 -6.0821]: The authors address the privacy issues related to pre-trained language models by proposing a novel framework, TextObfuscator. This perturbs clustered representations to obfuscate word information while preserving original word functionality.", "target": "The authors address the privacy issues related to pre-trained language models by proposing a novel framework, TextObfuscator. This perturbs clustered representations to obfuscate word information while preserving original word functionality.", "example": "Convert the coordinate to text: [-1.3099 -6.0821]:"}
{"text": "Convert the coordinate to text: [-7.8695 -0.7084]: The authors introduce the new task of extracting unclaimed embodiments from patents (UEE) and provide a novel dataset to facilitate this task.", "target": "The authors introduce the new task of extracting unclaimed embodiments from patents (UEE) and provide a novel dataset to facilitate this task.", "example": "Convert the coordinate to text: [-7.8695 -0.7084]:"}
{"text": "Convert the coordinate to text: [-5.3518 -4.9908]: The paper presents a token-level matching inference algorithm that calculates pairwise token-level similarity and token matching scores, consolidating them with pretrained token weights to determine sentence similarity.", "target": "The paper presents a token-level matching inference algorithm that calculates pairwise token-level similarity and token matching scores, consolidating them with pretrained token weights to determine sentence similarity.", "example": "Convert the coordinate to text: [-5.3518 -4.9908]:"}
{"text": "Convert the coordinate to text: [-3.2558 -5.864 ]: This study investigates the performance of language models in providing specialized information by getting an assessment from 10 domain experts across science and culture.", "target": "This study investigates the performance of language models in providing specialized information by getting an assessment from 10 domain experts across science and culture.", "example": "Convert the coordinate to text: [-3.2558 -5.864 ]:"}
{"text": "Convert the coordinate to text: [ 9.7362 11.4079]: The study reveals that the stochastic gradient bandit algorithm converges to a globally optimal policy at an O(1/t) rate, even with a constant step size. It assured that 'exploration vs. exploitation' is automatically balanced via stochastic gradient updates, ensuring convergence.", "target": "The study reveals that the stochastic gradient bandit algorithm converges to a globally optimal policy at an O(1/t) rate, even with a constant step size. It assured that 'exploration vs. exploitation' is automatically balanced via stochastic gradient updates, ensuring convergence.", "example": "Convert the coordinate to text: [ 9.7362 11.4079]:"}
{"text": "Convert the coordinate to text: [7.2768 2.3002]: The authors propose an information-theoretic generalization of CCA named max-sliced mutual information (mSMI). It equals the maximal mutual information between low-dimensional projections of the high-dimensional variables, reducing back to CCA in the Gaussian case.", "target": "The authors propose an information-theoretic generalization of CCA named max-sliced mutual information (mSMI). It equals the maximal mutual information between low-dimensional projections of the high-dimensional variables, reducing back to CCA in the Gaussian case.", "example": "Convert the coordinate to text: [7.2768 2.3002]:"}
{"text": "Convert the coordinate to text: [13.6186  5.3922]: The authors propose a new uncertainty estimation framework that leverages data-adaptive high-dimensional hypothesis testing and the statistical properties of feature representations. This approach allows for operations on latent representations without requiring re-encoding under a modified objective, and its test statistic is more discriminative to uncertainties in the latent representations.", "target": "The authors propose a new uncertainty estimation framework that leverages data-adaptive high-dimensional hypothesis testing and the statistical properties of feature representations. This approach allows for operations on latent representations without requiring re-encoding under a modified objective, and its test statistic is more discriminative to uncertainties in the latent representations.", "example": "Convert the coordinate to text: [13.6186  5.3922]:"}
{"text": "Convert the coordinate to text: [12.4585  8.4558]: The key idea of this paper is the proposal of the FedNPG-ADMM framework, which uses the alternating direction method of multipliers (ADMM) to efficiently approximate global NPG directions and combat high communication overhead.", "target": "The key idea of this paper is the proposal of the FedNPG-ADMM framework, which uses the alternating direction method of multipliers (ADMM) to efficiently approximate global NPG directions and combat high communication overhead.", "example": "Convert the coordinate to text: [12.4585  8.4558]:"}
{"text": "Convert the coordinate to text: [  1.0905 -12.3099]: The authors propose a conditional diffusion model, InstructPix2Pix, which is capable of editing images based on human written instructions.", "target": "The authors propose a conditional diffusion model, InstructPix2Pix, which is capable of editing images based on human written instructions.", "example": "Convert the coordinate to text: [  1.0905 -12.3099]:"}
{"text": "Convert the coordinate to text: [10.5433 -4.8821]: The authors propose a new algorithm, PNI, that estimates the normal distribution using conditional probability given neighborhood features, and utilizes position information by creating a histogram of representative features at each position. An additional refine network is employed, trained on synthetic anomaly images, to better interpolate and account for the shape and edge of the input image.", "target": "The authors propose a new algorithm, PNI, that estimates the normal distribution using conditional probability given neighborhood features, and utilizes position information by creating a histogram of representative features at each position. An additional refine network is employed, trained on synthetic anomaly images, to better interpolate and account for the shape and edge of the input image.", "example": "Convert the coordinate to text: [10.5433 -4.8821]:"}
{"text": "Convert the coordinate to text: [-9.1916 13.5019]: This study developed and proposed a digital intervention termed DTFAD001, combining multitasking and alternating attention control; it is designed in a video game-like format targeted at improving attention control in children.", "target": "This study developed and proposed a digital intervention termed DTFAD001, combining multitasking and alternating attention control; it is designed in a video game-like format targeted at improving attention control in children.", "example": "Convert the coordinate to text: [-9.1916 13.5019]:"}
{"text": "Convert the coordinate to text: [4.2815 7.6017]: The authors introduce a refined upper bound, with a tighter fit than existing methods, and an inprocessing strategy which incrementally performs graph reduction, for enhancing the MKP solution.", "target": "The authors introduce a refined upper bound, with a tighter fit than existing methods, and an inprocessing strategy which incrementally performs graph reduction, for enhancing the MKP solution.", "example": "Convert the coordinate to text: [4.2815 7.6017]:"}
{"text": "Convert the coordinate to text: [ 0.7533 -2.0093]: The authors propose a new network, GLPocket, based on the Least Mean Square Error Reconstruction (Lmser) network, that uses a multi-scale representation to predict protein binding sites.", "target": "The authors propose a new network, GLPocket, based on the Least Mean Square Error Reconstruction (Lmser) network, that uses a multi-scale representation to predict protein binding sites.", "example": "Convert the coordinate to text: [ 0.7533 -2.0093]:"}
{"text": "Convert the coordinate to text: [ 4.829  -3.3124]: The paper proposes a strategy to overcome the capacity gap in model distillation by increasing the capacity of the student model without notably increasing the inference compute. This is achieved using a method called Mixture of Minimal Experts (MiniMoE), which introduces extra model parameters but doesn't increase inference compute.", "target": "The paper proposes a strategy to overcome the capacity gap in model distillation by increasing the capacity of the student model without notably increasing the inference compute. This is achieved using a method called Mixture of Minimal Experts (MiniMoE), which introduces extra model parameters but doesn't increase inference compute.", "example": "Convert the coordinate to text: [ 4.829  -3.3124]:"}
{"text": "Convert the coordinate to text: [-1.2579 -6.4143]: The authors propose improving zero-shot generalization by utilizing model-generated signals to design more challenging token replacements during pretraining. This idea is implemented in their new model, METRO-T0, which uses a redesigned ELECTRA-Style pretraining strategy and is prompt-finetuned on a mixture of NLP tasks.", "target": "The authors propose improving zero-shot generalization by utilizing model-generated signals to design more challenging token replacements during pretraining. This idea is implemented in their new model, METRO-T0, which uses a redesigned ELECTRA-Style pretraining strategy and is prompt-finetuned on a mixture of NLP tasks.", "example": "Convert the coordinate to text: [-1.2579 -6.4143]:"}
{"text": "Convert the coordinate to text: [-4.0522 -1.5431]: By modelling the explicit semantic structures crucial to ECI \u2013 the event-centric structure and the event-associated structure \u2013 the paper proposes a Semantic Structure Integration model (SemSIn), a new approach to studying implicit relations between events.", "target": "By modelling the explicit semantic structures crucial to ECI \u2013 the event-centric structure and the event-associated structure \u2013 the paper proposes a Semantic Structure Integration model (SemSIn), a new approach to studying implicit relations between events.", "example": "Convert the coordinate to text: [-4.0522 -1.5431]:"}
{"text": "Convert the coordinate to text: [-1.0217 -5.081 ]: The authors propose Consistency-based Self-adaptive Prompting (COSP), a new prompt design method for LLMs that requires neither handcrafted responses nor ground-truth labels, and instead builds examples from the LLM's zero-shot outputs using consistency, diversity and repetition criteria.", "target": "The authors propose Consistency-based Self-adaptive Prompting (COSP), a new prompt design method for LLMs that requires neither handcrafted responses nor ground-truth labels, and instead builds examples from the LLM's zero-shot outputs using consistency, diversity and repetition criteria.", "example": "Convert the coordinate to text: [-1.0217 -5.081 ]:"}
{"text": "Convert the coordinate to text: [-9.623   1.0203]: The authors introduce the new task of recommending relevant datasets based on a short natural language description of a research idea, addressing the unique challenges of dataset recommendation as an information retrieval problem.", "target": "The authors introduce the new task of recommending relevant datasets based on a short natural language description of a research idea, addressing the unique challenges of dataset recommendation as an information retrieval problem.", "example": "Convert the coordinate to text: [-9.623   1.0203]:"}
{"text": "Convert the coordinate to text: [-5.3111 -0.8776]: The authors propose CHANGES, a contrastive hierarchical graph neural network for extractive scientific paper summarization that uses a hierarchical discourse graph to represent a scientific paper and learns effective sentence representations via a specially designed hierarchical graph information aggregation. A graph contrastive learning module is also proposed to learn global theme-aware sentence representations.", "target": "The authors propose CHANGES, a contrastive hierarchical graph neural network for extractive scientific paper summarization that uses a hierarchical discourse graph to represent a scientific paper and learns effective sentence representations via a specially designed hierarchical graph information aggregation. A graph contrastive learning module is also proposed to learn global theme-aware sentence representations.", "example": "Convert the coordinate to text: [-5.3111 -0.8776]:"}
{"text": "Convert the coordinate to text: [12.962   0.7903]: This paper aims to solve an even more challenging problem: reconstructing Diffusion history from A Single Snapshot (DASH) without knowing the true diffusion parameters. It highlights fundamental limitations of the MLE formulation and introduces a new barycenter formulation to overcome MLE's inherent limitations. The barycenter formulation is proven to be resistant to the estimation error of diffusion parameters.", "target": "This paper aims to solve an even more challenging problem: reconstructing Diffusion history from A Single Snapshot (DASH) without knowing the true diffusion parameters. It highlights fundamental limitations of the MLE formulation and introduces a new barycenter formulation to overcome MLE's inherent limitations. The barycenter formulation is proven to be resistant to the estimation error of diffusion parameters.", "example": "Convert the coordinate to text: [12.962   0.7903]:"}
{"text": "Convert the coordinate to text: [-0.6904  1.5004]: The authors propose the OpenPI-C dataset, which addresses three types of issues on the procedure level, state level, and state change level via multiple rounds of human judgment. They also suggest a new cluster-based metric to correct the original metric's preference for repetition and propose a seq2seq model that reinstates two key properties for state tracking: temporal dependency and entity awareness.", "target": "The authors propose the OpenPI-C dataset, which addresses three types of issues on the procedure level, state level, and state change level via multiple rounds of human judgment. They also suggest a new cluster-based metric to correct the original metric's preference for repetition and propose a seq2seq model that reinstates two key properties for state tracking: temporal dependency and entity awareness.", "example": "Convert the coordinate to text: [-0.6904  1.5004]:"}
{"text": "Convert the coordinate to text: [ 0.5956 -9.5996]: The authors propose a new captioning method that treats captioning as a reference game between a speaker and a listener. Unlike previous methods, it uses an off-the-shelf CLIP model to parameterize the listener and benefits from rich vision-language alignment representations when reasoning over distractors.", "target": "The authors propose a new captioning method that treats captioning as a reference game between a speaker and a listener. Unlike previous methods, it uses an off-the-shelf CLIP model to parameterize the listener and benefits from rich vision-language alignment representations when reasoning over distractors.", "example": "Convert the coordinate to text: [ 0.5956 -9.5996]:"}
{"text": "Convert the coordinate to text: [-1.3745  0.0895]: This paper presents a fine-tuning approach for the pre-trained model based on several popular natural language processing methods to improve generalization ability in the face of different data for binary sexism detection.", "target": "This paper presents a fine-tuning approach for the pre-trained model based on several popular natural language processing methods to improve generalization ability in the face of different data for binary sexism detection.", "example": "Convert the coordinate to text: [-1.3745  0.0895]:"}
{"text": "Convert the coordinate to text: [-2.4505 -5.3924]: This study investigates the capability of large language models to generate correct responses to faux pas questions and to generate original faux pas stories, and it delves into the challenges these models might face in these tasks.", "target": "This study investigates the capability of large language models to generate correct responses to faux pas questions and to generate original faux pas stories, and it delves into the challenges these models might face in these tasks.", "example": "Convert the coordinate to text: [-2.4505 -5.3924]:"}
{"text": "Convert the coordinate to text: [-6.6173 -8.3982]: The authors propose an unsupervised approach to subtitle segmentation using pretrained masked language models. The approach predicts line endings and subtitle breaks based on the likelihood of punctuation at candidate segmentation points.", "target": "The authors propose an unsupervised approach to subtitle segmentation using pretrained masked language models. The approach predicts line endings and subtitle breaks based on the likelihood of punctuation at candidate segmentation points.", "example": "Convert the coordinate to text: [-6.6173 -8.3982]:"}
{"text": "Convert the coordinate to text: [2.4985 8.6722]: This work identifies that PH and CS methods degrade as the number of constraints increases but they have complementary strengths. The authors propose a new method that combines the advantages of PH and CS for improved robustness, particularly where constraint counts and lengths are high.", "target": "This work identifies that PH and CS methods degrade as the number of constraints increases but they have complementary strengths. The authors propose a new method that combines the advantages of PH and CS for improved robustness, particularly where constraint counts and lengths are high.", "example": "Convert the coordinate to text: [2.4985 8.6722]:"}
{"text": "Convert the coordinate to text: [-2.458  -2.1444]: The authors offer a probabilistic framework for discovering intents, in which intent assignments are treated as latent variables, leveraging both unlabeled data and knowledge from known intents.", "target": "The authors offer a probabilistic framework for discovering intents, in which intent assignments are treated as latent variables, leveraging both unlabeled data and knowledge from known intents.", "example": "Convert the coordinate to text: [-2.458  -2.1444]:"}
{"text": "Convert the coordinate to text: [-3.2756 -3.1059]: The study proposes a multi-task learning approach for query understanding which includes a large-scale entity-aware multi-task learning model (EAMT). This model retrieves entities from engagement data as a query context to augment the query representation.", "target": "The study proposes a multi-task learning approach for query understanding which includes a large-scale entity-aware multi-task learning model (EAMT). This model retrieves entities from engagement data as a query context to augment the query representation.", "example": "Convert the coordinate to text: [-3.2756 -3.1059]:"}
{"text": "Convert the coordinate to text: [12.2968 -4.4327]: The authors propose a defense method combining local and global defenses to improve the robustness of representation, and introduce the 'Perturbed Edges Harmfulness' (PEH) metric to determine the riskiness of an attack. They present a method of attention-based protection against high-risk attacks that penalizes attention coefficients of perturbed edges to encoders.", "target": "The authors propose a defense method combining local and global defenses to improve the robustness of representation, and introduce the 'Perturbed Edges Harmfulness' (PEH) metric to determine the riskiness of an attack. They present a method of attention-based protection against high-risk attacks that penalizes attention coefficients of perturbed edges to encoders.", "example": "Convert the coordinate to text: [12.2968 -4.4327]:"}
{"text": "Convert the coordinate to text: [13.008  -7.8828]: An innovative method, SCONE-GAN, has been introduced that leverages graph convolutional networks to learn object dependencies, maintaining image structure and preserving semantics during image transfer to the target domain. For increased realism and diversity in image generation, a style reference image is introduced.", "target": "An innovative method, SCONE-GAN, has been introduced that leverages graph convolutional networks to learn object dependencies, maintaining image structure and preserving semantics during image transfer to the target domain. For increased realism and diversity in image generation, a style reference image is introduced.", "example": "Convert the coordinate to text: [13.008  -7.8828]:"}
{"text": "Convert the coordinate to text: [ 13.0335 -16.7556]: This paper investigates generating highly realistic optical flow datasets from real-world images, by first constructing a layered depth representation, known as multiplane images (MPI), from single-view images to generate new, realistic images. It then calculates the optical flows for each plane using the camera matrix and plane depths, projecting these layered optical flows into the output map with volume rendering.", "target": "This paper investigates generating highly realistic optical flow datasets from real-world images, by first constructing a layered depth representation, known as multiplane images (MPI), from single-view images to generate new, realistic images. It then calculates the optical flows for each plane using the camera matrix and plane depths, projecting these layered optical flows into the output map with volume rendering.", "example": "Convert the coordinate to text: [ 13.0335 -16.7556]:"}
{"text": "Convert the coordinate to text: [ 13.0769 -13.8524]: The paper presents AffordPose, a large-scale dataset of hand-object interactions with affordance-driven hand poses. The particular affordance of each object part is annotated, allowing for the localization and understanding of fine-grained hand-object interactions.", "target": "The paper presents AffordPose, a large-scale dataset of hand-object interactions with affordance-driven hand poses. The particular affordance of each object part is annotated, allowing for the localization and understanding of fine-grained hand-object interactions.", "example": "Convert the coordinate to text: [ 13.0769 -13.8524]:"}
{"text": "Convert the coordinate to text: [  8.6141 -12.9326]: This research proposes a method to enhance multi-camera BEV based detection by training it to imitate the features of a well-trained LiDAR based teacher detector. The method uses a balancing strategy to ensure the student detector focuses on learning crucial features from the teacher, and generalizes knowledge transfer to multi-scale layers with temporal fusion.", "target": "This research proposes a method to enhance multi-camera BEV based detection by training it to imitate the features of a well-trained LiDAR based teacher detector. The method uses a balancing strategy to ensure the student detector focuses on learning crucial features from the teacher, and generalizes knowledge transfer to multi-scale layers with temporal fusion.", "example": "Convert the coordinate to text: [  8.6141 -12.9326]:"}
{"text": "Convert the coordinate to text: [ 4.6092 -8.8759]: The authors propose a self-supervised cross-view representation reconstruction (SCORER) network that models relationships between cross-view features from similar / dissimilar images and reconstructs the representations of unchanged objects for caption generation.", "target": "The authors propose a self-supervised cross-view representation reconstruction (SCORER) network that models relationships between cross-view features from similar / dissimilar images and reconstructs the representations of unchanged objects for caption generation.", "example": "Convert the coordinate to text: [ 4.6092 -8.8759]:"}
{"text": "Convert the coordinate to text: [ 7.3824 -9.8666]: The authors propose a single-pass network for open-vocabulary semantic segmentation that only requires a single pass through the visual-language model for each input image. They develop a novel network adaptation technique called patch severance to limit interference between patch embeddings in the pre-trained visual encoder, and they introduce classification anchor learning to focus the network on more discriminative features for classification.", "target": "The authors propose a single-pass network for open-vocabulary semantic segmentation that only requires a single pass through the visual-language model for each input image. They develop a novel network adaptation technique called patch severance to limit interference between patch embeddings in the pre-trained visual encoder, and they introduce classification anchor learning to focus the network on more discriminative features for classification.", "example": "Convert the coordinate to text: [ 7.3824 -9.8666]:"}
{"text": "Convert the coordinate to text: [4.9253 4.8102]: The key innovation in this paper is the proposal of the first truly polylogarithmic-approximate low-cost fair hierarchical clustering, thus significantly bridging the gap between the best fair and vanilla hierarchical clustering approximations.", "target": "The key innovation in this paper is the proposal of the first truly polylogarithmic-approximate low-cost fair hierarchical clustering, thus significantly bridging the gap between the best fair and vanilla hierarchical clustering approximations.", "example": "Convert the coordinate to text: [4.9253 4.8102]:"}
{"text": "Convert the coordinate to text: [-4.9044  8.7603]: The authors propose How2comm, a collaborative perception framework aimed at finding a balance between perception performance and communication bandwidth. This includes a mutual information-aware communication mechanism, a flow-guided delay compensation strategy, and a pragmatic collaboration transformer.", "target": "The authors propose How2comm, a collaborative perception framework aimed at finding a balance between perception performance and communication bandwidth. This includes a mutual information-aware communication mechanism, a flow-guided delay compensation strategy, and a pragmatic collaboration transformer.", "example": "Convert the coordinate to text: [-4.9044  8.7603]:"}
{"text": "Convert the coordinate to text: [4.7382 5.0134]: The authors aim to go beyond the constraint of semi-streaming algorithms and study correlation clustering via streaming algorithms with much smaller, polylog(n) bit memory requirements. This allows for the estimation of the cost of optimal correlation clustering solutions without having to recover full solutions.", "target": "The authors aim to go beyond the constraint of semi-streaming algorithms and study correlation clustering via streaming algorithms with much smaller, polylog(n) bit memory requirements. This allows for the estimation of the cost of optimal correlation clustering solutions without having to recover full solutions.", "example": "Convert the coordinate to text: [4.7382 5.0134]:"}
{"text": "Convert the coordinate to text: [9.1078 2.5296]: To overcome the limitations of OptEqs, the authors propose replacing the linear kernel with a function that can better capture nonlinear feature dependencies in the input data. The authors introduce the use of Gaussian kernels to serve this purpose, also known as the Gaussian kernel equilibrium (GEQ) model.", "target": "To overcome the limitations of OptEqs, the authors propose replacing the linear kernel with a function that can better capture nonlinear feature dependencies in the input data. The authors introduce the use of Gaussian kernels to serve this purpose, also known as the Gaussian kernel equilibrium (GEQ) model.", "example": "Convert the coordinate to text: [9.1078 2.5296]:"}
{"text": "Convert the coordinate to text: [15.7025 -0.1383]: The authors propose a post-training quantization scheme, Z-Fold, that reduces the computational burden during inference. This scheme is designed to fully utilize the features of the Transformer structure used in large language models.", "target": "The authors propose a post-training quantization scheme, Z-Fold, that reduces the computational burden during inference. This scheme is designed to fully utilize the features of the Transformer structure used in large language models.", "example": "Convert the coordinate to text: [15.7025 -0.1383]:"}
{"text": "Convert the coordinate to text: [-5.8174 -0.4706]: In order to address the broader inconsistency concerns in text summarization, a new model, EnergySum is introduced. This model applies the Residual Energy-based Model by designing energy scorers that reflect each type of consistency.", "target": "In order to address the broader inconsistency concerns in text summarization, a new model, EnergySum is introduced. This model applies the Residual Energy-based Model by designing energy scorers that reflect each type of consistency.", "example": "Convert the coordinate to text: [-5.8174 -0.4706]:"}
{"text": "Convert the coordinate to text: [-5.9772  4.4661]: In response to the challenges faced by traditional NLP models, the authors propose a non-parametric dense retrieval technique for temporal adaptation which does not require re-training. The technique is applied to the task of longitudinal hashtag prediction.", "target": "In response to the challenges faced by traditional NLP models, the authors propose a non-parametric dense retrieval technique for temporal adaptation which does not require re-training. The technique is applied to the task of longitudinal hashtag prediction.", "example": "Convert the coordinate to text: [-5.9772  4.4661]:"}
{"text": "Convert the coordinate to text: [-1.3344 -4.1056]: The paper proposes the Retrieve, Reorganize, and Rescale (Re 3 Dial) framework, which can automatically construct billion-scale long-turn dialogues by reorganizing existing short-turn ones, using a session retriever, diversity sampling, and session concatenation.", "target": "The paper proposes the Retrieve, Reorganize, and Rescale (Re 3 Dial) framework, which can automatically construct billion-scale long-turn dialogues by reorganizing existing short-turn ones, using a session retriever, diversity sampling, and session concatenation.", "example": "Convert the coordinate to text: [-1.3344 -4.1056]:"}
{"text": "Convert the coordinate to text: [14.7554 -0.0275]: The authors propose Equivariant Quantum Graph Circuits (EQGCs), a class of parameterized quantum circuits that unifies and extends existing methods for graph representation learning.", "target": "The authors propose Equivariant Quantum Graph Circuits (EQGCs), a class of parameterized quantum circuits that unifies and extends existing methods for graph representation learning.", "example": "Convert the coordinate to text: [14.7554 -0.0275]:"}
{"text": "Convert the coordinate to text: [-1.3727 -3.0164]: The authors propose a novel N-ary Query Embedding (NQE) model for CQA over hyper-relational knowledge graphs (HKGs), which include significant n-ary facts. This includes a dual-heterogeneous Transformer encoder and fuzzy logic theory for querying and satisfying n-ary First Order Logic (FOL) queries.", "target": "The authors propose a novel N-ary Query Embedding (NQE) model for CQA over hyper-relational knowledge graphs (HKGs), which include significant n-ary facts. This includes a dual-heterogeneous Transformer encoder and fuzzy logic theory for querying and satisfying n-ary First Order Logic (FOL) queries.", "example": "Convert the coordinate to text: [-1.3727 -3.0164]:"}
{"text": "Convert the coordinate to text: [ 13.3953 -14.0306]: The authors propose the first neural-implicit approach to photo-realistically render hands in real-time, which is a complex problem since hands are textured and undergo strong articulations with pose-dependent effects.", "target": "The authors propose the first neural-implicit approach to photo-realistically render hands in real-time, which is a complex problem since hands are textured and undergo strong articulations with pose-dependent effects.", "example": "Convert the coordinate to text: [ 13.3953 -14.0306]:"}
{"text": "Convert the coordinate to text: [-3.3967 -6.985 ]: The authors propose a recipe for training machine translation models by leveraging synthetic target data produced using a large pre-trained model, especially in limited resource settings.", "target": "The authors propose a recipe for training machine translation models by leveraging synthetic target data produced using a large pre-trained model, especially in limited resource settings.", "example": "Convert the coordinate to text: [-3.3967 -6.985 ]:"}
{"text": "Convert the coordinate to text: [-0.9333 -3.4841]: The authors propose a unified framework named HyNT which learns representations of hyper-relational knowledge graphs that contain numeric literals in either triplets or qualifiers, using a context transformer and a prediction transformer to take into account the correlations between a triplet and its qualifiers.", "target": "The authors propose a unified framework named HyNT which learns representations of hyper-relational knowledge graphs that contain numeric literals in either triplets or qualifiers, using a context transformer and a prediction transformer to take into account the correlations between a triplet and its qualifiers.", "example": "Convert the coordinate to text: [-0.9333 -3.4841]:"}
{"text": "Convert the coordinate to text: [3.551  5.8067]: The authors propose CentRA, a novel algorithm for centrality maximization. It is the first progressive sampling-based method that uses Monte Carlo Rademacher Averages from statistical learning theory to compute data-dependent approximation bounds.", "target": "The authors propose CentRA, a novel algorithm for centrality maximization. It is the first progressive sampling-based method that uses Monte Carlo Rademacher Averages from statistical learning theory to compute data-dependent approximation bounds.", "example": "Convert the coordinate to text: [3.551  5.8067]:"}
{"text": "Convert the coordinate to text: [ -1.4793 -10.0205]: The study chooses to focus on noise-invariant visual modality to increase the robustness of AVSR, in what is referred to as unsupervised noise adaptation. As such, they propose a universal viseme-phoneme mapping (UniVPM) method that restores clean audio from visual signals for speech recognition in any noise conditions.", "target": "The study chooses to focus on noise-invariant visual modality to increase the robustness of AVSR, in what is referred to as unsupervised noise adaptation. As such, they propose a universal viseme-phoneme mapping (UniVPM) method that restores clean audio from visual signals for speech recognition in any noise conditions.", "example": "Convert the coordinate to text: [ -1.4793 -10.0205]:"}
{"text": "Convert the coordinate to text: [-4.5466 -7.596 ]: This study aims to systematically analyze and compare various mainstream and cutting-edge automatic metrics from the perspective of guiding training of machine translation systems and improving their robustness.", "target": "This study aims to systematically analyze and compare various mainstream and cutting-edge automatic metrics from the perspective of guiding training of machine translation systems and improving their robustness.", "example": "Convert the coordinate to text: [-4.5466 -7.596 ]:"}
{"text": "Convert the coordinate to text: [ 2.0704 -9.6649]: The authors propose a retrieval-based framework to bolster model representations in the face of this key-object degeneracy, with an aim to improve dense video captioning.", "target": "The authors propose a retrieval-based framework to bolster model representations in the face of this key-object degeneracy, with an aim to improve dense video captioning.", "example": "Convert the coordinate to text: [ 2.0704 -9.6649]:"}
{"text": "Convert the coordinate to text: [-0.6837 -8.7056]: The authors introduce CheXOFA, a pre-trained vision-language model (VLM) for the chest X-ray domain, where domain-specific tasks are unified into a simple sequence-to-sequence schema.", "target": "The authors introduce CheXOFA, a pre-trained vision-language model (VLM) for the chest X-ray domain, where domain-specific tasks are unified into a simple sequence-to-sequence schema.", "example": "Convert the coordinate to text: [-0.6837 -8.7056]:"}
{"text": "Convert the coordinate to text: [-8.3429 10.8294]: The authors present ORBITS, a video-based student support platform that leverages knowledge tracing to enhance and personalize student learning.", "target": "The authors present ORBITS, a video-based student support platform that leverages knowledge tracing to enhance and personalize student learning.", "example": "Convert the coordinate to text: [-8.3429 10.8294]:"}
{"text": "Convert the coordinate to text: [-2.6941 -8.3425]: The authors propose a Self-Training with Feedback (STF) framework for event extraction which leverages large-scale unlabeled data and acquires feedback for each new event prediction by comparing it to the Abstract Meaning Representation (AMR) graph of the same sentence.", "target": "The authors propose a Self-Training with Feedback (STF) framework for event extraction which leverages large-scale unlabeled data and acquires feedback for each new event prediction by comparing it to the Abstract Meaning Representation (AMR) graph of the same sentence.", "example": "Convert the coordinate to text: [-2.6941 -8.3425]:"}
{"text": "Convert the coordinate to text: [-0.4151 -7.493 ]: This paper proposes a pre-training technique for AVE which improves the conventional token-level masking strategy to understand multi-scale values and applies clustering for a challenging negative set design for contrastive learning to discriminate similar attributes.", "target": "This paper proposes a pre-training technique for AVE which improves the conventional token-level masking strategy to understand multi-scale values and applies clustering for a challenging negative set design for contrastive learning to discriminate similar attributes.", "example": "Convert the coordinate to text: [-0.4151 -7.493 ]:"}
{"text": "Convert the coordinate to text: [-0.3484 -6.7129]: This study presents a large pretraining dataset and strategy for learning representations of text, tables, and SQL code, utilizing the entire context of the problem. It augments the existing encoder-decoder architecture using a multitask pretraining framework that accounts for the unique attributes of the diverse pretraining data.", "target": "This study presents a large pretraining dataset and strategy for learning representations of text, tables, and SQL code, utilizing the entire context of the problem. It augments the existing encoder-decoder architecture using a multitask pretraining framework that accounts for the unique attributes of the diverse pretraining data.", "example": "Convert the coordinate to text: [-0.3484 -6.7129]:"}
{"text": "Convert the coordinate to text: [ 6.2023 -1.18  ]: The authors propose Focus Learning (FocusL), a new approach that adjusts the contribution of each token to the optimization direction by directly scaling the corresponding objective loss.", "target": "The authors propose Focus Learning (FocusL), a new approach that adjusts the contribution of each token to the optimization direction by directly scaling the corresponding objective loss.", "example": "Convert the coordinate to text: [ 6.2023 -1.18  ]:"}
{"text": "Convert the coordinate to text: [12.1683 -5.9486]: The authors present Adversarial Camouflage for Transferable and Intensive Vehicle Evasion (ACTIVE), a physical camouflage attack framework designed to generate universal and robust adversarial camouflage that can conceal any 3D vehicle from detectors.", "target": "The authors present Adversarial Camouflage for Transferable and Intensive Vehicle Evasion (ACTIVE), a physical camouflage attack framework designed to generate universal and robust adversarial camouflage that can conceal any 3D vehicle from detectors.", "example": "Convert the coordinate to text: [12.1683 -5.9486]:"}
{"text": "Convert the coordinate to text: [  8.4401 -16.912 ]: The authors propose a new batch-based matching algorithm that pairs the front and back sides of archaeological fragments and a Bilateral Boundary ICP (Iterative Closest Point) algorithm which can register partial scans sharing very narrow overlapping regions efficiently.", "target": "The authors propose a new batch-based matching algorithm that pairs the front and back sides of archaeological fragments and a Bilateral Boundary ICP (Iterative Closest Point) algorithm which can register partial scans sharing very narrow overlapping regions efficiently.", "example": "Convert the coordinate to text: [  8.4401 -16.912 ]:"}
{"text": "Convert the coordinate to text: [ 4.8498 -0.7689]: The authors propose a new paradigm, termed ordinal label distribution learning (OLDL), that models the sequential patterns of labels from aspects of spatial, semantic, and temporal order relationships.", "target": "The authors propose a new paradigm, termed ordinal label distribution learning (OLDL), that models the sequential patterns of labels from aspects of spatial, semantic, and temporal order relationships.", "example": "Convert the coordinate to text: [ 4.8498 -0.7689]:"}
{"text": "Convert the coordinate to text: [  0.234  -10.5044]: The authors propose a new paradigm for open visual knowledge extraction, where these limitations do not apply. They develop OpenVik, an open relational region detector, and a visual knowledge generator that produces format-free knowledge by prompting a large multimodality model with the detected region of interest.", "target": "The authors propose a new paradigm for open visual knowledge extraction, where these limitations do not apply. They develop OpenVik, an open relational region detector, and a visual knowledge generator that produces format-free knowledge by prompting a large multimodality model with the detected region of interest.", "example": "Convert the coordinate to text: [  0.234  -10.5044]:"}
{"text": "Convert the coordinate to text: [11.7944 -5.1046]: The authors propose to use adversarial learning principles, utilizing several discriminators trained to distinguish between two distributions, in order to both detect corrupted features and fix them, thereby removing the distribution shift between datasets.", "target": "The authors propose to use adversarial learning principles, utilizing several discriminators trained to distinguish between two distributions, in order to both detect corrupted features and fix them, thereby removing the distribution shift between datasets.", "example": "Convert the coordinate to text: [11.7944 -5.1046]:"}
{"text": "Convert the coordinate to text: [ 3.7348 -8.1173]: A dictionary learning-based attention (Dic-Attn) module is proposed that models attention as a decomposition and reconstruction problem with a sparsity prior, taking inspiration from sparse coding in the human visual perception system. The Dic-Attn module decomposes the input into a dictionary and corresponding sparse representations, thereby disentangling underlying nonlinear structural information in visual data and reconstructing an attention embedding.", "target": "A dictionary learning-based attention (Dic-Attn) module is proposed that models attention as a decomposition and reconstruction problem with a sparsity prior, taking inspiration from sparse coding in the human visual perception system. The Dic-Attn module decomposes the input into a dictionary and corresponding sparse representations, thereby disentangling underlying nonlinear structural information in visual data and reconstructing an attention embedding.", "example": "Convert the coordinate to text: [ 3.7348 -8.1173]:"}
{"text": "Convert the coordinate to text: [0.1632 2.4094]: The authors propose FairLISA, a novel framework designed for scenarios with limited sensitive attribute data. The framework is able to efficiently utilize data with known and unknown sensitive attributes to facilitate fair model training.", "target": "The authors propose FairLISA, a novel framework designed for scenarios with limited sensitive attribute data. The framework is able to efficiently utilize data with known and unknown sensitive attributes to facilitate fair model training.", "example": "Convert the coordinate to text: [0.1632 2.4094]:"}
{"text": "Convert the coordinate to text: [12.7124 -4.617 ]: This paper proposes a new defense approach, called MeCo (Memory and Computation efficient defense approach), which utilizes distributionally robust defensive training on the target victim model to prevent DFME from occurring while maintaining model utility.", "target": "This paper proposes a new defense approach, called MeCo (Memory and Computation efficient defense approach), which utilizes distributionally robust defensive training on the target victim model to prevent DFME from occurring while maintaining model utility.", "example": "Convert the coordinate to text: [12.7124 -4.617 ]:"}
{"text": "Convert the coordinate to text: [-8.3849 10.2384]: This paper explores new settings where the scheduler has some imperfect prediction about the interruption, either describing the time of the interruption or elicited as responses to a set of binary queries.", "target": "This paper explores new settings where the scheduler has some imperfect prediction about the interruption, either describing the time of the interruption or elicited as responses to a set of binary queries.", "example": "Convert the coordinate to text: [-8.3849 10.2384]:"}
{"text": "Convert the coordinate to text: [ 8.7727 10.4897]: The authors introduce a new algorithm named GO-UCB that uses a parametric family of functions, such as neural networks, to tackle the problem of global optimization with noisy zeroth order oracles.", "target": "The authors introduce a new algorithm named GO-UCB that uses a parametric family of functions, such as neural networks, to tackle the problem of global optimization with noisy zeroth order oracles.", "example": "Convert the coordinate to text: [ 8.7727 10.4897]:"}
{"text": "Convert the coordinate to text: [-9.5104  1.3076]: The authors define and examine three important abilities that a functioning IR framework should possess: exclusivity, completeness, and relevance ordering. They propose a multi-task distillation approach to enhance the retrieval quality without altering the model structure.", "target": "The authors define and examine three important abilities that a functioning IR framework should possess: exclusivity, completeness, and relevance ordering. They propose a multi-task distillation approach to enhance the retrieval quality without altering the model structure.", "example": "Convert the coordinate to text: [-9.5104  1.3076]:"}
{"text": "Convert the coordinate to text: [ 6.6317 -2.4863]: To understand and mitigate the aforementioned training-inference discrepancies, the authors propose two methods, named Distance Penalty and Adaptive Decay Sampling.", "target": "To understand and mitigate the aforementioned training-inference discrepancies, the authors propose two methods, named Distance Penalty and Adaptive Decay Sampling.", "example": "Convert the coordinate to text: [ 6.6317 -2.4863]:"}
{"text": "Convert the coordinate to text: [ 7.4516 -2.1173]: The paper proposes a novel data uniform sampling strategy for federated learning, termed FedSampling, which takes the different data sizes across clients into account and provides better performance, especially when client data size distribution is highly imbalanced.", "target": "The paper proposes a novel data uniform sampling strategy for federated learning, termed FedSampling, which takes the different data sizes across clients into account and provides better performance, especially when client data size distribution is highly imbalanced.", "example": "Convert the coordinate to text: [ 7.4516 -2.1173]:"}
{"text": "Convert the coordinate to text: [-1.2698 11.9337]: The authors introduce NormBank, a knowledge bank of 155k situational norms. Unlike previous resources, it grounds each inference within a multivalent sociocultural frame, including settings, agents' roles, their attributes and other physical, social, and cultural constraints.", "target": "The authors introduce NormBank, a knowledge bank of 155k situational norms. Unlike previous resources, it grounds each inference within a multivalent sociocultural frame, including settings, agents' roles, their attributes and other physical, social, and cultural constraints.", "example": "Convert the coordinate to text: [-1.2698 11.9337]:"}
{"text": "Convert the coordinate to text: [13.0437 -4.8957]: This study presents a new attack methodology where the adversary deceptively omits a portion of the true training data to bias the learned causal structures in a desired manner.", "target": "This study presents a new attack methodology where the adversary deceptively omits a portion of the true training data to bias the learned causal structures in a desired manner.", "example": "Convert the coordinate to text: [13.0437 -4.8957]:"}
{"text": "Convert the coordinate to text: [-2.8495 -0.0285]: The paper explores the effectiveness of natural language inference (NLI) models in helping hate speech detection in situations with limited data in the target language.", "target": "The paper explores the effectiveness of natural language inference (NLI) models in helping hate speech detection in situations with limited data in the target language.", "example": "Convert the coordinate to text: [-2.8495 -0.0285]:"}
{"text": "Convert the coordinate to text: [-10.3017  -1.6083]: The authors propose interpreting the problem of integrating QA-pair and document corpora as a calibration task. This approach uses the confidence of predicted answers as an indicator to decide when to use a document corpus or a QA-pair corpus.", "target": "The authors propose interpreting the problem of integrating QA-pair and document corpora as a calibration task. This approach uses the confidence of predicted answers as an indicator to decide when to use a document corpus or a QA-pair corpus.", "example": "Convert the coordinate to text: [-10.3017  -1.6083]:"}
{"text": "Convert the coordinate to text: [-11.0998  -1.7721]: This paper presents CATS, a pragmatic Chinese answer-to-sequence dataset with large scale and high quality that aims to generate textual descriptions for the answer in the practical TableQA system. It also proposes a Unified Graph Transformation approach to bridge the structural gap between the input SQL and table and establish better semantic alignments, converting the task to a graph-to-text problem.", "target": "This paper presents CATS, a pragmatic Chinese answer-to-sequence dataset with large scale and high quality that aims to generate textual descriptions for the answer in the practical TableQA system. It also proposes a Unified Graph Transformation approach to bridge the structural gap between the input SQL and table and establish better semantic alignments, converting the task to a graph-to-text problem.", "example": "Convert the coordinate to text: [-11.0998  -1.7721]:"}
{"text": "Convert the coordinate to text: [-8.8704 -3.5788]: The authors propose M2C, a morphologically-aware framework for behavioural testing of NLP models that can generate tests which probe models' behavior in light of specific linguistic features in 12 typologically diverse languages.", "target": "The authors propose M2C, a morphologically-aware framework for behavioural testing of NLP models that can generate tests which probe models' behavior in light of specific linguistic features in 12 typologically diverse languages.", "example": "Convert the coordinate to text: [-8.8704 -3.5788]:"}
{"text": "Convert the coordinate to text: [-3.203  -6.5671]: The authors propose two approaches: Delta TF-IDF and a Language-Specific Model Fusion Algorithm using Language Identification, for sentiment analysis on African Languages.", "target": "The authors propose two approaches: Delta TF-IDF and a Language-Specific Model Fusion Algorithm using Language Identification, for sentiment analysis on African Languages.", "example": "Convert the coordinate to text: [-3.203  -6.5671]:"}
{"text": "Convert the coordinate to text: [-1.4389 -0.0039]: UMUTeam took part in the competition with a solution that expands new unlabeled sexism data in the Masked Language Model task of a pre-trained model such as RoBERTa-large, aiming to improve its generalization capacity and performance on classification tasks.", "target": "UMUTeam took part in the competition with a solution that expands new unlabeled sexism data in the Masked Language Model task of a pre-trained model such as RoBERTa-large, aiming to improve its generalization capacity and performance on classification tasks.", "example": "Convert the coordinate to text: [-1.4389 -0.0039]:"}
{"text": "Convert the coordinate to text: [-1.9186 -5.398 ]: The ADAIO team present a system that entails evaluating different baseline models using OpenAI's GPT-3 and designing a variety of prompts to guide the model's generation of teacher responses.", "target": "The ADAIO team present a system that entails evaluating different baseline models using OpenAI's GPT-3 and designing a variety of prompts to guide the model's generation of teacher responses.", "example": "Convert the coordinate to text: [-1.9186 -5.398 ]:"}
{"text": "Convert the coordinate to text: [ 1.0092 -7.1766]: This study introduces a quantum-inspired adaptive-priority-learning model (QAP) to handle the challenges in multimodal emotion recognition, utilizing quantum state to model modal features and a Q-attention mechanism to integrate the modality information while adaptively learning modality priority.", "target": "This study introduces a quantum-inspired adaptive-priority-learning model (QAP) to handle the challenges in multimodal emotion recognition, utilizing quantum state to model modal features and a Q-attention mechanism to integrate the modality information while adaptively learning modality priority.", "example": "Convert the coordinate to text: [ 1.0092 -7.1766]:"}
{"text": "Convert the coordinate to text: [-0.2398 -4.3309]: The authors propose a Static-Dynamic graph-based Dialogue Summarization model (SDDS) that fuses prior knowledge from human expertise and adaptively learns the graph structure in an end-to-end learning manner.", "target": "The authors propose a Static-Dynamic graph-based Dialogue Summarization model (SDDS) that fuses prior knowledge from human expertise and adaptively learns the graph structure in an end-to-end learning manner.", "example": "Convert the coordinate to text: [-0.2398 -4.3309]:"}
{"text": "Convert the coordinate to text: [-6.0054  3.4634]: The authors introduce the task of trigger warning assignment as a multi-label classification task and curate the Webis Trigger Warning Corpus 2022, which contains 1 million fanfiction works from Archive of our Own with up to 36 different warnings per document.", "target": "The authors introduce the task of trigger warning assignment as a multi-label classification task and curate the Webis Trigger Warning Corpus 2022, which contains 1 million fanfiction works from Archive of our Own with up to 36 different warnings per document.", "example": "Convert the coordinate to text: [-6.0054  3.4634]:"}
{"text": "Convert the coordinate to text: [-0.7803 -9.585 ]: The authors propose weakly-supervised spoken video grounding without extensive temporal annotations. They create Semantic Interaction Learning (SIL), a framework that includes acoustic-semantic pre-training (ASP) and acoustic-visual contrastive learning (AVCL) for effective representation of cross-modal semantics. ", "target": "The authors propose weakly-supervised spoken video grounding without extensive temporal annotations. They create Semantic Interaction Learning (SIL), a framework that includes acoustic-semantic pre-training (ASP) and acoustic-visual contrastive learning (AVCL) for effective representation of cross-modal semantics. ", "example": "Convert the coordinate to text: [-0.7803 -9.585 ]:"}
{"text": "Convert the coordinate to text: [-5.759  10.6406]: The authors introduce a new task of proactive response selection, where conversational models need to choose responses based on situational information in order to proactively advance the conversation.", "target": "The authors introduce a new task of proactive response selection, where conversational models need to choose responses based on situational information in order to proactively advance the conversation.", "example": "Convert the coordinate to text: [-5.759  10.6406]:"}
{"text": "Convert the coordinate to text: [ 0.8144 -5.3267]: This paper defines the overlap knowledge across datasets and bifurcates the EAE task knowledge into overlapped and specific knowledge of the target dataset. The authors propose the APE model which learns these knowledge types in two sequential learning phases without incurring catastrophic forgetting.", "target": "This paper defines the overlap knowledge across datasets and bifurcates the EAE task knowledge into overlapped and specific knowledge of the target dataset. The authors propose the APE model which learns these knowledge types in two sequential learning phases without incurring catastrophic forgetting.", "example": "Convert the coordinate to text: [ 0.8144 -5.3267]:"}
{"text": "Convert the coordinate to text: [ 11.648  -12.7977]: This paper presents Wavelet-aware Image-based Pose Transfer (WaveIPT), a novel approach that combines the strengths of both attention and flow in the wavelet domain to enhance human pose transfer, aiming at maximizing the semantic structure and texture details of the source image.", "target": "This paper presents Wavelet-aware Image-based Pose Transfer (WaveIPT), a novel approach that combines the strengths of both attention and flow in the wavelet domain to enhance human pose transfer, aiming at maximizing the semantic structure and texture details of the source image.", "example": "Convert the coordinate to text: [ 11.648  -12.7977]:"}
{"text": "Convert the coordinate to text: [ 12.1585 -18.3794]: The authors propose a deep homography mixture motion model for single image rolling shutter correction, in which they learn coefficients that combine several motion bases to produce correction motion, rather than directly learning the motion mapping.", "target": "The authors propose a deep homography mixture motion model for single image rolling shutter correction, in which they learn coefficients that combine several motion bases to produce correction motion, rather than directly learning the motion mapping.", "example": "Convert the coordinate to text: [ 12.1585 -18.3794]:"}
{"text": "Convert the coordinate to text: [ 6.6274 13.4511]: The authors present a probabilistic framework, Offline RL with DiscrEte pRoxy representations (ORDER), designed to aid offline RL methods to manage diverse masked observabilities better by leveraging novel state representations.", "target": "The authors present a probabilistic framework, Offline RL with DiscrEte pRoxy representations (ORDER), designed to aid offline RL methods to manage diverse masked observabilities better by leveraging novel state representations.", "example": "Convert the coordinate to text: [ 6.6274 13.4511]:"}
{"text": "Convert the coordinate to text: [11.627  -4.4073]: The authors address the problem by designing a new residual block, leading to the Linear ResNet (LiResNet) architecture. They also propose Efficient Margin MAximization (EMMA), a loss function that stabilizes robust training by penalizing worst-case adversarial examples from multiple classes simultaneously.", "target": "The authors address the problem by designing a new residual block, leading to the Linear ResNet (LiResNet) architecture. They also propose Efficient Margin MAximization (EMMA), a loss function that stabilizes robust training by penalizing worst-case adversarial examples from multiple classes simultaneously.", "example": "Convert the coordinate to text: [11.627  -4.4073]:"}
{"text": "Convert the coordinate to text: [-2.2308 -5.3894]: The authors propose specific SDC strategies designed for both general and aspect-specific opinion summarization. These strategies optimize the use of Pretrained Language Models (PLMs) for opinion summarization tasks.", "target": "The authors propose specific SDC strategies designed for both general and aspect-specific opinion summarization. These strategies optimize the use of Pretrained Language Models (PLMs) for opinion summarization tasks.", "example": "Convert the coordinate to text: [-2.2308 -5.3894]:"}
{"text": "Convert the coordinate to text: [-7.868  -0.9667]: The authors propose a new method, Path wIth expLOraTion (PILOT), that enhances the reasoning path by exploring the explicit clue information within the documents, finding bridging entities that directly guide the paths between entities and using them as stepstones to navigate desirable paths.", "target": "The authors propose a new method, Path wIth expLOraTion (PILOT), that enhances the reasoning path by exploring the explicit clue information within the documents, finding bridging entities that directly guide the paths between entities and using them as stepstones to navigate desirable paths.", "example": "Convert the coordinate to text: [-7.868  -0.9667]:"}
{"text": "Convert the coordinate to text: [-1.0326 -5.1018]: The authors introduce 'PromptRank', a method that leverages language model prompting for reranking multi-hop paths, reducing the need for extensive labeled training data.", "target": "The authors introduce 'PromptRank', a method that leverages language model prompting for reranking multi-hop paths, reducing the need for extensive labeled training data.", "example": "Convert the coordinate to text: [-1.0326 -5.1018]:"}
{"text": "Convert the coordinate to text: [13.8959 -2.381 ]: The study proposes a temporal-spectral transformer network (TSNet) to model the temporal, spectral, and mutual connections in spike-LFPs towards robust neural decoding.", "target": "The study proposes a temporal-spectral transformer network (TSNet) to model the temporal, spectral, and mutual connections in spike-LFPs towards robust neural decoding.", "example": "Convert the coordinate to text: [13.8959 -2.381 ]:"}
{"text": "Convert the coordinate to text: [ 0.5525 -8.356 ]: A new approach called Integrated Multimodal Perception (IMP) is proposed, integrating multimodal inputs such as image, video, text, and audio into a single Transformer encoder with minimal modality-specific components. The design combines Alternating Gradient Descent (AGD) and Mixture-of-Experts (MoE) for efficacious model and task scaling.", "target": "A new approach called Integrated Multimodal Perception (IMP) is proposed, integrating multimodal inputs such as image, video, text, and audio into a single Transformer encoder with minimal modality-specific components. The design combines Alternating Gradient Descent (AGD) and Mixture-of-Experts (MoE) for efficacious model and task scaling.", "example": "Convert the coordinate to text: [ 0.5525 -8.356 ]:"}
{"text": "Convert the coordinate to text: [-5.345   9.8393]: The authors propose a new task, speech dialogue translation mediating speakers of different languages, and present two ways of utilizing context in speech translation: monolingual context and bilingual context.", "target": "The authors propose a new task, speech dialogue translation mediating speakers of different languages, and present two ways of utilizing context in speech translation: monolingual context and bilingual context.", "example": "Convert the coordinate to text: [-5.345   9.8393]:"}
{"text": "Convert the coordinate to text: [-0.3116  9.0496]: The paper proposes a parameterised family of gradual semantics based on a parameter \u03b1 taking values from the interval (0,+\u221e), with each value leading to a different semantics. This novel approach is designed to solve dilemmas in varied ways.", "target": "The paper proposes a parameterised family of gradual semantics based on a parameter \u03b1 taking values from the interval (0,+\u221e), with each value leading to a different semantics. This novel approach is designed to solve dilemmas in varied ways.", "example": "Convert the coordinate to text: [-0.3116  9.0496]:"}
{"text": "Convert the coordinate to text: [ 0.6125 -9.4201]: The authors propose a method called LIVE (Learn to Imagine for Visuallyaugmented natural language gEneration) that makes pre-trained language models capable of synthesizing high-quality images conditioned on the input text to aid in natural language generation.", "target": "The authors propose a method called LIVE (Learn to Imagine for Visuallyaugmented natural language gEneration) that makes pre-trained language models capable of synthesizing high-quality images conditioned on the input text to aid in natural language generation.", "example": "Convert the coordinate to text: [ 0.6125 -9.4201]:"}
{"text": "Convert the coordinate to text: [-0.3322 -5.4609]: The authors propose using a pretraining corpus consisting of multitask demonstrations with an unobserved latent context variable to learn low dimensional representations of high dimensional observation spaces, which can then be transferred to a novel context for finetuning on a limited dataset of demonstrations. They argue that inverse dynamics modeling is particularly well-suited to this setting.", "target": "The authors propose using a pretraining corpus consisting of multitask demonstrations with an unobserved latent context variable to learn low dimensional representations of high dimensional observation spaces, which can then be transferred to a novel context for finetuning on a limited dataset of demonstrations. They argue that inverse dynamics modeling is particularly well-suited to this setting.", "example": "Convert the coordinate to text: [-0.3322 -5.4609]:"}
{"text": "Convert the coordinate to text: [ 1.0567 -9.839 ]: The authors propose a new unified Vision-Language model, based on the One For All model, focused on context-assisted image captioning. The image caption is generated based on both the image and its context, breaking away from the context-independent nature of existing models.", "target": "The authors propose a new unified Vision-Language model, based on the One For All model, focused on context-assisted image captioning. The image caption is generated based on both the image and its context, breaking away from the context-independent nature of existing models.", "example": "Convert the coordinate to text: [ 1.0567 -9.839 ]:"}
{"text": "Convert the coordinate to text: [ 3.7082 -7.5449]: This paper proposes a novel long-document encoding model, Recurrent Attention Network (RAN), that enables the recurrent operation of self-attention. This model combines the advantages of self-attention mechanisms and recurrent structures, and can effectively extract global semantics at both the token-level and document-level.", "target": "This paper proposes a novel long-document encoding model, Recurrent Attention Network (RAN), that enables the recurrent operation of self-attention. This model combines the advantages of self-attention mechanisms and recurrent structures, and can effectively extract global semantics at both the token-level and document-level.", "example": "Convert the coordinate to text: [ 3.7082 -7.5449]:"}
{"text": "Convert the coordinate to text: [-15.597   -0.9182]: The authors propose a single-pass streaming algorithm to identify high-utility tuples by receiving the minimum amount of user input through pairwise comparisons.", "target": "The authors propose a single-pass streaming algorithm to identify high-utility tuples by receiving the minimum amount of user input through pairwise comparisons.", "example": "Convert the coordinate to text: [-15.597   -0.9182]:"}
{"text": "Convert the coordinate to text: [0.5706 0.8369]: This work presents BLIND, a method for bias removal which does not require any prior knowledge of demographics in a dataset.", "target": "This work presents BLIND, a method for bias removal which does not require any prior knowledge of demographics in a dataset.", "example": "Convert the coordinate to text: [0.5706 0.8369]:"}
{"text": "Convert the coordinate to text: [-2.9056 -6.7182]: UMUTeam utilized a fine-tuned multilingual transformer-based model using the dataset of all languages at once and a sentence transformer model to extract the most relevant chunk of text for the subtasks of SemEval-2023 Task 3.", "target": "UMUTeam utilized a fine-tuned multilingual transformer-based model using the dataset of all languages at once and a sentence transformer model to extract the most relevant chunk of text for the subtasks of SemEval-2023 Task 3.", "example": "Convert the coordinate to text: [-2.9056 -6.7182]:"}
{"text": "Convert the coordinate to text: [-3.5117 -9.2677]: The authors propose a cascaded incremental decoding system that comprises an ASR model based on the U2++ architecture and an MT model that adopts the Deep-Transformer architecture.", "target": "The authors propose a cascaded incremental decoding system that comprises an ASR model based on the U2++ architecture and an MT model that adopts the Deep-Transformer architecture.", "example": "Convert the coordinate to text: [-3.5117 -9.2677]:"}
{"text": "Convert the coordinate to text: [-5.1849 -9.9963]: The authors propose two measures to evaluate the severity of mistakes made by ASR systems - one based on sentiment analysis and another based on text embeddings.", "target": "The authors propose two measures to evaluate the severity of mistakes made by ASR systems - one based on sentiment analysis and another based on text embeddings.", "example": "Convert the coordinate to text: [-5.1849 -9.9963]:"}
{"text": "Convert the coordinate to text: [ 3.5671 -1.1575]: The authors propose a different approach for selecting top negative samples that have high similarities with all the positive samples for training.", "target": "The authors propose a different approach for selecting top negative samples that have high similarities with all the positive samples for training.", "example": "Convert the coordinate to text: [ 3.5671 -1.1575]:"}
{"text": "Convert the coordinate to text: [16.2048  1.8072]: The paper proposes an unsupervised prefix-tuning-based OOD detection framework called PTO. The authors also propose two practical extensions of PTO to take advantage of optional training data labels and targeted OOD data.", "target": "The paper proposes an unsupervised prefix-tuning-based OOD detection framework called PTO. The authors also propose two practical extensions of PTO to take advantage of optional training data labels and targeted OOD data.", "example": "Convert the coordinate to text: [16.2048  1.8072]:"}
{"text": "Convert the coordinate to text: [  9.0995 -17.6537]: The authors propose a new method, OrthoPlanes, a hybrid explicit-implicit representation which encodes fine-grained 3D information into feature maps, which can be efficiently generated by modifying 2D StyleGANs.", "target": "The authors propose a new method, OrthoPlanes, a hybrid explicit-implicit representation which encodes fine-grained 3D information into feature maps, which can be efficiently generated by modifying 2D StyleGANs.", "example": "Convert the coordinate to text: [  9.0995 -17.6537]:"}
{"text": "Convert the coordinate to text: [11.0848 -3.5163]: This work presents an in-depth theoretical analysis of the limitations of Batch Normalization (BN) in continual learning, mainly focusing on its instability and poor generalization performance in incremental tasks. They introduce a new method called Adaptive Balance of BN (AdaB$^2$N), which utilizes a Bayesian-based strategy to adjust task-wise contributions and a modified momentum to balance BN statistics.", "target": "This work presents an in-depth theoretical analysis of the limitations of Batch Normalization (BN) in continual learning, mainly focusing on its instability and poor generalization performance in incremental tasks. They introduce a new method called Adaptive Balance of BN (AdaB$^2$N), which utilizes a Bayesian-based strategy to adjust task-wise contributions and a modified momentum to balance BN statistics.", "example": "Convert the coordinate to text: [11.0848 -3.5163]:"}
{"text": "Convert the coordinate to text: [ 4.4941 12.9524]: The authors propose an approach that combines DRL and traditional active search, decomposing the search policy into a prediction module and a search module. This separates the tasks of producing a geospatial distribution of regions of interest based on task embedding and search history and taking the predictions and search history as inputs to output the search distribution.", "target": "The authors propose an approach that combines DRL and traditional active search, decomposing the search policy into a prediction module and a search module. This separates the tasks of producing a geospatial distribution of regions of interest based on task embedding and search history and taking the predictions and search history as inputs to output the search distribution.", "example": "Convert the coordinate to text: [ 4.4941 12.9524]:"}
{"text": "Convert the coordinate to text: [ 6.7231 13.5528]: The authors propose a novel algorithm, Randomized Q-learning (RandQL), the first tractable model-free posterior sampling-based algorithm. Instead of using traditional bonuses, RandQL relies on learning rate randomization for optimistic exploration.", "target": "The authors propose a novel algorithm, Randomized Q-learning (RandQL), the first tractable model-free posterior sampling-based algorithm. Instead of using traditional bonuses, RandQL relies on learning rate randomization for optimistic exploration.", "example": "Convert the coordinate to text: [ 6.7231 13.5528]:"}
{"text": "Convert the coordinate to text: [ 9.4916 -8.4278]: The authors propose Color Equivariant Convolutions (CEConvs), a deep learning component that allows shape feature sharing across the color spectrum while retaining crucial color information. They do this by extending the concept of equivariance to photometric transformations via parameter sharing over hue-shifts in a neural network.", "target": "The authors propose Color Equivariant Convolutions (CEConvs), a deep learning component that allows shape feature sharing across the color spectrum while retaining crucial color information. They do this by extending the concept of equivariance to photometric transformations via parameter sharing over hue-shifts in a neural network.", "example": "Convert the coordinate to text: [ 9.4916 -8.4278]:"}
{"text": "Convert the coordinate to text: [13.8038 -0.0195]: The authors propose a model, Context-attended Graph ODE (CARE), to handle time-varying dynamic systems. CARE uses a context variable to model time-varying environment and constructs an encoder to initialize this context variable from historical trajectories.", "target": "The authors propose a model, Context-attended Graph ODE (CARE), to handle time-varying dynamic systems. CARE uses a context variable to model time-varying environment and constructs an encoder to initialize this context variable from historical trajectories.", "example": "Convert the coordinate to text: [13.8038 -0.0195]:"}
{"text": "Convert the coordinate to text: [-3.081  -6.5125]: The authors present the first Africentric SemEval Shared task, Sentiment Analysis for African Languages (AfriSenti-SemEval), a sentiment classification challenge in 14 African languages with a 3-class labeled data: positive, negative, and neutral.", "target": "The authors present the first Africentric SemEval Shared task, Sentiment Analysis for African Languages (AfriSenti-SemEval), a sentiment classification challenge in 14 African languages with a 3-class labeled data: positive, negative, and neutral.", "example": "Convert the coordinate to text: [-3.081  -6.5125]:"}
{"text": "Convert the coordinate to text: [-10.5461  -1.4483]: The proposed KB-BINDER is a unified training-free framework for questions over diverse KBQA datasets. It works by leveraging large language models like Codex to generate logical forms as the draft for a specific question by imitating a few demonstrations, then grounds on the knowledge base to bind the generated draft to an executable one with BM25 score matching.", "target": "The proposed KB-BINDER is a unified training-free framework for questions over diverse KBQA datasets. It works by leveraging large language models like Codex to generate logical forms as the draft for a specific question by imitating a few demonstrations, then grounds on the knowledge base to bind the generated draft to an executable one with BM25 score matching.", "example": "Convert the coordinate to text: [-10.5461  -1.4483]:"}
{"text": "Convert the coordinate to text: [ 1.1973 -4.2141]: The authors propose a method called Contrastive Learning of sentence embeddings from AI Feedback (CLAIF). This method employs AI feedback from large pre-trained language models (LLMs) to construct sample pairs with fine-grained sample similarity scores.", "target": "The authors propose a method called Contrastive Learning of sentence embeddings from AI Feedback (CLAIF). This method employs AI feedback from large pre-trained language models (LLMs) to construct sample pairs with fine-grained sample similarity scores.", "example": "Convert the coordinate to text: [ 1.1973 -4.2141]:"}
{"text": "Convert the coordinate to text: [-3.993   8.0101]: The authors propose a large-scale Persona Commonsense Knowledge graph (PeaCoK) containing approximately 100K human-validated persona facts. It schematizes five dimensions of persona knowledge identified in previous studies, distilling facts from both existing commonsense knowledge graphs and large-scale pretrained language models.", "target": "The authors propose a large-scale Persona Commonsense Knowledge graph (PeaCoK) containing approximately 100K human-validated persona facts. It schematizes five dimensions of persona knowledge identified in previous studies, distilling facts from both existing commonsense knowledge graphs and large-scale pretrained language models.", "example": "Convert the coordinate to text: [-3.993   8.0101]:"}
{"text": "Convert the coordinate to text: [-5.5106  1.717 ]: This paper describes the authors' participation in SemEval-2023 Task 3, aimed at developing systems for analyzing and verifying news spreading online.", "target": "This paper describes the authors' participation in SemEval-2023 Task 3, aimed at developing systems for analyzing and verifying news spreading online.", "example": "Convert the coordinate to text: [-5.5106  1.717 ]:"}
{"text": "Convert the coordinate to text: [12.2696 -4.6212]: This paper aims to create a unified automatic robustness evaluation framework that shifts towards model-centric evaluation. This is to further exploit the advantages of adversarial attacks by determining robustness evaluation dimensions based on model capabilities and specifying the appropriate algorithm to generate adversarial samples for each dimension.", "target": "This paper aims to create a unified automatic robustness evaluation framework that shifts towards model-centric evaluation. This is to further exploit the advantages of adversarial attacks by determining robustness evaluation dimensions based on model capabilities and specifying the appropriate algorithm to generate adversarial samples for each dimension.", "example": "Convert the coordinate to text: [12.2696 -4.6212]:"}
{"text": "Convert the coordinate to text: [-4.1032  6.2137]: The paper proposes a new IM variant called capacity constrained influence maximization (CIM) with the goal of selecting a limited number of influential friends for each initial adopter to enhance promotion reach.", "target": "The paper proposes a new IM variant called capacity constrained influence maximization (CIM) with the goal of selecting a limited number of influential friends for each initial adopter to enhance promotion reach.", "example": "Convert the coordinate to text: [-4.1032  6.2137]:"}
{"text": "Convert the coordinate to text: [-0.4912 -3.5123]: The authors introduce a new method for controllable text generation called Click that does not require modification to the model architecture. Click uses a contrastive loss on sequence likelihood which fundamentally decreases the generation probability of negative samples (i.e., generations with undesirable attributes).", "target": "The authors introduce a new method for controllable text generation called Click that does not require modification to the model architecture. Click uses a contrastive loss on sequence likelihood which fundamentally decreases the generation probability of negative samples (i.e., generations with undesirable attributes).", "example": "Convert the coordinate to text: [-0.4912 -3.5123]:"}
{"text": "Convert the coordinate to text: [-6.3853 11.8003]: The authors aim to develop a respectful and empathetic conversational counseling agent (PAL) that can adapt to clients' emotions and deliver a personalized experience. PAL is designed to support victims of crime and people with substance addictions.", "target": "The authors aim to develop a respectful and empathetic conversational counseling agent (PAL) that can adapt to clients' emotions and deliver a personalized experience. PAL is designed to support victims of crime and people with substance addictions.", "example": "Convert the coordinate to text: [-6.3853 11.8003]:"}
{"text": "Convert the coordinate to text: [-0.816  -6.9275]: The authors delve into the capability of transformer models to capture various phonological generalisations and benefit from exposure to one phonological rule to infer the behaviour of another similar rule.", "target": "The authors delve into the capability of transformer models to capture various phonological generalisations and benefit from exposure to one phonological rule to infer the behaviour of another similar rule.", "example": "Convert the coordinate to text: [-0.816  -6.9275]:"}
{"text": "Convert the coordinate to text: [18.5457 -3.1833]: The authors developed a model for clickbait spoiling, which generates short texts to satisfy the curiosity induced by a clickbait post. The model identifies the clickbait type and spoils the clickbait based on its type.", "target": "The authors developed a model for clickbait spoiling, which generates short texts to satisfy the curiosity induced by a clickbait post. The model identifies the clickbait type and spoils the clickbait based on its type.", "example": "Convert the coordinate to text: [18.5457 -3.1833]:"}
{"text": "Convert the coordinate to text: [-1.5046  0.1375]: SemEval-2023 Task 10 offers a task of developing models capable of accurately identifying, categorizing, and explaining sexist content online. The task is segmented into binary sexism detection, categorization of sexism, and fine-grained vector for sexism.", "target": "SemEval-2023 Task 10 offers a task of developing models capable of accurately identifying, categorizing, and explaining sexist content online. The task is segmented into binary sexism detection, categorization of sexism, and fine-grained vector for sexism.", "example": "Convert the coordinate to text: [-1.5046  0.1375]:"}
{"text": "Convert the coordinate to text: [-1.5589 -2.8222]: The authors propose Enhancing Temporal Knowledge Embeddings with Contextualized Language Representations (ECOLA), a system that considers the temporal aspect while injecting textual information into temporal knowledge embedding.", "target": "The authors propose Enhancing Temporal Knowledge Embeddings with Contextualized Language Representations (ECOLA), a system that considers the temporal aspect while injecting textual information into temporal knowledge embedding.", "example": "Convert the coordinate to text: [-1.5589 -2.8222]:"}
{"text": "Convert the coordinate to text: [-0.4553  0.7305]: The authors propose adopting the Stereotype Content Model (SCM), a social psychology framework, to make debiasing efforts social-group-agnostic by identifying the underlying connection between bias and stereotypes. The SCM suggests that stereotype contents map onto two psychological dimensions of warmth and competence.", "target": "The authors propose adopting the Stereotype Content Model (SCM), a social psychology framework, to make debiasing efforts social-group-agnostic by identifying the underlying connection between bias and stereotypes. The SCM suggests that stereotype contents map onto two psychological dimensions of warmth and competence.", "example": "Convert the coordinate to text: [-0.4553  0.7305]:"}
{"text": "Convert the coordinate to text: [ 5.7408 13.8666]: The authors propose the recasting of variational empowerment as curriculum learning in goal-conditioned RL with an intrinsic reward function, which they name Variational Curriculum RL (VCRL). They also propose a novel information theory-based approach to unsupervised skill discovery, termed Value Uncertainty Variational Curriculum (VUVC).", "target": "The authors propose the recasting of variational empowerment as curriculum learning in goal-conditioned RL with an intrinsic reward function, which they name Variational Curriculum RL (VCRL). They also propose a novel information theory-based approach to unsupervised skill discovery, termed Value Uncertainty Variational Curriculum (VUVC).", "example": "Convert the coordinate to text: [ 5.7408 13.8666]:"}
{"text": "Convert the coordinate to text: [ 5.2994 -4.7245]: The authors present a robust solution for the inductive NGIL problem that involves the evolution of graph structure. They propose a regularization-based technique, Structural-Shift-Risk-Mitigation (SSRM), that mitigates the impact of structural shifts on catastrophic forgetting.", "target": "The authors present a robust solution for the inductive NGIL problem that involves the evolution of graph structure. They propose a regularization-based technique, Structural-Shift-Risk-Mitigation (SSRM), that mitigates the impact of structural shifts on catastrophic forgetting.", "example": "Convert the coordinate to text: [ 5.2994 -4.7245]:"}
{"text": "Convert the coordinate to text: [7.7684 3.2636]: The paper proposes R-divergence, designed to assess model-oriented distribution discrepancies. Essentially, two distributions are considered likely identical if their optimal hypotheses yield the same expected risk for each distribution.", "target": "The paper proposes R-divergence, designed to assess model-oriented distribution discrepancies. Essentially, two distributions are considered likely identical if their optimal hypotheses yield the same expected risk for each distribution.", "example": "Convert the coordinate to text: [7.7684 3.2636]:"}
{"text": "Convert the coordinate to text: [ 7.6533 -2.0538]: This paper introduces FedNAR (Federated optimization with Normalized Annealing Regularization), an algorithmic plug-in that can be integrated into any existing FL algorithms to regulate the magnitude of each update by co-clipping the gradient and weight decay.", "target": "This paper introduces FedNAR (Federated optimization with Normalized Annealing Regularization), an algorithmic plug-in that can be integrated into any existing FL algorithms to regulate the magnitude of each update by co-clipping the gradient and weight decay.", "example": "Convert the coordinate to text: [ 7.6533 -2.0538]:"}
{"text": "Convert the coordinate to text: [ 0.9665 -2.5902]: In this study, the authors propose a novel contrastive learning framework, DrugCLIP, which reformulates virtual screening as a dense retrieval task, aligning representations of binding protein pockets and molecules using a large quantity of pairwise data without explicit binding-affinity scores. They also introduce a biological-knowledge inspired data augmentation strategy to learn better protein-molecule representations.", "target": "In this study, the authors propose a novel contrastive learning framework, DrugCLIP, which reformulates virtual screening as a dense retrieval task, aligning representations of binding protein pockets and molecules using a large quantity of pairwise data without explicit binding-affinity scores. They also introduce a biological-knowledge inspired data augmentation strategy to learn better protein-molecule representations.", "example": "Convert the coordinate to text: [ 0.9665 -2.5902]:"}
{"text": "Convert the coordinate to text: [9.6424 3.245 ]: The authors present the first conditional time hardness results for this problem, demonstrating that both conditions (1) $U = V^ op$ and (2) $f(x)$ is a PSD kernel function are in fact necessary for getting better than $n^{2-o(1)}$ time for a relative error low rank approximation for a wide class of functions.", "target": "The authors present the first conditional time hardness results for this problem, demonstrating that both conditions (1) $U = V^ op$ and (2) $f(x)$ is a PSD kernel function are in fact necessary for getting better than $n^{2-o(1)}$ time for a relative error low rank approximation for a wide class of functions.", "example": "Convert the coordinate to text: [9.6424 3.245 ]:"}
{"text": "Convert the coordinate to text: [-2.4907 -3.4716]: The authors introduce a new dataset called GraphNarrative to address the gap in large-scale, open-domain graph-to-text models. They propose a novel approach that trims the generated sentences to eliminate portions that are not present in the corresponding graph, based on the sentence's dependency parse tree to prevent information hallucination.", "target": "The authors introduce a new dataset called GraphNarrative to address the gap in large-scale, open-domain graph-to-text models. They propose a novel approach that trims the generated sentences to eliminate portions that are not present in the corresponding graph, based on the sentence's dependency parse tree to prevent information hallucination.", "example": "Convert the coordinate to text: [-2.4907 -3.4716]:"}
{"text": "Convert the coordinate to text: [-16.2895  10.8072]: This study forms a special interest group aimed at uniting researchers from both academia and industry interested in Human-Centered Responsible Artificial Intelligence.", "target": "This study forms a special interest group aimed at uniting researchers from both academia and industry interested in Human-Centered Responsible Artificial Intelligence.", "example": "Convert the coordinate to text: [-16.2895  10.8072]:"}
{"text": "Convert the coordinate to text: [  5.8942 -13.2609]: The paper presents a new WSCOS method which addresses the challenges of distinguishing concealed objects from the background and weak supervision of models. It does so by introducing a multi-scale feature grouping module and using a Segment Anything Model (SAM) with provided sparse annotations and a set of strategies to generate and use segmentation masks.", "target": "The paper presents a new WSCOS method which addresses the challenges of distinguishing concealed objects from the background and weak supervision of models. It does so by introducing a multi-scale feature grouping module and using a Segment Anything Model (SAM) with provided sparse annotations and a set of strategies to generate and use segmentation masks.", "example": "Convert the coordinate to text: [  5.8942 -13.2609]:"}
{"text": "Convert the coordinate to text: [-3.184 -9.847]: The authors propose to extract speaker-related information from semantic content in multi-party meetings, with the expectation that it could enhance speaker diarization. They introduce two sub-tasks, Dialogue Detection and Speaker-Turn Detection, as methods to extract conversational semantics.", "target": "The authors propose to extract speaker-related information from semantic content in multi-party meetings, with the expectation that it could enhance speaker diarization. They introduce two sub-tasks, Dialogue Detection and Speaker-Turn Detection, as methods to extract conversational semantics.", "example": "Convert the coordinate to text: [-3.184 -9.847]:"}
{"text": "Convert the coordinate to text: [ 0.6435 -4.3049]: The authors propose RankCSE, a new approach for unsupervised sentence representation learning that combines ranking consistency and ranking distillation with contrastive learning in a unified framework. This approach learns semantically discriminative sentence representations by ensuring ranking consistency between two representations with different dropout masks and by distilling listwise ranking knowledge from an instructor.", "target": "The authors propose RankCSE, a new approach for unsupervised sentence representation learning that combines ranking consistency and ranking distillation with contrastive learning in a unified framework. This approach learns semantically discriminative sentence representations by ensuring ranking consistency between two representations with different dropout masks and by distilling listwise ranking knowledge from an instructor.", "example": "Convert the coordinate to text: [ 0.6435 -4.3049]:"}
{"text": "Convert the coordinate to text: [-1.6933 -1.3378]: The authors introduce a method called Marked Personas that uses natural language prompts to measure stereotypes in LLMs for intersectional demographic groups without requiring any lexicon or data labeling.", "target": "The authors introduce a method called Marked Personas that uses natural language prompts to measure stereotypes in LLMs for intersectional demographic groups without requiring any lexicon or data labeling.", "example": "Convert the coordinate to text: [-1.6933 -1.3378]:"}
{"text": "Convert the coordinate to text: [12.7714 -5.119 ]: The authors propose VoteTRANS, a method to detect adversarial text without needing any training and does this by voting on hard labels from predictions of transformations.", "target": "The authors propose VoteTRANS, a method to detect adversarial text without needing any training and does this by voting on hard labels from predictions of transformations.", "example": "Convert the coordinate to text: [12.7714 -5.119 ]:"}
{"text": "Convert the coordinate to text: [3.4955 6.0701]: This work proposes two novel formulations, the densest diverse subgraph problem (DDSP) and the densest at-least-$\\vec{k}$-subgraph problem (Dal$\\vec{k}$S), to find the densest diverse subgraph in a graph where nodes represent different attributes, which are referred to as colors.", "target": "This work proposes two novel formulations, the densest diverse subgraph problem (DDSP) and the densest at-least-$\\vec{k}$-subgraph problem (Dal$\\vec{k}$S), to find the densest diverse subgraph in a graph where nodes represent different attributes, which are referred to as colors.", "example": "Convert the coordinate to text: [3.4955 6.0701]:"}
{"text": "Convert the coordinate to text: [1.4718 0.4673]: The authors propose a new, model-agnostic method to generate extractive explanations for predictions made by neural networks based on masking parts of the input which the model does not consider to be indicative of the respective class. This involves gradient-based optimization combined with a new regularization scheme that enforces sufficiency, comprehensiveness, and compactness of the generated explanation.", "target": "The authors propose a new, model-agnostic method to generate extractive explanations for predictions made by neural networks based on masking parts of the input which the model does not consider to be indicative of the respective class. This involves gradient-based optimization combined with a new regularization scheme that enforces sufficiency, comprehensiveness, and compactness of the generated explanation.", "example": "Convert the coordinate to text: [1.4718 0.4673]:"}
{"text": "Convert the coordinate to text: [ 6.5333 -4.1585]: The authors introduce the Learned Adapter framework, an automated system to derive optimal adapter architectures for better task adaptation of pre-trained models (PTMs), and a simple-yet-effective optimization method, GDNAS.", "target": "The authors introduce the Learned Adapter framework, an automated system to derive optimal adapter architectures for better task adaptation of pre-trained models (PTMs), and a simple-yet-effective optimization method, GDNAS.", "example": "Convert the coordinate to text: [ 6.5333 -4.1585]:"}
{"text": "Convert the coordinate to text: [-8.8063 -2.4695]: The authors suggest that a return to theoretically grounded research questions is necessary to bridge this gap in computational text analysis and advance the field.", "target": "The authors suggest that a return to theoretically grounded research questions is necessary to bridge this gap in computational text analysis and advance the field.", "example": "Convert the coordinate to text: [-8.8063 -2.4695]:"}
{"text": "Convert the coordinate to text: [6.4   5.458]: This work proposes IPOC, a lightweight and adaptive model for online interval prediction capable of producing effective confidence intervals and adapting to the dynamics of real-world workload streams. This is done by portraying ensemble learning for online interval prediction as a dynamic deterministic Markov Decision Process and making it a stateful online learning task.", "target": "This work proposes IPOC, a lightweight and adaptive model for online interval prediction capable of producing effective confidence intervals and adapting to the dynamics of real-world workload streams. This is done by portraying ensemble learning for online interval prediction as a dynamic deterministic Markov Decision Process and making it a stateful online learning task.", "example": "Convert the coordinate to text: [6.4   5.458]:"}
{"text": "Convert the coordinate to text: [-0.8008 -5.1884]: A novel training mechanism, SegPrompt, is proposed. It makes use of category information to boost the model's class-agnostic segmentation ability for both known and unknown categories.", "target": "A novel training mechanism, SegPrompt, is proposed. It makes use of category information to boost the model's class-agnostic segmentation ability for both known and unknown categories.", "example": "Convert the coordinate to text: [-0.8008 -5.1884]:"}
{"text": "Convert the coordinate to text: [ 4.0421 -6.857 ]: The authors propose a novel Intervention-Driven Relation Network (IDRNet), which uses a deletion diagnostics procedure to guide the modeling of contextual relations among different pixels.", "target": "The authors propose a novel Intervention-Driven Relation Network (IDRNet), which uses a deletion diagnostics procedure to guide the modeling of contextual relations among different pixels.", "example": "Convert the coordinate to text: [ 4.0421 -6.857 ]:"}
{"text": "Convert the coordinate to text: [ 4.7646 12.3455]: The authors suggest a novel neural heuristic with diversity enhancement (NHDE) for producing more varied Pareto solutions. This proposal includes an indicator-enhanced deep reinforcement learning method and a heterogeneous graph attention mechanism to capture relations between the instance graph and the Pareto front graph.", "target": "The authors suggest a novel neural heuristic with diversity enhancement (NHDE) for producing more varied Pareto solutions. This proposal includes an indicator-enhanced deep reinforcement learning method and a heterogeneous graph attention mechanism to capture relations between the instance graph and the Pareto front graph.", "example": "Convert the coordinate to text: [ 4.7646 12.3455]:"}
{"text": "Convert the coordinate to text: [ 1.348  -7.7241]: The paper introduces the Masked Space-Time Hash encoding (MSTH), a method to represent a dynamic scene as a weighted combination of a 3D hash encoding and a 4D hash encoding, using a learnable mask influenced by an uncertainty-based objective, reflecting the spatial and temporal importance of each 3D position.", "target": "The paper introduces the Masked Space-Time Hash encoding (MSTH), a method to represent a dynamic scene as a weighted combination of a 3D hash encoding and a 4D hash encoding, using a learnable mask influenced by an uncertainty-based objective, reflecting the spatial and temporal importance of each 3D position.", "example": "Convert the coordinate to text: [ 1.348  -7.7241]:"}
{"text": "Convert the coordinate to text: [12.3589  0.1439]: The authors propose a novel approach for learning distributions on the Grassmann manifold via continuous normalization flows with the explicit goal of generating stable shapes.", "target": "The authors propose a novel approach for learning distributions on the Grassmann manifold via continuous normalization flows with the explicit goal of generating stable shapes.", "example": "Convert the coordinate to text: [12.3589  0.1439]:"}
{"text": "Convert the coordinate to text: [ 6.9877 -0.1236]: The paper presents a novel idea to approximate the softmax output in attention-based networks to reduce memory usage during training. The method implied involves storing only a small fraction of the softmax output required for back-propagation during the forward pass, and approximating the evicted softmax activation output during the backward pass.", "target": "The paper presents a novel idea to approximate the softmax output in attention-based networks to reduce memory usage during training. The method implied involves storing only a small fraction of the softmax output required for back-propagation during the forward pass, and approximating the evicted softmax activation output during the backward pass.", "example": "Convert the coordinate to text: [ 6.9877 -0.1236]:"}
{"text": "Convert the coordinate to text: [13.377  -4.7827]: The authors propose a simple sentence-level attack on black-box toxicity detector models. The attack involves adding several positive words or sentences to the end of a hateful message to change the prediction of a neural network and pass the toxicity detection system check.", "target": "The authors propose a simple sentence-level attack on black-box toxicity detector models. The attack involves adding several positive words or sentences to the end of a hateful message to change the prediction of a neural network and pass the toxicity detection system check.", "example": "Convert the coordinate to text: [13.377  -4.7827]:"}
{"text": "Convert the coordinate to text: [-2.6154 -6.7849]: The paper proposes UL2R, a method for improving the performance of state-of-the-art large language models like PaLM with a tiny amount of extra compute, using the mixture-of-denoiser objective of UL2.", "target": "The paper proposes UL2R, a method for improving the performance of state-of-the-art large language models like PaLM with a tiny amount of extra compute, using the mixture-of-denoiser objective of UL2.", "example": "Convert the coordinate to text: [-2.6154 -6.7849]:"}
{"text": "Convert the coordinate to text: [-8.6589 -0.0736]: The authors propose TOME, a two-stage model-based retrieval approach. TOME's major contributions are its use of tokenized URLs as identifiers and its two-stage generation architecture.", "target": "The authors propose TOME, a two-stage model-based retrieval approach. TOME's major contributions are its use of tokenized URLs as identifiers and its two-stage generation architecture.", "example": "Convert the coordinate to text: [-8.6589 -0.0736]:"}
{"text": "Convert the coordinate to text: [-9.4589  0.7915]: The authors of the study design the LCP task to reflect the thought-process of lawyers and introduce a prototype architecture to achieve interpretability while maintaining performance.", "target": "The authors of the study design the LCP task to reflect the thought-process of lawyers and introduce a prototype architecture to achieve interpretability while maintaining performance.", "example": "Convert the coordinate to text: [-9.4589  0.7915]:"}
{"text": "Convert the coordinate to text: [-3.1201 -8.9926]: The paper outlines the use of foundation models for speech (wav2vec 2.0) and text (mBART50), incorporates a Siamese pretraining step of the speech and text encoders with CTC and Optimal Transport to enhance transfer learning from Machine Translation (MT), and the use of synthetic data creation with SegAugment for model adaptation.", "target": "The paper outlines the use of foundation models for speech (wav2vec 2.0) and text (mBART50), incorporates a Siamese pretraining step of the speech and text encoders with CTC and Optimal Transport to enhance transfer learning from Machine Translation (MT), and the use of synthetic data creation with SegAugment for model adaptation.", "example": "Convert the coordinate to text: [-3.1201 -8.9926]:"}
{"text": "Convert the coordinate to text: [3.2998 1.7753]: To address the challenge of distribution shifts, the authors propose an end-to-end framework named DoubleAdapt. DoubleAdapt uses two adapters to effectively adapt the data and the model, the key insight being that it can automatically learn how to adapt stock data into a locally stationary distribution to favor profitable updates.", "target": "To address the challenge of distribution shifts, the authors propose an end-to-end framework named DoubleAdapt. DoubleAdapt uses two adapters to effectively adapt the data and the model, the key insight being that it can automatically learn how to adapt stock data into a locally stationary distribution to favor profitable updates.", "example": "Convert the coordinate to text: [3.2998 1.7753]:"}
{"text": "Convert the coordinate to text: [-1.0648 -5.1652]: The authors propose a prompt-based approach, the Multimodal Prompt Learning framework, to accurately and efficiently generate titles for novel products with limited labels. The core challenges include understanding novel product characteristics and generating titles in a novel writing style.", "target": "The authors propose a prompt-based approach, the Multimodal Prompt Learning framework, to accurately and efficiently generate titles for novel products with limited labels. The core challenges include understanding novel product characteristics and generating titles in a novel writing style.", "example": "Convert the coordinate to text: [-1.0648 -5.1652]:"}
{"text": "Convert the coordinate to text: [-7.2299 -6.8754]: The authors propose a computational process for word acquisition that mimics the way human babies learn their first language, focusing on comparative learning and analyzing similarities and differences in various attributes. This approach involves an information filtration process and representation-symbol mapping.", "target": "The authors propose a computational process for word acquisition that mimics the way human babies learn their first language, focusing on comparative learning and analyzing similarities and differences in various attributes. This approach involves an information filtration process and representation-symbol mapping.", "example": "Convert the coordinate to text: [-7.2299 -6.8754]:"}
{"text": "Convert the coordinate to text: [-3.0535 -0.0098]: The study examines the impacts of (1) time and (2) different language conditions (English and German) on measurements of intra-annotator agreement in a hate speech labelling task.", "target": "The study examines the impacts of (1) time and (2) different language conditions (English and German) on measurements of intra-annotator agreement in a hate speech labelling task.", "example": "Convert the coordinate to text: [-3.0535 -0.0098]:"}
{"text": "Convert the coordinate to text: [-4.8577 -6.4893]: The paper identifies the target inconsistency issue in cross-lingual stance detection and proposes a fine-grained Target-oriented Relation Alignment (TaRA) method, which considers both target-level associations and language-level alignments.", "target": "The paper identifies the target inconsistency issue in cross-lingual stance detection and proposes a fine-grained Target-oriented Relation Alignment (TaRA) method, which considers both target-level associations and language-level alignments.", "example": "Convert the coordinate to text: [-4.8577 -6.4893]:"}
{"text": "Convert the coordinate to text: [-2.7434 -8.5567]: The authors propose AMR-TST, an AMR-based text style transfer technique, which converts the source text to an AMR graph and generates transferred text based on the modified AMR graph by a TST policy named style rewriting, combining the advantages of both explicit and implicit TST methods.", "target": "The authors propose AMR-TST, an AMR-based text style transfer technique, which converts the source text to an AMR graph and generates transferred text based on the modified AMR graph by a TST policy named style rewriting, combining the advantages of both explicit and implicit TST methods.", "example": "Convert the coordinate to text: [-2.7434 -8.5567]:"}
{"text": "Convert the coordinate to text: [-2.7017 -8.3889]: The authors propose AMRSim, a new similarity evaluation metric that evaluates the entire structure of AMR graphs, using silver AMR graphs and a self-supervised learning approach to solve the issue of costly human-annotated data collection.", "target": "The authors propose AMRSim, a new similarity evaluation metric that evaluates the entire structure of AMR graphs, using silver AMR graphs and a self-supervised learning approach to solve the issue of costly human-annotated data collection.", "example": "Convert the coordinate to text: [-2.7017 -8.3889]:"}
{"text": "Convert the coordinate to text: [-3.7807  1.244 ]: The authors propose EPIC (English Perspectivist Irony Corpus), the first annotated corpus for irony analysis based on data perspectivism, which includes short conversations from social media in five regional varieties of English, annotated by contributors from countries corresponding to those varieties.", "target": "The authors propose EPIC (English Perspectivist Irony Corpus), the first annotated corpus for irony analysis based on data perspectivism, which includes short conversations from social media in five regional varieties of English, annotated by contributors from countries corresponding to those varieties.", "example": "Convert the coordinate to text: [-3.7807  1.244 ]:"}
{"text": "Convert the coordinate to text: [ 3.7255 -2.6651]: The authors propose a method that applies a parameter isolation strategy. For each task, it allocates a small portion of private parameters and learns them with a shared pre-trained model.", "target": "The authors propose a method that applies a parameter isolation strategy. For each task, it allocates a small portion of private parameters and learns them with a shared pre-trained model.", "example": "Convert the coordinate to text: [ 3.7255 -2.6651]:"}
{"text": "Convert the coordinate to text: [-6.409  -9.8937]: To address these challenges, the authors propose a novel model, UMRSpell, that learns detection and correction together at the same time from a multi-task learning perspective and can handle different types of errors, including missing, redundant, and spelling errors through re-tagging rules.", "target": "To address these challenges, the authors propose a novel model, UMRSpell, that learns detection and correction together at the same time from a multi-task learning perspective and can handle different types of errors, including missing, redundant, and spelling errors through re-tagging rules.", "example": "Convert the coordinate to text: [-6.409  -9.8937]:"}
{"text": "Convert the coordinate to text: [12.0974 -1.883 ]: The authors investigate the learning trajectories of deep generative neural networks in comparison to children's developmental trajectories, using physical understanding as a testbed. They propose an approach that allows examination of two distinct hypotheses of human development -- stochastic optimization and complexity increase.", "target": "The authors investigate the learning trajectories of deep generative neural networks in comparison to children's developmental trajectories, using physical understanding as a testbed. They propose an approach that allows examination of two distinct hypotheses of human development -- stochastic optimization and complexity increase.", "example": "Convert the coordinate to text: [12.0974 -1.883 ]:"}
{"text": "Convert the coordinate to text: [ 9.7372 -7.8745]: The authors propose an unsupervised video semantic compression method. Instead of only focusing on visual quality, this paper introduces a technique (SMC framework) that enhances plain video codecs with semantic coding capability. This is further optimized using only unlabeled video data, which includes masking out some of the compressed video and reconstructing the masked portions of the original video, inspired by masked image modeling methods.", "target": "The authors propose an unsupervised video semantic compression method. Instead of only focusing on visual quality, this paper introduces a technique (SMC framework) that enhances plain video codecs with semantic coding capability. This is further optimized using only unlabeled video data, which includes masking out some of the compressed video and reconstructing the masked portions of the original video, inspired by masked image modeling methods.", "example": "Convert the coordinate to text: [ 9.7372 -7.8745]:"}
{"text": "Convert the coordinate to text: [ 5.6674 -7.2571]: The paper introduces a large-scale interactive trajectory prediction dataset, INT2, specifically designed for interactive trajectory prediction at intersections, with exceptionally long durations and details such as auto-labeled agent trajectories and traffic light information.", "target": "The paper introduces a large-scale interactive trajectory prediction dataset, INT2, specifically designed for interactive trajectory prediction at intersections, with exceptionally long durations and details such as auto-labeled agent trajectories and traffic light information.", "example": "Convert the coordinate to text: [ 5.6674 -7.2571]:"}
{"text": "Convert the coordinate to text: [  3.5272 -13.1817]: The authors explore the possibility of addressing visual place recognition as a classification problem, thus eliminating the need for similarity searches. Based on their findings that existing classification methods are inappropriate for fine-grained and city-wide localization, they propose a partitioning scheme geared towards enabling fast and accurate inference in dense scenarios, as well as the Divide & Classify (D&C) method that integrates an ensemble of novel classifiers.", "target": "The authors explore the possibility of addressing visual place recognition as a classification problem, thus eliminating the need for similarity searches. Based on their findings that existing classification methods are inappropriate for fine-grained and city-wide localization, they propose a partitioning scheme geared towards enabling fast and accurate inference in dense scenarios, as well as the Divide & Classify (D&C) method that integrates an ensemble of novel classifiers.", "example": "Convert the coordinate to text: [  3.5272 -13.1817]:"}
{"text": "Convert the coordinate to text: [  1.8057 -12.9648]: The authors present the Smartphone Camera Quality Assessment Dataset (SQAD), which includes natural images captured by 29 devices and defines camera system quality based on six widely accepted criteria.", "target": "The authors present the Smartphone Camera Quality Assessment Dataset (SQAD), which includes natural images captured by 29 devices and defines camera system quality based on six widely accepted criteria.", "example": "Convert the coordinate to text: [  1.8057 -12.9648]:"}
{"text": "Convert the coordinate to text: [8.4958 5.0977]: The paper proposes a hierarchical semi-implicit variational inference (HSIVI) method which generalizes SIVI, allowing for a multi-layer construction of semi-implicit distributions and enhancing the expressiveness of SIVI.", "target": "The paper proposes a hierarchical semi-implicit variational inference (HSIVI) method which generalizes SIVI, allowing for a multi-layer construction of semi-implicit distributions and enhancing the expressiveness of SIVI.", "example": "Convert the coordinate to text: [8.4958 5.0977]:"}
{"text": "Convert the coordinate to text: [12.4985 -1.3735]: The authors introduce Deep Power Laws (DPL), a collection of neural network models designed to generate predictions following a power-law scaling pattern. These configurations are then decided upon dynamically and trained incrementally using gray-box evaluations.", "target": "The authors introduce Deep Power Laws (DPL), a collection of neural network models designed to generate predictions following a power-law scaling pattern. These configurations are then decided upon dynamically and trained incrementally using gray-box evaluations.", "example": "Convert the coordinate to text: [12.4985 -1.3735]:"}
{"text": "Convert the coordinate to text: [-6.4444 -1.7338]: The authors propose a distant supervision approach that uses a medical ontology to generate a seed of potential clinical contradictions from 22 million medical abstracts.", "target": "The authors propose a distant supervision approach that uses a medical ontology to generate a seed of potential clinical contradictions from 22 million medical abstracts.", "example": "Convert the coordinate to text: [-6.4444 -1.7338]:"}
{"text": "Convert the coordinate to text: [ 7.4835 -5.0586]: The authors theoretically demonstrate that user preference prediction is biased under long-tail distributions due to discrepancies between training and test data in both prior and conditional probabilities. They propose a Cross Decoupling Network (CDN) to reduce these differences.", "target": "The authors theoretically demonstrate that user preference prediction is biased under long-tail distributions due to discrepancies between training and test data in both prior and conditional probabilities. They propose a Cross Decoupling Network (CDN) to reduce these differences.", "example": "Convert the coordinate to text: [ 7.4835 -5.0586]:"}
{"text": "Convert the coordinate to text: [8.936  2.0506]: This paper develops an algorithmic framework that enables clients to communicate with the server to send their updates with an affordable communication cost while using a large dictionary of kernels. The paper proposes a scalable online federated MKL algorithm utilizing random feature (RF) approximation.", "target": "This paper develops an algorithmic framework that enables clients to communicate with the server to send their updates with an affordable communication cost while using a large dictionary of kernels. The paper proposes a scalable online federated MKL algorithm utilizing random feature (RF) approximation.", "example": "Convert the coordinate to text: [8.936  2.0506]:"}
{"text": "Convert the coordinate to text: [9.5784 6.4876]: The authors argue that a stability analysis can provide insight into the convergence behavior of the models, suggesting that a bound on the norm which decreases with increasing step size leads to 'smoother' predictors in the multivariate case, similar to the univariate case.", "target": "The authors argue that a stability analysis can provide insight into the convergence behavior of the models, suggesting that a bound on the norm which decreases with increasing step size leads to 'smoother' predictors in the multivariate case, similar to the univariate case.", "example": "Convert the coordinate to text: [9.5784 6.4876]:"}
{"text": "Convert the coordinate to text: [-1.2352 -5.6201]: The authors investigate how well pre-trained models can understand and perform code execution. They develop a mutation-based data augmentation technique to create a large-scale and realistic Python dataset and task for code execution.", "target": "The authors investigate how well pre-trained models can understand and perform code execution. They develop a mutation-based data augmentation technique to create a large-scale and realistic Python dataset and task for code execution.", "example": "Convert the coordinate to text: [-1.2352 -5.6201]:"}
{"text": "Convert the coordinate to text: [ 4.1051 -1.4021]: In response to these issues, the authors introduce NoisywikiHow, the largest NLP benchmark constructed with minimal supervision. They construct multiple sources of label noise to imitate human errors throughout the annotation, aiming to better replicate real-world noise.", "target": "In response to these issues, the authors introduce NoisywikiHow, the largest NLP benchmark constructed with minimal supervision. They construct multiple sources of label noise to imitate human errors throughout the annotation, aiming to better replicate real-world noise.", "example": "Convert the coordinate to text: [ 4.1051 -1.4021]:"}
{"text": "Convert the coordinate to text: [10.2096 -3.2265]: This paper presents a novel neural architecture for capturing the deep interaction between Machine Learning pipeline components. It embeds pipelines into a latent representation through a unique per-component encoder mechanism, which is used with deep-kernel Gaussian Process surrogates inside a Bayesian Optimization setup for pipeline optimization.", "target": "This paper presents a novel neural architecture for capturing the deep interaction between Machine Learning pipeline components. It embeds pipelines into a latent representation through a unique per-component encoder mechanism, which is used with deep-kernel Gaussian Process surrogates inside a Bayesian Optimization setup for pipeline optimization.", "example": "Convert the coordinate to text: [10.2096 -3.2265]:"}
{"text": "Convert the coordinate to text: [-5.3772 10.3982]: The novel problem identified here is learning a TOD agent with dialog-KB inconsistencies in the training data. As a solution, a Dialog-KB Arbitration Framework (DKAF) is proposed, which reduces inconsistencies by predicting the contemporary KB snapshot for each train dialog.", "target": "The novel problem identified here is learning a TOD agent with dialog-KB inconsistencies in the training data. As a solution, a Dialog-KB Arbitration Framework (DKAF) is proposed, which reduces inconsistencies by predicting the contemporary KB snapshot for each train dialog.", "example": "Convert the coordinate to text: [-5.3772 10.3982]:"}
{"text": "Convert the coordinate to text: [-0.8365 -8.0291]: The paper proposes a novel multi-modal pre-training model, LayoutMask, focusing on improving text-layout interactions. LayoutMask uses local 1D position as layout input and introduces two pre-training objectives, namely, Masked Language Modeling and Masked Position Modeling.", "target": "The paper proposes a novel multi-modal pre-training model, LayoutMask, focusing on improving text-layout interactions. LayoutMask uses local 1D position as layout input and introduces two pre-training objectives, namely, Masked Language Modeling and Masked Position Modeling.", "example": "Convert the coordinate to text: [-0.8365 -8.0291]:"}
{"text": "Convert the coordinate to text: [-0.6451 -6.8528]: This paper examines the impact of architectural features (depth, width, and number of parameters) and the genre and size of the pre-training corpus on the inductive bias that favours hierarchical syntactic generalizations in encoder-decoder Transformers.", "target": "This paper examines the impact of architectural features (depth, width, and number of parameters) and the genre and size of the pre-training corpus on the inductive bias that favours hierarchical syntactic generalizations in encoder-decoder Transformers.", "example": "Convert the coordinate to text: [-0.6451 -6.8528]:"}
{"text": "Convert the coordinate to text: [ 5.8225 -0.4238]: The authors propose SWEET (Separating Weights in Early Exit Transformers), an Early-Exit fine-tuning method that gives each classifier its unique model weights which are not updated by other classifiers. This is in response to the observation that models with the same architecture and size, individual Multi-Model classifiers tend to outperform their Early-Exit counterparts due to parameter sharing during training.", "target": "The authors propose SWEET (Separating Weights in Early Exit Transformers), an Early-Exit fine-tuning method that gives each classifier its unique model weights which are not updated by other classifiers. This is in response to the observation that models with the same architecture and size, individual Multi-Model classifiers tend to outperform their Early-Exit counterparts due to parameter sharing during training.", "example": "Convert the coordinate to text: [ 5.8225 -0.4238]:"}
{"text": "Convert the coordinate to text: [-0.9081  1.9986]: The authors introduce a new approach for comprehensively evaluating a model, by considering its understanding and reasoning capabilities, alongside its performance. They also highlight the need for evaluations to consider whether model predictions align with human rationale.", "target": "The authors introduce a new approach for comprehensively evaluating a model, by considering its understanding and reasoning capabilities, alongside its performance. They also highlight the need for evaluations to consider whether model predictions align with human rationale.", "example": "Convert the coordinate to text: [-0.9081  1.9986]:"}
{"text": "Convert the coordinate to text: [-1.7057 -3.2783]: The researchers propose a Fine-to-Coarse Composition framework (FC-KBQA), which extracts relevant fine-grained knowledge components from a Knowledge Base (KB) and reformulates them into middle-grained knowledge pair format for generating final logical expressions.", "target": "The researchers propose a Fine-to-Coarse Composition framework (FC-KBQA), which extracts relevant fine-grained knowledge components from a Knowledge Base (KB) and reformulates them into middle-grained knowledge pair format for generating final logical expressions.", "example": "Convert the coordinate to text: [-1.7057 -3.2783]:"}
{"text": "Convert the coordinate to text: [-2.3563 -5.4231]: The authors' system for MultiCoNER II utilized pre-trained language models (PLMs) fine-tuned for each language included in the dataset, along with a data augmentation technique that increases the amount of available training data by adding new instances of relevant entities found within Wikipedia to the training corpus.", "target": "The authors' system for MultiCoNER II utilized pre-trained language models (PLMs) fine-tuned for each language included in the dataset, along with a data augmentation technique that increases the amount of available training data by adding new instances of relevant entities found within Wikipedia to the training corpus.", "example": "Convert the coordinate to text: [-2.3563 -5.4231]:"}
{"text": "Convert the coordinate to text: [-4.0471 -1.9532]: This paper proposes innovatively linking sentence-level and document-level event factuality semantically through an event factuality inference task, leveraging a new Sentence-to-Document Inference Network (SDIN).", "target": "This paper proposes innovatively linking sentence-level and document-level event factuality semantically through an event factuality inference task, leveraging a new Sentence-to-Document Inference Network (SDIN).", "example": "Convert the coordinate to text: [-4.0471 -1.9532]:"}
{"text": "Convert the coordinate to text: [-4.8573 -9.0376]: The authors propose a new constrained decoding method for the automatic generation of Shakespearean sonnets, using a modest neural backbone.", "target": "The authors propose a new constrained decoding method for the automatic generation of Shakespearean sonnets, using a modest neural backbone.", "example": "Convert the coordinate to text: [-4.8573 -9.0376]:"}
{"text": "Convert the coordinate to text: [-11.3965  16.6775]: The authors propose a model based on recent advances in latent diffusion to synthesize images from tactile signals (and vice versa), which is applied to multiple visuo-tactile synthesis tasks.", "target": "The authors propose a model based on recent advances in latent diffusion to synthesize images from tactile signals (and vice versa), which is applied to multiple visuo-tactile synthesis tasks.", "example": "Convert the coordinate to text: [-11.3965  16.6775]:"}
{"text": "Convert the coordinate to text: [ 3.1312 -0.6166]: The study introduces a Data Selection Curriculum (DSC) scoring system for ATS models, which considers both the difficulty of improving the model through a specific instance and the expected performance on that instance.", "target": "The study introduces a Data Selection Curriculum (DSC) scoring system for ATS models, which considers both the difficulty of improving the model through a specific instance and the expected performance on that instance.", "example": "Convert the coordinate to text: [ 3.1312 -0.6166]:"}
{"text": "Convert the coordinate to text: [ 0.0792 -6.8769]: The authors propose to edit the parameters of transformer models to improve their commonsense understanding. They also introduce a variation of the MEMIT editing algorithm for the commonsense domain ($MEMIT_{CSK}$).", "target": "The authors propose to edit the parameters of transformer models to improve their commonsense understanding. They also introduce a variation of the MEMIT editing algorithm for the commonsense domain ($MEMIT_{CSK}$).", "example": "Convert the coordinate to text: [ 0.0792 -6.8769]:"}
{"text": "Convert the coordinate to text: [10.9657 -2.8706]: The authors propose principled techniques for weight initialization in hypernetworks to address the problem of incorrect weight scale in the main network.", "target": "The authors propose principled techniques for weight initialization in hypernetworks to address the problem of incorrect weight scale in the main network.", "example": "Convert the coordinate to text: [10.9657 -2.8706]:"}
{"text": "Convert the coordinate to text: [ 2.9202 -2.7417]: The authors tackle the problem of zero-shot causal learning - predicting the personalized effects of novel, previously unseen interventions - by proposing CaML, a causal meta-learning framework that considers each intervention's effect prediction as a specific task. Rather than training individual models for each intervention, CaML trains a single meta-model across multiple tasks, making predictions using both intervention details and individual features.", "target": "The authors tackle the problem of zero-shot causal learning - predicting the personalized effects of novel, previously unseen interventions - by proposing CaML, a causal meta-learning framework that considers each intervention's effect prediction as a specific task. Rather than training individual models for each intervention, CaML trains a single meta-model across multiple tasks, making predictions using both intervention details and individual features.", "example": "Convert the coordinate to text: [ 2.9202 -2.7417]:"}
{"text": "Convert the coordinate to text: [-3.6523 -4.2092]: A Statistical Construction and Dual Adaptation of Gazetteer (SCDAG) method is proposed for Multilingual Complex NER. This method includes constructing a gazetteer using statistics, adapting the representations of gazetteer networks and language models, and integrating these networks for supervised named entity recognition (NER) training.", "target": "A Statistical Construction and Dual Adaptation of Gazetteer (SCDAG) method is proposed for Multilingual Complex NER. This method includes constructing a gazetteer using statistics, adapting the representations of gazetteer networks and language models, and integrating these networks for supervised named entity recognition (NER) training.", "example": "Convert the coordinate to text: [-3.6523 -4.2092]:"}
{"text": "Convert the coordinate to text: [-4.4005 -1.2311]: The authors propose a unique computational pipeline that automatically extracts a story's temporal narrative verb-based event chain for each character, along with character attributes such as gender, and an annotation scheme that facilitates bias analysis by aligning with traditional stereotypes.", "target": "The authors propose a unique computational pipeline that automatically extracts a story's temporal narrative verb-based event chain for each character, along with character attributes such as gender, and an annotation scheme that facilitates bias analysis by aligning with traditional stereotypes.", "example": "Convert the coordinate to text: [-4.4005 -1.2311]:"}
{"text": "Convert the coordinate to text: [-1.6613  6.5231]: The authors propose a new back translation-inspired evaluation methodology that uses earlier outputs of the explainer as ground truth proxies to investigate the consistency of explainers.", "target": "The authors propose a new back translation-inspired evaluation methodology that uses earlier outputs of the explainer as ground truth proxies to investigate the consistency of explainers.", "example": "Convert the coordinate to text: [-1.6613  6.5231]:"}
{"text": "Convert the coordinate to text: [ 0.429  -4.5352]: The authors propose SPLAT, a new structure that enhances generalization and efficiency by confining outputs to a restricted prediction space, allowing rich attention among descriptions and history, and controlling computation costs via linear-time attention.", "target": "The authors propose SPLAT, a new structure that enhances generalization and efficiency by confining outputs to a restricted prediction space, allowing rich attention among descriptions and history, and controlling computation costs via linear-time attention.", "example": "Convert the coordinate to text: [ 0.429  -4.5352]:"}
{"text": "Convert the coordinate to text: [-2.8539 -6.8946]: SinaAI proposed a novel approach combining the fine-tuning of multilingual language models, such as XLM, LaBSE, and mBERT, with data augmentation techniques to improve the detection of genre, framing, and persuasion techniques in multilingual news articles.", "target": "SinaAI proposed a novel approach combining the fine-tuning of multilingual language models, such as XLM, LaBSE, and mBERT, with data augmentation techniques to improve the detection of genre, framing, and persuasion techniques in multilingual news articles.", "example": "Convert the coordinate to text: [-2.8539 -6.8946]:"}
{"text": "Convert the coordinate to text: [-4.7133 -2.8884]: The paper proposes an approach that combines the results of multiple models through a voting mechanism to identify unique entities in legal texts.", "target": "The paper proposes an approach that combines the results of multiple models through a voting mechanism to identify unique entities in legal texts.", "example": "Convert the coordinate to text: [-4.7133 -2.8884]:"}
{"text": "Convert the coordinate to text: [-5.297  -4.1851]: The team's approach was to reduce the feature set size by splitting texts into subwords and then using these tokens as inputs to SVM or logistic regression classifiers.", "target": "The team's approach was to reduce the feature set size by splitting texts into subwords and then using these tokens as inputs to SVM or logistic regression classifiers.", "example": "Convert the coordinate to text: [-5.297  -4.1851]:"}
{"text": "Convert the coordinate to text: [-2.4263 -6.0656]: D2KLab's system, which is based on a fine-tuned transformer-based language model used for extracting named entities, is presented.", "target": "D2KLab's system, which is based on a fine-tuned transformer-based language model used for extracting named entities, is presented.", "example": "Convert the coordinate to text: [-2.4263 -6.0656]:"}
{"text": "Convert the coordinate to text: [-2.2842 -7.347 ]: The authors propose Descriptive Masked Language Modeling (DMLM), a knowledge-enhanced reading comprehension objective where the model predicts the most likely word in a context using the word\u2019s definition.", "target": "The authors propose Descriptive Masked Language Modeling (DMLM), a knowledge-enhanced reading comprehension objective where the model predicts the most likely word in a context using the word\u2019s definition.", "example": "Convert the coordinate to text: [-2.2842 -7.347 ]:"}
{"text": "Convert the coordinate to text: [ 0.5653 -7.3434]: The paper proposes LightFormer, a lighter transformer model that uses a low-rank factorization initialized by SVD-based weight transfer and parameter sharing to compress and accelerate the Transformer model.", "target": "The paper proposes LightFormer, a lighter transformer model that uses a low-rank factorization initialized by SVD-based weight transfer and parameter sharing to compress and accelerate the Transformer model.", "example": "Convert the coordinate to text: [ 0.5653 -7.3434]:"}
{"text": "Convert the coordinate to text: [-1.0587 -5.2153]: The authors propose the Task-Agnostic prompt tuning method for PLG tasks, CodePrompt, which leverages an Input-Dependent Prompt Template to bridge the pre-training and fine-tuning gap and Corpus-Specific Prefix Tuning for efficient parameter updates. They also introduce a method for providing richer prefix word information for limited prefix lengths.", "target": "The authors propose the Task-Agnostic prompt tuning method for PLG tasks, CodePrompt, which leverages an Input-Dependent Prompt Template to bridge the pre-training and fine-tuning gap and Corpus-Specific Prefix Tuning for efficient parameter updates. They also introduce a method for providing richer prefix word information for limited prefix lengths.", "example": "Convert the coordinate to text: [-1.0587 -5.2153]:"}
{"text": "Convert the coordinate to text: [-8.6716 -2.9216]: The thesis proposal aims at improving the reliability of NLG systems by focusing on the semantic accuracy of model outputs, examined from two perspectives: evaluation and interpretability.", "target": "The thesis proposal aims at improving the reliability of NLG systems by focusing on the semantic accuracy of model outputs, examined from two perspectives: evaluation and interpretability.", "example": "Convert the coordinate to text: [-8.6716 -2.9216]:"}
{"text": "Convert the coordinate to text: [-4.9311 -8.8417]: The authors introduce NeuroStructural Decoding, a decoding algorithm that incorporates syntactic constraints, in order to improve the quality of the generated text.", "target": "The authors introduce NeuroStructural Decoding, a decoding algorithm that incorporates syntactic constraints, in order to improve the quality of the generated text.", "example": "Convert the coordinate to text: [-4.9311 -8.8417]:"}
{"text": "Convert the coordinate to text: [ 3.918  -3.6034]: This paper proposes a hybrid knowledge-transfer approach that combines the direct and data transfer methods. It leverages a teacher-student framework where the teacher and student networks are trained following the direct and data transfer approaches, respectively. The approach also includes a hierarchical training-sample selection scheme designed to address the issue of noisy labels being generated by the teacher model.", "target": "This paper proposes a hybrid knowledge-transfer approach that combines the direct and data transfer methods. It leverages a teacher-student framework where the teacher and student networks are trained following the direct and data transfer approaches, respectively. The approach also includes a hierarchical training-sample selection scheme designed to address the issue of noisy labels being generated by the teacher model.", "example": "Convert the coordinate to text: [ 3.918  -3.6034]:"}
{"text": "Convert the coordinate to text: [-1.3033  7.7032]: This paper proposes to enhance the Abductive learning (ABL) paradigm to enable knowledge refinement and effectively handle new concepts that may emerge in open-environment tasks.", "target": "This paper proposes to enhance the Abductive learning (ABL) paradigm to enable knowledge refinement and effectively handle new concepts that may emerge in open-environment tasks.", "example": "Convert the coordinate to text: [-1.3033  7.7032]:"}
{"text": "Convert the coordinate to text: [ -2.1982 -10.0517]: The authors propose a disentanglement framework that simultaneously models speaker traits and content variability in speech using three Gaussian inference layers, each with a learnable transition model to extract distinctive speech components. They also suggest a self-supervision method to dynamically disentangle content without needing labels other than speaker identities.", "target": "The authors propose a disentanglement framework that simultaneously models speaker traits and content variability in speech using three Gaussian inference layers, each with a learnable transition model to extract distinctive speech components. They also suggest a self-supervision method to dynamically disentangle content without needing labels other than speaker identities.", "example": "Convert the coordinate to text: [ -2.1982 -10.0517]:"}
{"text": "Convert the coordinate to text: [-0.9065 -4.8691]: This study addresses the challenge of monitoring TPPs by adopting Continual Learning (CL), and it proposes a new framework, PromptTPP, by integrating the base TPP with a continuous-time retrieval prompt pool.", "target": "This study addresses the challenge of monitoring TPPs by adopting Continual Learning (CL), and it proposes a new framework, PromptTPP, by integrating the base TPP with a continuous-time retrieval prompt pool.", "example": "Convert the coordinate to text: [-0.9065 -4.8691]:"}
{"text": "Convert the coordinate to text: [-0.8308 -5.1678]: In this paper, the authors propose an Unsupervised Prompt Tuning framework for text-driven object detection, comprised of two novel teaching mechanisms - Nested Mean Teaching, and Dual Complementary Teaching.", "target": "In this paper, the authors propose an Unsupervised Prompt Tuning framework for text-driven object detection, comprised of two novel teaching mechanisms - Nested Mean Teaching, and Dual Complementary Teaching.", "example": "Convert the coordinate to text: [-0.8308 -5.1678]:"}
{"text": "Convert the coordinate to text: [10.6426 -2.1044]: The authors introduce a new proxy, \u03be-based gradient signal-to-noise ratio (\u03be-GSNR), for Zero-Shot NAS to predict network accuracy at initialization, and theoretically prove that larger GSNR at network initialization ensures better generalization and convergence.", "target": "The authors introduce a new proxy, \u03be-based gradient signal-to-noise ratio (\u03be-GSNR), for Zero-Shot NAS to predict network accuracy at initialization, and theoretically prove that larger GSNR at network initialization ensures better generalization and convergence.", "example": "Convert the coordinate to text: [10.6426 -2.1044]:"}
{"text": "Convert the coordinate to text: [ 6.872  -3.9868]: To address the domain shift problem in healthcare, the authors propose the SLGD self-learning framework that iteratively recognizes decoupled domains and trains personalized classifiers for each discovered domain.", "target": "To address the domain shift problem in healthcare, the authors propose the SLGD self-learning framework that iteratively recognizes decoupled domains and trains personalized classifiers for each discovered domain.", "example": "Convert the coordinate to text: [ 6.872  -3.9868]:"}
{"text": "Convert the coordinate to text: [14.4009 -2.5612]: This research explores the compatibility of continuous attractor neural networks (CANNs) and E-INNs, and proposes that a neural network can display traits from both CANNs and E-INNs if their neuronal synapses are composed of two sets: one that is strong and fast for irregular firing, and another that is weak and slow for attractor dynamics.", "target": "This research explores the compatibility of continuous attractor neural networks (CANNs) and E-INNs, and proposes that a neural network can display traits from both CANNs and E-INNs if their neuronal synapses are composed of two sets: one that is strong and fast for irregular firing, and another that is weak and slow for attractor dynamics.", "example": "Convert the coordinate to text: [14.4009 -2.5612]:"}
{"text": "Convert the coordinate to text: [-5.9855 11.8409]: This paper explores the role of an AI-powered chatbot as a tool to improve the informed consent process in online studies, hypothesizing that it might encourage participants' comprehension and consequent consent form reading, and balance the power dynamic between the participant and the researcher.", "target": "This paper explores the role of an AI-powered chatbot as a tool to improve the informed consent process in online studies, hypothesizing that it might encourage participants' comprehension and consequent consent form reading, and balance the power dynamic between the participant and the researcher.", "example": "Convert the coordinate to text: [-5.9855 11.8409]:"}
{"text": "Convert the coordinate to text: [13.2214  6.2704]: The authors propose two DFL algorithms: DFedSAM and DFedSAM-MGS that improve the performance of DFL. DFedSAM uses gradient perturbation to generate local flat models via Sharpness Aware Minimization (SAM), which finds models with uniformly low loss values. DFedSAM-MGS boosts DFedSAM by adopting Multiple Gossip Steps (MGS) for better model consistency, accelerating the aggregation of local flat models, and better balancing communication complexity and generalization.", "target": "The authors propose two DFL algorithms: DFedSAM and DFedSAM-MGS that improve the performance of DFL. DFedSAM uses gradient perturbation to generate local flat models via Sharpness Aware Minimization (SAM), which finds models with uniformly low loss values. DFedSAM-MGS boosts DFedSAM by adopting Multiple Gossip Steps (MGS) for better model consistency, accelerating the aggregation of local flat models, and better balancing communication complexity and generalization.", "example": "Convert the coordinate to text: [13.2214  6.2704]:"}
{"text": "Convert the coordinate to text: [-2.3792 -8.3079]: The authors propose a method of fine-tuning pre-trained speech encoders to enable direct extraction of spoken entities in human-readable form from speech, bypassing the need for text transcription.", "target": "The authors propose a method of fine-tuning pre-trained speech encoders to enable direct extraction of spoken entities in human-readable form from speech, bypassing the need for text transcription.", "example": "Convert the coordinate to text: [-2.3792 -8.3079]:"}
{"text": "Convert the coordinate to text: [ 1.7983 -3.7383]: The authors refute this assumption and argue that extra information can be obtained from contrasting higher and lower model layers during inference. A novel approach that uses this contrast is proposed to improve text generation output.", "target": "The authors refute this assumption and argue that extra information can be obtained from contrasting higher and lower model layers during inference. A novel approach that uses this contrast is proposed to improve text generation output.", "example": "Convert the coordinate to text: [ 1.7983 -3.7383]:"}
{"text": "Convert the coordinate to text: [ -0.8471 -12.479 ]: The paper proposes Duplex Masked Auto-Encoder (DupMAE), a pre-training method that improves the quality of semantic representation by leveraging all contextualized embeddings. DupMAE uses two complementary auto-encoding tasks: one that reconstructs the input sentence atop the [CLS] embedding, and another that predicts the bag-of-words representation of the input sentence based on ordinary token embeddings.", "target": "The paper proposes Duplex Masked Auto-Encoder (DupMAE), a pre-training method that improves the quality of semantic representation by leveraging all contextualized embeddings. DupMAE uses two complementary auto-encoding tasks: one that reconstructs the input sentence atop the [CLS] embedding, and another that predicts the bag-of-words representation of the input sentence based on ordinary token embeddings.", "example": "Convert the coordinate to text: [ -0.8471 -12.479 ]:"}
{"text": "Convert the coordinate to text: [-6.7356 11.8854]: The authors introduce Response Forecasting on Personas for News Media, a new task where the goal is to estimate how a persona, representing either an individual or a group, might respond to a piece of news message. This incorporates predicting not only the content but also the sentiment polarity and intensity of responses.", "target": "The authors introduce Response Forecasting on Personas for News Media, a new task where the goal is to estimate how a persona, representing either an individual or a group, might respond to a piece of news message. This incorporates predicting not only the content but also the sentiment polarity and intensity of responses.", "example": "Convert the coordinate to text: [-6.7356 11.8854]:"}
{"text": "Convert the coordinate to text: [ 6.5878 -4.311 ]: The authors propose a method for task-agnostic dialect adaptation, called Task-Agnostic Dialect Adapters (TADA), which works by aligning non-SAE dialects using adapters and composing them with task-specific adapters from SAE.", "target": "The authors propose a method for task-agnostic dialect adaptation, called Task-Agnostic Dialect Adapters (TADA), which works by aligning non-SAE dialects using adapters and composing them with task-specific adapters from SAE.", "example": "Convert the coordinate to text: [ 6.5878 -4.311 ]:"}
{"text": "Convert the coordinate to text: [ 0.0325 -8.4397]: The study introduces a novel retrieval approach, 'Cross Encoding as Augmentation' (CEAA), which utilizes transfer learning from question-answering datasets and incorporates a data augmentation method that introduces cross-encoder style texts to a bi-encoder architecture for efficient educational text classification.", "target": "The study introduces a novel retrieval approach, 'Cross Encoding as Augmentation' (CEAA), which utilizes transfer learning from question-answering datasets and incorporates a data augmentation method that introduces cross-encoder style texts to a bi-encoder architecture for efficient educational text classification.", "example": "Convert the coordinate to text: [ 0.0325 -8.4397]:"}
{"text": "Convert the coordinate to text: [11.9549 -8.8411]: The authors propose Text Style Transfer Back Translation (TST BT), which leverages a style transfer model to modify the source side of BT data, aiming at improving the translation of natural inputs.", "target": "The authors propose Text Style Transfer Back Translation (TST BT), which leverages a style transfer model to modify the source side of BT data, aiming at improving the translation of natural inputs.", "example": "Convert the coordinate to text: [11.9549 -8.8411]:"}
{"text": "Convert the coordinate to text: [ 5.1379 -6.4237]: This paper presents a new solution known as FRIGATE, a spatio-temporal Graph Neural Network (GNN) that incorporates positional, topological, and temporal information to address the limitations of current models.", "target": "This paper presents a new solution known as FRIGATE, a spatio-temporal Graph Neural Network (GNN) that incorporates positional, topological, and temporal information to address the limitations of current models.", "example": "Convert the coordinate to text: [ 5.1379 -6.4237]:"}
{"text": "Convert the coordinate to text: [-2.1777 -6.4516]: The authors propose a system utilizing three different models: FastText, MultiLang Transformers, and Language-Specific Transformers in an attempt to find the optimal model for the sentiment classification challenge.", "target": "The authors propose a system utilizing three different models: FastText, MultiLang Transformers, and Language-Specific Transformers in an attempt to find the optimal model for the sentiment classification challenge.", "example": "Convert the coordinate to text: [-2.1777 -6.4516]:"}
{"text": "Convert the coordinate to text: [-1.7126 -6.4668]: The authors propose the use of modified RoBERTa transformer models for the tasks. Particularly, for sub-task 1, they leverage NER, spoiler-title ratio, regex checks for enumerations and lists, and input reformulation; for sub-task 2, they use the RoBERTa-SQuAD2.0 model with a contextual rule-based approach.", "target": "The authors propose the use of modified RoBERTa transformer models for the tasks. Particularly, for sub-task 1, they leverage NER, spoiler-title ratio, regex checks for enumerations and lists, and input reformulation; for sub-task 2, they use the RoBERTa-SQuAD2.0 model with a contextual rule-based approach.", "example": "Convert the coordinate to text: [-1.7126 -6.4668]:"}
{"text": "Convert the coordinate to text: [-10.4926   0.6878]: This paper proposes a method to improve the performance of Natural Language Inference for Clinical Trial Data by integrating domain ontologies as a source of external knowledge within the inference process.", "target": "This paper proposes a method to improve the performance of Natural Language Inference for Clinical Trial Data by integrating domain ontologies as a source of external knowledge within the inference process.", "example": "Convert the coordinate to text: [-10.4926   0.6878]:"}
{"text": "Convert the coordinate to text: [-3.2849 -3.6374]: The authors propose a distantly supervised pipeline for Named Entity Recognition named DISTANT, which separates the tasks into entity span detection and entity classification. The first step uses distant supervision to extract possible entity mention spans. The second step uses a positive and unlabeled (PU) learning framework to assign each span to an entity type or none.", "target": "The authors propose a distantly supervised pipeline for Named Entity Recognition named DISTANT, which separates the tasks into entity span detection and entity classification. The first step uses distant supervision to extract possible entity mention spans. The second step uses a positive and unlabeled (PU) learning framework to assign each span to an entity type or none.", "example": "Convert the coordinate to text: [-3.2849 -3.6374]:"}
{"text": "Convert the coordinate to text: [-4.6898 -3.3669]: The authors propose a feature-based method for identifying pre-requisite dependencies between academic videos using a transcript engine with a language model to transcribe domain-specific terms and then using novel similarity-based features to determine pre-requisite dependencies.", "target": "The authors propose a feature-based method for identifying pre-requisite dependencies between academic videos using a transcript engine with a language model to transcribe domain-specific terms and then using novel similarity-based features to determine pre-requisite dependencies.", "example": "Convert the coordinate to text: [-4.6898 -3.3669]:"}
{"text": "Convert the coordinate to text: [-8.6441 -2.7458]: This paper measures the practical cost and value of LLMs for enterprise use, taking into account the quality of the responses generated. It introduces a cost framework for valuing an NLP model's utility for customer service chat applications.", "target": "This paper measures the practical cost and value of LLMs for enterprise use, taking into account the quality of the responses generated. It introduces a cost framework for valuing an NLP model's utility for customer service chat applications.", "example": "Convert the coordinate to text: [-8.6441 -2.7458]:"}
{"text": "Convert the coordinate to text: [-0.8831 -5.1497]: The authors propose a Hard Sample Aware Prompt-Tuning framework (HardPT), which uses reinforcement learning to solve the non-differentiable problem in hard sample identification, and also uses an adaptive contrastive learning method to enhance the discrimination of the feature space without changing the original data distribution.", "target": "The authors propose a Hard Sample Aware Prompt-Tuning framework (HardPT), which uses reinforcement learning to solve the non-differentiable problem in hard sample identification, and also uses an adaptive contrastive learning method to enhance the discrimination of the feature space without changing the original data distribution.", "example": "Convert the coordinate to text: [-0.8831 -5.1497]:"}
{"text": "Convert the coordinate to text: [-10.7926  -2.1299]: The authors propose the creation of a native QA dataset for an East African language, Tigrinya, which includes 10.6K question-answer pairs taken from 290 news articles with various topics.", "target": "The authors propose the creation of a native QA dataset for an East African language, Tigrinya, which includes 10.6K question-answer pairs taken from 290 news articles with various topics.", "example": "Convert the coordinate to text: [-10.7926  -2.1299]:"}
{"text": "Convert the coordinate to text: [-5.9401 -0.277 ]: This paper systematically reviews the use of the ROUGE metric in over two thousand publications and raises issues related to evaluation decisions, comparability of results, and software defects producing incorrect scores.", "target": "This paper systematically reviews the use of the ROUGE metric in over two thousand publications and raises issues related to evaluation decisions, comparability of results, and software defects producing incorrect scores.", "example": "Convert the coordinate to text: [-5.9401 -0.277 ]:"}
{"text": "Convert the coordinate to text: [10.3728 -3.3531]: The paper introduces the concept of 'contextual sparsity,' small, input-dependent sets of attention heads and MLP parameters that yield approximately the same output as the dense model for a given input. Based on these insights, they propose DejaVu, a system that predicts contextual sparsity on the fly given inputs to each layer.", "target": "The paper introduces the concept of 'contextual sparsity,' small, input-dependent sets of attention heads and MLP parameters that yield approximately the same output as the dense model for a given input. Based on these insights, they propose DejaVu, a system that predicts contextual sparsity on the fly given inputs to each layer.", "example": "Convert the coordinate to text: [10.3728 -3.3531]:"}
{"text": "Convert the coordinate to text: [  7.0411 -17.2435]: The authors present VoroMesh, a novel and differentiable Voronoi-based representation of watertight 3D shape surfaces, obtained from a set of 3D points and their associated occupancy. They introduce a new loss function, VoroLoss, which minimizes the distance from ground truth surface samples to the closest faces of the Voronoi diagram.", "target": "The authors present VoroMesh, a novel and differentiable Voronoi-based representation of watertight 3D shape surfaces, obtained from a set of 3D points and their associated occupancy. They introduce a new loss function, VoroLoss, which minimizes the distance from ground truth surface samples to the closest faces of the Voronoi diagram.", "example": "Convert the coordinate to text: [  7.0411 -17.2435]:"}
{"text": "Convert the coordinate to text: [0.1652 2.0238]: This study proposes a novel approach to evaluate the faithfulness of feature attribution methods by constructing an \u2018Attribution Confusion Matrix\u2019. This introduces various measures for faithfulness in feature attribution methods using a unified and consistent framework.", "target": "This study proposes a novel approach to evaluate the faithfulness of feature attribution methods by constructing an \u2018Attribution Confusion Matrix\u2019. This introduces various measures for faithfulness in feature attribution methods using a unified and consistent framework.", "example": "Convert the coordinate to text: [0.1652 2.0238]:"}
{"text": "Convert the coordinate to text: [ 5.7878 12.3508]: The paper proposes a method for learning to make collages using reinforcement learning without relying on demonstrations or collage artwork data. The authors introduce the Collage Markov Decision Process (MDP), a model-based soft actor-critic, as well as additional techniques such as active material selection and complexity-based multi-scale collage.", "target": "The paper proposes a method for learning to make collages using reinforcement learning without relying on demonstrations or collage artwork data. The authors introduce the Collage Markov Decision Process (MDP), a model-based soft actor-critic, as well as additional techniques such as active material selection and complexity-based multi-scale collage.", "example": "Convert the coordinate to text: [ 5.7878 12.3508]:"}
{"text": "Convert the coordinate to text: [ 5.1353 -2.7009]: This study aims to develop a generic SSL framework addressing two main obstacles in the existing SSL framework - the weakness of capturing distribution-invariant features and over-fitting to labeled data during training. The proposed framework called Aggregating & Decoupling consists of a Diffusion encoder and three decoders.", "target": "This study aims to develop a generic SSL framework addressing two main obstacles in the existing SSL framework - the weakness of capturing distribution-invariant features and over-fitting to labeled data during training. The proposed framework called Aggregating & Decoupling consists of a Diffusion encoder and three decoders.", "example": "Convert the coordinate to text: [ 5.1353 -2.7009]:"}
{"text": "Convert the coordinate to text: [ 4.961  14.0325]: The authors propose to use context-aware policies to improve the generalization of reinforcement learning algorithms. A novel neural network architecture, the Decision Adapter, is designed to generate the weights of an adapter module and condition the agent's behavior on the context information.", "target": "The authors propose to use context-aware policies to improve the generalization of reinforcement learning algorithms. A novel neural network architecture, the Decision Adapter, is designed to generate the weights of an adapter module and condition the agent's behavior on the context information.", "example": "Convert the coordinate to text: [ 4.961  14.0325]:"}
{"text": "Convert the coordinate to text: [ 7.3506 -0.3847]: The authors propose a Geometric Harmonization (GH) method that encourages category-level uniformity in representation learning, which is more favorable to the minority and does not significantly impact the majority under long-tailed distribution.", "target": "The authors propose a Geometric Harmonization (GH) method that encourages category-level uniformity in representation learning, which is more favorable to the minority and does not significantly impact the majority under long-tailed distribution.", "example": "Convert the coordinate to text: [ 7.3506 -0.3847]:"}
{"text": "Convert the coordinate to text: [ 1.9522 -3.4431]: This paper proposes a novel multi-stage training framework called Temporal Continual Learning (TCL), along with a Prior Compensation Factor (PCF) incorporated into model training to make up for the loss of prior information.", "target": "This paper proposes a novel multi-stage training framework called Temporal Continual Learning (TCL), along with a Prior Compensation Factor (PCF) incorporated into model training to make up for the loss of prior information.", "example": "Convert the coordinate to text: [ 1.9522 -3.4431]:"}
{"text": "Convert the coordinate to text: [-1.7243  8.8995]: The authors propose ANPL, an interactive programming system that allows users to refine generated code towards specific program intents through structured decompositions, with an ANPL program comprising a set of input-outputs, a 'sketch' in code, and 'holes' or sub-modules to be implemented by the LLM and specified with natural language.", "target": "The authors propose ANPL, an interactive programming system that allows users to refine generated code towards specific program intents through structured decompositions, with an ANPL program comprising a set of input-outputs, a 'sketch' in code, and 'holes' or sub-modules to be implemented by the LLM and specified with natural language.", "example": "Convert the coordinate to text: [-1.7243  8.8995]:"}
{"text": "Convert the coordinate to text: [-8.009  -2.4826]: The authors have developed an open-source dataset named 'The Vault', comprising of 43 million high-quality code-text pairs in multiple programming languages, extracted using both rules and deep learning for high-quality results.", "target": "The authors have developed an open-source dataset named 'The Vault', comprising of 43 million high-quality code-text pairs in multiple programming languages, extracted using both rules and deep learning for high-quality results.", "example": "Convert the coordinate to text: [-8.009  -2.4826]:"}
{"text": "Convert the coordinate to text: [ 0.2878 -8.1059]: The authors propose BridgeTower, a model that consists of multiple bridge layers that build a connection between the top layers of uni-modal encoders and each layer of the cross-modal encoder. This allows for effective bottom-up cross-modal alignment and fusion between visual and textual representations of different semantic levels of pre-trained uni-modal encoders in the cross-modal encoder.", "target": "The authors propose BridgeTower, a model that consists of multiple bridge layers that build a connection between the top layers of uni-modal encoders and each layer of the cross-modal encoder. This allows for effective bottom-up cross-modal alignment and fusion between visual and textual representations of different semantic levels of pre-trained uni-modal encoders in the cross-modal encoder.", "example": "Convert the coordinate to text: [ 0.2878 -8.1059]:"}
{"text": "Convert the coordinate to text: [ 0.3404 -9.2288]: The study probes the use of PI in the state-of-the-art LXMERT model and its effect on Visual Question Answering. It introduces two strategies, Positional Information Pre-training and Contrastive Learning on PI using Cross-Modality Matching, to improve the model's use of PI in image-text matching tasks.", "target": "The study probes the use of PI in the state-of-the-art LXMERT model and its effect on Visual Question Answering. It introduces two strategies, Positional Information Pre-training and Contrastive Learning on PI using Cross-Modality Matching, to improve the model's use of PI in image-text matching tasks.", "example": "Convert the coordinate to text: [ 0.3404 -9.2288]:"}
{"text": "Convert the coordinate to text: [-5.0305 14.6584]: The authors propose AeroRigUI, an actuated tangible UI that uses self-propelled swarm robots with a reeling mechanism on ceiling surfaces to control the position and orientation of physical objects in the air (a process referred to as rigging). This can be used for dynamic physical affordances, 3D information displays, haptics, and more.", "target": "The authors propose AeroRigUI, an actuated tangible UI that uses self-propelled swarm robots with a reeling mechanism on ceiling surfaces to control the position and orientation of physical objects in the air (a process referred to as rigging). This can be used for dynamic physical affordances, 3D information displays, haptics, and more.", "example": "Convert the coordinate to text: [-5.0305 14.6584]:"}
{"text": "Convert the coordinate to text: [-4.5648 -4.703 ]: The authors propose the first-ever meta-sense embedding method, Neighbour Preserving Meta-Sense Embeddings, which learns meta-sense embeddings by combining multiple independently trained source sense embeddings while preserving the sense neighborhoods computed from the source embeddings in the meta-embedding space.", "target": "The authors propose the first-ever meta-sense embedding method, Neighbour Preserving Meta-Sense Embeddings, which learns meta-sense embeddings by combining multiple independently trained source sense embeddings while preserving the sense neighborhoods computed from the source embeddings in the meta-embedding space.", "example": "Convert the coordinate to text: [-4.5648 -4.703 ]:"}
{"text": "Convert the coordinate to text: [-5.3204 -4.8313]: The authors present a method to use knowledge to identify important rare tokens that appear in both source and reference and uplift their conditional probability for high-stake, knowledge-rich domains. They introduce 'utilization rate', which encodes knowledge and serves as a regularizer by maximizing the marginal probability of selected tokens.", "target": "The authors present a method to use knowledge to identify important rare tokens that appear in both source and reference and uplift their conditional probability for high-stake, knowledge-rich domains. They introduce 'utilization rate', which encodes knowledge and serves as a regularizer by maximizing the marginal probability of selected tokens.", "example": "Convert the coordinate to text: [-5.3204 -4.8313]:"}
{"text": "Convert the coordinate to text: [ 1.5721 -8.4148]: The authors introduce a new framework, TransTIC, to transfer a Transformer-based image compression codec from human vision to machine perception. The novel aspect is the proposal of an instance-specific prompt generator that modifies the encoder and decoder based on the image and task at hand.", "target": "The authors introduce a new framework, TransTIC, to transfer a Transformer-based image compression codec from human vision to machine perception. The novel aspect is the proposal of an instance-specific prompt generator that modifies the encoder and decoder based on the image and task at hand.", "example": "Convert the coordinate to text: [ 1.5721 -8.4148]:"}
{"text": "Convert the coordinate to text: [-3.654   5.0822]: The authors propose a novel Multi-Modal Model for POI Tagging, M3PT, which enhances POI tagging by fusing the target POI's textual and visual features, and enables precise matching between the multi-modal representations.", "target": "The authors propose a novel Multi-Modal Model for POI Tagging, M3PT, which enhances POI tagging by fusing the target POI's textual and visual features, and enables precise matching between the multi-modal representations.", "example": "Convert the coordinate to text: [-3.654   5.0822]:"}
{"text": "Convert the coordinate to text: [-1.3259 -5.6699]: The authors propose Prefix-Adaptive Decoding (PREADD), a method that does not need external models. Instead, it relies on linearly combining output logits from multiple prompts, enabling both positive and negative control for any attribute through prefix-prepended prompts.", "target": "The authors propose Prefix-Adaptive Decoding (PREADD), a method that does not need external models. Instead, it relies on linearly combining output logits from multiple prompts, enabling both positive and negative control for any attribute through prefix-prepended prompts.", "example": "Convert the coordinate to text: [-1.3259 -5.6699]:"}
{"text": "Convert the coordinate to text: [-9.5284 -6.0913]: The authors propose a procedural graph construction method with syntactic information and discourse structures which automatically generates procedural graph with multiple dependency relations, extending the flow graph constructed by existing methods.", "target": "The authors propose a procedural graph construction method with syntactic information and discourse structures which automatically generates procedural graph with multiple dependency relations, extending the flow graph constructed by existing methods.", "example": "Convert the coordinate to text: [-9.5284 -6.0913]:"}
{"text": "Convert the coordinate to text: [-0.0219 -3.9015]: The researchers have introduced a novel multi-level contrastive learning framework for abstractive summarization (SimMCS), along with a tailored sparse decoder self-attention pattern (SDSA). The SimMCS framework improves the conventional focus by also considering the absolute positions of the summaries, not just the relative order. Additionally, SDSA simulates possible inference scenarios of deviation during the training phase.", "target": "The researchers have introduced a novel multi-level contrastive learning framework for abstractive summarization (SimMCS), along with a tailored sparse decoder self-attention pattern (SDSA). The SimMCS framework improves the conventional focus by also considering the absolute positions of the summaries, not just the relative order. Additionally, SDSA simulates possible inference scenarios of deviation during the training phase.", "example": "Convert the coordinate to text: [-0.0219 -3.9015]:"}
{"text": "Convert the coordinate to text: [ -6.0138 -10.3652]: The authors tackle the challenge of providing automatic feedback on orthographic errors in handwritten text, by creating a comprehensive dataset of handwriting retaining orthographic errors and creating a HWR system capable of transcribing words with such errors.", "target": "The authors tackle the challenge of providing automatic feedback on orthographic errors in handwritten text, by creating a comprehensive dataset of handwriting retaining orthographic errors and creating a HWR system capable of transcribing words with such errors.", "example": "Convert the coordinate to text: [ -6.0138 -10.3652]:"}
{"text": "Convert the coordinate to text: [-1.1923  0.0763]: To address the lack of resources, the authors introduce a new social bias dataset in Hindi and employ multilingual transfer learning using existing English, Italian, and Korean datasets.", "target": "To address the lack of resources, the authors introduce a new social bias dataset in Hindi and employ multilingual transfer learning using existing English, Italian, and Korean datasets.", "example": "Convert the coordinate to text: [-1.1923  0.0763]:"}
{"text": "Convert the coordinate to text: [-3.2571 -3.0167]: The authors propose treating the RTE task as an Object Detection task, introducing a one-stage Object Detection framework for Relational Triple Extraction (OD-RTE), featuring vertices-based bounding box detection along with auxiliary global relational triple region detection.", "target": "The authors propose treating the RTE task as an Object Detection task, introducing a one-stage Object Detection framework for Relational Triple Extraction (OD-RTE), featuring vertices-based bounding box detection along with auxiliary global relational triple region detection.", "example": "Convert the coordinate to text: [-3.2571 -3.0167]:"}
{"text": "Convert the coordinate to text: [ 9.3921 -2.5408]: This study introduces the Hierarchical Exponential-family Energy-based (HEE) model, which aims to better reflect the inference and learning dynamics of the brain. The HEE model decomposes the partition function into individual layers, based on groups of neurons with shorter time constants.", "target": "This study introduces the Hierarchical Exponential-family Energy-based (HEE) model, which aims to better reflect the inference and learning dynamics of the brain. The HEE model decomposes the partition function into individual layers, based on groups of neurons with shorter time constants.", "example": "Convert the coordinate to text: [ 9.3921 -2.5408]:"}
{"text": "Convert the coordinate to text: [ 1.8794 -8.4744]: To alleviate these challenges, the authors propose FDViT, an improved hierarchical architecture for vision transformer. The FDViT architecture employs a flexible downsampling layer which is not restricted to integer stride and a masked auto-encoder structure to facilitate its training.", "target": "To alleviate these challenges, the authors propose FDViT, an improved hierarchical architecture for vision transformer. The FDViT architecture employs a flexible downsampling layer which is not restricted to integer stride and a masked auto-encoder structure to facilitate its training.", "example": "Convert the coordinate to text: [ 1.8794 -8.4744]:"}
{"text": "Convert the coordinate to text: [ 6.5252 -2.8872]: The authors present a new multigraph topology for cross-silo federated learning, constructed using the overlay graph and parsed into different simple graphs with isolated nodes. The presence of these isolated nodes allows for model aggregation without waiting for other nodes, which can reduce training time.", "target": "The authors present a new multigraph topology for cross-silo federated learning, constructed using the overlay graph and parsed into different simple graphs with isolated nodes. The presence of these isolated nodes allows for model aggregation without waiting for other nodes, which can reduce training time.", "example": "Convert the coordinate to text: [ 6.5252 -2.8872]:"}
{"text": "Convert the coordinate to text: [ 4.9954 13.6061]: The paper proposes two Reinforcement Learning (RL) approaches combined with Graph Neural Networks (GNN) specifically for Suggesting Variable Order (SVO) in CAD. The models presented are GRL-SVO(UP), an integrated branching heuristic, and GRL-SVO(NUP), a faster heuristic that directly provides a total order.", "target": "The paper proposes two Reinforcement Learning (RL) approaches combined with Graph Neural Networks (GNN) specifically for Suggesting Variable Order (SVO) in CAD. The models presented are GRL-SVO(UP), an integrated branching heuristic, and GRL-SVO(NUP), a faster heuristic that directly provides a total order.", "example": "Convert the coordinate to text: [ 4.9954 13.6061]:"}
{"text": "Convert the coordinate to text: [7.4923 6.4112]: The authors propose using latent stochastic bridges to regularize the intermediate states and serve as the running cost for PETs, providing a way to include the intermediate stages of these systems in the tuning process.", "target": "The authors propose using latent stochastic bridges to regularize the intermediate states and serve as the running cost for PETs, providing a way to include the intermediate stages of these systems in the tuning process.", "example": "Convert the coordinate to text: [7.4923 6.4112]:"}
{"text": "Convert the coordinate to text: [ 3.1368 -6.7983]: This paper proposes the Transform Scene Graphs (TSG) approach which applies multi-head attention (MHA) to design GNN for embedding scene graphs and a Mixture-of-Expert (MOE)-based decoder that discriminates the graph embeddings to generate different kinds of words.", "target": "This paper proposes the Transform Scene Graphs (TSG) approach which applies multi-head attention (MHA) to design GNN for embedding scene graphs and a Mixture-of-Expert (MOE)-based decoder that discriminates the graph embeddings to generate different kinds of words.", "example": "Convert the coordinate to text: [ 3.1368 -6.7983]:"}
{"text": "Convert the coordinate to text: [-3.1874 -6.6893]: The authors tackle the sentiment analysis problem for low-resource African languages using different multilingual XLM-R models which are trained on various data, including those retrained in African dialects and then fine-tuned on target languages.", "target": "The authors tackle the sentiment analysis problem for low-resource African languages using different multilingual XLM-R models which are trained on various data, including those retrained in African dialects and then fine-tuned on target languages.", "example": "Convert the coordinate to text: [-3.1874 -6.6893]:"}
{"text": "Convert the coordinate to text: [-0.0206 -3.1098]: The authors propose a general continual training framework for TKG completion. The key ideas include a temporal regularization that encourages repurposing of less important model parameters for learning new knowledge, and a clustering-based experience replay that reinforces the past knowledge by selectively preserving a small portion of the past data.", "target": "The authors propose a general continual training framework for TKG completion. The key ideas include a temporal regularization that encourages repurposing of less important model parameters for learning new knowledge, and a clustering-based experience replay that reinforces the past knowledge by selectively preserving a small portion of the past data.", "example": "Convert the coordinate to text: [-0.0206 -3.1098]:"}
{"text": "Convert the coordinate to text: [ -0.2798 -10.6603]: The authors present a framework that formulates VQA as modular code generation. This approach requires no additional training and relies on pre-trained language and visual models, combined with minimal in-context learning.", "target": "The authors present a framework that formulates VQA as modular code generation. This approach requires no additional training and relies on pre-trained language and visual models, combined with minimal in-context learning.", "example": "Convert the coordinate to text: [ -0.2798 -10.6603]:"}
{"text": "Convert the coordinate to text: [-2.7383 -6.2937]: The authors propose JiuZhang 2.0, a unified Chinese pre-trained language model (PLM) specially designed for multi-task mathematical problem solving. This model maintains a moderate size and employs cross-task knowledge sharing to improve performance in a multi-task setting.", "target": "The authors propose JiuZhang 2.0, a unified Chinese pre-trained language model (PLM) specially designed for multi-task mathematical problem solving. This model maintains a moderate size and employs cross-task knowledge sharing to improve performance in a multi-task setting.", "example": "Convert the coordinate to text: [-2.7383 -6.2937]:"}
{"text": "Convert the coordinate to text: [-4.4178 -7.0428]: The paper introduces MAD-TSC, a new diverse and complex dataset for TSC in the news domain, which includes aligned examples in eight languages, facilitating comparison of performance across languages and between human and machine translations.", "target": "The paper introduces MAD-TSC, a new diverse and complex dataset for TSC in the news domain, which includes aligned examples in eight languages, facilitating comparison of performance across languages and between human and machine translations.", "example": "Convert the coordinate to text: [-4.4178 -7.0428]:"}
{"text": "Convert the coordinate to text: [-3.1759 -6.5722]: The authors study various machine learning algorithms for quantifying intimacy in tweets across multiple languages using a new multilingual textual intimacy dataset named MINT.", "target": "The authors study various machine learning algorithms for quantifying intimacy in tweets across multiple languages using a new multilingual textual intimacy dataset named MINT.", "example": "Convert the coordinate to text: [-3.1759 -6.5722]:"}
{"text": "Convert the coordinate to text: [-1.1873 -6.5286]: The authors make use of the GANBERT model, a transformer-based model, paired with data sampling strategies to address authorship attribution for late 19th century novels.", "target": "The authors make use of the GANBERT model, a transformer-based model, paired with data sampling strategies to address authorship attribution for late 19th century novels.", "example": "Convert the coordinate to text: [-1.1873 -6.5286]:"}
{"text": "Convert the coordinate to text: [-2.5415 -4.7658]: The authors introduce a new pipeline for automatically constructing NPC scripts using Transformer-based language models, and propose a self-diagnosis method to tailor these models for desirable NPC qualities such as coherency, believability, and degree of repetition. They also propose a new benchmark, called The Turing Quest.", "target": "The authors introduce a new pipeline for automatically constructing NPC scripts using Transformer-based language models, and propose a self-diagnosis method to tailor these models for desirable NPC qualities such as coherency, believability, and degree of repetition. They also propose a new benchmark, called The Turing Quest.", "example": "Convert the coordinate to text: [-2.5415 -4.7658]:"}
{"text": "Convert the coordinate to text: [ 3.8295 -6.2617]: The authors propose a double-branch multi-attention based graph neural network (MA-GNN) that learns richer entity representations containing both global and local structural information. They find a simple attention-based method is more effective than a general GNN approach for KGC.", "target": "The authors propose a double-branch multi-attention based graph neural network (MA-GNN) that learns richer entity representations containing both global and local structural information. They find a simple attention-based method is more effective than a general GNN approach for KGC.", "example": "Convert the coordinate to text: [ 3.8295 -6.2617]:"}
{"text": "Convert the coordinate to text: [-1.3146 -8.5806]: The key idea is to develop a framework, INDENT, which uses a cross-attention-based model and the temporal ordering of sentences to learn speech embeddings that capture the semantics of the underlying spoken text. These embeddings can be used to retrieve the audio segment corresponding to the text queries.", "target": "The key idea is to develop a framework, INDENT, which uses a cross-attention-based model and the temporal ordering of sentences to learn speech embeddings that capture the semantics of the underlying spoken text. These embeddings can be used to retrieve the audio segment corresponding to the text queries.", "example": "Convert the coordinate to text: [-1.3146 -8.5806]:"}
{"text": "Convert the coordinate to text: [ 13.2525 -18.6324]: The authors propose a Fourier-based frequency-temporal video deblurring solution using intrinsic frequency-temporal priors discovered in the Fourier space. The new solution features a spectrum prior-guided alignment module and a temporal energy prior-driven aggregation process.", "target": "The authors propose a Fourier-based frequency-temporal video deblurring solution using intrinsic frequency-temporal priors discovered in the Fourier space. The new solution features a spectrum prior-guided alignment module and a temporal energy prior-driven aggregation process.", "example": "Convert the coordinate to text: [ 13.2525 -18.6324]:"}
{"text": "Convert the coordinate to text: [ 6.3958 -5.6097]: The authors present a novel approach to overcome the oversmoothing issues in graph generation. They propose the Wavelet Graph Diffusion Model (Wave-GD) that captures the dependency between nodes and edges at multiple resolutions in the spectral space, by modeling the joint distribution of node and edge signals in a shared graph wavelet space.", "target": "The authors present a novel approach to overcome the oversmoothing issues in graph generation. They propose the Wavelet Graph Diffusion Model (Wave-GD) that captures the dependency between nodes and edges at multiple resolutions in the spectral space, by modeling the joint distribution of node and edge signals in a shared graph wavelet space.", "example": "Convert the coordinate to text: [ 6.3958 -5.6097]:"}
{"text": "Convert the coordinate to text: [ 3.8707 13.3833]: The authors propose E3T, an Efficient End-to-End Training approach for zero-shot human-AI coordination. This approach constructs a partner policy using a mix of ego policy and random policy, which makes it both skilled at coordination and diverse. A partner modeling module is also proposed for predicting a partner's actions using historical data.", "target": "The authors propose E3T, an Efficient End-to-End Training approach for zero-shot human-AI coordination. This approach constructs a partner policy using a mix of ego policy and random policy, which makes it both skilled at coordination and diverse. A partner modeling module is also proposed for predicting a partner's actions using historical data.", "example": "Convert the coordinate to text: [ 3.8707 13.3833]:"}
{"text": "Convert the coordinate to text: [-2.4949 -4.0134]: The authors introduce 'PersonaLM', a method that improves ASR personalization through Domain-distributed Span-Aggregated K-nearest N-gram retrieval augmentation. It leverages contextually similar n-gram word frequencies and aggregates the next-word probability distribution based on different domain importance to the input query. Moreover, the authors propose a Span Aggregated Group-Contrastive Neural (SCAN) retriever for ranking external domains/users.", "target": "The authors introduce 'PersonaLM', a method that improves ASR personalization through Domain-distributed Span-Aggregated K-nearest N-gram retrieval augmentation. It leverages contextually similar n-gram word frequencies and aggregates the next-word probability distribution based on different domain importance to the input query. Moreover, the authors propose a Span Aggregated Group-Contrastive Neural (SCAN) retriever for ranking external domains/users.", "example": "Convert the coordinate to text: [-2.4949 -4.0134]:"}
{"text": "Convert the coordinate to text: [  6.4791 -11.6133]: The study proposes an exemplar-based image editing framework, where self-supervised training is used to disentangle and re-organize the source image and the exemplar. The authors introduce a content bottleneck, strong augmentations, and an arbitrary shape mask for the exemplar image to improve controllability and prevent artifacting.", "target": "The study proposes an exemplar-based image editing framework, where self-supervised training is used to disentangle and re-organize the source image and the exemplar. The authors introduce a content bottleneck, strong augmentations, and an arbitrary shape mask for the exemplar image to improve controllability and prevent artifacting.", "example": "Convert the coordinate to text: [  6.4791 -11.6133]:"}
{"text": "Convert the coordinate to text: [ 4.0781 -7.6067]: The authors propose breaking down an RNN layer into a sequence of simple RNNs and incorporating the localized recurrence into the positional encodings of a multihead self-attention, forming a new module called Self-Attention with Recurrence (RSA).", "target": "The authors propose breaking down an RNN layer into a sequence of simple RNNs and incorporating the localized recurrence into the positional encodings of a multihead self-attention, forming a new module called Self-Attention with Recurrence (RSA).", "example": "Convert the coordinate to text: [ 4.0781 -7.6067]:"}
{"text": "Convert the coordinate to text: [-9.9513 16.8453]: The authors propose a new interactive smell training solution with a scent-delivery device and companion app, which utilise advances in digital technology to help people train their sense of smell.", "target": "The authors propose a new interactive smell training solution with a scent-delivery device and companion app, which utilise advances in digital technology to help people train their sense of smell.", "example": "Convert the coordinate to text: [-9.9513 16.8453]:"}
{"text": "Convert the coordinate to text: [-2.9236 -4.0249]: This study proposes an approach that leverages external knowledge bases to improve upon an existing adversarial attack for detecting inconsistent NLEs and an off-the-shelf mitigation method to ground the model into external background knowledge, thus reducing inconsistencies.", "target": "This study proposes an approach that leverages external knowledge bases to improve upon an existing adversarial attack for detecting inconsistent NLEs and an off-the-shelf mitigation method to ground the model into external background knowledge, thus reducing inconsistencies.", "example": "Convert the coordinate to text: [-2.9236 -4.0249]:"}
{"text": "Convert the coordinate to text: [ 5.3825 -3.2945]: This paper presents AUGUST, a novel automatic dataset synthesis approach that can generate both large-scale and high-quality recommendation dialogues through a data2text generation process, where unstructured recommendation conversations are generated from structured graphs based on real-world user-item information.", "target": "This paper presents AUGUST, a novel automatic dataset synthesis approach that can generate both large-scale and high-quality recommendation dialogues through a data2text generation process, where unstructured recommendation conversations are generated from structured graphs based on real-world user-item information.", "example": "Convert the coordinate to text: [ 5.3825 -3.2945]:"}
{"text": "Convert the coordinate to text: [ 0.5532 -3.3423]: The authors propose \u201cSubset kNN-MT\u201d, a novel methodology for improving the decoding speed of kNN-MT by retrieving neighbor target tokens from a subset of neighbor sentences of the input sentence rather than all sentences, and by using an efficient distance computation technique.", "target": "The authors propose \u201cSubset kNN-MT\u201d, a novel methodology for improving the decoding speed of kNN-MT by retrieving neighbor target tokens from a subset of neighbor sentences of the input sentence rather than all sentences, and by using an efficient distance computation technique.", "example": "Convert the coordinate to text: [ 0.5532 -3.3423]:"}
{"text": "Convert the coordinate to text: [-3.0337  0.5906]: The paper introduces a manually annotated dataset of 10,000 English and Hindi-English code-mixed tweets, specifically annotated for aggression detection and offensive language detection tasks.", "target": "The paper introduces a manually annotated dataset of 10,000 English and Hindi-English code-mixed tweets, specifically annotated for aggression detection and offensive language detection tasks.", "example": "Convert the coordinate to text: [-3.0337  0.5906]:"}
{"text": "Convert the coordinate to text: [-3.6269 -9.3499]: For the constrained system, they used an ST model based on the Fairseq S2T framework using log mel-scale filter banks for audio representations. For the unconstrained system, they used a pipeline approach combining automatic speech recognition (ASR) with machine translation (MT), incorporating a fine-tuned language model for transcription and translation.", "target": "For the constrained system, they used an ST model based on the Fairseq S2T framework using log mel-scale filter banks for audio representations. For the unconstrained system, they used a pipeline approach combining automatic speech recognition (ASR) with machine translation (MT), incorporating a fine-tuned language model for transcription and translation.", "example": "Convert the coordinate to text: [-3.6269 -9.3499]:"}
{"text": "Convert the coordinate to text: [ -1.0589 -12.6357]: The study introduces an autoencoder named ZeroAE, which uses two separate BERT-based encoders to encode text into two separate spaces: label-relevant and label-irrelevant. These two spaces are then decoded by prompting GPT-2 to recover the text and generate text with labels in unseen domains to train the encoder in turn.", "target": "The study introduces an autoencoder named ZeroAE, which uses two separate BERT-based encoders to encode text into two separate spaces: label-relevant and label-irrelevant. These two spaces are then decoded by prompting GPT-2 to recover the text and generate text with labels in unseen domains to train the encoder in turn.", "example": "Convert the coordinate to text: [ -1.0589 -12.6357]:"}
{"text": "Convert the coordinate to text: [-3.2321 -4.0215]: The authors propose a novel method for few-shot nested NER that includes focusing, bridging and prompting components, without using source domain data. These components utilize the limited labeled data to identify unique features of nested entities, such as the relationships between inner and outer entities and contextual positioning information.", "target": "The authors propose a novel method for few-shot nested NER that includes focusing, bridging and prompting components, without using source domain data. These components utilize the limited labeled data to identify unique features of nested entities, such as the relationships between inner and outer entities and contextual positioning information.", "example": "Convert the coordinate to text: [-3.2321 -4.0215]:"}
{"text": "Convert the coordinate to text: [-4.4514 -4.3593]: The authors propose detecting ambiguity by utilizing similarity in a semantic space for service scenarios and training data. They also suggest using task-specific embedding to enhance performance.", "target": "The authors propose detecting ambiguity by utilizing similarity in a semantic space for service scenarios and training data. They also suggest using task-specific embedding to enhance performance.", "example": "Convert the coordinate to text: [-4.4514 -4.3593]:"}
{"text": "Convert the coordinate to text: [12.2638 -3.2521]: The study proposes a so-called Safe-visor architecture that sandboxes DNNs-based controllers as a solution to counter the risks associated with the inability to formally verify DNNs-based controllers.", "target": "The study proposes a so-called Safe-visor architecture that sandboxes DNNs-based controllers as a solution to counter the risks associated with the inability to formally verify DNNs-based controllers.", "example": "Convert the coordinate to text: [12.2638 -3.2521]:"}
{"text": "Convert the coordinate to text: [ 7.3885 -8.7869]: A keypoint-augmented fusion layer is proposed which captures both short and long-range self-attention. This is achieved by augmenting the CNN feature map at multiple scales with an additional input for learning long-range spatial self-attention among localized keypoint features.", "target": "A keypoint-augmented fusion layer is proposed which captures both short and long-range self-attention. This is achieved by augmenting the CNN feature map at multiple scales with an additional input for learning long-range spatial self-attention among localized keypoint features.", "example": "Convert the coordinate to text: [ 7.3885 -8.7869]:"}
{"text": "Convert the coordinate to text: [ 12.0001 -15.4154]: The authors propose a hierarchical generation framework that first generates a set of milestones and then synthesizes the motion along them, thereby reducing the long-range motion generation to synthesizing several short motion sequences.", "target": "The authors propose a hierarchical generation framework that first generates a set of milestones and then synthesizes the motion along them, thereby reducing the long-range motion generation to synthesizing several short motion sequences.", "example": "Convert the coordinate to text: [ 12.0001 -15.4154]:"}
{"text": "Convert the coordinate to text: [ 4.5602 -8.8719]: To address this context, the authors introduce a self-supervised learning framework that synergizes invariance loss and clustering loss for histopathology slide analysis, focusing on achieving transferable representation learning and semantically meaningful clustering.", "target": "To address this context, the authors introduce a self-supervised learning framework that synergizes invariance loss and clustering loss for histopathology slide analysis, focusing on achieving transferable representation learning and semantically meaningful clustering.", "example": "Convert the coordinate to text: [ 4.5602 -8.8719]:"}
{"text": "Convert the coordinate to text: [  9.4401 -13.6163]: A Homography Guided Fusion (HomoFusion) module is proposed to utilize temporally-adjacent video frames for complementary cues facilitating accurate classification of occluded road lines or markings. It also includes a novel surface normal estimator for establishing spatial correspondences between frames.", "target": "A Homography Guided Fusion (HomoFusion) module is proposed to utilize temporally-adjacent video frames for complementary cues facilitating accurate classification of occluded road lines or markings. It also includes a novel surface normal estimator for establishing spatial correspondences between frames.", "example": "Convert the coordinate to text: [  9.4401 -13.6163]:"}
{"text": "Convert the coordinate to text: [-4.3199 -8.8328]: The authors propose a simple, parallel decoding algorithm - Mutate Everything, which can predict the effect of all single, double, and higher-order mutations in one forward pass, with minimal computational overhead.", "target": "The authors propose a simple, parallel decoding algorithm - Mutate Everything, which can predict the effect of all single, double, and higher-order mutations in one forward pass, with minimal computational overhead.", "example": "Convert the coordinate to text: [-4.3199 -8.8328]:"}
{"text": "Convert the coordinate to text: [-0.8926 -5.2199]: The study introduces a novel framework, Selective Prompt Tuning (SPT), which improves upon conventional prompt tuning by learning to select the proper prompt layers via inserting a prompt controlled by a learnable probabilistic gate at each intermediate layer.", "target": "The study introduces a novel framework, Selective Prompt Tuning (SPT), which improves upon conventional prompt tuning by learning to select the proper prompt layers via inserting a prompt controlled by a learnable probabilistic gate at each intermediate layer.", "example": "Convert the coordinate to text: [-0.8926 -5.2199]:"}
{"text": "Convert the coordinate to text: [ 1.0373 -5.7103]: The authors propose an end-to-end Neural Divide-and-Conquer Reasoning framework (NDCR), which regards linguistically complex texts as compound proposition texts composed of multiple simple proposition sentences. The framework divides, conquers and then combines proposition sentences and their corresponding images using a neural logic reasoning approach.", "target": "The authors propose an end-to-end Neural Divide-and-Conquer Reasoning framework (NDCR), which regards linguistically complex texts as compound proposition texts composed of multiple simple proposition sentences. The framework divides, conquers and then combines proposition sentences and their corresponding images using a neural logic reasoning approach.", "example": "Convert the coordinate to text: [ 1.0373 -5.7103]:"}
{"text": "Convert the coordinate to text: [12.7506 -5.0582]: The researchers propose DGSlow, a white-box multi-objective attack method that balances two objectives: generation accuracy and length. They hypothesize that forcing longer generation outputs through crafted adversarial samples improves attack effectiveness, as the generated responses are typically irrelevant, lengthy, and repetitive.", "target": "The researchers propose DGSlow, a white-box multi-objective attack method that balances two objectives: generation accuracy and length. They hypothesize that forcing longer generation outputs through crafted adversarial samples improves attack effectiveness, as the generated responses are typically irrelevant, lengthy, and repetitive.", "example": "Convert the coordinate to text: [12.7506 -5.0582]:"}
{"text": "Convert the coordinate to text: [-3.4646 -2.3486]: The authors propose MetaEvent, a meta learning-based framework for zero- and few-shot event detection, that leverages cloze-based prompts and a trigger-aware soft verbalizer to project output to unseen event types.", "target": "The authors propose MetaEvent, a meta learning-based framework for zero- and few-shot event detection, that leverages cloze-based prompts and a trigger-aware soft verbalizer to project output to unseen event types.", "example": "Convert the coordinate to text: [-3.4646 -2.3486]:"}
{"text": "Convert the coordinate to text: [0.5468 1.5346]: The paper presents the hypothesis that current model editing techniques can introduce large unwanted side effects that go undetected by existing benchmarks. Therefore, it suggests improving the existing CounterFact benchmark (now called CounterFact+) and extending the metrics used for measuring specificity by using a KL divergence-based metric.", "target": "The paper presents the hypothesis that current model editing techniques can introduce large unwanted side effects that go undetected by existing benchmarks. Therefore, it suggests improving the existing CounterFact benchmark (now called CounterFact+) and extending the metrics used for measuring specificity by using a KL divergence-based metric.", "example": "Convert the coordinate to text: [0.5468 1.5346]:"}
{"text": "Convert the coordinate to text: [-9.4139 -7.0624]: The authors introduce a new dependency parser, the hexatagger, which constructs dependency trees by tagging words in a sentence with elements from a finite set of tags. This approach enables fully parallelizable model training and ensures linear time and space complexity during exact decoding.", "target": "The authors introduce a new dependency parser, the hexatagger, which constructs dependency trees by tagging words in a sentence with elements from a finite set of tags. This approach enables fully parallelizable model training and ensures linear time and space complexity during exact decoding.", "example": "Convert the coordinate to text: [-9.4139 -7.0624]:"}
{"text": "Convert the coordinate to text: [-5.3794  1.3371]: The authors propose HonestBait, a framework for generating headlines using forward references (FRs), a writing technique often used for clickbait, along with a self-verification process during training to avoid spurious inventions.", "target": "The authors propose HonestBait, a framework for generating headlines using forward references (FRs), a writing technique often used for clickbait, along with a self-verification process during training to avoid spurious inventions.", "example": "Convert the coordinate to text: [-5.3794  1.3371]:"}
{"text": "Convert the coordinate to text: [-13.3829  -1.1174]: A unified framework, called sampling adapters, is proposed for understanding techniques like nucleus or top-k sampling. These adapters are believed to balance precision and recall when generating text, leading to higher-quality output.", "target": "A unified framework, called sampling adapters, is proposed for understanding techniques like nucleus or top-k sampling. These adapters are believed to balance precision and recall when generating text, leading to higher-quality output.", "example": "Convert the coordinate to text: [-13.3829  -1.1174]:"}
{"text": "Convert the coordinate to text: [-3.9115 -9.2308]: The authors describe their two systems for this task: an end-to-end direct speech translation system and a cascaded system. Both systems have a backbone of a Hindi-Marathi bilingual ASR system.", "target": "The authors describe their two systems for this task: an end-to-end direct speech translation system and a cascaded system. Both systems have a backbone of a Hindi-Marathi bilingual ASR system.", "example": "Convert the coordinate to text: [-3.9115 -9.2308]:"}
{"text": "Convert the coordinate to text: [-3.2453 -9.0268]: The authors develop an end-to-end system using the Wav2Vec2 model for speech recognition and mBART50 models for machine translation. An adapter module is used to bridge the speech and translation modules, and CTC loss between speech features and source token sequence is incorporated during training.", "target": "The authors develop an end-to-end system using the Wav2Vec2 model for speech recognition and mBART50 models for machine translation. An adapter module is used to bridge the speech and translation modules, and CTC loss between speech features and source token sequence is incorporated during training.", "example": "Convert the coordinate to text: [-3.2453 -9.0268]:"}
{"text": "Convert the coordinate to text: [1.3843 3.2115]: The authors propose a framework and simulator for estimating p-values for comparisons between two systems' results, using inherent variances in test set items and individual responses to define a null hypothesis.", "target": "The authors propose a framework and simulator for estimating p-values for comparisons between two systems' results, using inherent variances in test set items and individual responses to define a null hypothesis.", "example": "Convert the coordinate to text: [1.3843 3.2115]:"}
{"text": "Convert the coordinate to text: [16.1233 -8.6716]: A novel joint IE framework, CRFIE, is introduced which models joint IE as a high-order Conditional Random Field, directly modeling the interactions between both pairs and triplets of instances.", "target": "A novel joint IE framework, CRFIE, is introduced which models joint IE as a high-order Conditional Random Field, directly modeling the interactions between both pairs and triplets of instances.", "example": "Convert the coordinate to text: [16.1233 -8.6716]:"}
{"text": "Convert the coordinate to text: [-6.6542 12.4113]: The authors introduce a new paradigm to formalize multi-turn ESC as a process of positive emotion elicitation, which requires adjusting the elicitation intensity in ES as the conversation progresses while maintaining conversational goals like coherence.", "target": "The authors introduce a new paradigm to formalize multi-turn ESC as a process of positive emotion elicitation, which requires adjusting the elicitation intensity in ES as the conversation progresses while maintaining conversational goals like coherence.", "example": "Convert the coordinate to text: [-6.6542 12.4113]:"}
{"text": "Convert the coordinate to text: [ 12.9631 -14.249 ]: This paper sets up an egocentric 3D hand trajectory forecasting task that predicts hand trajectories in 3D space from early observed RGB videos in a first-person view and proposes an uncertainty-aware state space Transformer (USST) that combines the attention mechanism and aleatoric uncertainty within the framework of the classical state-space model.", "target": "This paper sets up an egocentric 3D hand trajectory forecasting task that predicts hand trajectories in 3D space from early observed RGB videos in a first-person view and proposes an uncertainty-aware state space Transformer (USST) that combines the attention mechanism and aleatoric uncertainty within the framework of the classical state-space model.", "example": "Convert the coordinate to text: [ 12.9631 -14.249 ]:"}
{"text": "Convert the coordinate to text: [  5.5956 -12.4867]: The authors propose a learning-based approach to visual disambiguation by formulating it as a binary classification task on image pairs and designing a network architecture that takes the spatial distribution of local keypoints and matches as input.", "target": "The authors propose a learning-based approach to visual disambiguation by formulating it as a binary classification task on image pairs and designing a network architecture that takes the spatial distribution of local keypoints and matches as input.", "example": "Convert the coordinate to text: [  5.5956 -12.4867]:"}
{"text": "Convert the coordinate to text: [ 4.1857 -0.35  ]: This paper proposes the Prototype-based Aleatoric Uncertainty Quantification (PAU) framework designed to offer reliable predictions by quantifying the uncertainty originating from the inherent data ambiguity. The different learnable prototypes for each modality represent the entire semantics subspace.", "target": "This paper proposes the Prototype-based Aleatoric Uncertainty Quantification (PAU) framework designed to offer reliable predictions by quantifying the uncertainty originating from the inherent data ambiguity. The different learnable prototypes for each modality represent the entire semantics subspace.", "example": "Convert the coordinate to text: [ 4.1857 -0.35  ]:"}
{"text": "Convert the coordinate to text: [ 12.5844 -12.6396]: The authors propose GETAvatar, a Generative model that directly generates Explicit Textured 3D meshes for animatable human avatars with photo-realistic appearance and geometric details. They achieve this by designing an articulated 3D human representation with explicit surface modeling and learning from the 2D normal maps of 3D scan data.", "target": "The authors propose GETAvatar, a Generative model that directly generates Explicit Textured 3D meshes for animatable human avatars with photo-realistic appearance and geometric details. They achieve this by designing an articulated 3D human representation with explicit surface modeling and learning from the 2D normal maps of 3D scan data.", "example": "Convert the coordinate to text: [ 12.5844 -12.6396]:"}
{"text": "Convert the coordinate to text: [ 4.6033 -4.9962]: Pretraining GNNs on the fragment level is proposed as an intermediate solution to overcome the limitations of node-level and graph-level pretraining. A contrastive learning task is introduced that jointly pretrains two GNNs\u2014one based on molecular graphs and the other on fragment graphs\u2014and several fragment-based contrastive and predictive pretraining tasks are introduced.", "target": "Pretraining GNNs on the fragment level is proposed as an intermediate solution to overcome the limitations of node-level and graph-level pretraining. A contrastive learning task is introduced that jointly pretrains two GNNs\u2014one based on molecular graphs and the other on fragment graphs\u2014and several fragment-based contrastive and predictive pretraining tasks are introduced.", "example": "Convert the coordinate to text: [ 4.6033 -4.9962]:"}
{"text": "Convert the coordinate to text: [8.7748 4.9467]: The authors propose the use of neural samplers that specify implicit distributions, an approach capable of approximating complex, high-dimensional posteriors. They introduce novel bounds achieved by locally linearising the neural sampler, which is a departure from methods requiring additional discriminator networks and unstable adversarial objectives.", "target": "The authors propose the use of neural samplers that specify implicit distributions, an approach capable of approximating complex, high-dimensional posteriors. They introduce novel bounds achieved by locally linearising the neural sampler, which is a departure from methods requiring additional discriminator networks and unstable adversarial objectives.", "example": "Convert the coordinate to text: [8.7748 4.9467]:"}
{"text": "Convert the coordinate to text: [10.9302 -6.2345]: The authors propose AdvDiffuser, a new method for synthesizing natural UAEs using diffusion models. It can generate UAEs from scratch or conditionally based on reference images.", "target": "The authors propose AdvDiffuser, a new method for synthesizing natural UAEs using diffusion models. It can generate UAEs from scratch or conditionally based on reference images.", "example": "Convert the coordinate to text: [10.9302 -6.2345]:"}
{"text": "Convert the coordinate to text: [ 3.0716 -4.9335]: This paper proposes a Representation Fusion and Promotion Learning (RFPL) mechanism with two sub-modules: meta-action learning (MAL) and reinforced image representation (RIR) to address the issue of capturing rich action semantics and reducing the influence of irrelevant frames.", "target": "This paper proposes a Representation Fusion and Promotion Learning (RFPL) mechanism with two sub-modules: meta-action learning (MAL) and reinforced image representation (RIR) to address the issue of capturing rich action semantics and reducing the influence of irrelevant frames.", "example": "Convert the coordinate to text: [ 3.0716 -4.9335]:"}
{"text": "Convert the coordinate to text: [-5.73  -0.758]: The authors aim to enhance the performance of language models in biomedical abstractive summarisation by aggregating knowledge from external papers cited within the source article. They propose a novel attention-based citation aggregation model which integrates domain-specific knowledge from citation papers.", "target": "The authors aim to enhance the performance of language models in biomedical abstractive summarisation by aggregating knowledge from external papers cited within the source article. They propose a novel attention-based citation aggregation model which integrates domain-specific knowledge from citation papers.", "example": "Convert the coordinate to text: [-5.73  -0.758]:"}
{"text": "Convert the coordinate to text: [  8.68   -16.5142]: The authors propose a learning-based framework for non-rigid shape registration without correspondence supervision. They deform a source mesh towards a target point cloud, guided by correspondences induced by high-dimensional embeddings learned from deep functional maps (DFM).", "target": "The authors propose a learning-based framework for non-rigid shape registration without correspondence supervision. They deform a source mesh towards a target point cloud, guided by correspondences induced by high-dimensional embeddings learned from deep functional maps (DFM).", "example": "Convert the coordinate to text: [  8.68   -16.5142]:"}
{"text": "Convert the coordinate to text: [ 6.3022 13.4394]: The authors propose a PbRL algorithm that learns directly from preference without requiring any reward modeling, using a contrastive learning framework to design a novel policy scoring metric that assigns high scores to policies that align with the given preferences.", "target": "The authors propose a PbRL algorithm that learns directly from preference without requiring any reward modeling, using a contrastive learning framework to design a novel policy scoring metric that assigns high scores to policies that align with the given preferences.", "example": "Convert the coordinate to text: [ 6.3022 13.4394]:"}
{"text": "Convert the coordinate to text: [12.8857  2.4627]: The authors propose a novel orthogonal non-negative tensor factorization (Orth-NTF) based multi-view clustering method that directly applies Orth-NTF on the 3rd-order tensor composed of the anchor graphs of views, allowing the model to directly consider the between-view relationship.", "target": "The authors propose a novel orthogonal non-negative tensor factorization (Orth-NTF) based multi-view clustering method that directly applies Orth-NTF on the 3rd-order tensor composed of the anchor graphs of views, allowing the model to directly consider the between-view relationship.", "example": "Convert the coordinate to text: [12.8857  2.4627]:"}
{"text": "Convert the coordinate to text: [15.6487 -0.1906]: The paper proposes a novel approach to improve the speed of the noise estimation network that leverages the robustness of early-stage diffusion models and post-training quantization (PTQ) to use low-bit activation for the early reverse diffusion process while maintaining high-bit activation for the later stages.", "target": "The paper proposes a novel approach to improve the speed of the noise estimation network that leverages the robustness of early-stage diffusion models and post-training quantization (PTQ) to use low-bit activation for the early reverse diffusion process while maintaining high-bit activation for the later stages.", "example": "Convert the coordinate to text: [15.6487 -0.1906]:"}
{"text": "Convert the coordinate to text: [ 9.4168 12.1228]: This study introduces ProbFair, a probabilistically fair stationary policy that maximizes total expected reward, satisfies budget constraints, and ensures a positive lower bound on the probability of an arm being pulled at each timestep.", "target": "This study introduces ProbFair, a probabilistically fair stationary policy that maximizes total expected reward, satisfies budget constraints, and ensures a positive lower bound on the probability of an arm being pulled at each timestep.", "example": "Convert the coordinate to text: [ 9.4168 12.1228]:"}
{"text": "Convert the coordinate to text: [12.9804  0.5899]: The paper proposes a solution to this limitation via distilling classifier-free guided diffusion models into models that are fast to sample. The method learns a single model to match the output of the combined conditional and unconditional models, and then progressively distills that model to a diffusion model that requires much fewer sampling steps.", "target": "The paper proposes a solution to this limitation via distilling classifier-free guided diffusion models into models that are fast to sample. The method learns a single model to match the output of the combined conditional and unconditional models, and then progressively distills that model to a diffusion model that requires much fewer sampling steps.", "example": "Convert the coordinate to text: [12.9804  0.5899]:"}
{"text": "Convert the coordinate to text: [-4.4713 -4.6511]: The authors attempt to improve WMD by incorporating sentence structure represented by BERT's self-attention matrix (SAM). The proposed method is based on the Fused Gromov-Wasserstein distance, which simultaneously considers the similarity of the word embedding and the SAM for calculating the optimal transport between two sentences.", "target": "The authors attempt to improve WMD by incorporating sentence structure represented by BERT's self-attention matrix (SAM). The proposed method is based on the Fused Gromov-Wasserstein distance, which simultaneously considers the similarity of the word embedding and the SAM for calculating the optimal transport between two sentences.", "example": "Convert the coordinate to text: [-4.4713 -4.6511]:"}
{"text": "Convert the coordinate to text: [ 11.1407 -12.8229]: The authors propose the use of multiple views to minimize the issue of missing information and generate an accurate representation of the underlying human model. They design a multi-view fusion network that takes pose key points and texture from multiple source images to produce an appearance retrieval map.", "target": "The authors propose the use of multiple views to minimize the issue of missing information and generate an accurate representation of the underlying human model. They design a multi-view fusion network that takes pose key points and texture from multiple source images to produce an appearance retrieval map.", "example": "Convert the coordinate to text: [ 11.1407 -12.8229]:"}
{"text": "Convert the coordinate to text: [  6.0292 -12.784 ]: This paper presents a novel tree-structure baseline, the Multiple Hypotheses Segment Tree (MHST), for one-shot TSL, designed to capture the query-aware discriminative frame-wise information even when annotations are sparse. It treats each video frame as leaf nodes and merges adjacent frames that share the same visual-linguistic semantics into upper non-leaf nodes as the tree builds.", "target": "This paper presents a novel tree-structure baseline, the Multiple Hypotheses Segment Tree (MHST), for one-shot TSL, designed to capture the query-aware discriminative frame-wise information even when annotations are sparse. It treats each video frame as leaf nodes and merges adjacent frames that share the same visual-linguistic semantics into upper non-leaf nodes as the tree builds.", "example": "Convert the coordinate to text: [  6.0292 -12.784 ]:"}
{"text": "Convert the coordinate to text: [ 1.9791 -3.1195]: The authors propose the residual-memorization (ResMem) algorithm, which improves model generalization via explicit memorization by fitting the model's residuals with a $k$-nearest neighbor based regressor.", "target": "The authors propose the residual-memorization (ResMem) algorithm, which improves model generalization via explicit memorization by fitting the model's residuals with a $k$-nearest neighbor based regressor.", "example": "Convert the coordinate to text: [ 1.9791 -3.1195]:"}
{"text": "Convert the coordinate to text: [ 1.5547 -4.5753]: This paper presents CaFo, a Cascade of Foundation models that combines the various kinds of pre-training knowledge\u2014from contrastive to generative\u2014in order to improve few-shot learning. The architecture incorporates the language-contrastive knowledge of CLIP, the vision-contrastive knowledge of DINO, the vision-generative knowledge of DALL-E, and the language-generative knowledge of GPT-3.", "target": "This paper presents CaFo, a Cascade of Foundation models that combines the various kinds of pre-training knowledge\u2014from contrastive to generative\u2014in order to improve few-shot learning. The architecture incorporates the language-contrastive knowledge of CLIP, the vision-contrastive knowledge of DINO, the vision-generative knowledge of DALL-E, and the language-generative knowledge of GPT-3.", "example": "Convert the coordinate to text: [ 1.5547 -4.5753]:"}
{"text": "Convert the coordinate to text: [ 3.9623 12.72  ]: The authors propose a new approach to learn from passive data by modeling intentions, which measures how the likelihood of future outcomes changes when the agent acts to achieve a particular task. They propose a temporal difference learning objective to learn about intentions.", "target": "The authors propose a new approach to learn from passive data by modeling intentions, which measures how the likelihood of future outcomes changes when the agent acts to achieve a particular task. They propose a temporal difference learning objective to learn about intentions.", "example": "Convert the coordinate to text: [ 3.9623 12.72  ]:"}
{"text": "Convert the coordinate to text: [ 3.7956 -3.9449]: The authors propose a novel method for KD, named Top-1 Information Enhanced Knowledge Distillation (TIE-KD). The method includes a hierarchical ranking loss for learning top-1 information from the teacher and an iterative KD procedure to infuse more knowledge by distilling on data without ground-truth targets.", "target": "The authors propose a novel method for KD, named Top-1 Information Enhanced Knowledge Distillation (TIE-KD). The method includes a hierarchical ranking loss for learning top-1 information from the teacher and an iterative KD procedure to infuse more knowledge by distilling on data without ground-truth targets.", "example": "Convert the coordinate to text: [ 3.7956 -3.9449]:"}
{"text": "Convert the coordinate to text: [12.7803 11.4345]: To achieve a balance between stability and efficiency, the authors propose an amortized model that predicts each input feature's Shapley Value directly, eliminating the need for additional model evaluations.", "target": "To achieve a balance between stability and efficiency, the authors propose an amortized model that predicts each input feature's Shapley Value directly, eliminating the need for additional model evaluations.", "example": "Convert the coordinate to text: [12.7803 11.4345]:"}
{"text": "Convert the coordinate to text: [-5.7422 -0.71  ]: The authors introduce a two-stage framework for lay summarization: the first stage generates summaries using large language models with LSG attention and the second stage uses a zero-shot sentence simplification method to improve readability.", "target": "The authors introduce a two-stage framework for lay summarization: the first stage generates summaries using large language models with LSG attention and the second stage uses a zero-shot sentence simplification method to improve readability.", "example": "Convert the coordinate to text: [-5.7422 -0.71  ]:"}
{"text": "Convert the coordinate to text: [ 9.4905 11.7805]: The authors propose a multi-armed bandit framework for the sequential selection of pre-training hyperparameters, aimed at optimizing language model performance, in a resource efficient manner. The framework uses Thompson sampling algorithm with a surrogate Gaussian process reward model of the Masked Language Model (MLM) pre-training objective, for its sequential minimization.", "target": "The authors propose a multi-armed bandit framework for the sequential selection of pre-training hyperparameters, aimed at optimizing language model performance, in a resource efficient manner. The framework uses Thompson sampling algorithm with a surrogate Gaussian process reward model of the Masked Language Model (MLM) pre-training objective, for its sequential minimization.", "example": "Convert the coordinate to text: [ 9.4905 11.7805]:"}
{"text": "Convert the coordinate to text: [-2.7508  0.4282]: The paper proposes a new framework for generating adversarial implicit hate speech (HS) short-text messages using Auto-regressive Language Models. It also suggests a strategy to group these implicit messages into complexity levels to measure their difficulty for supervised classifiers.", "target": "The paper proposes a new framework for generating adversarial implicit hate speech (HS) short-text messages using Auto-regressive Language Models. It also suggests a strategy to group these implicit messages into complexity levels to measure their difficulty for supervised classifiers.", "example": "Convert the coordinate to text: [-2.7508  0.4282]:"}
{"text": "Convert the coordinate to text: [ 2.4516 -2.957 ]: The authors introduce the concept of Class Lifelong Learning for Intent Detection (CLL-ID), where the model constantly learns new intent classes from fresh data, while avoiding significant performance decline on old data.", "target": "The authors introduce the concept of Class Lifelong Learning for Intent Detection (CLL-ID), where the model constantly learns new intent classes from fresh data, while avoiding significant performance decline on old data.", "example": "Convert the coordinate to text: [ 2.4516 -2.957 ]:"}
{"text": "Convert the coordinate to text: [-3.5544 -7.8925]: A new multimodal neural machine translation (MNMT) model has been proposed which uses a synthetic image generated by a latent diffusion model, corresponding to the content of the source language sentence, to perform translation.", "target": "A new multimodal neural machine translation (MNMT) model has been proposed which uses a synthetic image generated by a latent diffusion model, corresponding to the content of the source language sentence, to perform translation.", "example": "Convert the coordinate to text: [-3.5544 -7.8925]:"}
{"text": "Convert the coordinate to text: [-4.7504 -0.1713]: This paper conducts a large-scale correlation analysis of coherence metrics and proposes a novel sampling approach to mine topics for the purpose of metric evaluation.", "target": "This paper conducts a large-scale correlation analysis of coherence metrics and proposes a novel sampling approach to mine topics for the purpose of metric evaluation.", "example": "Convert the coordinate to text: [-4.7504 -0.1713]:"}
{"text": "Convert the coordinate to text: [1.4084 3.2255]: The authors propose a concept of consolidating causal mechanisms to transform large-scale SCM while preserving consistent interventional behaviour, which can simplify these models without destroying their causal properties.", "target": "The authors propose a concept of consolidating causal mechanisms to transform large-scale SCM while preserving consistent interventional behaviour, which can simplify these models without destroying their causal properties.", "example": "Convert the coordinate to text: [1.4084 3.2255]:"}
{"text": "Convert the coordinate to text: [-12.9897   5.7196]: This study introduces a large-scale benchmark called 'InstructExcel' to evaluate the performance of LLMs in generating Excel OfficeScripts from natural language user instructions.", "target": "This study introduces a large-scale benchmark called 'InstructExcel' to evaluate the performance of LLMs in generating Excel OfficeScripts from natural language user instructions.", "example": "Convert the coordinate to text: [-12.9897   5.7196]:"}
{"text": "Convert the coordinate to text: [ 6.495  13.7252]: This paper investigates why bisimulation methods are successful in online settings but falter in offline tasks. The authors propose the use of the expectile operator for representation learning in offline RL settings and implement a reward scaling strategy to prevent feature collapse in representation space.", "target": "This paper investigates why bisimulation methods are successful in online settings but falter in offline tasks. The authors propose the use of the expectile operator for representation learning in offline RL settings and implement a reward scaling strategy to prevent feature collapse in representation space.", "example": "Convert the coordinate to text: [ 6.495  13.7252]:"}
{"text": "Convert the coordinate to text: [-1.0683 -5.1589]: The paper introduces MetaL-Prompt, a new lightweight automatic prompt-generation method for LMaaS. MetaL-Prompt utilizes a meta-trained prompt generation model (PGM) that can generate prompts for unseen tasks without requiring additional task-specific training.", "target": "The paper introduces MetaL-Prompt, a new lightweight automatic prompt-generation method for LMaaS. MetaL-Prompt utilizes a meta-trained prompt generation model (PGM) that can generate prompts for unseen tasks without requiring additional task-specific training.", "example": "Convert the coordinate to text: [-1.0683 -5.1589]:"}
{"text": "Convert the coordinate to text: [2.5639 4.9015]: The authors challenge the existing measures of homophily and propose a new measure called 'adjusted homophily', which satisfies more properties than other popular measures. Additionally, they introduce a new characteristic, 'label informativeness' (LI), which indicates the amount of information a neighbor's label provides about a node's label.", "target": "The authors challenge the existing measures of homophily and propose a new measure called 'adjusted homophily', which satisfies more properties than other popular measures. Additionally, they introduce a new characteristic, 'label informativeness' (LI), which indicates the amount of information a neighbor's label provides about a node's label.", "example": "Convert the coordinate to text: [2.5639 4.9015]:"}
{"text": "Convert the coordinate to text: [-0.953  -5.2396]: The authors propose a new method termed Residual Prompt Tuning, reparameterizing soft prompt embeddings using a shallow network with a residual connection, hoping to improve the performance and stability of prompt tuning.", "target": "The authors propose a new method termed Residual Prompt Tuning, reparameterizing soft prompt embeddings using a shallow network with a residual connection, hoping to improve the performance and stability of prompt tuning.", "example": "Convert the coordinate to text: [-0.953  -5.2396]:"}
{"text": "Convert the coordinate to text: [ 4.2583 -1.0001]: The authors propose the concept of Uncertainty Guided label denoising, embedded within a new framework called UGDRE, that incorporates an instance-level uncertainty estimation method to measure the reliability of pseudo labels with overlapping relations.", "target": "The authors propose the concept of Uncertainty Guided label denoising, embedded within a new framework called UGDRE, that incorporates an instance-level uncertainty estimation method to measure the reliability of pseudo labels with overlapping relations.", "example": "Convert the coordinate to text: [ 4.2583 -1.0001]:"}
{"text": "Convert the coordinate to text: [-4.8079 -4.9079]: The authors propose a Word-Context-Coupled Space (W2CSpace) which aligns uninterpretable neural representation with interpretable statistical logic enhancing the interpretability of language models.", "target": "The authors propose a Word-Context-Coupled Space (W2CSpace) which aligns uninterpretable neural representation with interpretable statistical logic enhancing the interpretability of language models.", "example": "Convert the coordinate to text: [-4.8079 -4.9079]:"}
{"text": "Convert the coordinate to text: [-1.2064 -5.7005]: Based on the observation that the learned syntax and semantics representation varies a lot at different layers, the authors argue for an adaptive prefix that will be further tailored to each layer than the fixed one. The authors propose Adaptive Prefix Tuning (APT) to adjust the prefix both at the fine-grained token level and at the coarse-grained layer level using a gate mechanism.", "target": "Based on the observation that the learned syntax and semantics representation varies a lot at different layers, the authors argue for an adaptive prefix that will be further tailored to each layer than the fixed one. The authors propose Adaptive Prefix Tuning (APT) to adjust the prefix both at the fine-grained token level and at the coarse-grained layer level using a gate mechanism.", "example": "Convert the coordinate to text: [-1.2064 -5.7005]:"}
{"text": "Convert the coordinate to text: [-11.6064  -1.6014]: The authors introduce the cross-schema text-to-SQL task where the databases of evaluation data are different from the training data but from the same domain. They also present CSS, a large-scale, cross-schema Chinese text-to-SQL dataset for related studies, which is composed of 4,340 question/SQL pairs across two databases and further extended to 19 new databases with 29,280 dataset examples for enhanced generalization.", "target": "The authors introduce the cross-schema text-to-SQL task where the databases of evaluation data are different from the training data but from the same domain. They also present CSS, a large-scale, cross-schema Chinese text-to-SQL dataset for related studies, which is composed of 4,340 question/SQL pairs across two databases and further extended to 19 new databases with 29,280 dataset examples for enhanced generalization.", "example": "Convert the coordinate to text: [-11.6064  -1.6014]:"}
{"text": "Convert the coordinate to text: [-10.4446  -1.3933]: The authors propose to systematically review and analyze the current state of Asking Clarification Questions (ACQs) research, including a detailed comparison of publicly available datasets, discussion on applied evaluation metrics, and benchmarks for tasks related to ACQs.", "target": "The authors propose to systematically review and analyze the current state of Asking Clarification Questions (ACQs) research, including a detailed comparison of publicly available datasets, discussion on applied evaluation metrics, and benchmarks for tasks related to ACQs.", "example": "Convert the coordinate to text: [-10.4446  -1.3933]:"}
{"text": "Convert the coordinate to text: [ 6.5322 -3.3014]: The authors propose an unknown-aware training method for open-set relation extraction that regularizes the model by dynamically synthesizing negative instances. These instances, inspired by text adversarial attacks, are created by applying small perturbations to original training instances, making them more likely to be mistaken by the model as known relations.", "target": "The authors propose an unknown-aware training method for open-set relation extraction that regularizes the model by dynamically synthesizing negative instances. These instances, inspired by text adversarial attacks, are created by applying small perturbations to original training instances, making them more likely to be mistaken by the model as known relations.", "example": "Convert the coordinate to text: [ 6.5322 -3.3014]:"}
{"text": "Convert the coordinate to text: [ 1.5975 -6.7768]: The paper introduces a new MMRE framework known as DGF-PT, designed to better capture deeper correlations among text, entity pairs, and images/objects, in order to yield more useful information for MMRE task.", "target": "The paper introduces a new MMRE framework known as DGF-PT, designed to better capture deeper correlations among text, entity pairs, and images/objects, in order to yield more useful information for MMRE task.", "example": "Convert the coordinate to text: [ 1.5975 -6.7768]:"}
{"text": "Convert the coordinate to text: [-3.748  -3.2917]: The authors propose a method for sentence classification into four categories - claim, experience, experience_based_claim or a question, based on the BioBERT model coupled with a Multilayer Perceptron (MLP) layer for the SemEval competition.", "target": "The authors propose a method for sentence classification into four categories - claim, experience, experience_based_claim or a question, based on the BioBERT model coupled with a Multilayer Perceptron (MLP) layer for the SemEval competition.", "example": "Convert the coordinate to text: [-3.748  -3.2917]:"}
{"text": "Convert the coordinate to text: [-2.617  -7.4761]: The authors propose a system consisting of a pretrained multilingual masked language model as a text encoder and a neural network as a regression model. An innovative feature is the incorporation of data augmentation via neural machine translation models to improve performance under low-resource scenarios.", "target": "The authors propose a system consisting of a pretrained multilingual masked language model as a text encoder and a neural network as a regression model. An innovative feature is the incorporation of data augmentation via neural machine translation models to improve performance under low-resource scenarios.", "example": "Convert the coordinate to text: [-2.617  -7.4761]:"}
{"text": "Convert the coordinate to text: [-3.8801 -7.6393]: In this study, the authors propose: (1) verification of the effectiveness of integrating pretrained knowledge into NMT models, with these models then being used as robust testbeds for researching CR in NMT; and (2) a novel entity-aware evaluation method that takes into account both the NMT candidate and important entities in the candidate, aligning more with human judgement.", "target": "In this study, the authors propose: (1) verification of the effectiveness of integrating pretrained knowledge into NMT models, with these models then being used as robust testbeds for researching CR in NMT; and (2) a novel entity-aware evaluation method that takes into account both the NMT candidate and important entities in the candidate, aligning more with human judgement.", "example": "Convert the coordinate to text: [-3.8801 -7.6393]:"}
{"text": "Convert the coordinate to text: [-0.2343 -4.7422]: The authors propose a novel approach of developing a sparsely activated modular network and formulating dialogue generation as the execution of a generated programme, which recursively composes and assembles modules.", "target": "The authors propose a novel approach of developing a sparsely activated modular network and formulating dialogue generation as the execution of a generated programme, which recursively composes and assembles modules.", "example": "Convert the coordinate to text: [-0.2343 -4.7422]:"}
{"text": "Convert the coordinate to text: [ 2.1039 -0.7047]: This study proposes a novel framework for unlearning data from GBDT, and formalizes the machine unlearning problem and its relaxed version.", "target": "This study proposes a novel framework for unlearning data from GBDT, and formalizes the machine unlearning problem and its relaxed version.", "example": "Convert the coordinate to text: [ 2.1039 -0.7047]:"}
{"text": "Convert the coordinate to text: [ 11.57   -12.9319]: The paper introduces DreamPose, a diffusion-based method for generating animated fashion videos. It synthesizes a video from a given image and sequence of human body poses by transforming a pretrained text-to-image model (Stable Diffusion) into a pose-and-image guided video synthesis model.", "target": "The paper introduces DreamPose, a diffusion-based method for generating animated fashion videos. It synthesizes a video from a given image and sequence of human body poses by transforming a pretrained text-to-image model (Stable Diffusion) into a pose-and-image guided video synthesis model.", "example": "Convert the coordinate to text: [ 11.57   -12.9319]:"}
{"text": "Convert the coordinate to text: [-1.1493 -5.1677]: The authors proposed a method, PromptMix, that utilizes the LLM's ability to follow instructions and perform few-shot classifications to generate augmented data that is more helpful. It involves generating challenging text augmentations near class boundaries and then relabeling these augmentations using a prompting-based LLM to ensure the accuracy of the labels in the generated data.", "target": "The authors proposed a method, PromptMix, that utilizes the LLM's ability to follow instructions and perform few-shot classifications to generate augmented data that is more helpful. It involves generating challenging text augmentations near class boundaries and then relabeling these augmentations using a prompting-based LLM to ensure the accuracy of the labels in the generated data.", "example": "Convert the coordinate to text: [-1.1493 -5.1677]:"}
{"text": "Convert the coordinate to text: [12.2866 -5.2308]: This study uncovers that in batch normalized deep image recognition architectures, intermediate latents produced after a batch normalization step can produce adversarial examples using an intermediate loss relying solely on angular deviations\u2014without the need for any labels.", "target": "This study uncovers that in batch normalized deep image recognition architectures, intermediate latents produced after a batch normalization step can produce adversarial examples using an intermediate loss relying solely on angular deviations\u2014without the need for any labels.", "example": "Convert the coordinate to text: [12.2866 -5.2308]:"}
{"text": "Convert the coordinate to text: [ 6.5111 -6.5787]: The authors investigate how recurrent neural circuits learn to represent the abstract order structure of temporal sequences, and how this disentangled representation from that of contents enables processing of temporal sequences.", "target": "The authors investigate how recurrent neural circuits learn to represent the abstract order structure of temporal sequences, and how this disentangled representation from that of contents enables processing of temporal sequences.", "example": "Convert the coordinate to text: [ 6.5111 -6.5787]:"}
{"text": "Convert the coordinate to text: [ 5.7962 -3.0798]: The authors propose Adversarial Invariant Augmentation (AIA), a data augmentation strategy designed specifically to manage covariate shifts on graphs. AIA extrapolates and generates new environments while preserving original stable features during the augmentation process.", "target": "The authors propose Adversarial Invariant Augmentation (AIA), a data augmentation strategy designed specifically to manage covariate shifts on graphs. AIA extrapolates and generates new environments while preserving original stable features during the augmentation process.", "example": "Convert the coordinate to text: [ 5.7962 -3.0798]:"}
{"text": "Convert the coordinate to text: [ 0.0337 -7.02  ]: This paper is a survey reviewing Transformer schemes for time series modelling, highlighting their strengths and limitations.", "target": "This paper is a survey reviewing Transformer schemes for time series modelling, highlighting their strengths and limitations.", "example": "Convert the coordinate to text: [ 0.0337 -7.02  ]:"}
{"text": "Convert the coordinate to text: [-0.8713 -5.0539]: The authors propose meta prompt tuning (MPT) which explores how meta-learning can improve cross-task generalization in PT through learning to initialize the prompt embeddings from other relevant tasks.", "target": "The authors propose meta prompt tuning (MPT) which explores how meta-learning can improve cross-task generalization in PT through learning to initialize the prompt embeddings from other relevant tasks.", "example": "Convert the coordinate to text: [-0.8713 -5.0539]:"}
{"text": "Convert the coordinate to text: [-6.3612  8.7255]: The authors propose CrowdIDEA, a novel tool integrating crowdsourced beliefs, data analytics, and causal diagrams, designed to stimulate and enhance causal reasoning.", "target": "The authors propose CrowdIDEA, a novel tool integrating crowdsourced beliefs, data analytics, and causal diagrams, designed to stimulate and enhance causal reasoning.", "example": "Convert the coordinate to text: [-6.3612  8.7255]:"}
{"text": "Convert the coordinate to text: [-2.9532 -7.5993]: The authors propose a communication-efficient Fed-MNMT framework by keeping pre-trained language models (PLMs) frozen and transferring only lightweight adapter modules between clients, grouping parameters to minimize the negative effect of conflicting parameters from different language pairs.", "target": "The authors propose a communication-efficient Fed-MNMT framework by keeping pre-trained language models (PLMs) frozen and transferring only lightweight adapter modules between clients, grouping parameters to minimize the negative effect of conflicting parameters from different language pairs.", "example": "Convert the coordinate to text: [-2.9532 -7.5993]:"}
{"text": "Convert the coordinate to text: [ 3.6845 -1.1224]: The authors propose to leverage the original multi-annotator labels directly by introducing a Confidence-based Partial Label Learning (CPLL) method integrating 'prior confidence' given by annotators and 'posterior confidences' learned by models for crowd-annotated NER.", "target": "The authors propose to leverage the original multi-annotator labels directly by introducing a Confidence-based Partial Label Learning (CPLL) method integrating 'prior confidence' given by annotators and 'posterior confidences' learned by models for crowd-annotated NER.", "example": "Convert the coordinate to text: [ 3.6845 -1.1224]:"}
{"text": "Convert the coordinate to text: [-3.7661  3.0049]: This paper introduces a novel framework, Recformer, which models user preferences and item features as language representations that can be extended to new items and datasets. An item is formulated as a 'sentence' by flattening item key-value attributes described by text, and the item sequence for a user becomes a sequence of 'sentences'.", "target": "This paper introduces a novel framework, Recformer, which models user preferences and item features as language representations that can be extended to new items and datasets. An item is formulated as a 'sentence' by flattening item key-value attributes described by text, and the item sequence for a user becomes a sequence of 'sentences'.", "example": "Convert the coordinate to text: [-3.7661  3.0049]:"}
{"text": "Convert the coordinate to text: [-0.934  -2.7662]: The authors propose a joint framework called CREST (ContRastive Edits with Sparse raTionalization) that unifies selective rationalization and counterfactual text generation to enhance model outcomes in terms of quality, robustness and interpretability.", "target": "The authors propose a joint framework called CREST (ContRastive Edits with Sparse raTionalization) that unifies selective rationalization and counterfactual text generation to enhance model outcomes in terms of quality, robustness and interpretability.", "example": "Convert the coordinate to text: [-0.934  -2.7662]:"}
{"text": "Convert the coordinate to text: [-4.3166 -8.2133]: The paper seeks to determine the best way to utilize a context-aware translation model in decoding. Different decoding schemes were used, including existing ones and new proposals from the authors.", "target": "The paper seeks to determine the best way to utilize a context-aware translation model in decoding. Different decoding schemes were used, including existing ones and new proposals from the authors.", "example": "Convert the coordinate to text: [-4.3166 -8.2133]:"}
{"text": "Convert the coordinate to text: [11.8615 -8.5548]: The paper proposes a new method, MSSRNet, that addresses the existing issue by assigning an individual style vector to each token in a text, allowing for fine-grained control and manipulation of the style strength. Furthermore, an adversarial training framework integrated with teacher-student learning is introduced to enhance training stability and lessen the complexity of high-dimensional optimization.", "target": "The paper proposes a new method, MSSRNet, that addresses the existing issue by assigning an individual style vector to each token in a text, allowing for fine-grained control and manipulation of the style strength. Furthermore, an adversarial training framework integrated with teacher-student learning is introduced to enhance training stability and lessen the complexity of high-dimensional optimization.", "example": "Convert the coordinate to text: [11.8615 -8.5548]:"}
{"text": "Convert the coordinate to text: [ 0.0183 -4.4772]: The paper proposes RefPyDST, a method for improving in-context learning for DST with three advancements: formulating DST as a Python programming task, retrieving a diverse set of relevant examples to improve performance, and introducing a re-weighting method during decoding that takes into account probabilities of competing surface forms, which results in a more accurate dialogue state prediction.", "target": "The paper proposes RefPyDST, a method for improving in-context learning for DST with three advancements: formulating DST as a Python programming task, retrieving a diverse set of relevant examples to improve performance, and introducing a re-weighting method during decoding that takes into account probabilities of competing surface forms, which results in a more accurate dialogue state prediction.", "example": "Convert the coordinate to text: [ 0.0183 -4.4772]:"}
{"text": "Convert the coordinate to text: [-5.0373 -2.9149]: The authors proposed a method to improve named entity recognition performance in legal documents by including information about the document type in a token classification model.", "target": "The authors proposed a method to improve named entity recognition performance in legal documents by including information about the document type in a token classification model.", "example": "Convert the coordinate to text: [-5.0373 -2.9149]:"}
{"text": "Convert the coordinate to text: [-3.5591 -8.1317]: This year, NVIDIA NeMo\u2019s approach for their speech translation systems focuses on an end-to-end system that capitalizes on pre-trained models and synthetic data to mitigate the problem of direct speech translation data scarcity.", "target": "This year, NVIDIA NeMo\u2019s approach for their speech translation systems focuses on an end-to-end system that capitalizes on pre-trained models and synthetic data to mitigate the problem of direct speech translation data scarcity.", "example": "Convert the coordinate to text: [-3.5591 -8.1317]:"}
{"text": "Convert the coordinate to text: [-1.2009 -4.872 ]: This paper explores the application of prompt engineering approaches in legal reasoning tasks like the COLIEE entailment task, which is based on the Japanese Bar exam. The focus is on the potential effectiveness of various prompting approaches, including zero-shot, few-shot, fine-tuning, and the use of specific legal reasoning techniques like IRAC.", "target": "This paper explores the application of prompt engineering approaches in legal reasoning tasks like the COLIEE entailment task, which is based on the Japanese Bar exam. The focus is on the potential effectiveness of various prompting approaches, including zero-shot, few-shot, fine-tuning, and the use of specific legal reasoning techniques like IRAC.", "example": "Convert the coordinate to text: [-1.2009 -4.872 ]:"}
{"text": "Convert the coordinate to text: [-5.3863 -1.0175]: This paper introduces a cross-lingual factuality dataset created by collecting human annotations of reference summaries as well as generated summaries from models at the summary and sentence level.", "target": "This paper introduces a cross-lingual factuality dataset created by collecting human annotations of reference summaries as well as generated summaries from models at the summary and sentence level.", "example": "Convert the coordinate to text: [-5.3863 -1.0175]:"}
{"text": "Convert the coordinate to text: [ 6.3174 -0.8075]: The authors propose a novel approach for improving KD by introducing a new loss function agnostic to the task and model architecture.", "target": "The authors propose a novel approach for improving KD by introducing a new loss function agnostic to the task and model architecture.", "example": "Convert the coordinate to text: [ 6.3174 -0.8075]:"}
{"text": "Convert the coordinate to text: [ 2.6464 -2.9734]: The authors propose a new framework for low-resource knowledge graph completion, composed of three components: a few-shot learner, a task generator, and a task selector. The goal is to generate and select beneficial few-shot tasks that will supplement the current tasks and optimize the few-shot learner using these selected tasks.", "target": "The authors propose a new framework for low-resource knowledge graph completion, composed of three components: a few-shot learner, a task generator, and a task selector. The goal is to generate and select beneficial few-shot tasks that will supplement the current tasks and optimize the few-shot learner using these selected tasks.", "example": "Convert the coordinate to text: [ 2.6464 -2.9734]:"}
{"text": "Convert the coordinate to text: [11.7709 -4.2304]: The authors propose a combination of regularization methods with adversarial training, particularly 'flooding', a loss scaling method, to mitigate robust overfitting in pre-trained language models.", "target": "The authors propose a combination of regularization methods with adversarial training, particularly 'flooding', a loss scaling method, to mitigate robust overfitting in pre-trained language models.", "example": "Convert the coordinate to text: [11.7709 -4.2304]:"}
{"text": "Convert the coordinate to text: [-6.8301 -4.2141]: The authors propose a new definition for lexical substitutes that is grounded in the relation of entailment such that the sentence that results from the substitution should be in the relation of mutual entailment with the original sentence.", "target": "The authors propose a new definition for lexical substitutes that is grounded in the relation of entailment such that the sentence that results from the substitution should be in the relation of mutual entailment with the original sentence.", "example": "Convert the coordinate to text: [-6.8301 -4.2141]:"}
{"text": "Convert the coordinate to text: [-1.7035 -4.0848]: The authors propose the Retrieval as Ambiguous Supervision (RAS) framework which constructs a retrieval system based on pretrained language models to collect high-coverage candidates, transforming the zero-shot task into an ambiguously supervised task.", "target": "The authors propose the Retrieval as Ambiguous Supervision (RAS) framework which constructs a retrieval system based on pretrained language models to collect high-coverage candidates, transforming the zero-shot task into an ambiguously supervised task.", "example": "Convert the coordinate to text: [-1.7035 -4.0848]:"}
{"text": "Convert the coordinate to text: [-5.4341  1.5826]: The authors propose that active and passive cosponsorship are driven by two different motivations: the backing of political colleagues and the backing of the bill\u2019s content. An Encoder+RGCN based model is developed to learn legislator representations from bill texts and speech transcripts.", "target": "The authors propose that active and passive cosponsorship are driven by two different motivations: the backing of political colleagues and the backing of the bill\u2019s content. An Encoder+RGCN based model is developed to learn legislator representations from bill texts and speech transcripts.", "example": "Convert the coordinate to text: [-5.4341  1.5826]:"}
{"text": "Convert the coordinate to text: [ 5.0837 -5.5375]: The study proposes the WinGNN framework, a simple GNN model incorporating a meta-learning strategy and a novel mechanism of random gradient aggregation, to model dynamic graphs without the need for temporal encoders.", "target": "The study proposes the WinGNN framework, a simple GNN model incorporating a meta-learning strategy and a novel mechanism of random gradient aggregation, to model dynamic graphs without the need for temporal encoders.", "example": "Convert the coordinate to text: [ 5.0837 -5.5375]:"}
{"text": "Convert the coordinate to text: [3.779  6.7237]: The authors propose a new vertex colouring scheme that allows classical search algorithms to compute graph representations that extend beyond the 1-WL. They also develop a new type of GNN based on two search strategies: breadth-first search and depth-first search.", "target": "The authors propose a new vertex colouring scheme that allows classical search algorithms to compute graph representations that extend beyond the 1-WL. They also develop a new type of GNN based on two search strategies: breadth-first search and depth-first search.", "example": "Convert the coordinate to text: [3.779  6.7237]:"}
{"text": "Convert the coordinate to text: [ 4.72   13.7082]: A Global-And-Local learning approach for the VNE problem (GAL-VNE) is proposed, which uses reinforcement learning at the global level across requests to capture the cross-request relation and improve global resource accommodation. Simultaneously, within each request, a one-shot solution generation scheme is proposed to replace the sequential decision-making procedure.", "target": "A Global-And-Local learning approach for the VNE problem (GAL-VNE) is proposed, which uses reinforcement learning at the global level across requests to capture the cross-request relation and improve global resource accommodation. Simultaneously, within each request, a one-shot solution generation scheme is proposed to replace the sequential decision-making procedure.", "example": "Convert the coordinate to text: [ 4.72   13.7082]:"}
{"text": "Convert the coordinate to text: [5.3448 0.0066]: The authors investigate the impact of adding a classification loss to regression tasks and find it is most markedly beneficial when dealing with imbalanced data.", "target": "The authors investigate the impact of adding a classification loss to regression tasks and find it is most markedly beneficial when dealing with imbalanced data.", "example": "Convert the coordinate to text: [5.3448 0.0066]:"}
{"text": "Convert the coordinate to text: [15.9931  1.8056]: The authors propose an adaptive calibrator ensemble (ACE) to calibrate OOD datasets that usually have a higher difficulty than the calibration set. ACE uses an adaptive weighting method involving two trained calibration functions for balancing performance across in-distribution data and severely OOD data.", "target": "The authors propose an adaptive calibrator ensemble (ACE) to calibrate OOD datasets that usually have a higher difficulty than the calibration set. ACE uses an adaptive weighting method involving two trained calibration functions for balancing performance across in-distribution data and severely OOD data.", "example": "Convert the coordinate to text: [15.9931  1.8056]:"}
{"text": "Convert the coordinate to text: [  2.6392 -10.3923]: The authors introduce a grounding module coupled with the Stable Diffusion model that can train to align the visual and textual embedding space of the diffusion model with a narrow set of object categories.", "target": "The authors introduce a grounding module coupled with the Stable Diffusion model that can train to align the visual and textual embedding space of the diffusion model with a narrow set of object categories.", "example": "Convert the coordinate to text: [  2.6392 -10.3923]:"}
{"text": "Convert the coordinate to text: [13.8099  5.7114]: Granting the need for a method that offers more flexibility, the authors of this paper propose called generalized Wasserstein gradient descent (GWG) based on a generalized Wasserstein gradient flow of the KL divergence, which transforms the method into a functional gradient method with a broader class of regularizers induced by convex functions.", "target": "Granting the need for a method that offers more flexibility, the authors of this paper propose called generalized Wasserstein gradient descent (GWG) based on a generalized Wasserstein gradient flow of the KL divergence, which transforms the method into a functional gradient method with a broader class of regularizers induced by convex functions.", "example": "Convert the coordinate to text: [13.8099  5.7114]:"}
{"text": "Convert the coordinate to text: [7.3243 3.6626]: The authors propose a novel Bayesian pseudocoreset construction method that operates in a function space, instead of the usual parameter space. By creating variational approximations to the pseudocoreset posterior in the function space and aligning it with the full data posterior also in the function space, the proposed method bypasses challenges related to scalability and the issue of multi-modality that arise when working in a weight space.", "target": "The authors propose a novel Bayesian pseudocoreset construction method that operates in a function space, instead of the usual parameter space. By creating variational approximations to the pseudocoreset posterior in the function space and aligning it with the full data posterior also in the function space, the proposed method bypasses challenges related to scalability and the issue of multi-modality that arise when working in a weight space.", "example": "Convert the coordinate to text: [7.3243 3.6626]:"}
{"text": "Convert the coordinate to text: [ 2.0172 -4.2359]: The authors propose a new method named tri-factor contrastive learning (triCL) that involves a 3-factor contrast in the form of sample contrast augmented with a learnable diagonal importance matrix, which helps to capture the importance of each feature, improves identifiability, and interpretability.", "target": "The authors propose a new method named tri-factor contrastive learning (triCL) that involves a 3-factor contrast in the form of sample contrast augmented with a learnable diagonal importance matrix, which helps to capture the importance of each feature, improves identifiability, and interpretability.", "example": "Convert the coordinate to text: [ 2.0172 -4.2359]:"}
{"text": "Convert the coordinate to text: [ 6.5739 13.7327]: This paper proposes a novel approach called Context Shift Reduction for OMRL (CSRO) to address the context shift problem using only offline datasets, aiming to minimize the influence of policy in context during both the meta-training and meta-test phases.", "target": "This paper proposes a novel approach called Context Shift Reduction for OMRL (CSRO) to address the context shift problem using only offline datasets, aiming to minimize the influence of policy in context during both the meta-training and meta-test phases.", "example": "Convert the coordinate to text: [ 6.5739 13.7327]:"}
{"text": "Convert the coordinate to text: [ 2.1195 13.0214]: We propose major improvements to AlphaStar's league training: training goal-conditioned exploiters with enhanced abilities to identify weaknesses in the main agent and the entire league, and endowing agents in the league with the new ability of opponent modeling, making them more responsive to the opponent's real-time strategy.", "target": "We propose major improvements to AlphaStar's league training: training goal-conditioned exploiters with enhanced abilities to identify weaknesses in the main agent and the entire league, and endowing agents in the league with the new ability of opponent modeling, making them more responsive to the opponent's real-time strategy.", "example": "Convert the coordinate to text: [ 2.1195 13.0214]:"}
{"text": "Convert the coordinate to text: [-3.2093  3.8102]: The authors propose a lightweight tuning method for personalized NLP classification tasks post-backbone replacement. Their approach uses a personalized matrix calculated from documents corresponding to users' old and new backbones and employs correlation clustering to curate a few examples from personalized cluster sets for individuals.", "target": "The authors propose a lightweight tuning method for personalized NLP classification tasks post-backbone replacement. Their approach uses a personalized matrix calculated from documents corresponding to users' old and new backbones and employs correlation clustering to curate a few examples from personalized cluster sets for individuals.", "example": "Convert the coordinate to text: [-3.2093  3.8102]:"}
{"text": "Convert the coordinate to text: [-3.1105 -5.2222]: The authors propose improving language models' understanding of negation by introducing a language model objective with a weighted cross-entropy loss and elastic weight consolidation regularization.", "target": "The authors propose improving language models' understanding of negation by introducing a language model objective with a weighted cross-entropy loss and elastic weight consolidation regularization.", "example": "Convert the coordinate to text: [-3.1105 -5.2222]:"}
{"text": "Convert the coordinate to text: [  6.0012 -11.1499]: The authors propose a novel 'weakly-guided self-supervised' pretraining method for detection, which leverages weak labels (classification) to introduce a self-supervised pretext task (detection) by generating frame-level pseudo labels, multi-action frames, and action segments. This allows the design of a detection task similar to downstream tasks, on large-scale classification data, without extra annotations.", "target": "The authors propose a novel 'weakly-guided self-supervised' pretraining method for detection, which leverages weak labels (classification) to introduce a self-supervised pretext task (detection) by generating frame-level pseudo labels, multi-action frames, and action segments. This allows the design of a detection task similar to downstream tasks, on large-scale classification data, without extra annotations.", "example": "Convert the coordinate to text: [  6.0012 -11.1499]:"}
{"text": "Convert the coordinate to text: [-8.4472 12.4853]: The paper introduces Health Buddy, a voice agent integrated into VUIs, designed to support informal SRL of health-related topics using various learning strategies.", "target": "The paper introduces Health Buddy, a voice agent integrated into VUIs, designed to support informal SRL of health-related topics using various learning strategies.", "example": "Convert the coordinate to text: [-8.4472 12.4853]:"}
{"text": "Convert the coordinate to text: [-10.6377  -1.6839]: The authors present SkillQG: a question generation framework capable of tailoring a fine-grained assessment and improvement to comprehension capabilities of question answering models built on it. It is framed based on a hierarchical skill-based schema and formulated as a skill-conditioned question generator.", "target": "The authors present SkillQG: a question generation framework capable of tailoring a fine-grained assessment and improvement to comprehension capabilities of question answering models built on it. It is framed based on a hierarchical skill-based schema and formulated as a skill-conditioned question generator.", "example": "Convert the coordinate to text: [-10.6377  -1.6839]:"}
{"text": "Convert the coordinate to text: [10.9946  4.7091]: The authors propose a general framework for training with label regularization that covers conventional LS but also allows for instance-specific variants. Within this framework they introduce LAbel regularization learned through a Bi-level Optimization process (LABO).", "target": "The authors propose a general framework for training with label regularization that covers conventional LS but also allows for instance-specific variants. Within this framework they introduce LAbel regularization learned through a Bi-level Optimization process (LABO).", "example": "Convert the coordinate to text: [10.9946  4.7091]:"}
{"text": "Convert the coordinate to text: [-0.954  -5.0643]: The authors propose a novel approach that combines prompting methods and linear probing then fine-tuning strategy, which does not add extra training cost, to enhance the generalization ability of both generative and discriminative models.", "target": "The authors propose a novel approach that combines prompting methods and linear probing then fine-tuning strategy, which does not add extra training cost, to enhance the generalization ability of both generative and discriminative models.", "example": "Convert the coordinate to text: [-0.954  -5.0643]:"}
{"text": "Convert the coordinate to text: [ 8.9978 -5.0704]: The authors propose a novel approach, the Clifford Group Equivariant Neural Networks, based on the modification of the Clifford group that enables the group's action to form an orthogonal automorphism that extends to the entire Clifford algebra while respecting the multivector grading.", "target": "The authors propose a novel approach, the Clifford Group Equivariant Neural Networks, based on the modification of the Clifford group that enables the group's action to form an orthogonal automorphism that extends to the entire Clifford algebra while respecting the multivector grading.", "example": "Convert the coordinate to text: [ 8.9978 -5.0704]:"}
{"text": "Convert the coordinate to text: [ 2.7477 -1.3438]: The authors propose 'neighbourhood attacks' where they compare model scores for a given sample to scores of synthetically generated neighbour texts, thereby eliminating the need for access to the training data distribution.", "target": "The authors propose 'neighbourhood attacks' where they compare model scores for a given sample to scores of synthetically generated neighbour texts, thereby eliminating the need for access to the training data distribution.", "example": "Convert the coordinate to text: [ 2.7477 -1.3438]:"}
{"text": "Convert the coordinate to text: [-2.2322 -5.9683]: A framework of graph-aware language model pre-training (GALM) on a large graph corpus is proposed, which utilizes large language models and graph neural networks, and introduces various fine-tuning methods on downstream applications.", "target": "A framework of graph-aware language model pre-training (GALM) on a large graph corpus is proposed, which utilizes large language models and graph neural networks, and introduces various fine-tuning methods on downstream applications.", "example": "Convert the coordinate to text: [-2.2322 -5.9683]:"}
{"text": "Convert the coordinate to text: [-2.8559 -8.5033]: This paper proposes the use of Distributed Marker Representation (DMR) to learn from unlimited discourse marker data with a latent discourse sense and bridge markers with sentence pairs. This representation is meant to better capture discourse information by relying on a context-dependent distribution over markers.", "target": "This paper proposes the use of Distributed Marker Representation (DMR) to learn from unlimited discourse marker data with a latent discourse sense and bridge markers with sentence pairs. This representation is meant to better capture discourse information by relying on a context-dependent distribution over markers.", "example": "Convert the coordinate to text: [-2.8559 -8.5033]:"}
{"text": "Convert the coordinate to text: [ 2.7494 -4.039 ]: The authors propose a new contrastive meta-learning framework for few-shot node classification on graphs, named COSMIC, which enhances intra-class generalizability through a contrastive two-step optimization in each episode and strengthens the inter-class generalizability by generating hard node classes via a novel similarity-sensitive mix-up strategy.", "target": "The authors propose a new contrastive meta-learning framework for few-shot node classification on graphs, named COSMIC, which enhances intra-class generalizability through a contrastive two-step optimization in each episode and strengthens the inter-class generalizability by generating hard node classes via a novel similarity-sensitive mix-up strategy.", "example": "Convert the coordinate to text: [ 2.7494 -4.039 ]:"}
{"text": "Convert the coordinate to text: [-2.7714 -7.5536]: This paper proposes the use of an auxiliary target-side language model to augment the training of the decoder model, referred to as 'target adaptive training', enabling the model to generate rare or difficult tokens and thereby improving translation quality while reducing latency.", "target": "This paper proposes the use of an auxiliary target-side language model to augment the training of the decoder model, referred to as 'target adaptive training', enabling the model to generate rare or difficult tokens and thereby improving translation quality while reducing latency.", "example": "Convert the coordinate to text: [-2.7714 -7.5536]:"}
{"text": "Convert the coordinate to text: [-5.854  -0.6149]: The authors' approach involves selecting key information using both explicit and implicit strategies. The explicit strategy involves extractive summarization, while the implicit strategy uses a factorized energy-based model to extract important information from long documents.", "target": "The authors' approach involves selecting key information using both explicit and implicit strategies. The explicit strategy involves extractive summarization, while the implicit strategy uses a factorized energy-based model to extract important information from long documents.", "example": "Convert the coordinate to text: [-5.854  -0.6149]:"}
{"text": "Convert the coordinate to text: [  1.0383 -10.5913]: The authors propose a retrieval-based approach that uses image similarities to generate additional text features. They also employ few-shot, chain-of-thought, and ensemble techniques to improve performance.", "target": "The authors propose a retrieval-based approach that uses image similarities to generate additional text features. They also employ few-shot, chain-of-thought, and ensemble techniques to improve performance.", "example": "Convert the coordinate to text: [  1.0383 -10.5913]:"}
{"text": "Convert the coordinate to text: [-8.9843 -2.4464]: The study designs and implements 'Reviewriter', a tool that offers AI-generated instructions for writing peer reviews in German language, filling a gap in the personalization of learning experiences.", "target": "The study designs and implements 'Reviewriter', a tool that offers AI-generated instructions for writing peer reviews in German language, filling a gap in the personalization of learning experiences.", "example": "Convert the coordinate to text: [-8.9843 -2.4464]:"}
{"text": "Convert the coordinate to text: [-0.9944 -5.1941]: The authors propose Multi-task Pre-trained Modular Prompt (MP2), a set of combinable prompts pre-trained on 38 Chinese tasks. The prompts are selectively activated and combined for strong compositional generalization to unseen tasks.", "target": "The authors propose Multi-task Pre-trained Modular Prompt (MP2), a set of combinable prompts pre-trained on 38 Chinese tasks. The prompts are selectively activated and combined for strong compositional generalization to unseen tasks.", "example": "Convert the coordinate to text: [-0.9944 -5.1941]:"}
{"text": "Convert the coordinate to text: [ 1.0917 12.6036]: The paper proposes a dual-agent scheduler framework that jointly learns the ordering and placement policies to make better-informed scheduling decisions. It introduces an ordering agent with a scalable squeeze-and-communicate strategy for better cooperation and a placement agent using a Random Walk Gaussian Process to understand GPU machine performance similarities and uncertain performance fluctuations.", "target": "The paper proposes a dual-agent scheduler framework that jointly learns the ordering and placement policies to make better-informed scheduling decisions. It introduces an ordering agent with a scalable squeeze-and-communicate strategy for better cooperation and a placement agent using a Random Walk Gaussian Process to understand GPU machine performance similarities and uncertain performance fluctuations.", "example": "Convert the coordinate to text: [ 1.0917 12.6036]:"}
{"text": "Convert the coordinate to text: [3.0708 6.3323]: The author focuses on developing search methods for subgraph structures on both complete and incomplete heterogeneous graphs, acknowledging the complexity and difficulties associated with effective and efficient subgraph searching.", "target": "The author focuses on developing search methods for subgraph structures on both complete and incomplete heterogeneous graphs, acknowledging the complexity and difficulties associated with effective and efficient subgraph searching.", "example": "Convert the coordinate to text: [3.0708 6.3323]:"}
{"text": "Convert the coordinate to text: [ 2.4189 -1.9539]: The authors introduce an inside-outside learning strategy in an undergraduate deep learning course, that involves student-generated instructional materials. They also propose a context-aware deep learning framework to derive insights from the student-generated materials for anomaly detection in group activities and prediction of the median quiz performance of students in each group.", "target": "The authors introduce an inside-outside learning strategy in an undergraduate deep learning course, that involves student-generated instructional materials. They also propose a context-aware deep learning framework to derive insights from the student-generated materials for anomaly detection in group activities and prediction of the median quiz performance of students in each group.", "example": "Convert the coordinate to text: [ 2.4189 -1.9539]:"}
{"text": "Convert the coordinate to text: [-4.5398 -7.5434]: The study addresses the demand for inclusive language in machine translation by focusing on gender-neutral translation from English to Italian, proposing a benchmark for this task, and exploring automated evaluation methods.", "target": "The study addresses the demand for inclusive language in machine translation by focusing on gender-neutral translation from English to Italian, proposing a benchmark for this task, and exploring automated evaluation methods.", "example": "Convert the coordinate to text: [-4.5398 -7.5434]:"}
{"text": "Convert the coordinate to text: [ 7.656  -6.7548]: The study proposes methods to enable constant compute and memory cost per token in any pre-trained long convolution architecture. The methods involve extracting low-dimensional linear state-space models from each convolution layer and improving the architecture of convolution-based layers such as Hyena by weight-tying the filters across channels into heads.", "target": "The study proposes methods to enable constant compute and memory cost per token in any pre-trained long convolution architecture. The methods involve extracting low-dimensional linear state-space models from each convolution layer and improving the architecture of convolution-based layers such as Hyena by weight-tying the filters across channels into heads.", "example": "Convert the coordinate to text: [ 7.656  -6.7548]:"}
{"text": "Convert the coordinate to text: [11.7273 -2.1551]: The authors aim to study the implicit bias of gradient descent for training two-layer fully connected (leaky) ReLU neural networks, especially when the training data are nearly-orthogonal.", "target": "The authors aim to study the implicit bias of gradient descent for training two-layer fully connected (leaky) ReLU neural networks, especially when the training data are nearly-orthogonal.", "example": "Convert the coordinate to text: [11.7273 -2.1551]:"}
{"text": "Convert the coordinate to text: [14.0726  5.5458]: The paper proposes to reformulate energy functional minimization in the space of Born distributions, rather than the space of wave functions, which leads to the creation of the Wasserstein Quantum Monte Carlo (WQMC) method. This method uses the gradient flow induced by the Wasserstein metrics, corresponding to transporting the probability mass, rather than teleporting it.", "target": "The paper proposes to reformulate energy functional minimization in the space of Born distributions, rather than the space of wave functions, which leads to the creation of the Wasserstein Quantum Monte Carlo (WQMC) method. This method uses the gradient flow induced by the Wasserstein metrics, corresponding to transporting the probability mass, rather than teleporting it.", "example": "Convert the coordinate to text: [14.0726  5.5458]:"}
{"text": "Convert the coordinate to text: [-3.2864 -1.6279]: The authors propose the Implicit Cause-Effect interaction (ICE) framework that formulates ECE as a template-based conditional generation problem and captures the implicit intra- and inter-event interactions using privileged information and a knowledge distillation mechanism.", "target": "The authors propose the Implicit Cause-Effect interaction (ICE) framework that formulates ECE as a template-based conditional generation problem and captures the implicit intra- and inter-event interactions using privileged information and a knowledge distillation mechanism.", "example": "Convert the coordinate to text: [-3.2864 -1.6279]:"}
{"text": "Convert the coordinate to text: [-2.2851 -6.8863]: The author introduced a system relying on a language-specific model. Kinyarwanda morphology is modeled in a two-tier transformer architecture, and the model is pre-trained on a large text corpus using multi-task masked morphology prediction.", "target": "The author introduced a system relying on a language-specific model. Kinyarwanda morphology is modeled in a two-tier transformer architecture, and the model is pre-trained on a large text corpus using multi-task masked morphology prediction.", "example": "Convert the coordinate to text: [-2.2851 -6.8863]:"}
{"text": "Convert the coordinate to text: [-3.1309  7.056 ]: The authors redefine a theme to include more than just a word distribution and introduce relevant generalized concepts. They propose an interactive framework that encodes expert feedback at different levels of abstraction.", "target": "The authors redefine a theme to include more than just a word distribution and introduce relevant generalized concepts. They propose an interactive framework that encodes expert feedback at different levels of abstraction.", "example": "Convert the coordinate to text: [-3.1309  7.056 ]:"}
{"text": "Convert the coordinate to text: [-0.8051 -6.1884]: This study embarks on a comprehensive exploration of the design space of these models, by comparing various architectural innovations and different pretraining objectives on a suite of tasks with a fixed training procedure.", "target": "This study embarks on a comprehensive exploration of the design space of these models, by comparing various architectural innovations and different pretraining objectives on a suite of tasks with a fixed training procedure.", "example": "Convert the coordinate to text: [-0.8051 -6.1884]:"}
{"text": "Convert the coordinate to text: [-8.0643 -1.5407]: A novel concept for universal information extraction called UniEX has been proposed, which can be used with any schema format and for multiple IE tasks. The approach transforms text-based IE tasks into a token-pair problem which is handled through joint span detection, classification, and association problems.", "target": "A novel concept for universal information extraction called UniEX has been proposed, which can be used with any schema format and for multiple IE tasks. The approach transforms text-based IE tasks into a token-pair problem which is handled through joint span detection, classification, and association problems.", "example": "Convert the coordinate to text: [-8.0643 -1.5407]:"}
{"text": "Convert the coordinate to text: [ 4.6945 -3.1746]: To improve the robustness of 'true' ZS-XLT and FS-XLT, the authors propose a simple and effective method of averaging different model checkpoints (model snapshots) during task fine-tuning.", "target": "To improve the robustness of 'true' ZS-XLT and FS-XLT, the authors propose a simple and effective method of averaging different model checkpoints (model snapshots) during task fine-tuning.", "example": "Convert the coordinate to text: [ 4.6945 -3.1746]:"}
{"text": "Convert the coordinate to text: [-5.4373 10.0913]: The authors argue that capturing the transitions of medical entities and the doctor's dialogue acts in each turn are key to understanding how dialogue flows. Accordingly, they propose a Dual Flow enhanced Medical (DFMed) dialogue generation framework. The framework models transitions of medical entities and dialogue acts with an entity-centric graph flow and a sequential act flow respectively.", "target": "The authors argue that capturing the transitions of medical entities and the doctor's dialogue acts in each turn are key to understanding how dialogue flows. Accordingly, they propose a Dual Flow enhanced Medical (DFMed) dialogue generation framework. The framework models transitions of medical entities and dialogue acts with an entity-centric graph flow and a sequential act flow respectively.", "example": "Convert the coordinate to text: [-5.4373 10.0913]:"}
{"text": "Convert the coordinate to text: [-14.6196  14.2799]: In this study, the authors collected and analyzed readers' reactions to two short stories, using eye tracking, sentence-level annotations, and engagement scale surveys, to determine what qualities in a text make it more engaging.", "target": "In this study, the authors collected and analyzed readers' reactions to two short stories, using eye tracking, sentence-level annotations, and engagement scale surveys, to determine what qualities in a text make it more engaging.", "example": "Convert the coordinate to text: [-14.6196  14.2799]:"}
{"text": "Convert the coordinate to text: [-10.3907  -1.883 ]: The authors propose a novel data processing technique based on de-lexicalization that allows for consistent question generation across domains, which does not exclude training data and can be applied to all question-generation models.", "target": "The authors propose a novel data processing technique based on de-lexicalization that allows for consistent question generation across domains, which does not exclude training data and can be applied to all question-generation models.", "example": "Convert the coordinate to text: [-10.3907  -1.883 ]:"}
{"text": "Convert the coordinate to text: [ -3.0326 -10.0323]: This work proposes a system that focuses on identifying, replacing and inserting replacement named entities synthesized using voice cloning into original audio, with the aim of retaining prosodic information while reducing the likelihood of deanonymization.", "target": "This work proposes a system that focuses on identifying, replacing and inserting replacement named entities synthesized using voice cloning into original audio, with the aim of retaining prosodic information while reducing the likelihood of deanonymization.", "example": "Convert the coordinate to text: [ -3.0326 -10.0323]:"}
{"text": "Convert the coordinate to text: [-3.2851  0.9958]: The authors propose a novel sarcasm detection method called Sarcasm Detector with Augmentation of Potential Result and Reaction (SD-APRR). This method treats sarcastic text as an incomplete version without latent content associated with implied negative situations and fills the latent content by inferring potential results and human reactions.", "target": "The authors propose a novel sarcasm detection method called Sarcasm Detector with Augmentation of Potential Result and Reaction (SD-APRR). This method treats sarcastic text as an incomplete version without latent content associated with implied negative situations and fills the latent content by inferring potential results and human reactions.", "example": "Convert the coordinate to text: [-3.2851  0.9958]:"}
{"text": "Convert the coordinate to text: [  9.9134 -20.1454]: The authors propose a new framework that integrates active stereo principles into standard passive camera systems. Instead of using a physical pattern projector, they propose virtually projecting a pattern over left and right images using sparse measurements obtained from a depth sensor.", "target": "The authors propose a new framework that integrates active stereo principles into standard passive camera systems. Instead of using a physical pattern projector, they propose virtually projecting a pattern over left and right images using sparse measurements obtained from a depth sensor.", "example": "Convert the coordinate to text: [  9.9134 -20.1454]:"}
{"text": "Convert the coordinate to text: [2.0662 2.9376]: The authors propose a federated approach to derive valid causal inferences for a target population using multi-site data. This involves adjusting for covariate shift and covariate mismatch between sites through multiply-robust and privacy-preserving nuisance function estimation.", "target": "The authors propose a federated approach to derive valid causal inferences for a target population using multi-site data. This involves adjusting for covariate shift and covariate mismatch between sites through multiply-robust and privacy-preserving nuisance function estimation.", "example": "Convert the coordinate to text: [2.0662 2.9376]:"}
{"text": "Convert the coordinate to text: [4.7332 8.6138]: The authors presented a generalized extension of Lattanzi and Sohler's local search algorithm, considering larger and more sophisticated local search neighborhoods, which allows for the swapping of multiple centers simultaneously.", "target": "The authors presented a generalized extension of Lattanzi and Sohler's local search algorithm, considering larger and more sophisticated local search neighborhoods, which allows for the swapping of multiple centers simultaneously.", "example": "Convert the coordinate to text: [4.7332 8.6138]:"}
{"text": "Convert the coordinate to text: [  7.6338 -16.0619]: This paper introduces a new method that learns shape primitives from multi-view images via implicit surface rendering. A novel regularization term called Implicit Convexity Regularization (ICR) is proposed to guide the learning process of implicit shapes.", "target": "This paper introduces a new method that learns shape primitives from multi-view images via implicit surface rendering. A novel regularization term called Implicit Convexity Regularization (ICR) is proposed to guide the learning process of implicit shapes.", "example": "Convert the coordinate to text: [  7.6338 -16.0619]:"}
{"text": "Convert the coordinate to text: [ 2.1789 -2.73  ]: The authors propose to reframe continual learning as a sequence modeling problem, therefore allowing the implementation of sophisticated sequence models for continual learning tasks.", "target": "The authors propose to reframe continual learning as a sequence modeling problem, therefore allowing the implementation of sophisticated sequence models for continual learning tasks.", "example": "Convert the coordinate to text: [ 2.1789 -2.73  ]:"}
{"text": "Convert the coordinate to text: [12.4711  7.3532]: This study introduces a new approach to investigate the primal-dual generalization bound of the Decentralized Stochastic Gradient Descent Ascent (D-SGDA) algorithm using the concept of algorithmic stability. The authors aim to verify that the decentralized structure does not compromise the stability and generalization of D-SGDA.", "target": "This study introduces a new approach to investigate the primal-dual generalization bound of the Decentralized Stochastic Gradient Descent Ascent (D-SGDA) algorithm using the concept of algorithmic stability. The authors aim to verify that the decentralized structure does not compromise the stability and generalization of D-SGDA.", "example": "Convert the coordinate to text: [12.4711  7.3532]:"}
{"text": "Convert the coordinate to text: [  8.6857 -15.9572]: This paper presents GenS, an end-to-end generalizable neural surface reconstruction model that performs well in both sparse and dense settings. Unlike other methods that train a separate network for each scene, GenS constructs a generalized multi-scale volume to directly encode all scenes.", "target": "This paper presents GenS, an end-to-end generalizable neural surface reconstruction model that performs well in both sparse and dense settings. Unlike other methods that train a separate network for each scene, GenS constructs a generalized multi-scale volume to directly encode all scenes.", "example": "Convert the coordinate to text: [  8.6857 -15.9572]:"}
{"text": "Convert the coordinate to text: [-3.0552 -6.9984]: The authors introduce a multilingual language model called ESCOXLM-R, based on XLM-R, which incorporates domain-adaptive pre-training from the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy that covers 27 languages.", "target": "The authors introduce a multilingual language model called ESCOXLM-R, based on XLM-R, which incorporates domain-adaptive pre-training from the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy that covers 27 languages.", "example": "Convert the coordinate to text: [-3.0552 -6.9984]:"}
{"text": "Convert the coordinate to text: [-5.8459 10.1162]: The authors propose a method to operationalize a conversational thread, including the notion of a floor change, in dramatic texts, leading to the creation of a new dataset for conversation disentanglement in movies and TV series.", "target": "The authors propose a method to operationalize a conversational thread, including the notion of a floor change, in dramatic texts, leading to the creation of a new dataset for conversation disentanglement in movies and TV series.", "example": "Convert the coordinate to text: [-5.8459 10.1162]:"}
{"text": "Convert the coordinate to text: [-9.705  10.5266]: The authors present a novel dataset, MedNgage, which consists of patient-nurse conversations about cancer symptom management. They also introduce a novel framework of categories of patient engagement from two different angles, namely: i) socio-affective engagement, and ii) cognitive engagement.", "target": "The authors present a novel dataset, MedNgage, which consists of patient-nurse conversations about cancer symptom management. They also introduce a novel framework of categories of patient engagement from two different angles, namely: i) socio-affective engagement, and ii) cognitive engagement.", "example": "Convert the coordinate to text: [-9.705  10.5266]:"}
{"text": "Convert the coordinate to text: [-2.0917 -5.2832]: The authors explore the possibility of using generative AI, specifically ChatGPT, as a cost-effective, automated teacher coaching tool that can score classroom transcript segments, identify instructional strategies, and provide actionable suggestions for eliciting more student reasoning.", "target": "The authors explore the possibility of using generative AI, specifically ChatGPT, as a cost-effective, automated teacher coaching tool that can score classroom transcript segments, identify instructional strategies, and provide actionable suggestions for eliciting more student reasoning.", "example": "Convert the coordinate to text: [-2.0917 -5.2832]:"}
{"text": "Convert the coordinate to text: [-2.208  -5.3706]: This study aims to evaluate the performance of ChatGPT on various benchmark biomedical tasks, such as relation extraction, document classification, question answering, and summarization.", "target": "This study aims to evaluate the performance of ChatGPT on various benchmark biomedical tasks, such as relation extraction, document classification, question answering, and summarization.", "example": "Convert the coordinate to text: [-2.208  -5.3706]:"}
{"text": "Convert the coordinate to text: [ 6.2155 11.0453]: This paper introduces an algorithm for decodable POMDPs that combines maximum likelihood estimation (MLE) and optimism in the face of uncertainty (OFU) to perform representation learning with efficient sample complexity.", "target": "This paper introduces an algorithm for decodable POMDPs that combines maximum likelihood estimation (MLE) and optimism in the face of uncertainty (OFU) to perform representation learning with efficient sample complexity.", "example": "Convert the coordinate to text: [ 6.2155 11.0453]:"}
{"text": "Convert the coordinate to text: [-0.8227 -8.3742]: The authors propose a template-based approach to generate radiology reports from radiographs, which includes producing tags with a multilabel image classifier, generating pathological descriptions from the tags with a transformer-based model, finding spans in the normal report template to replace with the generated pathological descriptions using a BERT-based multi-label text classifier, and replacing the identified span with the generated pathological description using a rule-based system.", "target": "The authors propose a template-based approach to generate radiology reports from radiographs, which includes producing tags with a multilabel image classifier, generating pathological descriptions from the tags with a transformer-based model, finding spans in the normal report template to replace with the generated pathological descriptions using a BERT-based multi-label text classifier, and replacing the identified span with the generated pathological description using a rule-based system.", "example": "Convert the coordinate to text: [-0.8227 -8.3742]:"}
{"text": "Convert the coordinate to text: [16.0553  1.736 ]: The authors introduce the term 'OOC' (out-of-candidate) for examples whose true labels are outside the candidate label set. They propose to learn with these OOC examples by differentiating between two types of OOC examples based on whether the true label is inside or outside the known label space.", "target": "The authors introduce the term 'OOC' (out-of-candidate) for examples whose true labels are outside the candidate label set. They propose to learn with these OOC examples by differentiating between two types of OOC examples based on whether the true label is inside or outside the known label space.", "example": "Convert the coordinate to text: [16.0553  1.736 ]:"}
{"text": "Convert the coordinate to text: [-6.0446 -9.7662]: The authors propose AMR-GEC, a sequence-to-sequence model that incorporates a denoised version of AMR as additional knowledge for the task of Grammatical Error Correction.", "target": "The authors propose AMR-GEC, a sequence-to-sequence model that incorporates a denoised version of AMR as additional knowledge for the task of Grammatical Error Correction.", "example": "Convert the coordinate to text: [-6.0446 -9.7662]:"}
{"text": "Convert the coordinate to text: [-1.564 -6.294]: The authors propose a Grouped-BERT architecture which uses Natural Language Inference and leverages commonality between classes for multi-label classification tasks.", "target": "The authors propose a Grouped-BERT architecture which uses Natural Language Inference and leverages commonality between classes for multi-label classification tasks.", "example": "Convert the coordinate to text: [-1.564 -6.294]:"}
{"text": "Convert the coordinate to text: [-2.1217 -6.5212]: The team 'PCJ' developed a system utilizing methods based on RoBERTa, SimCSE-RoBERTa pre-training models, and a model ensemble to classify and train on provided datasets.", "target": "The team 'PCJ' developed a system utilizing methods based on RoBERTa, SimCSE-RoBERTa pre-training models, and a model ensemble to classify and train on provided datasets.", "example": "Convert the coordinate to text: [-2.1217 -6.5212]:"}
{"text": "Convert the coordinate to text: [-1.6228 -4.1437]: The authors propose a simpler and more effective approach to automatically acquire and label affective events for training using Multiple View Co-prompting, which leverages two language model prompts providing independent views of an event.", "target": "The authors propose a simpler and more effective approach to automatically acquire and label affective events for training using Multiple View Co-prompting, which leverages two language model prompts providing independent views of an event.", "example": "Convert the coordinate to text: [-1.6228 -4.1437]:"}
{"text": "Convert the coordinate to text: [-4.5137 -1.3507]: The authors propose an end-to-end generative task and system for predicting event factuality holders, targets, and their associated factuality values, advocating for careful domain-specific target text output format in generative systems.", "target": "The authors propose an end-to-end generative task and system for predicting event factuality holders, targets, and their associated factuality values, advocating for careful domain-specific target text output format in generative systems.", "example": "Convert the coordinate to text: [-4.5137 -1.3507]:"}
{"text": "Convert the coordinate to text: [-0.976  -3.9396]: The paper introduces DiVeRSe, a new approach that generates diverse prompts to explore different reasoning paths, uses a verifier to filter out incorrect answers based on a weighted voting scheme, and verifies each reasoning step individually rather than the whole chain to enhance the reasoning ability of language models.", "target": "The paper introduces DiVeRSe, a new approach that generates diverse prompts to explore different reasoning paths, uses a verifier to filter out incorrect answers based on a weighted voting scheme, and verifies each reasoning step individually rather than the whole chain to enhance the reasoning ability of language models.", "example": "Convert the coordinate to text: [-0.976  -3.9396]:"}
{"text": "Convert the coordinate to text: [6.9258 0.0266]: The authors propose a robust training algorithm, aiming to increase the margin in the output (logit) space while regularizing the Lipschitz constant of the model along vulnerable directions. They argue that these objectives can directly promote larger margins in the input space.", "target": "The authors propose a robust training algorithm, aiming to increase the margin in the output (logit) space while regularizing the Lipschitz constant of the model along vulnerable directions. They argue that these objectives can directly promote larger margins in the input space.", "example": "Convert the coordinate to text: [6.9258 0.0266]:"}
{"text": "Convert the coordinate to text: [7.619  6.2294]: The authors introduce confidence interval estimation for deterministic partial differential equations as a novel problem and propose a method called Physics-Informed Confidence Propagation (PICProp) based on bi-level optimization to compute a valid confidence interval without making heavy assumptions.", "target": "The authors introduce confidence interval estimation for deterministic partial differential equations as a novel problem and propose a method called Physics-Informed Confidence Propagation (PICProp) based on bi-level optimization to compute a valid confidence interval without making heavy assumptions.", "example": "Convert the coordinate to text: [7.619  6.2294]:"}
{"text": "Convert the coordinate to text: [ 7.0306 -4.4162]: The authors propose Bidirectional Alignment for domain adaptive Detection with Transformers (BiADT), a method that estimates token-wise domain-invariant and domain-specific features in image and object token sequences. BiADT uses a novel deformable attention and self-attention for bi-directional domain alignment and mutual information minimization.", "target": "The authors propose Bidirectional Alignment for domain adaptive Detection with Transformers (BiADT), a method that estimates token-wise domain-invariant and domain-specific features in image and object token sequences. BiADT uses a novel deformable attention and self-attention for bi-directional domain alignment and mutual information minimization.", "example": "Convert the coordinate to text: [ 7.0306 -4.4162]:"}
{"text": "Convert the coordinate to text: [-0.2748  1.256 ]: This paper proposes the first attempt in the FIQA field to offer a solution to the aforementioned challenges by introducing a new Ethnic-Quality-Bias Mitigating (EQBM) framework.", "target": "This paper proposes the first attempt in the FIQA field to offer a solution to the aforementioned challenges by introducing a new Ethnic-Quality-Bias Mitigating (EQBM) framework.", "example": "Convert the coordinate to text: [-0.2748  1.256 ]:"}
{"text": "Convert the coordinate to text: [-0.7136 -8.0392]: To address the representation conflict issue, this study proposes a new framework named DQTrack, which uses a decoupled query system (object query and track query) instead of a single embedding to retain a compact pipeline and avoid heuristic designs.", "target": "To address the representation conflict issue, this study proposes a new framework named DQTrack, which uses a decoupled query system (object query and track query) instead of a single embedding to retain a compact pipeline and avoid heuristic designs.", "example": "Convert the coordinate to text: [-0.7136 -8.0392]:"}
{"text": "Convert the coordinate to text: [-5.6434 -0.3808]: SUBSUMM, a supervised summarization framework for large-scale multi-perspective opinion summarization, is proposed. The framework consists of a review sampling strategy set and a two-stage training scheme, taking into account sentiment orientation and contrastive information value for selecting review subsets.", "target": "SUBSUMM, a supervised summarization framework for large-scale multi-perspective opinion summarization, is proposed. The framework consists of a review sampling strategy set and a two-stage training scheme, taking into account sentiment orientation and contrastive information value for selecting review subsets.", "example": "Convert the coordinate to text: [-5.6434 -0.3808]:"}
{"text": "Convert the coordinate to text: [-2.5478 -4.9184]: The authors propose the use of LLM-based metrics for the evaluation of IFT as they are well-suited to meet these new requirements, and conduct an investigation of task-specialization strategies.", "target": "The authors propose the use of LLM-based metrics for the evaluation of IFT as they are well-suited to meet these new requirements, and conduct an investigation of task-specialization strategies.", "example": "Convert the coordinate to text: [-2.5478 -4.9184]:"}
{"text": "Convert the coordinate to text: [ 4.5124 -0.9356]: This paper critically examines the choice of either combining multiple noisy labels into a singular one or using them as individually received. It questions whether one should aggregate separate noisy labels into single ones or use them separately.", "target": "This paper critically examines the choice of either combining multiple noisy labels into a singular one or using them as individually received. It questions whether one should aggregate separate noisy labels into single ones or use them separately.", "example": "Convert the coordinate to text: [ 4.5124 -0.9356]:"}
{"text": "Convert the coordinate to text: [-8.705   4.5903]: This study dives specifically into the connection between SEME and sponsored content in the health domain. It differentiates between two types of sponsored content: Direct marketing ads that market the product without expressing an opinion about its effectiveness, and indirect marketing ads that explicitly advocate for the product's effectiveness.", "target": "This study dives specifically into the connection between SEME and sponsored content in the health domain. It differentiates between two types of sponsored content: Direct marketing ads that market the product without expressing an opinion about its effectiveness, and indirect marketing ads that explicitly advocate for the product's effectiveness.", "example": "Convert the coordinate to text: [-8.705   4.5903]:"}
{"text": "Convert the coordinate to text: [-0.4466 -7.4603]: A new format-independent framework, the Unified Multiple-Choice (UniMC), is introduced. It is optimized to various formats and tasks, such as text classification and sentiment analysis, combined with a two-stage tuning method, to foster format-agnostic capabilities and zero-shot learning.", "target": "A new format-independent framework, the Unified Multiple-Choice (UniMC), is introduced. It is optimized to various formats and tasks, such as text classification and sentiment analysis, combined with a two-stage tuning method, to foster format-agnostic capabilities and zero-shot learning.", "example": "Convert the coordinate to text: [-0.4466 -7.4603]:"}
{"text": "Convert the coordinate to text: [-15.0101   0.6145]: The paper introduces the Illinois Graph Benchmark (IGB) - a research dataset tool that includes both homogeneous and heterogeneous graphs of large sizes, with more than 40% of their nodes labeled, providing significantly more labeled data compared to the largest graph datasets publicly available.", "target": "The paper introduces the Illinois Graph Benchmark (IGB) - a research dataset tool that includes both homogeneous and heterogeneous graphs of large sizes, with more than 40% of their nodes labeled, providing significantly more labeled data compared to the largest graph datasets publicly available.", "example": "Convert the coordinate to text: [-15.0101   0.6145]:"}
{"text": "Convert the coordinate to text: [5.3103 9.5715]: The authors propose UTSP, an unsupervised learning framework that uses a Graph Neural Network (GNN) to solve the TSP. The GNN outputs a heat map representing the probability of each edge being part of the optimal path, and a local search is then applied to generate the final prediction based on the heat map.", "target": "The authors propose UTSP, an unsupervised learning framework that uses a Graph Neural Network (GNN) to solve the TSP. The GNN outputs a heat map representing the probability of each edge being part of the optimal path, and a local search is then applied to generate the final prediction based on the heat map.", "example": "Convert the coordinate to text: [5.3103 9.5715]:"}
{"text": "Convert the coordinate to text: [ 12.2754 -16.5674]: The authors propose a shape-constraint recurrent matching framework for 6D object pose estimation, which combines pose-induced flow, that implicitly incorporates the 3D shape of the target, with traditional optical flow methods.", "target": "The authors propose a shape-constraint recurrent matching framework for 6D object pose estimation, which combines pose-induced flow, that implicitly incorporates the 3D shape of the target, with traditional optical flow methods.", "example": "Convert the coordinate to text: [ 12.2754 -16.5674]:"}
{"text": "Convert the coordinate to text: [13.056  -7.5697]: The study investigates the manner in which GANs, particularly the ciwGAN architecture, deal with contrastive and non-contrastive nasality in French and English vowels, and the resultant effects on phonological feature learning.", "target": "The study investigates the manner in which GANs, particularly the ciwGAN architecture, deal with contrastive and non-contrastive nasality in French and English vowels, and the resultant effects on phonological feature learning.", "example": "Convert the coordinate to text: [13.056  -7.5697]:"}
{"text": "Convert the coordinate to text: [ 1.8868 -4.0759]: The authors propose a method, ContProto, that aims to improve self-training for cross-lingual NER by combining representation learning and pseudo label refinement in one framework. ContProto uses contrastive self-training and prototype-based pseudo-labeling.", "target": "The authors propose a method, ContProto, that aims to improve self-training for cross-lingual NER by combining representation learning and pseudo label refinement in one framework. ContProto uses contrastive self-training and prototype-based pseudo-labeling.", "example": "Convert the coordinate to text: [ 1.8868 -4.0759]:"}
{"text": "Convert the coordinate to text: [0.7301 2.0527]: The study leverages counterfactual conditionals, which force language models to predict unusual consequences based on hypothetical propositions, to differentiate between statistical correlation and logical reasoning.", "target": "The study leverages counterfactual conditionals, which force language models to predict unusual consequences based on hypothetical propositions, to differentiate between statistical correlation and logical reasoning.", "example": "Convert the coordinate to text: [0.7301 2.0527]:"}
{"text": "Convert the coordinate to text: [-3.5639 -7.4296]: The key idea proposed in the paper is a new training schedule that incorporates a language discriminator loss, which puts constraints on the intermediate translation so that it's in the desired language. This helps tackle the copying problem in UNMT.", "target": "The key idea proposed in the paper is a new training schedule that incorporates a language discriminator loss, which puts constraints on the intermediate translation so that it's in the desired language. This helps tackle the copying problem in UNMT.", "example": "Convert the coordinate to text: [-3.5639 -7.4296]:"}
{"text": "Convert the coordinate to text: [-6.8106 -8.8601]: The authors introduce CDBERT, a learning paradigm that enhances Chinese PLMs semantics understanding with dictionary knowledge and structure of Chinese characters. The two core modules are named Shuowen for dictionary knowledge and Jiezi for enhancing glyph representations.", "target": "The authors introduce CDBERT, a learning paradigm that enhances Chinese PLMs semantics understanding with dictionary knowledge and structure of Chinese characters. The two core modules are named Shuowen for dictionary knowledge and Jiezi for enhancing glyph representations.", "example": "Convert the coordinate to text: [-6.8106 -8.8601]:"}
{"text": "Convert the coordinate to text: [-4.4693  2.1305]: The team's task was to score the intimacy in tweets, placing them in a range from 0-5 based on the level of intimacy using the provided dataset, which included tweet scores. These scores indicate a tweet's intimacy level.", "target": "The team's task was to score the intimacy in tweets, placing them in a range from 0-5 based on the level of intimacy using the provided dataset, which included tweet scores. These scores indicate a tweet's intimacy level.", "example": "Convert the coordinate to text: [-4.4693  2.1305]:"}
{"text": "Convert the coordinate to text: [-1.5466  0.1823]: This paper explores simple methods for automatically detecting online sexism in textual statements.", "target": "This paper explores simple methods for automatically detecting online sexism in textual statements.", "example": "Convert the coordinate to text: [-1.5466  0.1823]:"}
{"text": "Convert the coordinate to text: [-1.8961 -6.2165]: The study introduces FTBC, a framework that combines FastText and pre-trained Bert for NER tasks involving complex entities over noisy datasets.", "target": "The study introduces FTBC, a framework that combines FastText and pre-trained Bert for NER tasks involving complex entities over noisy datasets.", "example": "Convert the coordinate to text: [-1.8961 -6.2165]:"}
{"text": "Convert the coordinate to text: [-4.4408 -5.1311]: The authors propose the use of different position spaces for different languages, based on an analysis of the relationship between a language's position space and its typological characterization. They also develop a position generation network which combines typology features and existing position vectors.", "target": "The authors propose the use of different position spaces for different languages, based on an analysis of the relationship between a language's position space and its typological characterization. They also develop a position generation network which combines typology features and existing position vectors.", "example": "Convert the coordinate to text: [-4.4408 -5.1311]:"}
{"text": "Convert the coordinate to text: [16.1566  1.7819]: The paper proposes to apply computationally lightweight density-based uncertainty estimation (UE) methods to seq2seq models, with an aim to improve the detection of out-of-domain (OOD) input.", "target": "The paper proposes to apply computationally lightweight density-based uncertainty estimation (UE) methods to seq2seq models, with an aim to improve the detection of out-of-domain (OOD) input.", "example": "Convert the coordinate to text: [16.1566  1.7819]:"}
{"text": "Convert the coordinate to text: [ 2.1827 -2.6137]: The paper proposes a conditional generation framework that formulates the problem as denoising from partially-filled templates to better utilize the semantics among the input, label, and target texts. This framework incorporates an auxiliary task of target prediction and uses manually constructed incorrect samples with unlikelihood training.", "target": "The paper proposes a conditional generation framework that formulates the problem as denoising from partially-filled templates to better utilize the semantics among the input, label, and target texts. This framework incorporates an auxiliary task of target prediction and uses manually constructed incorrect samples with unlikelihood training.", "example": "Convert the coordinate to text: [ 2.1827 -2.6137]:"}
{"text": "Convert the coordinate to text: [-1.9034 -6.5205]: The authors propose a double-domain adaptation model (DisorBERT) by first adjusting a language model to familiarize it with social media language, and then adapting it to the mental health domain. A lexical resource is used to guide the masking process of the language model to make it sensitive to words related to mental disorders.", "target": "The authors propose a double-domain adaptation model (DisorBERT) by first adjusting a language model to familiarize it with social media language, and then adapting it to the mental health domain. A lexical resource is used to guide the masking process of the language model to make it sensitive to words related to mental disorders.", "example": "Convert the coordinate to text: [-1.9034 -6.5205]:"}
{"text": "Convert the coordinate to text: [-3.3971 -5.6635]: The authors propose using laypeople, instead of experts, to evaluate the coherence and context-consistency of reflections produced by language models.", "target": "The authors propose using laypeople, instead of experts, to evaluate the coherence and context-consistency of reflections produced by language models.", "example": "Convert the coordinate to text: [-3.3971 -5.6635]:"}
{"text": "Convert the coordinate to text: [ 0.3789 -9.1183]: The authors propose a new map-based pre-training paradigm that is spatial-aware for use in VLN, consisting of a local metric map to explicitly aggregate incomplete observations and remove duplicates, while modeling navigation dependency in a global topological map, and a pre-training framework based on the hybrid map for learning a multimodal map representation.", "target": "The authors propose a new map-based pre-training paradigm that is spatial-aware for use in VLN, consisting of a local metric map to explicitly aggregate incomplete observations and remove duplicates, while modeling navigation dependency in a global topological map, and a pre-training framework based on the hybrid map for learning a multimodal map representation.", "example": "Convert the coordinate to text: [ 0.3789 -9.1183]:"}
{"text": "Convert the coordinate to text: [12.0165 -4.3424]: The authors investigate the effects of adversarial training on linear regression models, comparing it with other regularization methods. This study reveals that adversarial training can lead to minimum-norm interpolating solutions and can be equivalent to parameter shrinking methods under certain conditions.", "target": "The authors investigate the effects of adversarial training on linear regression models, comparing it with other regularization methods. This study reveals that adversarial training can lead to minimum-norm interpolating solutions and can be equivalent to parameter shrinking methods under certain conditions.", "example": "Convert the coordinate to text: [12.0165 -4.3424]:"}
{"text": "Convert the coordinate to text: [11.462  -2.1165]: The authors investigated the causes of numerical deviations in inference results of convolutional neural networks on realistic end-to-end inference pipelines and in isolated experiments.", "target": "The authors investigated the causes of numerical deviations in inference results of convolutional neural networks on realistic end-to-end inference pipelines and in isolated experiments.", "example": "Convert the coordinate to text: [11.462  -2.1165]:"}
{"text": "Convert the coordinate to text: [-1.04   -4.5729]: The authors propose task instructions as a novel and promising resource for supervision, aiming at enhancing AI and ML technologies for NLP generalization in a low-shot scenario.", "target": "The authors propose task instructions as a novel and promising resource for supervision, aiming at enhancing AI and ML technologies for NLP generalization in a low-shot scenario.", "example": "Convert the coordinate to text: [-1.04   -4.5729]:"}
{"text": "Convert the coordinate to text: [13.5892 -2.0438]: The paper proposes an algorithm framework that fuses brain dynamics, estimated as Dynamic Functional Connectivity (DFC) matrices, with an SNN for the recognition of brain states, creating a novel method called DFC-SNN.", "target": "The paper proposes an algorithm framework that fuses brain dynamics, estimated as Dynamic Functional Connectivity (DFC) matrices, with an SNN for the recognition of brain states, creating a novel method called DFC-SNN.", "example": "Convert the coordinate to text: [13.5892 -2.0438]:"}
{"text": "Convert the coordinate to text: [ 9.2871 -9.1935]: This paper proposes the Spherical Space feature Decomposition Network (SSDNet) to address the stated issues. The network uses Restormer block-based RGB/depth encoders for feature extraction, maps the extracted features to spherical space for separation and alignment of private and shared features, and uses a spherical contrast refinement (SCR) module to further refine details.", "target": "This paper proposes the Spherical Space feature Decomposition Network (SSDNet) to address the stated issues. The network uses Restormer block-based RGB/depth encoders for feature extraction, maps the extracted features to spherical space for separation and alignment of private and shared features, and uses a spherical contrast refinement (SCR) module to further refine details.", "example": "Convert the coordinate to text: [ 9.2871 -9.1935]:"}
{"text": "Convert the coordinate to text: [-13.2816  16.9832]: The authors propose two novel freehand pointing selection techniques for dense VR environments - HandDepthCursor and HandConeGrid, and apply an existing method called MultiFingerBubble.", "target": "The authors propose two novel freehand pointing selection techniques for dense VR environments - HandDepthCursor and HandConeGrid, and apply an existing method called MultiFingerBubble.", "example": "Convert the coordinate to text: [-13.2816  16.9832]:"}
{"text": "Convert the coordinate to text: [-2.0841 -7.1637]: The authors propose the hypothesis that the lack of complexity in other pretraining objectives contributes to their inability to outperform MLM. They aim to evaluate if more complex masked objectives yield better results and ascertain the required complexity for these tasks to attain performance akin to MLM.", "target": "The authors propose the hypothesis that the lack of complexity in other pretraining objectives contributes to their inability to outperform MLM. They aim to evaluate if more complex masked objectives yield better results and ascertain the required complexity for these tasks to attain performance akin to MLM.", "example": "Convert the coordinate to text: [-2.0841 -7.1637]:"}
{"text": "Convert the coordinate to text: [-4.052  -9.0207]: The authors present Discrete Unit Back-translation (DUB), a method that utilizes unsupervised discrete units to represent speech in direct ST, intending to evaluate if it's better to use these discrete units instead of continuous features and assess the benefits of applying MT techniques to ST.", "target": "The authors present Discrete Unit Back-translation (DUB), a method that utilizes unsupervised discrete units to represent speech in direct ST, intending to evaluate if it's better to use these discrete units instead of continuous features and assess the benefits of applying MT techniques to ST.", "example": "Convert the coordinate to text: [-4.052  -9.0207]:"}
{"text": "Convert the coordinate to text: [-4.9116 -1.1158]: This paper presents the first dataset with fine-grained factual error annotations named DIASUMFACT and propose an unsupervised model ENDERANKER via candidate ranking using pretrained encoder-decoder models.", "target": "This paper presents the first dataset with fine-grained factual error annotations named DIASUMFACT and propose an unsupervised model ENDERANKER via candidate ranking using pretrained encoder-decoder models.", "example": "Convert the coordinate to text: [-4.9116 -1.1158]:"}
{"text": "Convert the coordinate to text: [-1.009  -5.1789]: The authors introduce an instance-specific prompt-tuning algorithm for dialogue generation where prompts are generated based on instance-level control code, rather than the conversation history.", "target": "The authors introduce an instance-specific prompt-tuning algorithm for dialogue generation where prompts are generated based on instance-level control code, rather than the conversation history.", "example": "Convert the coordinate to text: [-1.009  -5.1789]:"}
{"text": "Convert the coordinate to text: [6.6882 7.933 ]: The authors propose a new method called Contrastive Parameter Ensembling (CaPE) to utilize variations in noise in training samples more effectively for reducing hallucination. The method involves training models on clean and noisy subsets of the data and adjust parameters accordingly, advancing existing work on additive parameter ensembling approaches.", "target": "The authors propose a new method called Contrastive Parameter Ensembling (CaPE) to utilize variations in noise in training samples more effectively for reducing hallucination. The method involves training models on clean and noisy subsets of the data and adjust parameters accordingly, advancing existing work on additive parameter ensembling approaches.", "example": "Convert the coordinate to text: [6.6882 7.933 ]:"}
{"text": "Convert the coordinate to text: [-3.0463 -6.636 ]: In this study, a transformer-based method for sentiment analysis is proposed focusing on low-resource African languages; namely, Nigerian Pidgin and Yoruba.", "target": "In this study, a transformer-based method for sentiment analysis is proposed focusing on low-resource African languages; namely, Nigerian Pidgin and Yoruba.", "example": "Convert the coordinate to text: [-3.0463 -6.636 ]:"}
{"text": "Convert the coordinate to text: [-3.781  -6.9126]: The team's approach to solve both subtasks is based on the combination of features extracted from several multilingual Large Language Models and a subset of language-independent linguistic features", "target": "The team's approach to solve both subtasks is based on the combination of features extracted from several multilingual Large Language Models and a subset of language-independent linguistic features", "example": "Convert the coordinate to text: [-3.781  -6.9126]:"}
{"text": "Convert the coordinate to text: [-3.3327 -1.6756]: This paper proposes a new framework that enhances the representation of event pairs by introducing the event causal label information and the interaction information. An event-causal-label-aware module is designed to model the event causal label information and an event pair interaction graph module to model the interaction information between event pairs.", "target": "This paper proposes a new framework that enhances the representation of event pairs by introducing the event causal label information and the interaction information. An event-causal-label-aware module is designed to model the event causal label information and an event pair interaction graph module to model the interaction information between event pairs.", "example": "Convert the coordinate to text: [-3.3327 -1.6756]:"}
{"text": "Convert the coordinate to text: [-13.9037   1.7402]: This paper focuses on the challenges presented by schema generalizability in the context of text-to-SQL tasks, observing that current datasets are too templated to study this aspect effectively.", "target": "This paper focuses on the challenges presented by schema generalizability in the context of text-to-SQL tasks, observing that current datasets are too templated to study this aspect effectively.", "example": "Convert the coordinate to text: [-13.9037   1.7402]:"}
{"text": "Convert the coordinate to text: [-4.0895 -2.1108]: The authors developed a pipeline that leverages a Large Language Model to identify causal claims in natural language documents, and it aggregates these claims across a corpus to produce a causal claim network. It further applies a clustering algorithm to group causal claims based on their semantic topics.", "target": "The authors developed a pipeline that leverages a Large Language Model to identify causal claims in natural language documents, and it aggregates these claims across a corpus to produce a causal claim network. It further applies a clustering algorithm to group causal claims based on their semantic topics.", "example": "Convert the coordinate to text: [-4.0895 -2.1108]:"}
{"text": "Convert the coordinate to text: [ 2.7622 -1.0943]: This paper presents a method for cooperative training of the response retriever and the reranker, where their parameters are dynamically optimized by ground-truth labels and list-wise supervision signals from each other, allowing these two modules to learn from each other and evolve together through the training.", "target": "This paper presents a method for cooperative training of the response retriever and the reranker, where their parameters are dynamically optimized by ground-truth labels and list-wise supervision signals from each other, allowing these two modules to learn from each other and evolve together through the training.", "example": "Convert the coordinate to text: [ 2.7622 -1.0943]:"}
{"text": "Convert the coordinate to text: [-2.6158 -8.5176]: A new model, named AMR-based Path Aggregation Relational Network (APARN), has been proposed to replace the syntactic dependency tree with the semantic structure called Abstract Meaning Representation (AMR). This model uses a path aggregator and a relation-enhanced self-attention mechanism that complement each other.", "target": "A new model, named AMR-based Path Aggregation Relational Network (APARN), has been proposed to replace the syntactic dependency tree with the semantic structure called Abstract Meaning Representation (AMR). This model uses a path aggregator and a relation-enhanced self-attention mechanism that complement each other.", "example": "Convert the coordinate to text: [-2.6158 -8.5176]:"}
{"text": "Convert the coordinate to text: [2.0578 1.4566]: The authors propose a new generalization measure called REF Complexity (RElative Fitting degree between signal and noise), founded on the idea that a model-algorithm pair may generalize well if it fits the signal (true labels) quickly while fitting noise (random labels) slowly.", "target": "The authors propose a new generalization measure called REF Complexity (RElative Fitting degree between signal and noise), founded on the idea that a model-algorithm pair may generalize well if it fits the signal (true labels) quickly while fitting noise (random labels) slowly.", "example": "Convert the coordinate to text: [2.0578 1.4566]:"}
{"text": "Convert the coordinate to text: [ -2.5709 -10.4816]: The paper introduces shift-invariant learning for generating high-resolution dubbed videos with accurate Lip-Sync. A pyramid network is used for coarse-to-fine image generation to improve stability and lip synchronization.", "target": "The paper introduces shift-invariant learning for generating high-resolution dubbed videos with accurate Lip-Sync. A pyramid network is used for coarse-to-fine image generation to improve stability and lip synchronization.", "example": "Convert the coordinate to text: [ -2.5709 -10.4816]:"}
{"text": "Convert the coordinate to text: [ 11.9447 -10.4279]: The authors have developed a Clothing-Oriented Transformation Try-On Network (COTTON), which uses clothing structure with landmarks and segmentation to generate a novel landmark-guided transformation, capable of precisely deforming clothes and allowing for size adjustment during the try-on process.", "target": "The authors have developed a Clothing-Oriented Transformation Try-On Network (COTTON), which uses clothing structure with landmarks and segmentation to generate a novel landmark-guided transformation, capable of precisely deforming clothes and allowing for size adjustment during the try-on process.", "example": "Convert the coordinate to text: [ 11.9447 -10.4279]:"}
{"text": "Convert the coordinate to text: [  7.432  -21.0876]: The authors propose a framework to process graphics images to mimic RAW sensor images accurately, which includes a one-to-many mapping where a single graphics image can be transformed to match multiple sensors and multiple scene illuminations.", "target": "The authors propose a framework to process graphics images to mimic RAW sensor images accurately, which includes a one-to-many mapping where a single graphics image can be transformed to match multiple sensors and multiple scene illuminations.", "example": "Convert the coordinate to text: [  7.432  -21.0876]:"}
{"text": "Convert the coordinate to text: [10.5089 -2.7139]: The authors propose a method that linearly correlates each weight of the target model to all the weights of the pretrained model, using multi-linear operators to reduce computational and spatial complexity, enhancing acceleration ability while keeping resource requirements manageable.", "target": "The authors propose a method that linearly correlates each weight of the target model to all the weights of the pretrained model, using multi-linear operators to reduce computational and spatial complexity, enhancing acceleration ability while keeping resource requirements manageable.", "example": "Convert the coordinate to text: [10.5089 -2.7139]:"}
{"text": "Convert the coordinate to text: [ 0.255  -6.7806]: This work proposes that the robustness of language models is proportional to the extent of pre-trained knowledge they encompass. Accordingly, an adaptive knowledge-retention pruning strategy is introduced, designed to faithfully replicate the embedding space and feature space of dense language models to conserve more pre-trained knowledge during the pruning process.", "target": "This work proposes that the robustness of language models is proportional to the extent of pre-trained knowledge they encompass. Accordingly, an adaptive knowledge-retention pruning strategy is introduced, designed to faithfully replicate the embedding space and feature space of dense language models to conserve more pre-trained knowledge during the pruning process.", "example": "Convert the coordinate to text: [ 0.255  -6.7806]:"}
{"text": "Convert the coordinate to text: [  3.3115 -12.1339]: This paper underscores the essential role of architectural design choices in achieving optimum performance in federated learning, particularly for visual recognition tasks, which is often neglected in the FL literature.", "target": "This paper underscores the essential role of architectural design choices in achieving optimum performance in federated learning, particularly for visual recognition tasks, which is often neglected in the FL literature.", "example": "Convert the coordinate to text: [  3.3115 -12.1339]:"}
{"text": "Convert the coordinate to text: [ 5.7404 13.6495]: The authors propose MolRL-MGPT, a reinforcement learning algorithm with multiple GPT agents, for drug molecular generation. To enhance molecular diversity the algorithm encourages agents to collaborate in searching for desirable molecules in diverse directions.", "target": "The authors propose MolRL-MGPT, a reinforcement learning algorithm with multiple GPT agents, for drug molecular generation. To enhance molecular diversity the algorithm encourages agents to collaborate in searching for desirable molecules in diverse directions.", "example": "Convert the coordinate to text: [ 5.7404 13.6495]:"}
{"text": "Convert the coordinate to text: [6.8826 7.6819]: The authors propose introducing differential privacy (DP) as an incentive in collaborative machine learning. Parties can select their required DP guarantees and correspondingly adjust their sufficient statistics (SS). The mediator values the perturbed SS based on the Bayesian surprise it elicits about the model parameters, thus introducing a privacy-valuation trade-off.", "target": "The authors propose introducing differential privacy (DP) as an incentive in collaborative machine learning. Parties can select their required DP guarantees and correspondingly adjust their sufficient statistics (SS). The mediator values the perturbed SS based on the Bayesian surprise it elicits about the model parameters, thus introducing a privacy-valuation trade-off.", "example": "Convert the coordinate to text: [6.8826 7.6819]:"}
{"text": "Convert the coordinate to text: [-5.2206 -3.8968]: This article introduces a new dataset, BenCoref, comprising of coreference annotations for Bengali texts from four distinct domains to encourage research and understanding of coreference phenomena in multiple domains in Bengali.", "target": "This article introduces a new dataset, BenCoref, comprising of coreference annotations for Bengali texts from four distinct domains to encourage research and understanding of coreference phenomena in multiple domains in Bengali.", "example": "Convert the coordinate to text: [-5.2206 -3.8968]:"}
{"text": "Convert the coordinate to text: [13.0176 -1.5843]: The authors propose to model physics-principled interatomic potentials directly. This includes modelling the complete set of potentials among all atoms. These techniques are incorporated into message passing neural networks.", "target": "The authors propose to model physics-principled interatomic potentials directly. This includes modelling the complete set of potentials among all atoms. These techniques are incorporated into message passing neural networks.", "example": "Convert the coordinate to text: [13.0176 -1.5843]:"}
{"text": "Convert the coordinate to text: [-10.2731  15.2567]: The authors developed a 'SoundVizVR Plugin' for the Unity platform, which enables game developers to incorporate the SoundVizVR system in their VR games and applications.", "target": "The authors developed a 'SoundVizVR Plugin' for the Unity platform, which enables game developers to incorporate the SoundVizVR system in their VR games and applications.", "example": "Convert the coordinate to text: [-10.2731  15.2567]:"}
{"text": "Convert the coordinate to text: [-4.3364  9.4598]: The authors present a hypothesis that system transparency is critical for tasks that involve expert sensemaking.", "target": "The authors present a hypothesis that system transparency is critical for tasks that involve expert sensemaking.", "example": "Convert the coordinate to text: [-4.3364  9.4598]:"}
{"text": "Convert the coordinate to text: [12.9983 -4.8324]: The paper proposes a semantics- and domain-aware word-level attack method that relies on important word replacements suggested by a specially trained language model.", "target": "The paper proposes a semantics- and domain-aware word-level attack method that relies on important word replacements suggested by a specially trained language model.", "example": "Convert the coordinate to text: [12.9983 -4.8324]:"}
{"text": "Convert the coordinate to text: [-1.4344 -2.4641]: This study presents a principled, probabilistic approach for training explainable multi-hop QA systems by explicitly modeling rationales as sets, capturing interactions between documents and sentences within a document, without rationale supervision.", "target": "This study presents a principled, probabilistic approach for training explainable multi-hop QA systems by explicitly modeling rationales as sets, capturing interactions between documents and sentences within a document, without rationale supervision.", "example": "Convert the coordinate to text: [-1.4344 -2.4641]:"}
{"text": "Convert the coordinate to text: [ 3.3682 -8.0758]: The authors propose Grouped Head Attention, a self-supervised group constraint that groups attention heads to focus on essential but distinctive feature subsets.", "target": "The authors propose Grouped Head Attention, a self-supervised group constraint that groups attention heads to focus on essential but distinctive feature subsets.", "example": "Convert the coordinate to text: [ 3.3682 -8.0758]:"}
{"text": "Convert the coordinate to text: [-6.578  -9.0627]: In this work, the authors propose to disentangle textual and phonetic feature representations, allowing for direct interaction between the two. This includes introducing a pinyin-to-character objective, asking the model to predict the correct characters based on phonetic information alone, slightly reducing attention from phonetic input to text via a separation mask, and a self-distillation module to ensure that semantic information is a major prediction factor.", "target": "In this work, the authors propose to disentangle textual and phonetic feature representations, allowing for direct interaction between the two. This includes introducing a pinyin-to-character objective, asking the model to predict the correct characters based on phonetic information alone, slightly reducing attention from phonetic input to text via a separation mask, and a self-distillation module to ensure that semantic information is a major prediction factor.", "example": "Convert the coordinate to text: [-6.578  -9.0627]:"}
{"text": "Convert the coordinate to text: [-0.8185 -6.9216]: The authors introduce a language transformer finetuning strategy that incorporates task-specific parameters in multiple transformer layers, derived from fixed random projections of a single trainable vector, thus significantly reducing the number of parameters while maintaining performance.", "target": "The authors introduce a language transformer finetuning strategy that incorporates task-specific parameters in multiple transformer layers, derived from fixed random projections of a single trainable vector, thus significantly reducing the number of parameters while maintaining performance.", "example": "Convert the coordinate to text: [-0.8185 -6.9216]:"}
{"text": "Convert the coordinate to text: [ 2.4303 -3.9733]: The authors propose a supervised adversarial contrastive learning (SACL) framework that applies contrast-aware adversarial training to generate worst-case samples and uses a joint class-spread contrastive learning objective on both original and adversarial samples.", "target": "The authors propose a supervised adversarial contrastive learning (SACL) framework that applies contrast-aware adversarial training to generate worst-case samples and uses a joint class-spread contrastive learning objective on both original and adversarial samples.", "example": "Convert the coordinate to text: [ 2.4303 -3.9733]:"}
{"text": "Convert the coordinate to text: [-5.3837  2.5596]: This study introduces a new paradigm for fake news video detection, cross-sample fake news video detection, and a new framework, Neighbor-Enhanced fakE news video Detection (NEED), which takes into consideration the neighborhood relationship of news videos related to the same event.", "target": "This study introduces a new paradigm for fake news video detection, cross-sample fake news video detection, and a new framework, Neighbor-Enhanced fakE news video Detection (NEED), which takes into consideration the neighborhood relationship of news videos related to the same event.", "example": "Convert the coordinate to text: [-5.3837  2.5596]:"}
{"text": "Convert the coordinate to text: [-1.1331 -4.0338]: The authors propose a single-sequence prediction method over a local reasoning graph that uses a graph structure connecting key context entities to relevant subsequent passages for each question. This structure is encoded using a graph neural network and fused into the entity representations of the model.", "target": "The authors propose a single-sequence prediction method over a local reasoning graph that uses a graph structure connecting key context entities to relevant subsequent passages for each question. This structure is encoded using a graph neural network and fused into the entity representations of the model.", "example": "Convert the coordinate to text: [-1.1331 -4.0338]:"}
{"text": "Convert the coordinate to text: [-3.4344 -4.9849]: The approach involved experimenting with pre-trained embeddings and refining them with statistical and neural classifiers.", "target": "The approach involved experimenting with pre-trained embeddings and refining them with statistical and neural classifiers.", "example": "Convert the coordinate to text: [-3.4344 -4.9849]:"}
{"text": "Convert the coordinate to text: [-2.0167 -6.4532]: Samsung Research China - Beijing proposes an AL-R (Adjustable Loss RoBERTa) model for SemEval-2023 Task 2 Multilingual Complex Named Entity Recognition (MultiCoNER II), designed to handle issues of long-tail data distribution, entities outside the knowledge base, and noise scenarios.", "target": "Samsung Research China - Beijing proposes an AL-R (Adjustable Loss RoBERTa) model for SemEval-2023 Task 2 Multilingual Complex Named Entity Recognition (MultiCoNER II), designed to handle issues of long-tail data distribution, entities outside the knowledge base, and noise scenarios.", "example": "Convert the coordinate to text: [-2.0167 -6.4532]:"}
{"text": "Convert the coordinate to text: [-2.3001 -6.5671]: The paper investigates the effects of model parameters, dataset size, and computational costs on the performance of language models in low-resource settings, and builds lightweight BERT models trained over small corpora.", "target": "The paper investigates the effects of model parameters, dataset size, and computational costs on the performance of language models in low-resource settings, and builds lightweight BERT models trained over small corpora.", "example": "Convert the coordinate to text: [-2.3001 -6.5671]:"}
{"text": "Convert the coordinate to text: [11.7183 -1.9508]: This study investigates the causes for these observations empirically and theoretically, discovering that the LN in Post-LN is the source of the vanishing gradient problem and preserves larger gradient norms in higher layers during back-propagation.", "target": "This study investigates the causes for these observations empirically and theoretically, discovering that the LN in Post-LN is the source of the vanishing gradient problem and preserves larger gradient norms in higher layers during back-propagation.", "example": "Convert the coordinate to text: [11.7183 -1.9508]:"}
{"text": "Convert the coordinate to text: [ 5.4774 -0.6292]: A new training method is proposed to reduce the reliance of NLI models on shortcuts and improve their out-of-distribution performance, it involves a minimax objective between a learner model (being trained for NLI) and an auxiliary model (aimed at maximizing the learner's loss by up-weighting examples from regions of high losses).", "target": "A new training method is proposed to reduce the reliance of NLI models on shortcuts and improve their out-of-distribution performance, it involves a minimax objective between a learner model (being trained for NLI) and an auxiliary model (aimed at maximizing the learner's loss by up-weighting examples from regions of high losses).", "example": "Convert the coordinate to text: [ 5.4774 -0.6292]:"}
{"text": "Convert the coordinate to text: [-10.5875  -2.069 ]: The authors present ELQA, a metalinguistic corpus of questions and answers in and about the English language, covering topics like grammar, meaning, fluency, and etymology, collected from two online forums.", "target": "The authors present ELQA, a metalinguistic corpus of questions and answers in and about the English language, covering topics like grammar, meaning, fluency, and etymology, collected from two online forums.", "example": "Convert the coordinate to text: [-10.5875  -2.069 ]:"}
{"text": "Convert the coordinate to text: [9.6228 0.5296]: The authors propose a topological framework that quantifies the local intrinsic dimension and provides a Euclidicity score to assess the 'manifoldness' of a point along multiple scales. This allows for the detection of data singularities.", "target": "The authors propose a topological framework that quantifies the local intrinsic dimension and provides a Euclidicity score to assess the 'manifoldness' of a point along multiple scales. This allows for the detection of data singularities.", "example": "Convert the coordinate to text: [9.6228 0.5296]:"}
{"text": "Convert the coordinate to text: [-4.8077  6.5993]: This paper proposes a method to infer social interventions like social distancing compliance, extent and efficacy of vaccination, and disease transmissibility by analyzing the structure of the contagion cascade using a machine learning approach.", "target": "This paper proposes a method to infer social interventions like social distancing compliance, extent and efficacy of vaccination, and disease transmissibility by analyzing the structure of the contagion cascade using a machine learning approach.", "example": "Convert the coordinate to text: [-4.8077  6.5993]:"}
{"text": "Convert the coordinate to text: [ 6.0432 -2.6225]: This work introduces TMI (TRANSFERABILITY MEASUREMENT WITH INTRA-CLASS FEATURE VARIANCE), a fast and accurate algorithm to measure transferability, viewing transferability as the generalization of a pre-trained model on a target task by measuring intra-class feature variance.", "target": "This work introduces TMI (TRANSFERABILITY MEASUREMENT WITH INTRA-CLASS FEATURE VARIANCE), a fast and accurate algorithm to measure transferability, viewing transferability as the generalization of a pre-trained model on a target task by measuring intra-class feature variance.", "example": "Convert the coordinate to text: [ 6.0432 -2.6225]:"}
{"text": "Convert the coordinate to text: [2.9629 0.6944]: 3S Testing, a deep generative modeling framework, is introduced to improve model evaluation by generating synthetic test sets for small subgroups and simulating distributional shifts.", "target": "3S Testing, a deep generative modeling framework, is introduced to improve model evaluation by generating synthetic test sets for small subgroups and simulating distributional shifts.", "example": "Convert the coordinate to text: [2.9629 0.6944]:"}
{"text": "Convert the coordinate to text: [11.9387 -7.4163]: The authors develop a method that is alteration-free and model-agnostic for origin attribution via reverse-engineering on image generation models. Their approach inverts the input of a particular model for a specific image.", "target": "The authors develop a method that is alteration-free and model-agnostic for origin attribution via reverse-engineering on image generation models. Their approach inverts the input of a particular model for a specific image.", "example": "Convert the coordinate to text: [11.9387 -7.4163]:"}
{"text": "Convert the coordinate to text: [-1.171e-03 -1.541e+01]: In this paper, the authors propose to use electroencephalogram (EEG) signals during finger motor execution and motor imagery to investigate the influence relationship between the brain network of the brain motor system and the relevant motor intervals.", "target": "In this paper, the authors propose to use electroencephalogram (EEG) signals during finger motor execution and motor imagery to investigate the influence relationship between the brain network of the brain motor system and the relevant motor intervals.", "example": "Convert the coordinate to text: [-1.171e-03 -1.541e+01]:"}
{"text": "Convert the coordinate to text: [-5.4515  7.9451]: This paper proposes to examine the trustworthiness of interaction concepts from four perspectives.", "target": "This paper proposes to examine the trustworthiness of interaction concepts from four perspectives.", "example": "Convert the coordinate to text: [-5.4515  7.9451]:"}
{"text": "Convert the coordinate to text: [-14.5351  10.9326]: In light of this, this paper presents a thorough review of autonomy-supportive designs in HCI research, resulting in an overview of existing conceptualisations of Digital Autonomy for children in HCI, a framework of design mechanisms to support children's digital autonomy, and critical design considerations for future support.", "target": "In light of this, this paper presents a thorough review of autonomy-supportive designs in HCI research, resulting in an overview of existing conceptualisations of Digital Autonomy for children in HCI, a framework of design mechanisms to support children's digital autonomy, and critical design considerations for future support.", "example": "Convert the coordinate to text: [-14.5351  10.9326]:"}
{"text": "Convert the coordinate to text: [ 3.7027 -3.9635]: The authors conduct a systematic study of task-specific Knowledge Distillation techniques for various Natural Language Generation tasks. They propose a family of Pseudo-Target (PT) augmentation methods and a Joint-Teaching method for NLG distillation, which applies word-level Knowledge Distillation to multiple PTs generated by both the teacher and the student.", "target": "The authors conduct a systematic study of task-specific Knowledge Distillation techniques for various Natural Language Generation tasks. They propose a family of Pseudo-Target (PT) augmentation methods and a Joint-Teaching method for NLG distillation, which applies word-level Knowledge Distillation to multiple PTs generated by both the teacher and the student.", "example": "Convert the coordinate to text: [ 3.7027 -3.9635]:"}
{"text": "Convert the coordinate to text: [-11.2193  10.8505]: The authors developed an intervention to train public housing residents to provide digital support to their community members, which involves a cohort-based basic digital skills training program that includes online courses and offline social learning support.", "target": "The authors developed an intervention to train public housing residents to provide digital support to their community members, which involves a cohort-based basic digital skills training program that includes online courses and offline social learning support.", "example": "Convert the coordinate to text: [-11.2193  10.8505]:"}
{"text": "Convert the coordinate to text: [-4.3353 -6.9068]: The authors introduce a new dataset, MultiTACRED, which covers 12 typologically diverse languages from 9 different families. This dataset is created by machine-translating TACRED instances and projecting their entity annotations automatically.", "target": "The authors introduce a new dataset, MultiTACRED, which covers 12 typologically diverse languages from 9 different families. This dataset is created by machine-translating TACRED instances and projecting their entity annotations automatically.", "example": "Convert the coordinate to text: [-4.3353 -6.9068]:"}
{"text": "Convert the coordinate to text: [-2.8061 -7.3885]: The authors propose an adapted metric, named PLL-word-l2r, in which not only the target token, but all within-word tokens to the right of the target are masked, aiming to improve estimation of log-likelihood in masked language models.", "target": "The authors propose an adapted metric, named PLL-word-l2r, in which not only the target token, but all within-word tokens to the right of the target are masked, aiming to improve estimation of log-likelihood in masked language models.", "example": "Convert the coordinate to text: [-2.8061 -7.3885]:"}
{"text": "Convert the coordinate to text: [ 2.4957 -1.0945]: This paper proposes a theoretical and empirical examination of the trade-off between intra-class and inter-class diversity within a fixed-size pre-training dataset, and how achieving an optimum balance impacts downstream performance.", "target": "This paper proposes a theoretical and empirical examination of the trade-off between intra-class and inter-class diversity within a fixed-size pre-training dataset, and how achieving an optimum balance impacts downstream performance.", "example": "Convert the coordinate to text: [ 2.4957 -1.0945]:"}
{"text": "Convert the coordinate to text: [-1.4181 -7.1447]: The authors propose that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through reduced self-attention variance.", "target": "The authors propose that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through reduced self-attention variance.", "example": "Convert the coordinate to text: [-1.4181 -7.1447]:"}
{"text": "Convert the coordinate to text: [-2.7441 -3.2278]: A new framework called KNSE is proposed for symptom status recognition (SSR) by formulating SSR as a natural language inference (NLI) task, where a triplet consisting of a premise, knowledge, and hypothesis is employed for each symptom mentioned in a dialogue.", "target": "A new framework called KNSE is proposed for symptom status recognition (SSR) by formulating SSR as a natural language inference (NLI) task, where a triplet consisting of a premise, knowledge, and hypothesis is employed for each symptom mentioned in a dialogue.", "example": "Convert the coordinate to text: [-2.7441 -3.2278]:"}
{"text": "Convert the coordinate to text: [ 6.5167 -1.5266]: This paper introduces a new task of federated learning for semantic parsing and proposes a novel LOss Reduction Adjusted Re-weighting (Lorar) mechanism to mitigate performance degradation. The Lorar mechanism allows each client's contribution to the global model update to be adjusted based on its training loss reduction per round.", "target": "This paper introduces a new task of federated learning for semantic parsing and proposes a novel LOss Reduction Adjusted Re-weighting (Lorar) mechanism to mitigate performance degradation. The Lorar mechanism allows each client's contribution to the global model update to be adjusted based on its training loss reduction per round.", "example": "Convert the coordinate to text: [ 6.5167 -1.5266]:"}
{"text": "Convert the coordinate to text: [  1.5146 -10.3742]: The authors propose re-annotating the captions in Visual Genome using a new intermediate representation, FACTUAL-MR, which can be converted into faithful and consistent scene graph annotations.", "target": "The authors propose re-annotating the captions in Visual Genome using a new intermediate representation, FACTUAL-MR, which can be converted into faithful and consistent scene graph annotations.", "example": "Convert the coordinate to text: [  1.5146 -10.3742]:"}
{"text": "Convert the coordinate to text: [-5.5151 -0.1474]: The authors conduct a meta-analysis on human and automated evaluation methods for Text Style Transfer, revealing substantial gaps in standardization and validation, and exposing resultant pitfalls.", "target": "The authors conduct a meta-analysis on human and automated evaluation methods for Text Style Transfer, revealing substantial gaps in standardization and validation, and exposing resultant pitfalls.", "example": "Convert the coordinate to text: [-5.5151 -0.1474]:"}
{"text": "Convert the coordinate to text: [-1.5484 -5.3228]: The authors propose a simple yet effective data augmentation approach through prompt-based Generative NLP models to improve the pre-screening task of classifying WD.", "target": "The authors propose a simple yet effective data augmentation approach through prompt-based Generative NLP models to improve the pre-screening task of classifying WD.", "example": "Convert the coordinate to text: [-1.5484 -5.3228]:"}
{"text": "Convert the coordinate to text: [-3.4043 -8.5869]: The authors have built a cascading NPU-MSXF system that employs various data augmentation strategies, a ROVER-based score fusion, a three-stage fine-tuning strategy for translation accuracy, and a two-stage framework for text-to-speech conversion that maintains high naturalness and sound quality.", "target": "The authors have built a cascading NPU-MSXF system that employs various data augmentation strategies, a ROVER-based score fusion, a three-stage fine-tuning strategy for translation accuracy, and a two-stage framework for text-to-speech conversion that maintains high naturalness and sound quality.", "example": "Convert the coordinate to text: [-3.4043 -8.5869]:"}
{"text": "Convert the coordinate to text: [-3.5429 -2.743 ]: A new document classification method is proposed, which incorporates the representations of a literature graph created from bibliographic and entity information to deeply model the relationships among documents.", "target": "A new document classification method is proposed, which incorporates the representations of a literature graph created from bibliographic and entity information to deeply model the relationships among documents.", "example": "Convert the coordinate to text: [-3.5429 -2.743 ]:"}
{"text": "Convert the coordinate to text: [ 1.0702 -0.3562]: The authors utilized a behavioral segmentation analysis on the annotators to model them independently and combine the results to yield soft and hard scores. They experimented with hierarchical clustering with various distance metrics for similarity, dissimilarity, and reliability.", "target": "The authors utilized a behavioral segmentation analysis on the annotators to model them independently and combine the results to yield soft and hard scores. They experimented with hierarchical clustering with various distance metrics for similarity, dissimilarity, and reliability.", "example": "Convert the coordinate to text: [ 1.0702 -0.3562]:"}
{"text": "Convert the coordinate to text: [-1.4556 -6.5032]: The authors propose using hierarchical multitask neural networks combined with transformers to detect persuasion techniques, with span detection as an auxiliary task aiding in the identification of propaganda techniques. Additionally, they propose changing the index of BERT embedding from the first token of the entire input to the first token of the identified span to improve performance.", "target": "The authors propose using hierarchical multitask neural networks combined with transformers to detect persuasion techniques, with span detection as an auxiliary task aiding in the identification of propaganda techniques. Additionally, they propose changing the index of BERT embedding from the first token of the entire input to the first token of the identified span to improve performance.", "example": "Convert the coordinate to text: [-1.4556 -6.5032]:"}
{"text": "Convert the coordinate to text: [ 4.9714 14.6456]: The paper focuses on improving performances of neural agents in a signaling game by considering multiple design choices such as pretraining the visual components of the agents, introducing regularization terms, and sampling training items from the dataset.", "target": "The paper focuses on improving performances of neural agents in a signaling game by considering multiple design choices such as pretraining the visual components of the agents, introducing regularization terms, and sampling training items from the dataset.", "example": "Convert the coordinate to text: [ 4.9714 14.6456]:"}
{"text": "Convert the coordinate to text: [-4.9626 -0.3658]: The authors propose a novel framework for unsupervised opinion summarization that disentangles text representation into content and pattern. A disentangling module is added to the encoder-decoder architecture, and a counter-template (automatically generated based on contrastive learning) is used to capture pattern information.", "target": "The authors propose a novel framework for unsupervised opinion summarization that disentangles text representation into content and pattern. A disentangling module is added to the encoder-decoder architecture, and a counter-template (automatically generated based on contrastive learning) is used to capture pattern information.", "example": "Convert the coordinate to text: [-4.9626 -0.3658]:"}
{"text": "Convert the coordinate to text: [-6.3609  5.3172]: This study aims to explore open-domain Twitter user profile inference, collecting data from publicly available WikiData public figure profiles and using a diverse set of WikiData predicates for profile inference.", "target": "This study aims to explore open-domain Twitter user profile inference, collecting data from publicly available WikiData public figure profiles and using a diverse set of WikiData predicates for profile inference.", "example": "Convert the coordinate to text: [-6.3609  5.3172]:"}
{"text": "Convert the coordinate to text: [ 9.9272 -3.974 ]: The authors propose a new approach - a partially dynamic network called PAD-Net, which transforms redundant dynamic parameters into static ones, thereby challenging the common practice in implementing dynamic networks.", "target": "The authors propose a new approach - a partially dynamic network called PAD-Net, which transforms redundant dynamic parameters into static ones, thereby challenging the common practice in implementing dynamic networks.", "example": "Convert the coordinate to text: [ 9.9272 -3.974 ]:"}
{"text": "Convert the coordinate to text: [ 2.8603 -4.9938]: The paper introduces Hypernetworks for INstruction Tuning (HINT), which convert task instructions and examples into parameter-efficient modules inserted into an underlying model to eliminate the need for including instructions in the model input.", "target": "The paper introduces Hypernetworks for INstruction Tuning (HINT), which convert task instructions and examples into parameter-efficient modules inserted into an underlying model to eliminate the need for including instructions in the model input.", "example": "Convert the coordinate to text: [ 2.8603 -4.9938]:"}
{"text": "Convert the coordinate to text: [-13.1831  10.5713]: The authors propose 'ecosystem-level analysis', a method that involves analyzing the collection of models that are deployed in a given context, rather than a single model. This method recognizes that outcomes are shaped by multiple models (or systems) interacting in a particular setting, not just one.", "target": "The authors propose 'ecosystem-level analysis', a method that involves analyzing the collection of models that are deployed in a given context, rather than a single model. This method recognizes that outcomes are shaped by multiple models (or systems) interacting in a particular setting, not just one.", "example": "Convert the coordinate to text: [-13.1831  10.5713]:"}
{"text": "Convert the coordinate to text: [ 5.4753 12.8421]: This study argues that Markovian aggregation of Markovian reward functions is not adequate when the time preference for each objective varies, and, instead, optimal multi-objective agents must admit rewards that are non-Markovian with respect to the individual objectives.", "target": "This study argues that Markovian aggregation of Markovian reward functions is not adequate when the time preference for each objective varies, and, instead, optimal multi-objective agents must admit rewards that are non-Markovian with respect to the individual objectives.", "example": "Convert the coordinate to text: [ 5.4753 12.8421]:"}
{"text": "Convert the coordinate to text: [  9.0348 -11.5617]: The authors propose an unsupervised viewpoint representation learning scheme for 3D point cloud completion without explicit viewpoint estimation. They introduce the Viewpoint-Aware Point cloud Completion Network (VAPCNet), which adapts to various viewpoints based on the learned representations.", "target": "The authors propose an unsupervised viewpoint representation learning scheme for 3D point cloud completion without explicit viewpoint estimation. They introduce the Viewpoint-Aware Point cloud Completion Network (VAPCNet), which adapts to various viewpoints based on the learned representations.", "example": "Convert the coordinate to text: [  9.0348 -11.5617]:"}
{"text": "Convert the coordinate to text: [-0.8095 -3.9853]: A novel framework for visual commonsense generation, DIVE, is proposed. DIVE is designed to enhance the descriptiveness and diversity of generated inferences. It incorporates two methods: generic inference filtering and contrastive retrieval learning.", "target": "A novel framework for visual commonsense generation, DIVE, is proposed. DIVE is designed to enhance the descriptiveness and diversity of generated inferences. It incorporates two methods: generic inference filtering and contrastive retrieval learning.", "example": "Convert the coordinate to text: [-0.8095 -3.9853]:"}
{"text": "Convert the coordinate to text: [ 0.8913 -2.2175]: The authors introduce an unsupervised approach that reformulates binding energy prediction as a generative modeling task. They propose a new equivariant rotation prediction network called Neural Euler's Rotation Equations (NERE) for SE(3) score matching, which models the force and torque between protein and ligand atoms to predict a rotation.", "target": "The authors introduce an unsupervised approach that reformulates binding energy prediction as a generative modeling task. They propose a new equivariant rotation prediction network called Neural Euler's Rotation Equations (NERE) for SE(3) score matching, which models the force and torque between protein and ligand atoms to predict a rotation.", "example": "Convert the coordinate to text: [ 0.8913 -2.2175]:"}
{"text": "Convert the coordinate to text: [11.9347  3.7812]: The paper introduces OPORP (one permutation + one random projection), a method that uses count-sketch type data structures to reduce data and control variance. This involves permuting data vectors, generating a random vector, breaking down columns into equal-length bins and normalizing the samples.", "target": "The paper introduces OPORP (one permutation + one random projection), a method that uses count-sketch type data structures to reduce data and control variance. This involves permuting data vectors, generating a random vector, breaking down columns into equal-length bins and normalizing the samples.", "example": "Convert the coordinate to text: [11.9347  3.7812]:"}
{"text": "Convert the coordinate to text: [-3.1901 15.1346]: To deal with this, the authors propose a translator module for the navigation agent that converts original instructions into easy-to-follow sub-instruction representations at each step, focusing on the recognizable and distinctive landmarks based on the agent's visual abilities and the observed visual environment.", "target": "To deal with this, the authors propose a translator module for the navigation agent that converts original instructions into easy-to-follow sub-instruction representations at each step, focusing on the recognizable and distinctive landmarks based on the agent's visual abilities and the observed visual environment.", "example": "Convert the coordinate to text: [-3.1901 15.1346]:"}
{"text": "Convert the coordinate to text: [ 0.2732 -8.437 ]: The paper proposes a Regularized Contrastive Cross-lingual Cross-modal (RC^3) pre-training method, that utilizes more abundant weakly-aligned multilingual image-text pairs.", "target": "The paper proposes a Regularized Contrastive Cross-lingual Cross-modal (RC^3) pre-training method, that utilizes more abundant weakly-aligned multilingual image-text pairs.", "example": "Convert the coordinate to text: [ 0.2732 -8.437 ]:"}
{"text": "Convert the coordinate to text: [ 4.8279 -5.0442]: The paper proposes a novel and general federated graph learning (FGL) framework called FedHGN for HGNNs that implements schema-weight decoupling for schema-agnostic knowledge sharing and uses coefficients alignment to stabilize the training process and improve HGNN performance.", "target": "The paper proposes a novel and general federated graph learning (FGL) framework called FedHGN for HGNNs that implements schema-weight decoupling for schema-agnostic knowledge sharing and uses coefficients alignment to stabilize the training process and improve HGNN performance.", "example": "Convert the coordinate to text: [ 4.8279 -5.0442]:"}
{"text": "Convert the coordinate to text: [-4.5352  1.1371]: The authors present PersoNet, the first labeled dataset for situated and fine-grained personality understanding. They adopt a novel annotation strategy that involves annotating user notes from online reading apps as an alternative to original books.", "target": "The authors present PersoNet, the first labeled dataset for situated and fine-grained personality understanding. They adopt a novel annotation strategy that involves annotating user notes from online reading apps as an alternative to original books.", "example": "Convert the coordinate to text: [-4.5352  1.1371]:"}
{"text": "Convert the coordinate to text: [-2.3036 -4.9783]: The authors propose an in-context learning-based NER approach which enables pre-trained language models (PLMs) to recognize entities of novel types on-the-fly. They model the PLMs as a meta-function and demonstrate that new entity extractors can be constructed implicitly by applying the instructions and demonstrations to PLMs.", "target": "The authors propose an in-context learning-based NER approach which enables pre-trained language models (PLMs) to recognize entities of novel types on-the-fly. They model the PLMs as a meta-function and demonstrate that new entity extractors can be constructed implicitly by applying the instructions and demonstrations to PLMs.", "example": "Convert the coordinate to text: [-2.3036 -4.9783]:"}
{"text": "Convert the coordinate to text: [-5.1854 -4.0404]: The authors propose three dimensions of linguistic dataset drift (vocabulary, structural, and semantic drift) and corresponding interpretable metrics", "target": "The authors propose three dimensions of linguistic dataset drift (vocabulary, structural, and semantic drift) and corresponding interpretable metrics", "example": "Convert the coordinate to text: [-5.1854 -4.0404]:"}
{"text": "Convert the coordinate to text: [ 4.0179 -5.4685]: The paper presents GVdoc, a new graph-based visual document classification model designed to improve accuracy on out-of-distribution instances by generating a document graph based on the document layout and training a graph neural network to learn node and graph embeddings.", "target": "The paper presents GVdoc, a new graph-based visual document classification model designed to improve accuracy on out-of-distribution instances by generating a document graph based on the document layout and training a graph neural network to learn node and graph embeddings.", "example": "Convert the coordinate to text: [ 4.0179 -5.4685]:"}
{"text": "Convert the coordinate to text: [ 0.8325 -2.0922]: The authors propose a novel model for molecular relational learning, CMRL, that is robust to distributional shifts by identifying core substructures that are causally related to chemical reactions.", "target": "The authors propose a novel model for molecular relational learning, CMRL, that is robust to distributional shifts by identifying core substructures that are causally related to chemical reactions.", "example": "Convert the coordinate to text: [ 0.8325 -2.0922]:"}
{"text": "Convert the coordinate to text: [-2.8749 -4.8426]: To address the bias of existing models, the authors propose DLAMA, a framework for curating culturally diverse factual triples from Wikidata, and introduce a more balanced benchmark (DLAMA-v1).", "target": "To address the bias of existing models, the authors propose DLAMA, a framework for curating culturally diverse factual triples from Wikidata, and introduce a more balanced benchmark (DLAMA-v1).", "example": "Convert the coordinate to text: [-2.8749 -4.8426]:"}
{"text": "Convert the coordinate to text: [-10.7034  -1.8246]: A Question-Answering (QA) approach, using the Unified-QA model on two large mental health datasets, is proposed for assessing mental health risk from users' social media data. To protect user data, differential privacy is introduced during the model training process.", "target": "A Question-Answering (QA) approach, using the Unified-QA model on two large mental health datasets, is proposed for assessing mental health risk from users' social media data. To protect user data, differential privacy is introduced during the model training process.", "example": "Convert the coordinate to text: [-10.7034  -1.8246]:"}
{"text": "Convert the coordinate to text: [ 2.4999 -1.1097]: The paper proposes a neuro-symbolic approach called 'Rapid', which learns image labeling rules from a small amount of labeled data provided by domain experts and automatically labels unannotated data using those rules. 'Rapid' leverages pre-trained CV models and inductive logic learning to infer logic-based labeling rules.", "target": "The paper proposes a neuro-symbolic approach called 'Rapid', which learns image labeling rules from a small amount of labeled data provided by domain experts and automatically labels unannotated data using those rules. 'Rapid' leverages pre-trained CV models and inductive logic learning to infer logic-based labeling rules.", "example": "Convert the coordinate to text: [ 2.4999 -1.1097]:"}
{"text": "Convert the coordinate to text: [ 5.4022 -3.3436]: The authors propose Text AUgmentation by Dataset Reconstruction (TAU-DR), a new method of data augmentation for text classification.", "target": "The authors propose Text AUgmentation by Dataset Reconstruction (TAU-DR), a new method of data augmentation for text classification.", "example": "Convert the coordinate to text: [ 5.4022 -3.3436]:"}
{"text": "Convert the coordinate to text: [10.8909 -8.247 ]: In this paper, a novel method was proposed for image local forgery detection by firstly analyzing the JPEG compression traces and designing a trace extractor to learn such traces. The trace extractor was then used as the backbone and trained in a self-supervised manner to strengthen the discriminative ability of the learned traces.", "target": "In this paper, a novel method was proposed for image local forgery detection by firstly analyzing the JPEG compression traces and designing a trace extractor to learn such traces. The trace extractor was then used as the backbone and trained in a self-supervised manner to strengthen the discriminative ability of the learned traces.", "example": "Convert the coordinate to text: [10.8909 -8.247 ]:"}
{"text": "Convert the coordinate to text: [-2.3235 -3.6139]: The authors propose an Entity-Aware Subsequences-based Active Learning (EASAL) method using a Head-Tail pointer to query one entity-aware subsequence for each sentence based on BERT.", "target": "The authors propose an Entity-Aware Subsequences-based Active Learning (EASAL) method using a Head-Tail pointer to query one entity-aware subsequence for each sentence based on BERT.", "example": "Convert the coordinate to text: [-2.3235 -3.6139]:"}
{"text": "Convert the coordinate to text: [ 6.7602 -5.9976]: This study attempts an empirical investigation on the possibility of a recurrent network for meta-RL being an effective baseline and suggests the use of hypernetworks as instrumental to maximize their potential.", "target": "This study attempts an empirical investigation on the possibility of a recurrent network for meta-RL being an effective baseline and suggests the use of hypernetworks as instrumental to maximize their potential.", "example": "Convert the coordinate to text: [ 6.7602 -5.9976]:"}
{"text": "Convert the coordinate to text: [ 10.602  -13.4607]: The authors propose XVO, a semi-supervised learning method for training generalized monocular VO models across diverse datasets without relying on known camera parameters, by learning to recover relative pose with real-world scale from visual scene semantics.", "target": "The authors propose XVO, a semi-supervised learning method for training generalized monocular VO models across diverse datasets without relying on known camera parameters, by learning to recover relative pose with real-world scale from visual scene semantics.", "example": "Convert the coordinate to text: [ 10.602  -13.4607]:"}
{"text": "Convert the coordinate to text: [ 13.0318 -17.556 ]: This paper presents a real-world dataset for degraded video frame interpolation, RD-VFI, and explores the performance differences of three types of shutter-induced degradations. It proposes a new Progressive Mutual Boosting Network (PMBNet) that can interpolate middle frames at arbitrary time for all shutter modes.", "target": "This paper presents a real-world dataset for degraded video frame interpolation, RD-VFI, and explores the performance differences of three types of shutter-induced degradations. It proposes a new Progressive Mutual Boosting Network (PMBNet) that can interpolate middle frames at arbitrary time for all shutter modes.", "example": "Convert the coordinate to text: [ 13.0318 -17.556 ]:"}
{"text": "Convert the coordinate to text: [-1.1457 -9.8698]: The study proposes a cross-modal semi-supervised framework comprising of a Speech-to-Image Transcoder and a Face-to-Geometry Regressor, which jointly learns a common representation space from speech and image domains, enabling the transition from speech into semantically-consistent facial images and reducing dependence on costly supervised data.", "target": "The study proposes a cross-modal semi-supervised framework comprising of a Speech-to-Image Transcoder and a Face-to-Geometry Regressor, which jointly learns a common representation space from speech and image domains, enabling the transition from speech into semantically-consistent facial images and reducing dependence on costly supervised data.", "example": "Convert the coordinate to text: [-1.1457 -9.8698]:"}
{"text": "Convert the coordinate to text: [ 2.4496 13.2361]: The authors propose a technique for generating diverse conventions that maximizes rewards during self-play while minimizing rewards when playing with previously discovered conventions (cross-play); this stimulates conventions to be semantically different.", "target": "The authors propose a technique for generating diverse conventions that maximizes rewards during self-play while minimizing rewards when playing with previously discovered conventions (cross-play); this stimulates conventions to be semantically different.", "example": "Convert the coordinate to text: [ 2.4496 13.2361]:"}
{"text": "Convert the coordinate to text: [ 5.6473 -2.4205]: The paper proposes an efficient mixup objective function with a decoupled regularizer, named Decoupled Mixup (DM), which doesn't attempt to optimize mixed samples according to mixed labels but rather makes use of label-mismatched mixed samples (informative hard mixed samples) to locate discriminative features without sacrificing the original smoothness of the mixup.", "target": "The paper proposes an efficient mixup objective function with a decoupled regularizer, named Decoupled Mixup (DM), which doesn't attempt to optimize mixed samples according to mixed labels but rather makes use of label-mismatched mixed samples (informative hard mixed samples) to locate discriminative features without sacrificing the original smoothness of the mixup.", "example": "Convert the coordinate to text: [ 5.6473 -2.4205]:"}
{"text": "Convert the coordinate to text: [4.2457 1.0471]: The authors' key insight is based on an empirical observation that the improvement of the ensemble largely comes from top-ambiguity samples where its member models diverge.", "target": "The authors' key insight is based on an empirical observation that the improvement of the ensemble largely comes from top-ambiguity samples where its member models diverge.", "example": "Convert the coordinate to text: [4.2457 1.0471]:"}
{"text": "Convert the coordinate to text: [3.3735 7.6003]: The authors propose two novel characterisations for hypertree width in terms of linear orderings and talk about their use in developing SAT, MaxSAT, and SMT encodings for exact computation of hypertree width.", "target": "The authors propose two novel characterisations for hypertree width in terms of linear orderings and talk about their use in developing SAT, MaxSAT, and SMT encodings for exact computation of hypertree width.", "example": "Convert the coordinate to text: [3.3735 7.6003]:"}
{"text": "Convert the coordinate to text: [-0.4789 -6.8797]: The authors present Angel-PTM, a productive deep learning system specifically designed for pre-training and fine-tuning Transformer models, with key design elements including fine-grained memory management via the Page abstraction, a unified scheduling method, and supporting extreme model scaling with SSD storage.", "target": "The authors present Angel-PTM, a productive deep learning system specifically designed for pre-training and fine-tuning Transformer models, with key design elements including fine-grained memory management via the Page abstraction, a unified scheduling method, and supporting extreme model scaling with SSD storage.", "example": "Convert the coordinate to text: [-0.4789 -6.8797]:"}
{"text": "Convert the coordinate to text: [ 7.1752 -4.2715]: This study focuses on the development of an unsupervised domain adaptation algorithm for training a deep network for event-based data image classification, using contrastive learning and uncorrelated data conditioning.", "target": "This study focuses on the development of an unsupervised domain adaptation algorithm for training a deep network for event-based data image classification, using contrastive learning and uncorrelated data conditioning.", "example": "Convert the coordinate to text: [ 7.1752 -4.2715]:"}
{"text": "Convert the coordinate to text: [-9.786  14.9544]: The authors propose LearnIoTVR, an end-to-end Virtual Reality (VR) learning environment that allows students to learn about IoT through immersive design, programming, and exploration of real-world environments. This system utilizes a custom-designed 3D block-based language to allow students to program IoT behaviors directly within VR.", "target": "The authors propose LearnIoTVR, an end-to-end Virtual Reality (VR) learning environment that allows students to learn about IoT through immersive design, programming, and exploration of real-world environments. This system utilizes a custom-designed 3D block-based language to allow students to program IoT behaviors directly within VR.", "example": "Convert the coordinate to text: [-9.786  14.9544]:"}
{"text": "Convert the coordinate to text: [-11.6756  16.8841]: The author suggests that haptic devices should be redesigned with users in mind, rather than focusing solely on delivering realistic sensations. They propose that haptic devices need to be compatible with everyday tasks and always available without the need for bulky batteries or cables.", "target": "The author suggests that haptic devices should be redesigned with users in mind, rather than focusing solely on delivering realistic sensations. They propose that haptic devices need to be compatible with everyday tasks and always available without the need for bulky batteries or cables.", "example": "Convert the coordinate to text: [-11.6756  16.8841]:"}
{"text": "Convert the coordinate to text: [  8.737  -21.8856]: The authors develop a new HDR image dataset named Mobile-HDR dataset, constructed using mobile phone cameras, which includes paired low dynamic range (LDR)-HDR images in the raw image domain, captured during both daytime and night-time. Additionally, they propose a transformer-based model with a pyramid cross-attention alignment module for joint HDR denoising and fusion.", "target": "The authors develop a new HDR image dataset named Mobile-HDR dataset, constructed using mobile phone cameras, which includes paired low dynamic range (LDR)-HDR images in the raw image domain, captured during both daytime and night-time. Additionally, they propose a transformer-based model with a pyramid cross-attention alignment module for joint HDR denoising and fusion.", "example": "Convert the coordinate to text: [  8.737  -21.8856]:"}
{"text": "Convert the coordinate to text: [ 6.4206 13.6454]: The study presents a novel reward shifting-based method to address the distribution shift problem in offline reinforcement learning. The method modifies the reward to be received by the new policy by shifting it adaptively according to its proximity to the behavior policy, applying the reward shifting along opposite directions for in-distribution actions and the ones not.", "target": "The study presents a novel reward shifting-based method to address the distribution shift problem in offline reinforcement learning. The method modifies the reward to be received by the new policy by shifting it adaptively according to its proximity to the behavior policy, applying the reward shifting along opposite directions for in-distribution actions and the ones not.", "example": "Convert the coordinate to text: [ 6.4206 13.6454]:"}
{"text": "Convert the coordinate to text: [-3.8953  3.5889]: The authors formulate the integrated recommendation task with exposure constraints as a binary online programming problem and propose a two-layer framework named Multi-channel Integrated Recommendation with Exposure Constraints (MIREC).", "target": "The authors formulate the integrated recommendation task with exposure constraints as a binary online programming problem and propose a two-layer framework named Multi-channel Integrated Recommendation with Exposure Constraints (MIREC).", "example": "Convert the coordinate to text: [-3.8953  3.5889]:"}
{"text": "Convert the coordinate to text: [-0.9148  0.5447]: The authors investigate the continuities and transformations of bias in historical Caribbean newspapers from the colonial era (18th to 19th centuries), especially along the axes of gender, race, and their intersection. They also test the effectiveness and stability of techniques processing OCR-generated data.", "target": "The authors investigate the continuities and transformations of bias in historical Caribbean newspapers from the colonial era (18th to 19th centuries), especially along the axes of gender, race, and their intersection. They also test the effectiveness and stability of techniques processing OCR-generated data.", "example": "Convert the coordinate to text: [-0.9148  0.5447]:"}
{"text": "Convert the coordinate to text: [-5.5896 -0.4013]: The authors propose EFACTSUM (Effective Factual Summarization), a candidate summary generation and ranking technique to improve summary factuality without sacrificing summary quality. They also propose a ranking strategy in which two metrics are effectively combined, thereby preventing any conflict during training.", "target": "The authors propose EFACTSUM (Effective Factual Summarization), a candidate summary generation and ranking technique to improve summary factuality without sacrificing summary quality. They also propose a ranking strategy in which two metrics are effectively combined, thereby preventing any conflict during training.", "example": "Convert the coordinate to text: [-5.5896 -0.4013]:"}
{"text": "Convert the coordinate to text: [-1.1083 -3.6008]: The authors introduce a new framework called 'commonsense knowledge transfer', which transfers the commonsense knowledge stored in a neural commonsense knowledge model to a general-purpose language model.", "target": "The authors introduce a new framework called 'commonsense knowledge transfer', which transfers the commonsense knowledge stored in a neural commonsense knowledge model to a general-purpose language model.", "example": "Convert the coordinate to text: [-1.1083 -3.6008]:"}
{"text": "Convert the coordinate to text: [-1.7568 -9.7855]: The authors propose an Open-modality Speech Recognition system (OpenSR) that leverages multi-modality alignment in phoneme space, aiming for zero-shot modality transfer. This system allows models trained on a single modality, such as audio-only, to be applicable to more modalities, like visual-only and audio-visual.", "target": "The authors propose an Open-modality Speech Recognition system (OpenSR) that leverages multi-modality alignment in phoneme space, aiming for zero-shot modality transfer. This system allows models trained on a single modality, such as audio-only, to be applicable to more modalities, like visual-only and audio-visual.", "example": "Convert the coordinate to text: [-1.7568 -9.7855]:"}
{"text": "Convert the coordinate to text: [-4.5552 -6.3877]: The authors introduce a new proxy score named xSIM++ that uses rule-based approaches to extend English sentences with synthetic examples that are challenging to distinguish, offering a more realistic estimation of large-scale mining scenarios.", "target": "The authors introduce a new proxy score named xSIM++ that uses rule-based approaches to extend English sentences with synthetic examples that are challenging to distinguish, offering a more realistic estimation of large-scale mining scenarios.", "example": "Convert the coordinate to text: [-4.5552 -6.3877]:"}
{"text": "Convert the coordinate to text: [-2.8315 -5.3806]: The authors explored the use of large language models (LLMs) for automatic summarization of biomedical research articles. The models were fine-tuned on two provided datasets and adapted to the shared task.", "target": "The authors explored the use of large language models (LLMs) for automatic summarization of biomedical research articles. The models were fine-tuned on two provided datasets and adapted to the shared task.", "example": "Convert the coordinate to text: [-2.8315 -5.3806]:"}
{"text": "Convert the coordinate to text: [-7.6882 -6.9176]: The authors introduce Card-it, a web-based application which integrates a large-scale finite-state morphological analyzer with a digital flashcard system, to aid in learning Italian verb conjugation. It includes features for classroom management to track progression and share flashcards with a class.", "target": "The authors introduce Card-it, a web-based application which integrates a large-scale finite-state morphological analyzer with a digital flashcard system, to aid in learning Italian verb conjugation. It includes features for classroom management to track progression and share flashcards with a class.", "example": "Convert the coordinate to text: [-7.6882 -6.9176]:"}
{"text": "Convert the coordinate to text: [-3.1344  0.8841]: A new task, Multi-modal Sarcasm Generation (MSG), is presented, where sarcastic descriptions are generated for a given image and its attached hashtags. An accompanying dataset (MuSG) and a multi-modal Transformer-based method are also proposed for MSG.", "target": "A new task, Multi-modal Sarcasm Generation (MSG), is presented, where sarcastic descriptions are generated for a given image and its attached hashtags. An accompanying dataset (MuSG) and a multi-modal Transformer-based method are also proposed for MSG.", "example": "Convert the coordinate to text: [-3.1344  0.8841]:"}
{"text": "Convert the coordinate to text: [ -0.6949 -12.1549]: The authors propose a novel non-autoregressive approach to GEC that decouples the architecture into a permutation network, which outputs a self-attention weight matrix, and a decoder network based on a step-unrolled denoising autoencoder that fills in specific tokens.", "target": "The authors propose a novel non-autoregressive approach to GEC that decouples the architecture into a permutation network, which outputs a self-attention weight matrix, and a decoder network based on a step-unrolled denoising autoencoder that fills in specific tokens.", "example": "Convert the coordinate to text: [ -0.6949 -12.1549]:"}
{"text": "Convert the coordinate to text: [-0.7926 -3.0413]: The authors propose an explainable extrapolation reasoning framework TEemporal logiCal grapH networkS (TECHS), which contains a temporal graph encoder and a logical decoder in order to address the challenges in TKGs.", "target": "The authors propose an explainable extrapolation reasoning framework TEemporal logiCal grapH networkS (TECHS), which contains a temporal graph encoder and a logical decoder in order to address the challenges in TKGs.", "example": "Convert the coordinate to text: [-0.7926 -3.0413]:"}
{"text": "Convert the coordinate to text: [ 9.9669 -1.3934]: The authors propose a method to address the inference bias of neural metrics through uncertainty minimization during test time, without requiring additional data. The method consists of uncertainty estimation, test-time adaptation, and inference, using the prediction uncertainty of the current data as a signal to update a small fraction of parameters during test time.", "target": "The authors propose a method to address the inference bias of neural metrics through uncertainty minimization during test time, without requiring additional data. The method consists of uncertainty estimation, test-time adaptation, and inference, using the prediction uncertainty of the current data as a signal to update a small fraction of parameters during test time.", "example": "Convert the coordinate to text: [ 9.9669 -1.3934]:"}
{"text": "Convert the coordinate to text: [  7.1545 -11.4212]: The authors propose a novel night-time semantic segmentation paradigm, called Disentangle then Parse (DTP). DTP disentangles night-time images into light-invariant reflectance and light-specific illumination components, then recognizes semantics based on their adaptive fusion.", "target": "The authors propose a novel night-time semantic segmentation paradigm, called Disentangle then Parse (DTP). DTP disentangles night-time images into light-invariant reflectance and light-specific illumination components, then recognizes semantics based on their adaptive fusion.", "example": "Convert the coordinate to text: [  7.1545 -11.4212]:"}
{"text": "Convert the coordinate to text: [12.3107 -5.2489]: This paper proposes to investigate how to craft image and text perturbations using pre-trained VL models to attack black-box fine-tuned models on different downstream tasks. It introduces VLAttack, a method to generate adversarial samples by fusing perturbations of images and texts from both single-modal and multimodal levels.", "target": "This paper proposes to investigate how to craft image and text perturbations using pre-trained VL models to attack black-box fine-tuned models on different downstream tasks. It introduces VLAttack, a method to generate adversarial samples by fusing perturbations of images and texts from both single-modal and multimodal levels.", "example": "Convert the coordinate to text: [12.3107 -5.2489]:"}
{"text": "Convert the coordinate to text: [ 9.4345 -8.4933]: The authors propose a compact invertible dyadic network called CIDNet that interprets video demoir\u00e9ing as a multi-frame decomposition problem. The CIDNet progressively decouples latent frames and the moir\u00e9 patterns from an input video sequence.", "target": "The authors propose a compact invertible dyadic network called CIDNet that interprets video demoir\u00e9ing as a multi-frame decomposition problem. The CIDNet progressively decouples latent frames and the moir\u00e9 patterns from an input video sequence.", "example": "Convert the coordinate to text: [ 9.4345 -8.4933]:"}
{"text": "Convert the coordinate to text: [ 0.7503 -9.1347]: The authors propose to address the more practical Partially Relevant Video Retrieval (PRVR) task from a new perspective: distilling the generalization knowledge from the large-scale vision-language pre-trained model and transferring it to a task-specific PRVR network.", "target": "The authors propose to address the more practical Partially Relevant Video Retrieval (PRVR) task from a new perspective: distilling the generalization knowledge from the large-scale vision-language pre-trained model and transferring it to a task-specific PRVR network.", "example": "Convert the coordinate to text: [ 0.7503 -9.1347]:"}
{"text": "Convert the coordinate to text: [ 1.8899 -4.3889]: The authors propose Semantic Information in Contrastive Learning (SemCL), an advanced pretext task where a contrast is performed between each object and its environment within a scene, thus enhancing the spatial understanding of the pretrained models.", "target": "The authors propose Semantic Information in Contrastive Learning (SemCL), an advanced pretext task where a contrast is performed between each object and its environment within a scene, thus enhancing the spatial understanding of the pretrained models.", "example": "Convert the coordinate to text: [ 1.8899 -4.3889]:"}
{"text": "Convert the coordinate to text: [-3.4277 -6.0299]: The authors propose that a pre-trained language model can be used to learn linguistic disorder patterns by focusing on reformulated natural language processing (NLP) tasks and associated linguistic patterns. They also propose the construction of digital linguistic markers that measure the overall quality in communication and the intensity of a variety of language disorders.", "target": "The authors propose that a pre-trained language model can be used to learn linguistic disorder patterns by focusing on reformulated natural language processing (NLP) tasks and associated linguistic patterns. They also propose the construction of digital linguistic markers that measure the overall quality in communication and the intensity of a variety of language disorders.", "example": "Convert the coordinate to text: [-3.4277 -6.0299]:"}
{"text": "Convert the coordinate to text: [ 6.5758 -6.8471]: The authors propose a novel method, State Sequences Prediction via Fourier Transform (SPF), which uses the frequency domain of state sequences to extract underlying patterns in time series data for efficient learning of expressive representations.", "target": "The authors propose a novel method, State Sequences Prediction via Fourier Transform (SPF), which uses the frequency domain of state sequences to extract underlying patterns in time series data for efficient learning of expressive representations.", "example": "Convert the coordinate to text: [ 6.5758 -6.8471]:"}
{"text": "Convert the coordinate to text: [  8.1291 -13.7414]: The authors present a method that maps 2D image observations to a persistent 3D scene representation using what they term as conditional neural groundplans, ground-aligned 2D feature grids.", "target": "The authors present a method that maps 2D image observations to a persistent 3D scene representation using what they term as conditional neural groundplans, ground-aligned 2D feature grids.", "example": "Convert the coordinate to text: [  8.1291 -13.7414]:"}
{"text": "Convert the coordinate to text: [13.7133 -2.5562]: The authors propose a four-layer SNN structure to solve the MI four-classification problem, an improved optimization algorithm for Ben\u2019s spiker algorithm (BSA) to convert EEG signals into spike signals, and a SNN combined with a spike long-short-time-memory (LSTM) module for four-classification tasks in MI.", "target": "The authors propose a four-layer SNN structure to solve the MI four-classification problem, an improved optimization algorithm for Ben\u2019s spiker algorithm (BSA) to convert EEG signals into spike signals, and a SNN combined with a spike long-short-time-memory (LSTM) module for four-classification tasks in MI.", "example": "Convert the coordinate to text: [13.7133 -2.5562]:"}
{"text": "Convert the coordinate to text: [ 7.4846 -6.0388]: A structure called ControlNet is introduced in this study to augment pretrained diffusion models, i.e., Stable Diffusion, with the ability to support additional task-specific conditions learned in an end-to-end way.", "target": "A structure called ControlNet is introduced in this study to augment pretrained diffusion models, i.e., Stable Diffusion, with the ability to support additional task-specific conditions learned in an end-to-end way.", "example": "Convert the coordinate to text: [ 7.4846 -6.0388]:"}
{"text": "Convert the coordinate to text: [-4.184  -2.9903]: This study presents an in-depth definition and evaluation procedures for the partial knowledge base inference scenario and also proposes two simple and effective methods to combat the NIL (unlinkable mentions) issue in these entity linking paradigms.", "target": "This study presents an in-depth definition and evaluation procedures for the partial knowledge base inference scenario and also proposes two simple and effective methods to combat the NIL (unlinkable mentions) issue in these entity linking paradigms.", "example": "Convert the coordinate to text: [-4.184  -2.9903]:"}
{"text": "Convert the coordinate to text: [-5.9895 10.7126]: The paper introduces NatCS, a multi-domain collection of spoken customer service conversations. The dataset is created using synthetic conversations between customers and agents based on natural language phenomena observed in real conversations.", "target": "The paper introduces NatCS, a multi-domain collection of spoken customer service conversations. The dataset is created using synthetic conversations between customers and agents based on natural language phenomena observed in real conversations.", "example": "Convert the coordinate to text: [-5.9895 10.7126]:"}
{"text": "Convert the coordinate to text: [-6.7402 -8.3751]: The authors introduce a multilingual punctuation-agnostic sentence segmentation method that is trained on unsegmented text in a self-supervised manner using newline characters, and includes an approach to adapt the method to specific corpus segmentation with a small number of sentence-segmented examples.", "target": "The authors introduce a multilingual punctuation-agnostic sentence segmentation method that is trained on unsegmented text in a self-supervised manner using newline characters, and includes an approach to adapt the method to specific corpus segmentation with a small number of sentence-segmented examples.", "example": "Convert the coordinate to text: [-6.7402 -8.3751]:"}
{"text": "Convert the coordinate to text: [-7.6349 -2.4169]: The primary objective of this study is to evaluate how NLP tasks are affected by disagreements in annotations, particularly the influence of demographic factors among the annotators.", "target": "The primary objective of this study is to evaluate how NLP tasks are affected by disagreements in annotations, particularly the influence of demographic factors among the annotators.", "example": "Convert the coordinate to text: [-7.6349 -2.4169]:"}
{"text": "Convert the coordinate to text: [-7.8648 -2.0746]: The authors propose a new legal annotation procedure which takes into account annotator certainty and improves it through negotiation.", "target": "The authors propose a new legal annotation procedure which takes into account annotator certainty and improves it through negotiation.", "example": "Convert the coordinate to text: [-7.8648 -2.0746]:"}
{"text": "Convert the coordinate to text: [-3.71   -9.0904]: Overall, the primary submissions by the ON-TRAC consortium for the IWSLT 2023 evaluation campaign are based on an end-to-end speech-to-text neural architecture that uses a pretrained SAMU-XLSR model as a speech encoder and an mbart model as a decoder to improve input speech representations.", "target": "Overall, the primary submissions by the ON-TRAC consortium for the IWSLT 2023 evaluation campaign are based on an end-to-end speech-to-text neural architecture that uses a pretrained SAMU-XLSR model as a speech encoder and an mbart model as a decoder to improve input speech representations.", "example": "Convert the coordinate to text: [-3.71   -9.0904]:"}
{"text": "Convert the coordinate to text: [-4.2677 -4.8815]: The authors observe that the \u21132 norm of a word's contextualised embeddings correlates with its log-frequency in the pre-training corpus. To address the underestimation problem, they propose a method to discount the \u21132 norm of a contextualised word embedding by the frequency of that word in a corpus.", "target": "The authors observe that the \u21132 norm of a word's contextualised embeddings correlates with its log-frequency in the pre-training corpus. To address the underestimation problem, they propose a method to discount the \u21132 norm of a contextualised word embedding by the frequency of that word in a corpus.", "example": "Convert the coordinate to text: [-4.2677 -4.8815]:"}
{"text": "Convert the coordinate to text: [ 2.038  -6.1249]: The authors introduce the Self-adaptive Context and Modal-interaction Modeling (SCMM) framework that models multiple contextual representations and fully utilizes each modality through the modal-interaction module. Additionally, a self-adaptive path selection module is proposed to select an appropriate path in each module and integrate the features to obtain the final representation.", "target": "The authors introduce the Self-adaptive Context and Modal-interaction Modeling (SCMM) framework that models multiple contextual representations and fully utilizes each modality through the modal-interaction module. Additionally, a self-adaptive path selection module is proposed to select an appropriate path in each module and integrate the features to obtain the final representation.", "example": "Convert the coordinate to text: [ 2.038  -6.1249]:"}
{"text": "Convert the coordinate to text: [0.3336 1.0714]: The authors propose a unified debiasing framework called Causal-Debias that removes unwanted stereotypical associations in PLMs during the fine-tuning stage, by treating bias-relevant factors as non-causal and making interventions on these factors across different demographic groups.", "target": "The authors propose a unified debiasing framework called Causal-Debias that removes unwanted stereotypical associations in PLMs during the fine-tuning stage, by treating bias-relevant factors as non-causal and making interventions on these factors across different demographic groups.", "example": "Convert the coordinate to text: [0.3336 1.0714]:"}
{"text": "Convert the coordinate to text: [10.4627 -8.9586]: The authors propose to generate realistic SR datasets for unseen degradation levels by exploring the latent space of real LR images, which allows for the production of more diverse yet realistic LR images with complex real-world artifacts.", "target": "The authors propose to generate realistic SR datasets for unseen degradation levels by exploring the latent space of real LR images, which allows for the production of more diverse yet realistic LR images with complex real-world artifacts.", "example": "Convert the coordinate to text: [10.4627 -8.9586]:"}
{"text": "Convert the coordinate to text: [  8.988  -21.6148]: The authors propose a new compact, cost-effective snapshot spectral imaging system, the Aperture Diffraction Imaging Spectrometer (ADIS), that only consists of an imaging lens with an ultra-thin orthogonal aperture mask and a mosaic filter sensor. An innovative optical design is also introduced that multiplexes each point in the object space to discrete encoding locations on the sensor.", "target": "The authors propose a new compact, cost-effective snapshot spectral imaging system, the Aperture Diffraction Imaging Spectrometer (ADIS), that only consists of an imaging lens with an ultra-thin orthogonal aperture mask and a mosaic filter sensor. An innovative optical design is also introduced that multiplexes each point in the object space to discrete encoding locations on the sensor.", "example": "Convert the coordinate to text: [  8.988  -21.6148]:"}
{"text": "Convert the coordinate to text: [ 4.2904 -4.4437]: The authors propose a Structure-broadcasting Graph Dataset Distillation (SGDD) scheme, which broadcasts the original structure information to the generation of the synthetic one, thus preventing the omission of the original structure information.", "target": "The authors propose a Structure-broadcasting Graph Dataset Distillation (SGDD) scheme, which broadcasts the original structure information to the generation of the synthetic one, thus preventing the omission of the original structure information.", "example": "Convert the coordinate to text: [ 4.2904 -4.4437]:"}
{"text": "Convert the coordinate to text: [ 4.7607 -4.8895]: The authors propose Asymmetric Contrastive Learning for Graphs (GraphACL), an approach to contrastive learning on homophilic and heterophilic graphs that considers an asymmetric view of the neighboring nodes. Unlike existing methods, it does not rely on graph augmentations and homophily assumptions.", "target": "The authors propose Asymmetric Contrastive Learning for Graphs (GraphACL), an approach to contrastive learning on homophilic and heterophilic graphs that considers an asymmetric view of the neighboring nodes. Unlike existing methods, it does not rely on graph augmentations and homophily assumptions.", "example": "Convert the coordinate to text: [ 4.7607 -4.8895]:"}
{"text": "Convert the coordinate to text: [9.3398 2.6692]: The authors propose a technique involving parameterized, positive, non-trigonometric random features for approximating Gaussian and softmax kernels, where the parameters can be optimized to minimize the variance of the approximation with a closed-form expression for the optimum.", "target": "The authors propose a technique involving parameterized, positive, non-trigonometric random features for approximating Gaussian and softmax kernels, where the parameters can be optimized to minimize the variance of the approximation with a closed-form expression for the optimum.", "example": "Convert the coordinate to text: [9.3398 2.6692]:"}
{"text": "Convert the coordinate to text: [-2.3186  5.6638]: The discipline of managing applied machine learning teams requires a mix of agile product development tool-set and a long term research oriented mindset; with an aim to connect the outcomes to significant business results.", "target": "The discipline of managing applied machine learning teams requires a mix of agile product development tool-set and a long term research oriented mindset; with an aim to connect the outcomes to significant business results.", "example": "Convert the coordinate to text: [-2.3186  5.6638]:"}
{"text": "Convert the coordinate to text: [ 4.7195 14.7429]: The paper proposes Reinforcement Learning To Pace (RLTP), a new algorithm designed to effectively manage ad delivery for preloaded ads by sequentially producing selection probabilities across the delivery period.", "target": "The paper proposes Reinforcement Learning To Pace (RLTP), a new algorithm designed to effectively manage ad delivery for preloaded ads by sequentially producing selection probabilities across the delivery period.", "example": "Convert the coordinate to text: [ 4.7195 14.7429]:"}
{"text": "Convert the coordinate to text: [ 7.665  -8.6308]: The paper proposes a dual-view correlation hybrid attention network (DCHA-Net) for robust holistic mammogram classification. The model is designed to maximize the underlying correlations between the two views, extracting and reinventing deep features from each view", "target": "The paper proposes a dual-view correlation hybrid attention network (DCHA-Net) for robust holistic mammogram classification. The model is designed to maximize the underlying correlations between the two views, extracting and reinventing deep features from each view", "example": "Convert the coordinate to text: [ 7.665  -8.6308]:"}
{"text": "Convert the coordinate to text: [-1.8247  5.0653]: The paper proposes AlerTiger, a deep-learning-based MLOps model monitoring system aimed at helping AI teams monitor their AI models' health by detecting anomalies in models' input features and output score over time.", "target": "The paper proposes AlerTiger, a deep-learning-based MLOps model monitoring system aimed at helping AI teams monitor their AI models' health by detecting anomalies in models' input features and output score over time.", "example": "Convert the coordinate to text: [-1.8247  5.0653]:"}
{"text": "Convert the coordinate to text: [-9.1805 -4.2371]: The authors propose principles for constructing and resolving ambiguity in implicit discourse relations, and based on these principles, they created a dataset in English and Egyptian Arabic that controls for semantic disambiguation.", "target": "The authors propose principles for constructing and resolving ambiguity in implicit discourse relations, and based on these principles, they created a dataset in English and Egyptian Arabic that controls for semantic disambiguation.", "example": "Convert the coordinate to text: [-9.1805 -4.2371]:"}
{"text": "Convert the coordinate to text: [-4.4682 -8.7253]: The 20th IWSLT Conference organized shared tasks addressing nine scientific challenges in spoken language translation, such as simultaneous and offline translation, automatic subtitling and dubbing, speech-to-speech translation, and formality control.", "target": "The 20th IWSLT Conference organized shared tasks addressing nine scientific challenges in spoken language translation, such as simultaneous and offline translation, automatic subtitling and dubbing, speech-to-speech translation, and formality control.", "example": "Convert the coordinate to text: [-4.4682 -8.7253]:"}
{"text": "Convert the coordinate to text: [-9.7626 -1.4361]: This paper introduces a new methodology for enhancing bullet point student notes into fully fledged summaries aimed at improving the quality of question-answer generation.", "target": "This paper introduces a new methodology for enhancing bullet point student notes into fully fledged summaries aimed at improving the quality of question-answer generation.", "example": "Convert the coordinate to text: [-9.7626 -1.4361]:"}
{"text": "Convert the coordinate to text: [0.3075 7.2921]: The authors introduce a symbolic modeling approach for the FOL operators, which emphasizes direct calculation of the intersection between geometric shapes, particularly sector-cones, in the embedding space to model the conjunction operator.", "target": "The authors introduce a symbolic modeling approach for the FOL operators, which emphasizes direct calculation of the intersection between geometric shapes, particularly sector-cones, in the embedding space to model the conjunction operator.", "example": "Convert the coordinate to text: [0.3075 7.2921]:"}
{"text": "Convert the coordinate to text: [-2.3832 -6.2677]: The authors seek to explore the predictive power of the brain encoding models in three settings: the individual performance of constituency and dependency syntactic parsing based embedding methods; their performance when controlling for basic syntactic signals; and the relative effectiveness of each syntactic embedding method when controlling for the other. The study also aims to compare the relative importance of syntactic information versus semantic information using BERT embeddings.", "target": "The authors seek to explore the predictive power of the brain encoding models in three settings: the individual performance of constituency and dependency syntactic parsing based embedding methods; their performance when controlling for basic syntactic signals; and the relative effectiveness of each syntactic embedding method when controlling for the other. The study also aims to compare the relative importance of syntactic information versus semantic information using BERT embeddings.", "example": "Convert the coordinate to text: [-2.3832 -6.2677]:"}
{"text": "Convert the coordinate to text: [ 1.7043 -5.1004]: The authors propose a novel ZSL framework, Zshot, which provides a platform allowing researchers to compare different state-of-the-art ZSL methods with standard benchmark datasets. This framework also includes readily available APIs for production under the standard SpaCy NLP pipeline.", "target": "The authors propose a novel ZSL framework, Zshot, which provides a platform allowing researchers to compare different state-of-the-art ZSL methods with standard benchmark datasets. This framework also includes readily available APIs for production under the standard SpaCy NLP pipeline.", "example": "Convert the coordinate to text: [ 1.7043 -5.1004]:"}
{"text": "Convert the coordinate to text: [ 1.317  -3.9591]: The authors propose Token-Level Self-Evolution Training (SE), a dynamic training method that focuses on learning under-explored tokens for each forward pass and adaptively regularizes training through a token-specific label smoothing approach.", "target": "The authors propose Token-Level Self-Evolution Training (SE), a dynamic training method that focuses on learning under-explored tokens for each forward pass and adaptively regularizes training through a token-specific label smoothing approach.", "example": "Convert the coordinate to text: [ 1.317  -3.9591]:"}
{"text": "Convert the coordinate to text: [ 2.0934 -7.5188]: A method named Dynamic Routing Transformer Network (DynRT-Net) is proposed, which uses dynamic paths to activate different routing transformer modules with hierarchical co-attention to adapt to cross-modal incongruity.", "target": "A method named Dynamic Routing Transformer Network (DynRT-Net) is proposed, which uses dynamic paths to activate different routing transformer modules with hierarchical co-attention to adapt to cross-modal incongruity.", "example": "Convert the coordinate to text: [ 2.0934 -7.5188]:"}
{"text": "Convert the coordinate to text: [ 4.2689 -4.0264]: This paper introduces a kernel ridge regression-based meta-learning objective, offers a computationally efficient solution to graph data distillation, and designs a graph kernel, named LiteGNTK, tailored for the dataset distillation problem.", "target": "This paper introduces a kernel ridge regression-based meta-learning objective, offers a computationally efficient solution to graph data distillation, and designs a graph kernel, named LiteGNTK, tailored for the dataset distillation problem.", "example": "Convert the coordinate to text: [ 4.2689 -4.0264]:"}
{"text": "Convert the coordinate to text: [2.0733 1.2625]: A new framework is proposed to study the value exchange in machine learning models by modeling and measuring contributions (outflows), benefits (inflows), and the balance between these two (reciprocity).", "target": "A new framework is proposed to study the value exchange in machine learning models by modeling and measuring contributions (outflows), benefits (inflows), and the balance between these two (reciprocity).", "example": "Convert the coordinate to text: [2.0733 1.2625]:"}
{"text": "Convert the coordinate to text: [  8.4888 -11.9118]: The authors propose an effective method, Point2Mask, achieving high-quality panoptic prediction using only a single random point annotation per target during training. They transform the panoptic pseudo-mask generation into an Optimal Transport (OT) problem.", "target": "The authors propose an effective method, Point2Mask, achieving high-quality panoptic prediction using only a single random point annotation per target during training. They transform the panoptic pseudo-mask generation into an Optimal Transport (OT) problem.", "example": "Convert the coordinate to text: [  8.4888 -11.9118]:"}
{"text": "Convert the coordinate to text: [ 9.084  -8.3496]: The paper puts forward the concept of a multi-input multi-output NeRF (MIMO-NeRF) that minimizes the number of MLPs executed by substituting the SISO MLP with a MIMO MLP and executing mappings collectively. The authors also suggest a self-supervised learning strategy to resolve the anticipated ambiguity that may arise due to differing color and volume densities depending on the choice of input coordinates in a group.", "target": "The paper puts forward the concept of a multi-input multi-output NeRF (MIMO-NeRF) that minimizes the number of MLPs executed by substituting the SISO MLP with a MIMO MLP and executing mappings collectively. The authors also suggest a self-supervised learning strategy to resolve the anticipated ambiguity that may arise due to differing color and volume densities depending on the choice of input coordinates in a group.", "example": "Convert the coordinate to text: [ 9.084  -8.3496]:"}
{"text": "Convert the coordinate to text: [11.783   7.6617]: The authors propose the first federated conditional stochastic optimization algorithm (FCSG) and a momentum-based version (FCSG-M) for nonconvex conditional stochastic optimization in federated learning. They also propose an accelerated version (Acc-FCSG-M) designed via variance reduction.", "target": "The authors propose the first federated conditional stochastic optimization algorithm (FCSG) and a momentum-based version (FCSG-M) for nonconvex conditional stochastic optimization in federated learning. They also propose an accelerated version (Acc-FCSG-M) designed via variance reduction.", "example": "Convert the coordinate to text: [11.783   7.6617]:"}
{"text": "Convert the coordinate to text: [-1.1517 -9.6227]: This paper proposes an Emotional Motion Memory Network (EMMN) that uses emotion embedding and lip motion to synthesise expression on a talking face, instead of relying solely on audio.", "target": "This paper proposes an Emotional Motion Memory Network (EMMN) that uses emotion embedding and lip motion to synthesise expression on a talking face, instead of relying solely on audio.", "example": "Convert the coordinate to text: [-1.1517 -9.6227]:"}
{"text": "Convert the coordinate to text: [ 12.9291 -13.8677]: To complement the reliance on annotation and deal with the issues of noisy labels and 'groupthink', HaMuCo, a self-supervised learning framework for single-view hand pose estimator, is proposed. This framework makes use of multi-view pseudo 2D labels.", "target": "To complement the reliance on annotation and deal with the issues of noisy labels and 'groupthink', HaMuCo, a self-supervised learning framework for single-view hand pose estimator, is proposed. This framework makes use of multi-view pseudo 2D labels.", "example": "Convert the coordinate to text: [ 12.9291 -13.8677]:"}
{"text": "Convert the coordinate to text: [7.7551 5.1811]: The paper proposes a human pose regression framework to examine the behavior of two established methods for simultaneous aleatoric and epistemic uncertainty estimation: maximum a-posteriori (MAP) estimation with Monte-Carlo variational inference and deep evidential regression (DER). They also introduce additional recalibration step to extract reliable confidence intervals.", "target": "The paper proposes a human pose regression framework to examine the behavior of two established methods for simultaneous aleatoric and epistemic uncertainty estimation: maximum a-posteriori (MAP) estimation with Monte-Carlo variational inference and deep evidential regression (DER). They also introduce additional recalibration step to extract reliable confidence intervals.", "example": "Convert the coordinate to text: [7.7551 5.1811]:"}
{"text": "Convert the coordinate to text: [  3.2269 -11.1187]: This paper presents a novel scene-aware label graph learning framework which learns visual label representations and their co-occurrence relationships in different scenes.", "target": "This paper presents a novel scene-aware label graph learning framework which learns visual label representations and their co-occurrence relationships in different scenes.", "example": "Convert the coordinate to text: [  3.2269 -11.1187]:"}
{"text": "Convert the coordinate to text: [ 7.0568 -4.1534]: The authors propose Secure Source-Free Domain Adaptation (SSDA), a target domain protection scheme that relies on single-shot model compression of a pre-trained source model and a novel knowledge transfer scheme with a spectral-norm-based loss penalty for target training.", "target": "The authors propose Secure Source-Free Domain Adaptation (SSDA), a target domain protection scheme that relies on single-shot model compression of a pre-trained source model and a novel knowledge transfer scheme with a spectral-norm-based loss penalty for target training.", "example": "Convert the coordinate to text: [ 7.0568 -4.1534]:"}
{"text": "Convert the coordinate to text: [-2.2188 -5.419 ]: This study investigates the morphological capabilities of ChatGPT in four typologically varied languages (English, German, Tamil, and Turkish) aimed at bringing more clarity to the model's linguistic proficiency.", "target": "This study investigates the morphological capabilities of ChatGPT in four typologically varied languages (English, German, Tamil, and Turkish) aimed at bringing more clarity to the model's linguistic proficiency.", "example": "Convert the coordinate to text: [-2.2188 -5.419 ]:"}
{"text": "Convert the coordinate to text: [-6.0644 -0.2318]: The authors argue the necessity for a measure to evaluate the degree of personalization in summarization models and propose a novel measure, EGISES, for this purpose. They also propose a generalized accuracy measure, P-Accuracy, that takes personalization into account.", "target": "The authors argue the necessity for a measure to evaluate the degree of personalization in summarization models and propose a novel measure, EGISES, for this purpose. They also propose a generalized accuracy measure, P-Accuracy, that takes personalization into account.", "example": "Convert the coordinate to text: [-6.0644 -0.2318]:"}
{"text": "Convert the coordinate to text: [3.3485 8.6865]: The authors develop a certification method for optimization problems where symmetry and dominance breaking can be easily expressed, building on the existing cutting planes proof system.", "target": "The authors develop a certification method for optimization problems where symmetry and dominance breaking can be easily expressed, building on the existing cutting planes proof system.", "example": "Convert the coordinate to text: [3.3485 8.6865]:"}
{"text": "Convert the coordinate to text: [11.0091 -5.8552]: The authors propose a novel model called DiffMD that estimates the gradient of the log density of molecular conformations directly, thereby eliminating the need for additional computations. The model uses a score-based denoising diffusion generative model to perturb molecular structure conditionally depending on atomic accelerations.", "target": "The authors propose a novel model called DiffMD that estimates the gradient of the log density of molecular conformations directly, thereby eliminating the need for additional computations. The model uses a score-based denoising diffusion generative model to perturb molecular structure conditionally depending on atomic accelerations.", "example": "Convert the coordinate to text: [11.0091 -5.8552]:"}
{"text": "Convert the coordinate to text: [ 3.9019 -3.9084]: The authors propose a self-distillation framework with meta learning (MetaSD) for knowledge graph completion with dynamic pruning, aiming to learn compressed graph embeddings and tackle the long-tail samples.", "target": "The authors propose a self-distillation framework with meta learning (MetaSD) for knowledge graph completion with dynamic pruning, aiming to learn compressed graph embeddings and tackle the long-tail samples.", "example": "Convert the coordinate to text: [ 3.9019 -3.9084]:"}
{"text": "Convert the coordinate to text: [-1.8652 -4.4933]: In this study, the authors conduct an empirical comparison of five state-of-the-art ST approaches and TAPT across NLP tasks, data sizes, and in- and out-of-domain settings.", "target": "In this study, the authors conduct an empirical comparison of five state-of-the-art ST approaches and TAPT across NLP tasks, data sizes, and in- and out-of-domain settings.", "example": "Convert the coordinate to text: [-1.8652 -4.4933]:"}
{"text": "Convert the coordinate to text: [-0.6066 -3.3966]: The authors propose ChatCoT, a tool-augmented chain-of-thought reasoning framework for chat-based LLMs. In ChatCoT, the chain-of-thought reasoning is modelled as multi-turn conversations, enabling LLMs to interact with tools or perform reasoning in a more natural way.", "target": "The authors propose ChatCoT, a tool-augmented chain-of-thought reasoning framework for chat-based LLMs. In ChatCoT, the chain-of-thought reasoning is modelled as multi-turn conversations, enabling LLMs to interact with tools or perform reasoning in a more natural way.", "example": "Convert the coordinate to text: [-0.6066 -3.3966]:"}
{"text": "Convert the coordinate to text: [-0.8067 -4.1366]: A technique has been proposed to improve multi-hop reasoning in language models by utilizing random walks over structured knowledge graphs and use of soft prompts.", "target": "A technique has been proposed to improve multi-hop reasoning in language models by utilizing random walks over structured knowledge graphs and use of soft prompts.", "example": "Convert the coordinate to text: [-0.8067 -4.1366]:"}
{"text": "Convert the coordinate to text: [-4.1918 11.7781]: Recent advances in artificial intelligence (AI) can be leveraged to optimize many data preparation tasks. The AI for data preparation (AI4DP) model should capture real-world knowledge, be adaptable to new datasets/tasks, and efficiently explore the large space of possible data preparation pipelines.", "target": "Recent advances in artificial intelligence (AI) can be leveraged to optimize many data preparation tasks. The AI for data preparation (AI4DP) model should capture real-world knowledge, be adaptable to new datasets/tasks, and efficiently explore the large space of possible data preparation pipelines.", "example": "Convert the coordinate to text: [-4.1918 11.7781]:"}
{"text": "Convert the coordinate to text: [-2.9848  3.9472]: The authors propose the first generation-based model for shilling attacks against RBRSs. A fake review generator is learned through reinforcement learning, which maliciously promotes items by forcing prediction shifts after adding generated reviews to the system.", "target": "The authors propose the first generation-based model for shilling attacks against RBRSs. A fake review generator is learned through reinforcement learning, which maliciously promotes items by forcing prediction shifts after adding generated reviews to the system.", "example": "Convert the coordinate to text: [-2.9848  3.9472]:"}
{"text": "Convert the coordinate to text: [-7.1577  6.2414]: The authors provide a robust measure of social media language's distinctiveness in terms of token distribution and rate of linguistic shift and introduce a new benchmark for Social MedIa Language Evaluation (SMILE) covering four social media platforms and eleven tasks.", "target": "The authors provide a robust measure of social media language's distinctiveness in terms of token distribution and rate of linguistic shift and introduce a new benchmark for Social MedIa Language Evaluation (SMILE) covering four social media platforms and eleven tasks.", "example": "Convert the coordinate to text: [-7.1577  6.2414]:"}
{"text": "Convert the coordinate to text: [-6.0116 10.4441]: The researchers have constructed SafeConv, a new dataset specifically designed for investigating conversational safety. Not only does it feature utterance-level safety labels, but it also provides unsafe spans in utterances and safe alternative responses when unsafe behavior is detected.", "target": "The researchers have constructed SafeConv, a new dataset specifically designed for investigating conversational safety. Not only does it feature utterance-level safety labels, but it also provides unsafe spans in utterances and safe alternative responses when unsafe behavior is detected.", "example": "Convert the coordinate to text: [-6.0116 10.4441]:"}
{"text": "Convert the coordinate to text: [-6.069   9.8942]: The paper introduces a set of dialog acts for studying decision-making mechanisms in large groups and presents a new annotated dataset based on real-world data from the public mail-archives of the Internet Engineering Task Force.", "target": "The paper introduces a set of dialog acts for studying decision-making mechanisms in large groups and presents a new annotated dataset based on real-world data from the public mail-archives of the Internet Engineering Task Force.", "example": "Convert the coordinate to text: [-6.069   9.8942]:"}
{"text": "Convert the coordinate to text: [-1.3959  0.0928]: The authors of the paper introduced an approach that combines data enhancement using dropout fed to the Sup-SimCSE-RoBERTa model, raw data input to the XLNet model, and combined outputs of these two for better results in sexism detection.", "target": "The authors of the paper introduced an approach that combines data enhancement using dropout fed to the Sup-SimCSE-RoBERTa model, raw data input to the XLNet model, and combined outputs of these two for better results in sexism detection.", "example": "Convert the coordinate to text: [-1.3959  0.0928]:"}
{"text": "Convert the coordinate to text: [ 4.4496 -1.4231]: This paper proposes SaFER, a fine-tuning framework for BERT-based text classifiers, designed to combat label noise without needing access to any clean data for training or validation. It uses a label-agnostic early-stopping strategy and self-supervised learning.", "target": "This paper proposes SaFER, a fine-tuning framework for BERT-based text classifiers, designed to combat label noise without needing access to any clean data for training or validation. It uses a label-agnostic early-stopping strategy and self-supervised learning.", "example": "Convert the coordinate to text: [ 4.4496 -1.4231]:"}
{"text": "Convert the coordinate to text: [-16.126    0.1092]: The authors propose E-partition, a data-driven delivery zone partition framework that aims for equitable workload assignment in last-mile logistics. The E-partition model uses a learning-based workload prediction model to estimate service time considering unseen courier-zone matching scenarios, and applies a delivery zone partition algorithm to iteratively optimize couriers' core-AOI (area of interest) generation and AOI assignment.", "target": "The authors propose E-partition, a data-driven delivery zone partition framework that aims for equitable workload assignment in last-mile logistics. The E-partition model uses a learning-based workload prediction model to estimate service time considering unseen courier-zone matching scenarios, and applies a delivery zone partition algorithm to iteratively optimize couriers' core-AOI (area of interest) generation and AOI assignment.", "example": "Convert the coordinate to text: [-16.126    0.1092]:"}
{"text": "Convert the coordinate to text: [ 3.9303 -0.6825]: The authors propose a framework to estimate model accuracy on unlabeled target data, without needing access to source data. They measure the disagreement rate between the source hypothesis and the target pseudo-labeling function, which is adapted from the source hypothesis, and mitigate the impact of erroneous pseudo-labels by employing adaptive adversarial perturbation on the input of the target model.", "target": "The authors propose a framework to estimate model accuracy on unlabeled target data, without needing access to source data. They measure the disagreement rate between the source hypothesis and the target pseudo-labeling function, which is adapted from the source hypothesis, and mitigate the impact of erroneous pseudo-labels by employing adaptive adversarial perturbation on the input of the target model.", "example": "Convert the coordinate to text: [ 3.9303 -0.6825]:"}
{"text": "Convert the coordinate to text: [ 4.4323 -4.0373]: This paper proposes Self-Decoupling and Ensemble Distillation for Efficient Segmentation (SDES). The goal of SDES is to alleviate the limitations of Self-KD by using a decoupled prediction ensemble distillation (DPED) algorithm that generates reliable soft-labels with multiple expert decoders and a decoupled feature ensemble distillation (DFED) mechanism to utilize important channel-wise feature maps for encoder learning.", "target": "This paper proposes Self-Decoupling and Ensemble Distillation for Efficient Segmentation (SDES). The goal of SDES is to alleviate the limitations of Self-KD by using a decoupled prediction ensemble distillation (DPED) algorithm that generates reliable soft-labels with multiple expert decoders and a decoupled feature ensemble distillation (DFED) mechanism to utilize important channel-wise feature maps for encoder learning.", "example": "Convert the coordinate to text: [ 4.4323 -4.0373]:"}
{"text": "Convert the coordinate to text: [  1.7395 -10.3797]: The fundamental idea of this study is the introduction of ViLLA, a model designed to capture fine-grained region-attribute relationships from complex datasets. ViLLA comprises a lightweight, self-supervised mapping model to decompose image-text samples into region-attribute pairs and a contrastive VLM to learn representations from these pairs.", "target": "The fundamental idea of this study is the introduction of ViLLA, a model designed to capture fine-grained region-attribute relationships from complex datasets. ViLLA comprises a lightweight, self-supervised mapping model to decompose image-text samples into region-attribute pairs and a contrastive VLM to learn representations from these pairs.", "example": "Convert the coordinate to text: [  1.7395 -10.3797]:"}
{"text": "Convert the coordinate to text: [-1.1947 -8.2926]: This study aims to investigate the transferability of visually grounded grammar induction by extending VC-PCFG to work across text domains in a zero-shot transfer learning setting.", "target": "This study aims to investigate the transferability of visually grounded grammar induction by extending VC-PCFG to work across text domains in a zero-shot transfer learning setting.", "example": "Convert the coordinate to text: [-1.1947 -8.2926]:"}
{"text": "Convert the coordinate to text: [ 2.1485 13.7087]: The authors model the strategic interactions between the defender and dynamic attackers in FL as a minimax game and propose an interactive defense mechanism called FedGame.", "target": "The authors model the strategic interactions between the defender and dynamic attackers in FL as a minimax game and propose an interactive defense mechanism called FedGame.", "example": "Convert the coordinate to text: [ 2.1485 13.7087]:"}
{"text": "Convert the coordinate to text: [-0.9413 -3.6254]: The authors propose ReasoningLM, a more capable Pre-trained Language Model that can directly support subgraph reasoning for KGQA. They introduce a subgraph-aware self-attention mechanism to mimic the GNN for performing structured reasoning and adopt an adaptation tuning strategy for model parameters.", "target": "The authors propose ReasoningLM, a more capable Pre-trained Language Model that can directly support subgraph reasoning for KGQA. They introduce a subgraph-aware self-attention mechanism to mimic the GNN for performing structured reasoning and adopt an adaptation tuning strategy for model parameters.", "example": "Convert the coordinate to text: [-0.9413 -3.6254]:"}
{"text": "Convert the coordinate to text: [-3.2859 -6.9325]: The study introduces a new multilingual pretraining corpus for 16 African languages, developed by carefully auditing existing pretraining corpora and rectifying quality issues, and pretrains a new T5-based model on this dataset.", "target": "The study introduces a new multilingual pretraining corpus for 16 African languages, developed by carefully auditing existing pretraining corpora and rectifying quality issues, and pretrains a new T5-based model on this dataset.", "example": "Convert the coordinate to text: [-3.2859 -6.9325]:"}
{"text": "Convert the coordinate to text: [ 2.7137 -0.186 ]: We tackle this infrequently-studied issue by minimizing the Active Learning error, which we formally define and separate into valid query error and invalid query error. We propose a contrastive Active Learning (AL) framework, ConAL, that learns the semantics and distinctiveness of instances using contrastive techniques, thereby reducing invalid and valid query errors.", "target": "We tackle this infrequently-studied issue by minimizing the Active Learning error, which we formally define and separate into valid query error and invalid query error. We propose a contrastive Active Learning (AL) framework, ConAL, that learns the semantics and distinctiveness of instances using contrastive techniques, thereby reducing invalid and valid query errors.", "example": "Convert the coordinate to text: [ 2.7137 -0.186 ]:"}
{"text": "Convert the coordinate to text: [15.4893  0.0925]: The authors propose Differentiable Optimized Product Quantization method (DOPQ), a solution that addresses the shortfalls of the existing approaches. DOPQ projects data into multiple orthogonal spaces to create diverse views and learns each codebook with one view, guaranteeing diverse codebooks. Rather than using differentiable relaxation, DOPQ optimizes the loss based on direct loss minimization to reduce the gradient bias problem.", "target": "The authors propose Differentiable Optimized Product Quantization method (DOPQ), a solution that addresses the shortfalls of the existing approaches. DOPQ projects data into multiple orthogonal spaces to create diverse views and learns each codebook with one view, guaranteeing diverse codebooks. Rather than using differentiable relaxation, DOPQ optimizes the loss based on direct loss minimization to reduce the gradient bias problem.", "example": "Convert the coordinate to text: [15.4893  0.0925]:"}
{"text": "Convert the coordinate to text: [-3.0952 -7.6967]: The authors propose the use of large language models (LLMs) to identify speaker labels from transcribed text, eliminating existing challenges in the speaker diarization process.", "target": "The authors propose the use of large language models (LLMs) to identify speaker labels from transcribed text, eliminating existing challenges in the speaker diarization process.", "example": "Convert the coordinate to text: [-3.0952 -7.6967]:"}
{"text": "Convert the coordinate to text: [-1.7295 -2.8925]: The authors introduce a new dataset, FactKG: Fact Verification via Reasoning on Knowledge Graphs, which leverages the strength of KGs in fact verification. The dataset comprises 108k natural language claims involving five types of reasoning - One-hop, Conjunction, Existence, Multi-hop, and Negation, and includes various linguistic patterns for practicality.", "target": "The authors introduce a new dataset, FactKG: Fact Verification via Reasoning on Knowledge Graphs, which leverages the strength of KGs in fact verification. The dataset comprises 108k natural language claims involving five types of reasoning - One-hop, Conjunction, Existence, Multi-hop, and Negation, and includes various linguistic patterns for practicality.", "example": "Convert the coordinate to text: [-1.7295 -2.8925]:"}
{"text": "Convert the coordinate to text: [-10.3741   3.2818]: The authors propose a cross-media retrieval system that integrates three search characteristics of the Web (textual content-based retrieval), SNS (timeliness), and map (spatial distance-aware retrieval) by generating and applying relevant suggestions to users based on analyzed similarities among retrieval results.", "target": "The authors propose a cross-media retrieval system that integrates three search characteristics of the Web (textual content-based retrieval), SNS (timeliness), and map (spatial distance-aware retrieval) by generating and applying relevant suggestions to users based on analyzed similarities among retrieval results.", "example": "Convert the coordinate to text: [-10.3741   3.2818]:"}
{"text": "Convert the coordinate to text: [-4.9143  8.679 ]: The authors introduce MediSage, an AI decision support assistant that utilizes a knowledge graph integrating general clinical resources and recent EHR data to simplify the interaction with EHRs and provide step-by-step reasoning support in healthcare scenarios.", "target": "The authors introduce MediSage, an AI decision support assistant that utilizes a knowledge graph integrating general clinical resources and recent EHR data to simplify the interaction with EHRs and provide step-by-step reasoning support in healthcare scenarios.", "example": "Convert the coordinate to text: [-4.9143  8.679 ]:"}
{"text": "Convert the coordinate to text: [-2.0831 -8.7479]: The authors propose to solve the issue by reframing the standard greedy autoregressive decoding of MT with a parallel formulation leveraging Jacobi and Gauss-Seidel fixed-point iteration methods for fast inference, which allows existing models to be sped up without requiring training or modifications.", "target": "The authors propose to solve the issue by reframing the standard greedy autoregressive decoding of MT with a parallel formulation leveraging Jacobi and Gauss-Seidel fixed-point iteration methods for fast inference, which allows existing models to be sped up without requiring training or modifications.", "example": "Convert the coordinate to text: [-2.0831 -8.7479]:"}
{"text": "Convert the coordinate to text: [ 7.0342 11.0934]: The paper presents Bayesian red teaming (BRT), a novel approach to black-box red teaming that uses Bayesian optimization to iteratively identify various positive test cases that lead to model failures by using a predefined user input pool and past evaluations.", "target": "The paper presents Bayesian red teaming (BRT), a novel approach to black-box red teaming that uses Bayesian optimization to iteratively identify various positive test cases that lead to model failures by using a predefined user input pool and past evaluations.", "example": "Convert the coordinate to text: [ 7.0342 11.0934]:"}
{"text": "Convert the coordinate to text: [-5.6876 11.4697]: The authors propose AI Coach Assist, a system that uses pre-trained transformer-based language models to determine if a call is coachable based on the quality assurance questions asked by contact center managers or supervisors.", "target": "The authors propose AI Coach Assist, a system that uses pre-trained transformer-based language models to determine if a call is coachable based on the quality assurance questions asked by contact center managers or supervisors.", "example": "Convert the coordinate to text: [-5.6876 11.4697]:"}
{"text": "Convert the coordinate to text: [-7.2211 -6.0707]: The authors propose two corpora consisting of excerpts from two novels with an informal narration style in German, providing fine-grained multi-layer annotations of animate referents and prominence-lending features, and including annotations of intra-sentential segments.", "target": "The authors propose two corpora consisting of excerpts from two novels with an informal narration style in German, providing fine-grained multi-layer annotations of animate referents and prominence-lending features, and including annotations of intra-sentential segments.", "example": "Convert the coordinate to text: [-7.2211 -6.0707]:"}
{"text": "Convert the coordinate to text: [-2.1021 -5.4688]: The authors propose the application of large language models, specifically GPT-3.5 and GPT-4, to automate the scoring of short essay responses written by L2 English learners in high-stakes language assessments.", "target": "The authors propose the application of large language models, specifically GPT-3.5 and GPT-4, to automate the scoring of short essay responses written by L2 English learners in high-stakes language assessments.", "example": "Convert the coordinate to text: [-2.1021 -5.4688]:"}
{"text": "Convert the coordinate to text: [-0.7112 -4.7655]: The authors propose a sequence labeling enhanced generative model. This model encodes the dependency between aspect and opinion into two bidirectional templates and introduces a marker-oriented sequence labeling module to improve generative model's ability to handle complex structures.", "target": "The authors propose a sequence labeling enhanced generative model. This model encodes the dependency between aspect and opinion into two bidirectional templates and introduces a marker-oriented sequence labeling module to improve generative model's ability to handle complex structures.", "example": "Convert the coordinate to text: [-0.7112 -4.7655]:"}
{"text": "Convert the coordinate to text: [-0.0936 -4.4896]: The paper proposes a new DST framework based on the value types of dialogue slots. The authors introduce a method to extract token types of each conversation turn and to refine the attention mechanism considering the value type information between the slot and the conversation history.", "target": "The paper proposes a new DST framework based on the value types of dialogue slots. The authors introduce a method to extract token types of each conversation turn and to refine the attention mechanism considering the value type information between the slot and the conversation history.", "example": "Convert the coordinate to text: [-0.0936 -4.4896]:"}
{"text": "Convert the coordinate to text: [-3.3927 -2.9706]: The authors propose TaG, a novel table-to-graph generation model for joint extraction of entities and relations at the document-level. The model induces a latent graph among mentions with different types of edges indicating different task information.", "target": "The authors propose TaG, a novel table-to-graph generation model for joint extraction of entities and relations at the document-level. The model induces a latent graph among mentions with different types of edges indicating different task information.", "example": "Convert the coordinate to text: [-3.3927 -2.9706]:"}
{"text": "Convert the coordinate to text: [ 1.0306 -3.1503]: The study proposes the Learning Behavior-oriented Knowledge Tracing (LBKT) model, which explicitly explores the effects of learning behavior on learners' knowledge states. The model separately estimates the effects of different behaviors on knowledge acquisition, then assesses combined effects of multiple behaviors by capturing their complex dependency patterns.", "target": "The study proposes the Learning Behavior-oriented Knowledge Tracing (LBKT) model, which explicitly explores the effects of learning behavior on learners' knowledge states. The model separately estimates the effects of different behaviors on knowledge acquisition, then assesses combined effects of multiple behaviors by capturing their complex dependency patterns.", "example": "Convert the coordinate to text: [ 1.0306 -3.1503]:"}
{"text": "Convert the coordinate to text: [ 8.3207 -4.6648]: The study proposes a robust NN training approach that begins with a small amount of seed training data and uses iterative feedback to generate additional data in regions where the model makes poor predictions.", "target": "The study proposes a robust NN training approach that begins with a small amount of seed training data and uses iterative feedback to generate additional data in regions where the model makes poor predictions.", "example": "Convert the coordinate to text: [ 8.3207 -4.6648]:"}
{"text": "Convert the coordinate to text: [12.8577 -4.7265]: The authors propose a novel, query-efficient, curvature-aware geometric decision-based black-box attack (CGBA) that conducts boundary search along a semicircular path on a restricted 2D plane to successfully find a boundary point irrespective of the boundary curvature.", "target": "The authors propose a novel, query-efficient, curvature-aware geometric decision-based black-box attack (CGBA) that conducts boundary search along a semicircular path on a restricted 2D plane to successfully find a boundary point irrespective of the boundary curvature.", "example": "Convert the coordinate to text: [12.8577 -4.7265]:"}
{"text": "Convert the coordinate to text: [ 11.2409 -13.2758]: The authors propose DECO, a novel 3D contact detector that uses both body-part-driven and scene-context-driven attention to estimate vertex-level contact on the SMPL body. The aim is to infer dense, 3D contact between the full body surface and objects in arbitrary images.", "target": "The authors propose DECO, a novel 3D contact detector that uses both body-part-driven and scene-context-driven attention to estimate vertex-level contact on the SMPL body. The aim is to infer dense, 3D contact between the full body surface and objects in arbitrary images.", "example": "Convert the coordinate to text: [ 11.2409 -13.2758]:"}
{"text": "Convert the coordinate to text: [11.5732  7.9324]: The authors introduce FL algorithms (FedSGDA+ and FedSGDA-M) for federated nonconvex minimax optimization problems.", "target": "The authors introduce FL algorithms (FedSGDA+ and FedSGDA-M) for federated nonconvex minimax optimization problems.", "example": "Convert the coordinate to text: [11.5732  7.9324]:"}
{"text": "Convert the coordinate to text: [11.3189 -2.654 ]: The authors identify a problem in GATs with standard initialization, where a significant portion of parameters struggles to change during training, especially so in deeper networks. They propose a balancing initialization scheme as a solution.", "target": "The authors identify a problem in GATs with standard initialization, where a significant portion of parameters struggles to change during training, especially so in deeper networks. They propose a balancing initialization scheme as a solution.", "example": "Convert the coordinate to text: [11.3189 -2.654 ]:"}
{"text": "Convert the coordinate to text: [ 4.5141 14.2455]: The authors propose GAIT, a framework that uses Deep Reinforcement Learning (DRL) to automatically control a camera to generate a sequence of aesthetically meaningful views for synthetic 3D indoor scenes.", "target": "The authors propose GAIT, a framework that uses Deep Reinforcement Learning (DRL) to automatically control a camera to generate a sequence of aesthetically meaningful views for synthetic 3D indoor scenes.", "example": "Convert the coordinate to text: [ 4.5141 14.2455]:"}
{"text": "Convert the coordinate to text: [ 3.9957 -1.5986]: The paper proposes Confidence-aware Pseudo-label Learning (CPL), a method that uses both uni-modal and cross-modal pre-trained models for visual grounding and addresses model drawbacks by generating multiple pseudo language queries for each region proposal.", "target": "The paper proposes Confidence-aware Pseudo-label Learning (CPL), a method that uses both uni-modal and cross-modal pre-trained models for visual grounding and addresses model drawbacks by generating multiple pseudo language queries for each region proposal.", "example": "Convert the coordinate to text: [ 3.9957 -1.5986]:"}
{"text": "Convert the coordinate to text: [11.9871 -5.6351]: This study proposes a novel image anonymization procedure that enables existing classifiers to become class decision invariant, meaning they don't change their decisions, on anonymized images without needing to modify the classification models.", "target": "This study proposes a novel image anonymization procedure that enables existing classifiers to become class decision invariant, meaning they don't change their decisions, on anonymized images without needing to modify the classification models.", "example": "Convert the coordinate to text: [11.9871 -5.6351]:"}
{"text": "Convert the coordinate to text: [ 5.3358 -4.8949]: A new problem, GNN model evaluation, is studied, which is aimed at assessing the performance of a specific GNN model trained on labeled and observed graphs, by precisely estimating its performance on unseen graphs without labels.", "target": "A new problem, GNN model evaluation, is studied, which is aimed at assessing the performance of a specific GNN model trained on labeled and observed graphs, by precisely estimating its performance on unseen graphs without labels.", "example": "Convert the coordinate to text: [ 5.3358 -4.8949]:"}
{"text": "Convert the coordinate to text: [ 8.7992 -6.1442]: The authors present GraphSplineNets, a new deep-learning method designed to speed up the forecasting of physical systems by reducing the grid size and number of iteration steps of deep surrogate models.", "target": "The authors present GraphSplineNets, a new deep-learning method designed to speed up the forecasting of physical systems by reducing the grid size and number of iteration steps of deep surrogate models.", "example": "Convert the coordinate to text: [ 8.7992 -6.1442]:"}
{"text": "Convert the coordinate to text: [ 9.976 -3.772]: The authors propose a new projection-based fine-tuning algorithm, Fast Trainable Projection (FTP), which facilitates efficient learning of per-layer projection constraints.", "target": "The authors propose a new projection-based fine-tuning algorithm, Fast Trainable Projection (FTP), which facilitates efficient learning of per-layer projection constraints.", "example": "Convert the coordinate to text: [ 9.976 -3.772]:"}
{"text": "Convert the coordinate to text: [ 0.5568 11.8686]: The paper proposes a new active-learning approach for modeling the capabilities of black-box AI systems that can plan and act in stochastic settings, enabling a high-level understanding of what the AI system can and cannot do.", "target": "The paper proposes a new active-learning approach for modeling the capabilities of black-box AI systems that can plan and act in stochastic settings, enabling a high-level understanding of what the AI system can and cannot do.", "example": "Convert the coordinate to text: [ 0.5568 11.8686]:"}
{"text": "Convert the coordinate to text: [-0.7909 -5.0635]: The authors propose Co 2 PT, an efficient and effective debias-while-prompt tuning method for mitigating biases via counterfactual contrastive prompt tuning on downstream tasks.", "target": "The authors propose Co 2 PT, an efficient and effective debias-while-prompt tuning method for mitigating biases via counterfactual contrastive prompt tuning on downstream tasks.", "example": "Convert the coordinate to text: [-0.7909 -5.0635]:"}
{"text": "Convert the coordinate to text: [-15.697   6.011]: The authors propose FS-Real, a scalable prototyping system for real-world cross-device FL which is designed to support heterogeneous device runtime and includes parallelism and robustness enhanced FL server. FS-Real also provides implementations and is extendable for advanced FL utility features such as personalization, communication compression and asynchronous aggregation.", "target": "The authors propose FS-Real, a scalable prototyping system for real-world cross-device FL which is designed to support heterogeneous device runtime and includes parallelism and robustness enhanced FL server. FS-Real also provides implementations and is extendable for advanced FL utility features such as personalization, communication compression and asynchronous aggregation.", "example": "Convert the coordinate to text: [-15.697   6.011]:"}
{"text": "Convert the coordinate to text: [-10.7156  -2.0569]: The researchers present xPQA, a large-scale annotated cross-lingual PQA dataset in 12 languages intended to study the industrial task of producing accurate answers to customer questions across languages.", "target": "The researchers present xPQA, a large-scale annotated cross-lingual PQA dataset in 12 languages intended to study the industrial task of producing accurate answers to customer questions across languages.", "example": "Convert the coordinate to text: [-10.7156  -2.0569]:"}
{"text": "Convert the coordinate to text: [ 4.5541 -4.6706]: The paper proposes the Adaptive Graph Contrastive Learning (AdaptiveGCL) framework, which uses two trainable generators - a graph generative model and a graph denoising model, to create adaptive contrastive views instead of relying on selected data augmentation techniques.", "target": "The paper proposes the Adaptive Graph Contrastive Learning (AdaptiveGCL) framework, which uses two trainable generators - a graph generative model and a graph denoising model, to create adaptive contrastive views instead of relying on selected data augmentation techniques.", "example": "Convert the coordinate to text: [ 4.5541 -4.6706]:"}
{"text": "Convert the coordinate to text: [ 6.6981 -4.3879]: The authors propose TADA, a task-agnostic domain adaptation method for transformers that is modular, parameter-efficient, and data-efficient, offering an alternative to full domain-adaptive pre-training and adapters for domain adaptation.", "target": "The authors propose TADA, a task-agnostic domain adaptation method for transformers that is modular, parameter-efficient, and data-efficient, offering an alternative to full domain-adaptive pre-training and adapters for domain adaptation.", "example": "Convert the coordinate to text: [ 6.6981 -4.3879]:"}
{"text": "Convert the coordinate to text: [-9.0582 -2.9098]: The authors put forth NeuroX, an open-source toolkit designed to facilitate neuron analysis of natural language processing models which unifies various interpretation methods under one API.", "target": "The authors put forth NeuroX, an open-source toolkit designed to facilitate neuron analysis of natural language processing models which unifies various interpretation methods under one API.", "example": "Convert the coordinate to text: [-9.0582 -2.9098]:"}
{"text": "Convert the coordinate to text: [ 0.3507 -7.1309]: This paper introduces Modular Transformers, a modularized encoder-decoder framework for flexible sequence-to-sequence model compression. Modular Transformers replace two or more consecutive layers in the original model with modularized layers that have the same function via module replacing and knowledge distillation.", "target": "This paper introduces Modular Transformers, a modularized encoder-decoder framework for flexible sequence-to-sequence model compression. Modular Transformers replace two or more consecutive layers in the original model with modularized layers that have the same function via module replacing and knowledge distillation.", "example": "Convert the coordinate to text: [ 0.3507 -7.1309]:"}
{"text": "Convert the coordinate to text: [12.8802 -4.9356]: The authors introduce a prompt-based learning approach, termed as PromptAttack, to automatically generate adversarial examples for probing DST models. Its key features include needing only the output of the DST without needing model parameters and the ability to generate natural language utterances targeting any DST.", "target": "The authors introduce a prompt-based learning approach, termed as PromptAttack, to automatically generate adversarial examples for probing DST models. Its key features include needing only the output of the DST without needing model parameters and the ability to generate natural language utterances targeting any DST.", "example": "Convert the coordinate to text: [12.8802 -4.9356]:"}
{"text": "Convert the coordinate to text: [-0.104  13.8269]: The authors propose to build a novel dataset for studying language use in bargaining through behavioral labs, involving both audio negotiation and a control setting where participants negotiate through purely written numeric offers.", "target": "The authors propose to build a novel dataset for studying language use in bargaining through behavioral labs, involving both audio negotiation and a control setting where participants negotiate through purely written numeric offers.", "example": "Convert the coordinate to text: [-0.104  13.8269]:"}
{"text": "Convert the coordinate to text: [6.7171 9.589 ]: The authors propose the explore-then-commit (EtC) and adaptive explore-then-commit (AEtC) algorithms, countering previous approach by eschewing the imposition of sparsity on the coefficients and instead relying on recent findings on overparameterized models.", "target": "The authors propose the explore-then-commit (EtC) and adaptive explore-then-commit (AEtC) algorithms, countering previous approach by eschewing the imposition of sparsity on the coefficients and instead relying on recent findings on overparameterized models.", "example": "Convert the coordinate to text: [6.7171 9.589 ]:"}
{"text": "Convert the coordinate to text: [6.6272 3.4914]: The paper suggests that good tokenizers lead to efficient channel usage which can be quantified in information-theoretic terms as the ratio of the Shannon entropy to the maximum possible entropy of the token distribution. The authors propose using R'enyi entropy to define efficiency as it penalizes distributions with either very high or low-frequency tokens.", "target": "The paper suggests that good tokenizers lead to efficient channel usage which can be quantified in information-theoretic terms as the ratio of the Shannon entropy to the maximum possible entropy of the token distribution. The authors propose using R'enyi entropy to define efficiency as it penalizes distributions with either very high or low-frequency tokens.", "example": "Convert the coordinate to text: [6.6272 3.4914]:"}
{"text": "Convert the coordinate to text: [-1.3857  0.1331]: The authors present a system for sexism detection that leverages RoBERTa as the base model, pre-training it on domain-specific data. They adopt Unsupervised Data Augmentation (UDA), employing the Easy Data Augmentation (EDA) method for noising operations in consistency training.", "target": "The authors present a system for sexism detection that leverages RoBERTa as the base model, pre-training it on domain-specific data. They adopt Unsupervised Data Augmentation (UDA), employing the Easy Data Augmentation (EDA) method for noising operations in consistency training.", "example": "Convert the coordinate to text: [-1.3857  0.1331]:"}
{"text": "Convert the coordinate to text: [11.8619 -8.6026]: The paper introduces 'style embedding intervention', a novel approach that learns a unique style-vector for each input token, theorizing it to be more capable in learning specific input tokens to modify during decoding for formality control.", "target": "The paper introduces 'style embedding intervention', a novel approach that learns a unique style-vector for each input token, theorizing it to be more capable in learning specific input tokens to modify during decoding for formality control.", "example": "Convert the coordinate to text: [11.8619 -8.6026]:"}
{"text": "Convert the coordinate to text: [-0.1747 -5.013 ]: The authors propose a Split-Parsing Method (SPM) for joint multiple intent detection and slot filling, which is a two-stage method that first splits an input sentence into multiple single-intent sub-sentences and then applies a joint single intent detection and slot filling model to parse each sub-sentence recurrently.", "target": "The authors propose a Split-Parsing Method (SPM) for joint multiple intent detection and slot filling, which is a two-stage method that first splits an input sentence into multiple single-intent sub-sentences and then applies a joint single intent detection and slot filling model to parse each sub-sentence recurrently.", "example": "Convert the coordinate to text: [-0.1747 -5.013 ]:"}
{"text": "Convert the coordinate to text: [-0.2551  6.5721]: The authors propose three simple augmentations for increasing the quality of existing rule sets, including transforming rules to their abductive forms, generating equivalent rules using inverse forms of constituent relations, and suggesting new rules through random walks.", "target": "The authors propose three simple augmentations for increasing the quality of existing rule sets, including transforming rules to their abductive forms, generating equivalent rules using inverse forms of constituent relations, and suggesting new rules through random walks.", "example": "Convert the coordinate to text: [-0.2551  6.5721]:"}
{"text": "Convert the coordinate to text: [-2.9329 -7.1877]: This study proposes a new adapter-based framework that leverages state-of-the-art multilingual models such as mBART and T5 to facilitate efficient zero-shot and few-shot transfer of code-switched responses by learning task-specific and language-specific representations.", "target": "This study proposes a new adapter-based framework that leverages state-of-the-art multilingual models such as mBART and T5 to facilitate efficient zero-shot and few-shot transfer of code-switched responses by learning task-specific and language-specific representations.", "example": "Convert the coordinate to text: [-2.9329 -7.1877]:"}
{"text": "Convert the coordinate to text: [ 2.7615 -8.6636]: This paper introduces the first DETR framework for Monocular DEtection with a depth-guided TRansformer, called MonoDETR. It modifies the transformer to be depth-aware and guides the whole detection process by contextual depth cues while still capturing object appearances with a visual encoder.", "target": "This paper introduces the first DETR framework for Monocular DEtection with a depth-guided TRansformer, called MonoDETR. It modifies the transformer to be depth-aware and guides the whole detection process by contextual depth cues while still capturing object appearances with a visual encoder.", "example": "Convert the coordinate to text: [ 2.7615 -8.6636]:"}
{"text": "Convert the coordinate to text: [1.6188 2.5608]: The authors suggest the importance of modeling confounders in discovering causal generative factors, and introduce the Confounded-Disentanglement (C-Disentanglement) framework that incorporates the inductive bias of confounder via labels from domain expertise.", "target": "The authors suggest the importance of modeling confounders in discovering causal generative factors, and introduce the Confounded-Disentanglement (C-Disentanglement) framework that incorporates the inductive bias of confounder via labels from domain expertise.", "example": "Convert the coordinate to text: [1.6188 2.5608]:"}
{"text": "Convert the coordinate to text: [2.691  5.1967]: This paper systematically analyzes how random walk on different orders of simplicial complexes (SC) facilitates GNNs in their theoretical expressivity. The authors also introduce the concept of inter-level random walk as a way to unify a wide range of simplicial networks.", "target": "This paper systematically analyzes how random walk on different orders of simplicial complexes (SC) facilitates GNNs in their theoretical expressivity. The authors also introduce the concept of inter-level random walk as a way to unify a wide range of simplicial networks.", "example": "Convert the coordinate to text: [2.691  5.1967]:"}
{"text": "Convert the coordinate to text: [ 2.6872 -0.5822]: This paper proposes a novel, efficient, and self-supervised method for discovering unknown categories at test time by conceiving categories as optimal solutions to well-defined problems. This method is characterized by the assignment of minimum length category codes to individual data instances.", "target": "This paper proposes a novel, efficient, and self-supervised method for discovering unknown categories at test time by conceiving categories as optimal solutions to well-defined problems. This method is characterized by the assignment of minimum length category codes to individual data instances.", "example": "Convert the coordinate to text: [ 2.6872 -0.5822]:"}
{"text": "Convert the coordinate to text: [12.1412 -4.3298]: The paper suggests that learnability suggests robust learnability in cases where the adversary can only perform additive contamination (and under Huber contamination), but if the adversary is allowed to do subtractive contamination, learnability does not necessitate robust learnability.", "target": "The paper suggests that learnability suggests robust learnability in cases where the adversary can only perform additive contamination (and under Huber contamination), but if the adversary is allowed to do subtractive contamination, learnability does not necessitate robust learnability.", "example": "Convert the coordinate to text: [12.1412 -4.3298]:"}
{"text": "Convert the coordinate to text: [-3.7645 -3.4188]: The authors introduce the ENtity-aware article GeneratIoN and rEtrieval (ENGINE) framework, which explicitly incorporates named entities into language models. This framework comprises a named-entity extraction module for pulling named entities from metadata and embedded images and an entity-aware mechanism for improving the model's ability to recognize and predict entity names.", "target": "The authors introduce the ENtity-aware article GeneratIoN and rEtrieval (ENGINE) framework, which explicitly incorporates named entities into language models. This framework comprises a named-entity extraction module for pulling named entities from metadata and embedded images and an entity-aware mechanism for improving the model's ability to recognize and predict entity names.", "example": "Convert the coordinate to text: [-3.7645 -3.4188]:"}
{"text": "Convert the coordinate to text: [-11.841    8.7274]: The authors collect an anthology of 100 visual stories, based on which they present five themes that characterize the variations in the creative visual storytelling process.", "target": "The authors collect an anthology of 100 visual stories, based on which they present five themes that characterize the variations in the creative visual storytelling process.", "example": "Convert the coordinate to text: [-11.841    8.7274]:"}
{"text": "Convert the coordinate to text: [-3.4963 -2.1291]: The paper proposes a denoised structure-to-text augmentation framework for event extraction (DAEE), which generates additional training data via a knowledge-based structure-to-text generation model and selects the most effective subset from this generated data iteratively using a deep reinforcement learning agent.", "target": "The paper proposes a denoised structure-to-text augmentation framework for event extraction (DAEE), which generates additional training data via a knowledge-based structure-to-text generation model and selects the most effective subset from this generated data iteratively using a deep reinforcement learning agent.", "example": "Convert the coordinate to text: [-3.4963 -2.1291]:"}
{"text": "Convert the coordinate to text: [10.9299 -6.6645]: The authors propose finetuning a pretrained image diffusion model with video data as a possible solution for video synthesis. They find that extending the image noise prior to video noise prior in video diffusion in a naive way causes sub-optimal performance and instead suggest a finely designed video noise prior.", "target": "The authors propose finetuning a pretrained image diffusion model with video data as a possible solution for video synthesis. They find that extending the image noise prior to video noise prior in video diffusion in a naive way causes sub-optimal performance and instead suggest a finely designed video noise prior.", "example": "Convert the coordinate to text: [10.9299 -6.6645]:"}
{"text": "Convert the coordinate to text: [-5.3226 -7.4268]: This paper presents BiSync, a bilingual writing assistant that allows users to freely compose text in two languages, while maintaining the two monolingual texts synchronized. It includes additional functionalities, such as the display of alternative prefix translations and paraphrases.", "target": "This paper presents BiSync, a bilingual writing assistant that allows users to freely compose text in two languages, while maintaining the two monolingual texts synchronized. It includes additional functionalities, such as the display of alternative prefix translations and paraphrases.", "example": "Convert the coordinate to text: [-5.3226 -7.4268]:"}
{"text": "Convert the coordinate to text: [-1.4855  0.2031]: The authors present a multi-task model for the detection and categorization of sexism in English social media posts. The model has been fine-tuned on a range of related tasks and datasets before being fine-tuned on the specific tasks of EDOS 2023.", "target": "The authors present a multi-task model for the detection and categorization of sexism in English social media posts. The model has been fine-tuned on a range of related tasks and datasets before being fine-tuned on the specific tasks of EDOS 2023.", "example": "Convert the coordinate to text: [-1.4855  0.2031]:"}
{"text": "Convert the coordinate to text: [-0.6502  0.4248]: This study makes a shift by proposing data intervention strategies to reduce gender bias in language models. Specifically, they show that fine-tuning a pre-trained model on only a few (10) de-biased or intervened training examples can significantly reduce gender favoritism.", "target": "This study makes a shift by proposing data intervention strategies to reduce gender bias in language models. Specifically, they show that fine-tuning a pre-trained model on only a few (10) de-biased or intervened training examples can significantly reduce gender favoritism.", "example": "Convert the coordinate to text: [-0.6502  0.4248]:"}
{"text": "Convert the coordinate to text: [-0.7863  6.3018]: This paper proposes learning by analogy to improve MWP solvers' understanding by generating diverse yet consistent questions/equations for a given MWP scenario including a question and its corresponding equation.", "target": "This paper proposes learning by analogy to improve MWP solvers' understanding by generating diverse yet consistent questions/equations for a given MWP scenario including a question and its corresponding equation.", "example": "Convert the coordinate to text: [-0.7863  6.3018]:"}
{"text": "Convert the coordinate to text: [-0.9208 -5.3862]: The authors implement prompt tuning in multimodal pretrained models by adding a sequence of learnable embeddings to each layer and finetuning the pretrained model on downstream tasks with only the learnable embeddings being optimised.", "target": "The authors implement prompt tuning in multimodal pretrained models by adding a sequence of learnable embeddings to each layer and finetuning the pretrained model on downstream tasks with only the learnable embeddings being optimised.", "example": "Convert the coordinate to text: [-0.9208 -5.3862]:"}
{"text": "Convert the coordinate to text: [-3.5025 -6.2094]: The authors propose associating contextualized representations with relevant representations across languages using co-occurrence counts. The resultant is MLM-GC pre-training, which learns local bidirectional information from MLM and global co-occurrence information from a log-bilinear regression.", "target": "The authors propose associating contextualized representations with relevant representations across languages using co-occurrence counts. The resultant is MLM-GC pre-training, which learns local bidirectional information from MLM and global co-occurrence information from a log-bilinear regression.", "example": "Convert the coordinate to text: [-3.5025 -6.2094]:"}
{"text": "Convert the coordinate to text: [-3.2819 -6.9077]: The authors propose a detachable model called Lego-MT, which assigns each language (or group of languages) to an individual branch that supports plug-and-play training and inference. They also propose a novel efficient training recipe for creating representations for all languages in a unified space.", "target": "The authors propose a detachable model called Lego-MT, which assigns each language (or group of languages) to an individual branch that supports plug-and-play training and inference. They also propose a novel efficient training recipe for creating representations for all languages in a unified space.", "example": "Convert the coordinate to text: [-3.2819 -6.9077]:"}
{"text": "Convert the coordinate to text: [-3.1892 -3.7664]: The authors present methods based on the BioBERT model and a CNN model, to determine the inference relation (entailment vs contradiction) between Clinical Trial Reports (CTRs) and statement pairs.", "target": "The authors present methods based on the BioBERT model and a CNN model, to determine the inference relation (entailment vs contradiction) between Clinical Trial Reports (CTRs) and statement pairs.", "example": "Convert the coordinate to text: [-3.1892 -3.7664]:"}
{"text": "Convert the coordinate to text: [-0.375  -6.6837]: The authors of the paper propose an approach that combines resampling techniques for handling imbalanced data, and the use of Transformers for argument analysis (which includes conclusion, stance, and premise).", "target": "The authors of the paper propose an approach that combines resampling techniques for handling imbalanced data, and the use of Transformers for argument analysis (which includes conclusion, stance, and premise).", "example": "Convert the coordinate to text: [-0.375  -6.6837]:"}
{"text": "Convert the coordinate to text: [-2.7511 -8.4963]: The authors propose a technique to incorporate Abstract Meaning Representation (AMR), which represents the semantic description of a sentence as a directed graph, into a text generation model. The study also presents two regularizers designed to guide cross-attention weight allocation over AMR graphs.", "target": "The authors propose a technique to incorporate Abstract Meaning Representation (AMR), which represents the semantic description of a sentence as a directed graph, into a text generation model. The study also presents two regularizers designed to guide cross-attention weight allocation over AMR graphs.", "example": "Convert the coordinate to text: [-2.7511 -8.4963]:"}
{"text": "Convert the coordinate to text: [-1.264  -1.9335]: The authors propose to use domain knowledge, specifically, the correlation bias between ICD-9 codes and other medical codes, as a prior to improve the language models' performance on ICD-9 code assignments.", "target": "The authors propose to use domain knowledge, specifically, the correlation bias between ICD-9 codes and other medical codes, as a prior to improve the language models' performance on ICD-9 code assignments.", "example": "Convert the coordinate to text: [-1.264  -1.9335]:"}
{"text": "Convert the coordinate to text: [-2.3632 -6.9226]: The paper proposes improving zero-shot transfer within the adapter framework by utilizing unlabeled text during task-specific finetuning when the target languages are known apriori. Language-specific subspaces are constructed using standard linear algebra constructs to project source-language representations into the target language subspace during task-specific finetuning.", "target": "The paper proposes improving zero-shot transfer within the adapter framework by utilizing unlabeled text during task-specific finetuning when the target languages are known apriori. Language-specific subspaces are constructed using standard linear algebra constructs to project source-language representations into the target language subspace during task-specific finetuning.", "example": "Convert the coordinate to text: [-2.3632 -6.9226]:"}
{"text": "Convert the coordinate to text: [-16.9087   2.5859]: This paper introduces the Kora platform, a cloud-native system for Apache Kafka central to Confluent Cloud, focusing on its design principles of reliability, elasticity, and cost efficiency.", "target": "This paper introduces the Kora platform, a cloud-native system for Apache Kafka central to Confluent Cloud, focusing on its design principles of reliability, elasticity, and cost efficiency.", "example": "Convert the coordinate to text: [-16.9087   2.5859]:"}
{"text": "Convert the coordinate to text: [16.208   1.8074]: This work proposes to detect out-of-distribution (OOD) images based on the reconstruction error from an encoder-decoder depth estimation model and differentiates in- and OOD images through the level of reconstruction error.", "target": "This work proposes to detect out-of-distribution (OOD) images based on the reconstruction error from an encoder-decoder depth estimation model and differentiates in- and OOD images through the level of reconstruction error.", "example": "Convert the coordinate to text: [16.208   1.8074]:"}
{"text": "Convert the coordinate to text: [ 2.8686 13.9156]: This paper explores the last-iterate behavior of various algorithms in two types of unconstrained, time-varying, bilinear zero-sum games - periodic and convergent perturbed games - which incorporate environmental factors like seasonal effects on species competition and disappearing external disturbance.", "target": "This paper explores the last-iterate behavior of various algorithms in two types of unconstrained, time-varying, bilinear zero-sum games - periodic and convergent perturbed games - which incorporate environmental factors like seasonal effects on species competition and disappearing external disturbance.", "example": "Convert the coordinate to text: [ 2.8686 13.9156]:"}
{"text": "Convert the coordinate to text: [  9.1718 -11.7097]: The authors introduce a new detector-free feature matching method called the Geometrized Transformer (GeoFormer), which uses the classical RANSAC geometry for attentive region search in homography estimation.", "target": "The authors introduce a new detector-free feature matching method called the Geometrized Transformer (GeoFormer), which uses the classical RANSAC geometry for attentive region search in homography estimation.", "example": "Convert the coordinate to text: [  9.1718 -11.7097]:"}
{"text": "Convert the coordinate to text: [ 14.3893 -13.7686]: A novel image synthesis method named HairNeRF is proposed, which transfers hairstyles while considering the underlying head geometry of two input images. This is achieved by registering two input heads in the volumetric space to make a transferred hairstyle fit on the head of a target image.", "target": "A novel image synthesis method named HairNeRF is proposed, which transfers hairstyles while considering the underlying head geometry of two input images. This is achieved by registering two input heads in the volumetric space to make a transferred hairstyle fit on the head of a target image.", "example": "Convert the coordinate to text: [ 14.3893 -13.7686]:"}
{"text": "Convert the coordinate to text: [ 7.3247 -2.4638]: To address the challenges of FL, the authors propose a Semi-Supervised Federated Object Detection (SSFOD) framework, specifically designed for scenarios where labeled data reside only at the server while clients possess unlabeled data.", "target": "To address the challenges of FL, the authors propose a Semi-Supervised Federated Object Detection (SSFOD) framework, specifically designed for scenarios where labeled data reside only at the server while clients possess unlabeled data.", "example": "Convert the coordinate to text: [ 7.3247 -2.4638]:"}
{"text": "Convert the coordinate to text: [0.2658 2.7527]: The authors propose a rigorously formulated concept called probably approximately fair and optimal (PAFO) learnability, and suggests a new setting called fair streaming Principal Component Analysis that addresses memory limitations.", "target": "The authors propose a rigorously formulated concept called probably approximately fair and optimal (PAFO) learnability, and suggests a new setting called fair streaming Principal Component Analysis that addresses memory limitations.", "example": "Convert the coordinate to text: [0.2658 2.7527]:"}
{"text": "Convert the coordinate to text: [ 4.5671 -0.8839]: This paper proposes a graph-theoretic framework that provides a conceptual understanding of open-world semi-supervised learning, where clustering can be theoretically characterized by graph factorization.", "target": "This paper proposes a graph-theoretic framework that provides a conceptual understanding of open-world semi-supervised learning, where clustering can be theoretically characterized by graph factorization.", "example": "Convert the coordinate to text: [ 4.5671 -0.8839]:"}
{"text": "Convert the coordinate to text: [ 9.4114 11.6447]: The study propounds a noise-adaptive Thompson sampling-style algorithm for linear contextual bandits with heteroscedastic noise, which is capable of managing unknown variance and providing provable guarantees.", "target": "The study propounds a noise-adaptive Thompson sampling-style algorithm for linear contextual bandits with heteroscedastic noise, which is capable of managing unknown variance and providing provable guarantees.", "example": "Convert the coordinate to text: [ 9.4114 11.6447]:"}
{"text": "Convert the coordinate to text: [0.2052 2.4907]: The authors identify the connection between distribution shift, data perturbation, and model weight perturbation and propose the robust fairness regularization (RFR) algorithm considering the worst case within the model weight perturbation ball for each sensitive attribute group.", "target": "The authors identify the connection between distribution shift, data perturbation, and model weight perturbation and propose the robust fairness regularization (RFR) algorithm considering the worst case within the model weight perturbation ball for each sensitive attribute group.", "example": "Convert the coordinate to text: [0.2052 2.4907]:"}
{"text": "Convert the coordinate to text: [12.7768 11.4371]: The authors propose a novel, equitable model valuation method called model Shapley, designed for the black-box access setting where a model's predictions can be observed without disclosing model-specific information.", "target": "The authors propose a novel, equitable model valuation method called model Shapley, designed for the black-box access setting where a model's predictions can be observed without disclosing model-specific information.", "example": "Convert the coordinate to text: [12.7768 11.4371]:"}
{"text": "Convert the coordinate to text: [-4.0704 -4.9651]: The researchers propose additional training to incorporate syntactic knowledge into a language model and design four pre-training tasks that learn different syntactic perspectives. They also address the problem of catastrophic forgetting that occurs when the model retains semantic information while learning additional syntactic knowledge.", "target": "The researchers propose additional training to incorporate syntactic knowledge into a language model and design four pre-training tasks that learn different syntactic perspectives. They also address the problem of catastrophic forgetting that occurs when the model retains semantic information while learning additional syntactic knowledge.", "example": "Convert the coordinate to text: [-4.0704 -4.9651]:"}
{"text": "Convert the coordinate to text: [ 6.5628 -6.5319]: The authors propose a recurrent neural network (RNN) class with rectified linear units that are iteratively applied to each item of a knapsack instance to compute optimal or provably good solution values.", "target": "The authors propose a recurrent neural network (RNN) class with rectified linear units that are iteratively applied to each item of a knapsack instance to compute optimal or provably good solution values.", "example": "Convert the coordinate to text: [ 6.5628 -6.5319]:"}
{"text": "Convert the coordinate to text: [10.9232 -6.1406]: The study proposes a novel fusion algorithm based on the denoising diffusion probabilistic model (DDPM), where the fusion task is formulated as a conditional generation problem within the DDPM sampling framework. The model factors the problem into an unconditional generation subproblem and a maximum likelihood subproblem, modeled in a hierarchical Bayesian manner.", "target": "The study proposes a novel fusion algorithm based on the denoising diffusion probabilistic model (DDPM), where the fusion task is formulated as a conditional generation problem within the DDPM sampling framework. The model factors the problem into an unconditional generation subproblem and a maximum likelihood subproblem, modeled in a hierarchical Bayesian manner.", "example": "Convert the coordinate to text: [10.9232 -6.1406]:"}
{"text": "Convert the coordinate to text: [-14.8561  10.7081]: The authors aim to bring to light the strengths, limitations, and deficiencies of Foundation Models in healthcare, along with the ethical and societal concerns they raise.", "target": "The authors aim to bring to light the strengths, limitations, and deficiencies of Foundation Models in healthcare, along with the ethical and societal concerns they raise.", "example": "Convert the coordinate to text: [-14.8561  10.7081]:"}
{"text": "Convert the coordinate to text: [-1.9565 -4.2608]: The authors propose to recast the structured output in the form of code instead of natural language, and utilize generative LLMs of code (Code-LLMs) such as Codex to perform IE tasks, particularly named entity recognition and relation extraction. They suggest that Code-LLMs can be well-matched with these IE tasks by designing code-style prompts and formulating these IE tasks as code generation tasks.", "target": "The authors propose to recast the structured output in the form of code instead of natural language, and utilize generative LLMs of code (Code-LLMs) such as Codex to perform IE tasks, particularly named entity recognition and relation extraction. They suggest that Code-LLMs can be well-matched with these IE tasks by designing code-style prompts and formulating these IE tasks as code generation tasks.", "example": "Convert the coordinate to text: [-1.9565 -4.2608]:"}
{"text": "Convert the coordinate to text: [  8.9719 -11.5018]: The authors introduce MVPSNet, a solution to MVPS which employs a feature extraction network that combines images from the same view captured under multiple lighting conditions to extract geometric features from shading cues for stereo matching, termed 'Light Aggregated Feature Maps' (LAFM).", "target": "The authors introduce MVPSNet, a solution to MVPS which employs a feature extraction network that combines images from the same view captured under multiple lighting conditions to extract geometric features from shading cues for stereo matching, termed 'Light Aggregated Feature Maps' (LAFM).", "example": "Convert the coordinate to text: [  8.9719 -11.5018]:"}
{"text": "Convert the coordinate to text: [-10.1401  -1.9098]: The authors design a taxonomy to categorize commonly-seen multi-answer MRC instances and then leverage this taxonomy to analyse corresponding datasets. They also explore strategies to combine the strengths of different paradigms to better address multi-answer challenges.", "target": "The authors design a taxonomy to categorize commonly-seen multi-answer MRC instances and then leverage this taxonomy to analyse corresponding datasets. They also explore strategies to combine the strengths of different paradigms to better address multi-answer challenges.", "example": "Convert the coordinate to text: [-10.1401  -1.9098]:"}
{"text": "Convert the coordinate to text: [-0.8345  0.4312]: The authors aim to measure more complex human biases in text-to-image generation tasks and propose a novel Text-to-Image Association Test (T2IAT) framework for quantifying implicit stereotypes between concepts, valence, and images.", "target": "The authors aim to measure more complex human biases in text-to-image generation tasks and propose a novel Text-to-Image Association Test (T2IAT) framework for quantifying implicit stereotypes between concepts, valence, and images.", "example": "Convert the coordinate to text: [-0.8345  0.4312]:"}
{"text": "Convert the coordinate to text: [ 1.9129 -3.9258]: The authors propose relevance-aware contrastive learning, where the intermediate-trained model itself is used as an imperfect oracle to estimate the relevance of positive pairs and adaptively weigh the contrastive loss of different pairs based on the estimated relevance.", "target": "The authors propose relevance-aware contrastive learning, where the intermediate-trained model itself is used as an imperfect oracle to estimate the relevance of positive pairs and adaptively weigh the contrastive loss of different pairs based on the estimated relevance.", "example": "Convert the coordinate to text: [ 1.9129 -3.9258]:"}
{"text": "Convert the coordinate to text: [-2.2109 -4.8758]: The paper proposes QUERT, a continual pre-trained language model for query understanding in travel domain search, which is jointly trained on four tailored pre-training tasks: Geography-aware Mask Prediction, Geohash Code Prediction, User Click Behavior Learning, and Phrase and Token Order Prediction.", "target": "The paper proposes QUERT, a continual pre-trained language model for query understanding in travel domain search, which is jointly trained on four tailored pre-training tasks: Geography-aware Mask Prediction, Geohash Code Prediction, User Click Behavior Learning, and Phrase and Token Order Prediction.", "example": "Convert the coordinate to text: [-2.2109 -4.8758]:"}
{"text": "Convert the coordinate to text: [ 7.435  11.8385]: The authors propose an optimistic modification of least-squares value iteration, named $\\pi$-KRVI, in which the state-action value function is represented by an Reproducing Kernel Hilbert Space (RKHS).", "target": "The authors propose an optimistic modification of least-squares value iteration, named $\\pi$-KRVI, in which the state-action value function is represented by an Reproducing Kernel Hilbert Space (RKHS).", "example": "Convert the coordinate to text: [ 7.435  11.8385]:"}
{"text": "Convert the coordinate to text: [  9.8894 -13.5782]: The authors propose an inference framework of ball trajectory from player trajectories as a cost-efficient alternative to ball tracking. The approach combines Set Transformers and a hierarchical architecture to intermediately predict the player ball possession to support the final trajectory inference.", "target": "The authors propose an inference framework of ball trajectory from player trajectories as a cost-efficient alternative to ball tracking. The approach combines Set Transformers and a hierarchical architecture to intermediately predict the player ball possession to support the final trajectory inference.", "example": "Convert the coordinate to text: [  9.8894 -13.5782]:"}
{"text": "Convert the coordinate to text: [-6.6828 -2.9889]: The authors propose the creation of a manually annotated corpus, Species-Species Interaction, for extracting meaningful binary relations between species at a sentence level in biomedical texts. It uses PubTator to annotate species in full-text articles.", "target": "The authors propose the creation of a manually annotated corpus, Species-Species Interaction, for extracting meaningful binary relations between species at a sentence level in biomedical texts. It uses PubTator to annotate species in full-text articles.", "example": "Convert the coordinate to text: [-6.6828 -2.9889]:"}
{"text": "Convert the coordinate to text: [-3.3877 -6.6109]: The key idea of the study is developing different models for 12 African languages and a 13th model for a multilingual dataset made from these languages. These models leverage tf-idf values of word and char n-grams, different machine and deep learning methods, oversampling techniques, and extensive hyperparameter tuning.", "target": "The key idea of the study is developing different models for 12 African languages and a 13th model for a multilingual dataset made from these languages. These models leverage tf-idf values of word and char n-grams, different machine and deep learning methods, oversampling techniques, and extensive hyperparameter tuning.", "example": "Convert the coordinate to text: [-3.3877 -6.6109]:"}
{"text": "Convert the coordinate to text: [-3.0286 -5.9446]: The team from TALP-UPC proposes an approach which combines additional steps of data annotation with fine-tuning of BERT pre-trained language models for the task of automated extraction of health issues.", "target": "The team from TALP-UPC proposes an approach which combines additional steps of data annotation with fine-tuning of BERT pre-trained language models for the task of automated extraction of health issues.", "example": "Convert the coordinate to text: [-3.0286 -5.9446]:"}
{"text": "Convert the coordinate to text: [-0.8073 -7.1765]: This paper investigates an example-based approach for GEC, which uses the k-nearest translation examples to enhance the results of a pretrained Transformer model.", "target": "This paper investigates an example-based approach for GEC, which uses the k-nearest translation examples to enhance the results of a pretrained Transformer model.", "example": "Convert the coordinate to text: [-0.8073 -7.1765]:"}
{"text": "Convert the coordinate to text: [-5.6844 -0.4976]: The authors propose TokenCluster, a new method for unsupervised extractive opinion summarization. This method identifies the underlying aspects described in review sentences using the roots of noun phrases and adjectives within these sentences and accordingly extracts sentences based on their aspects.", "target": "The authors propose TokenCluster, a new method for unsupervised extractive opinion summarization. This method identifies the underlying aspects described in review sentences using the roots of noun phrases and adjectives within these sentences and accordingly extracts sentences based on their aspects.", "example": "Convert the coordinate to text: [-5.6844 -0.4976]:"}
{"text": "Convert the coordinate to text: [-1.6421 -3.2815]: This paper proposes a novel method to manage target-oriented dialogues with complex semantics by using a combination of knowledge retrieval and relationship prediction to construct a context-related dynamic knowledge graph.", "target": "This paper proposes a novel method to manage target-oriented dialogues with complex semantics by using a combination of knowledge retrieval and relationship prediction to construct a context-related dynamic knowledge graph.", "example": "Convert the coordinate to text: [-1.6421 -3.2815]:"}
{"text": "Convert the coordinate to text: [-10.504   -1.9791]: To mitigate the challenges associated with labeled datasets for NER, the authors propose ECG-QALM, a novel approach that uses pre-trained language models for synthetically generating entity-controlled text through a contextual question and answering mechanism.", "target": "To mitigate the challenges associated with labeled datasets for NER, the authors propose ECG-QALM, a novel approach that uses pre-trained language models for synthetically generating entity-controlled text through a contextual question and answering mechanism.", "example": "Convert the coordinate to text: [-10.504   -1.9791]:"}
{"text": "Convert the coordinate to text: [-3.749  -3.4198]: The authors aim to address the lack of extensive multilingual datasets for RE and for that, they introduce two new resources: SREDFM, an automatically annotated dataset covering 18 languages, 400 relation types and 13 entity types, and REDFM, a smaller, human-revised dataset for seven languages.", "target": "The authors aim to address the lack of extensive multilingual datasets for RE and for that, they introduce two new resources: SREDFM, an automatically annotated dataset covering 18 languages, 400 relation types and 13 entity types, and REDFM, a smaller, human-revised dataset for seven languages.", "example": "Convert the coordinate to text: [-3.749  -3.4198]:"}
{"text": "Convert the coordinate to text: [-8.5136 -4.4175]: The authors propound transforming FrameNet, a comprehensive semantic role labeling (SRL) dataset for EAE, and gathering expert annotations to create a large and diverse EAE ontology with 115 events and 220 argument roles. Based on this ontology, they introduce a diverse generalizability benchmarking dataset called GENEVA comprising of four test suites.", "target": "The authors propound transforming FrameNet, a comprehensive semantic role labeling (SRL) dataset for EAE, and gathering expert annotations to create a large and diverse EAE ontology with 115 events and 220 argument roles. Based on this ontology, they introduce a diverse generalizability benchmarking dataset called GENEVA comprising of four test suites.", "example": "Convert the coordinate to text: [-8.5136 -4.4175]:"}
{"text": "Convert the coordinate to text: [8.1669 4.0347]: The authors propose a new hierarchical likelihood approach to DNNs with correlated random effects for clustered data, where the negative h-likelihood loss is jointly optimized resulting in exact MLEs for both mean and dispersion parameters and the best linear unbiased predictors for the random effects.", "target": "The authors propose a new hierarchical likelihood approach to DNNs with correlated random effects for clustered data, where the negative h-likelihood loss is jointly optimized resulting in exact MLEs for both mean and dispersion parameters and the best linear unbiased predictors for the random effects.", "example": "Convert the coordinate to text: [8.1669 4.0347]:"}
{"text": "Convert the coordinate to text: [ 11.9737 -15.1704]: The authors introduce the Priority-Centric Motion Discrete Diffusion Model (M2DM). It uses a Transformer-based VQ-VAE to create a concise, discrete motion representation, and incorporates a global self-attention mechanism and a regularization term to counter code collapse. The approach emphasizes the most salient motions during the reverse diffusion process.", "target": "The authors introduce the Priority-Centric Motion Discrete Diffusion Model (M2DM). It uses a Transformer-based VQ-VAE to create a concise, discrete motion representation, and incorporates a global self-attention mechanism and a regularization term to counter code collapse. The approach emphasizes the most salient motions during the reverse diffusion process.", "example": "Convert the coordinate to text: [ 11.9737 -15.1704]:"}
{"text": "Convert the coordinate to text: [  8.8144 -11.0528]: The authors introduce a new method called CASSPR to overcome these limitations by fusing point-based and voxel-based approaches using cross attention transformers. This involves utilizing a sparse voxel branch for lower resolution information extraction and a point-wise branch for fine-grained local information.", "target": "The authors introduce a new method called CASSPR to overcome these limitations by fusing point-based and voxel-based approaches using cross attention transformers. This involves utilizing a sparse voxel branch for lower resolution information extraction and a point-wise branch for fine-grained local information.", "example": "Convert the coordinate to text: [  8.8144 -11.0528]:"}
{"text": "Convert the coordinate to text: [ 3.7596 -4.0466]: The study proposes Universal Knowledge Distillation (UniKD) which introduces additional decoder heads with deformable cross-attention called Adaptive Knowledge Extractor (AKE). UniKD uses AKEs to pretrain on the teacher\u2019s output to infuse the teacher\u2019s content and positional knowledge into a fixed-number set of knowledge embeddings, then places these AKEs on the student\u2019s backbone to help the student absorb the teacher\u2019s knowledge.", "target": "The study proposes Universal Knowledge Distillation (UniKD) which introduces additional decoder heads with deformable cross-attention called Adaptive Knowledge Extractor (AKE). UniKD uses AKEs to pretrain on the teacher\u2019s output to infuse the teacher\u2019s content and positional knowledge into a fixed-number set of knowledge embeddings, then places these AKEs on the student\u2019s backbone to help the student absorb the teacher\u2019s knowledge.", "example": "Convert the coordinate to text: [ 3.7596 -4.0466]:"}
{"text": "Convert the coordinate to text: [15.6757 -0.1611]: The authors propose LLM-FP4, a method for quantizing weights and activations in large language models down to 4-bit floating-point values, in a post-training manner. They build a stronger FP-PTQ baseline by searching for the optimal quantization parameters and propose per-channel activation quantization to account for the high inter-channel variance and low intra-channel variance pattern observed in activation distributions.", "target": "The authors propose LLM-FP4, a method for quantizing weights and activations in large language models down to 4-bit floating-point values, in a post-training manner. They build a stronger FP-PTQ baseline by searching for the optimal quantization parameters and propose per-channel activation quantization to account for the high inter-channel variance and low intra-channel variance pattern observed in activation distributions.", "example": "Convert the coordinate to text: [15.6757 -0.1611]:"}
{"text": "Convert the coordinate to text: [-6.1446 11.223 ]: The paper introduces ToxicChat, a novel benchmark based on real user queries from an open-source chatbot which contains the rich, nuanced phenomena that can be tricky for current toxicity detection models to identify.", "target": "The paper introduces ToxicChat, a novel benchmark based on real user queries from an open-source chatbot which contains the rich, nuanced phenomena that can be tricky for current toxicity detection models to identify.", "example": "Convert the coordinate to text: [-6.1446 11.223 ]:"}
{"text": "Convert the coordinate to text: [10.0223 -2.9473]: The authors propose BasisFormer, an end-to-end time series forecasting architecture that leverages learnable and interpretable bases. This architecture acquires bases through adaptive self-supervised learning, designs a Coef module that calculates similarity coefficients between the time series and bases via bidirectional cross-attention, and a Forecast module that selects and consolidates the bases for accurate future predictions.", "target": "The authors propose BasisFormer, an end-to-end time series forecasting architecture that leverages learnable and interpretable bases. This architecture acquires bases through adaptive self-supervised learning, designs a Coef module that calculates similarity coefficients between the time series and bases via bidirectional cross-attention, and a Forecast module that selects and consolidates the bases for accurate future predictions.", "example": "Convert the coordinate to text: [10.0223 -2.9473]:"}
{"text": "Convert the coordinate to text: [12.4086 -5.3528]: The authors propose a novel model modification-based transfer attack: Blurred-Dilated method (BD), which works by reducing downsampling while introducing BlurPool and dilated convolutions in the source model and uses the modified model to generate adversarial samples.", "target": "The authors propose a novel model modification-based transfer attack: Blurred-Dilated method (BD), which works by reducing downsampling while introducing BlurPool and dilated convolutions in the source model and uses the modified model to generate adversarial samples.", "example": "Convert the coordinate to text: [12.4086 -5.3528]:"}
{"text": "Convert the coordinate to text: [12.4706  7.2497]: The authors propose an efficient algorithm variant of differentially private stochastic gradient descent (DP-SGD) with two key innovations: a full-batch gradient descent to improve sample complexity and a novel adaptive clipping to guarantee robustness.", "target": "The authors propose an efficient algorithm variant of differentially private stochastic gradient descent (DP-SGD) with two key innovations: a full-batch gradient descent to improve sample complexity and a novel adaptive clipping to guarantee robustness.", "example": "Convert the coordinate to text: [12.4706  7.2497]:"}
{"text": "Convert the coordinate to text: [-10.6302  -1.5608]: The authors introduce the task of temporal question answering on semi-structured tables.", "target": "The authors introduce the task of temporal question answering on semi-structured tables.", "example": "Convert the coordinate to text: [-10.6302  -1.5608]:"}
{"text": "Convert the coordinate to text: [ 5.8852 14.2112]: The authors propose AutoRLHF, an open-source framework for RLHF fine-tuning of models of 70 billion parameters or more. It supports various types of distributed training and compute and memory-saving features, offering flexibility to support users with a broad range of resources.", "target": "The authors propose AutoRLHF, an open-source framework for RLHF fine-tuning of models of 70 billion parameters or more. It supports various types of distributed training and compute and memory-saving features, offering flexibility to support users with a broad range of resources.", "example": "Convert the coordinate to text: [ 5.8852 14.2112]:"}
{"text": "Convert the coordinate to text: [  5.3292 -11.7385]: The authors propose OneFormer, a universal image segmentation framework that unifies segmentation with a multi-task train-once design, introducing a task-conditioned joint training strategy, task tokens to make the model task-dynamic, and a query-text contrastive loss to establish better inter-task and inter-class distinctions.", "target": "The authors propose OneFormer, a universal image segmentation framework that unifies segmentation with a multi-task train-once design, introducing a task-conditioned joint training strategy, task tokens to make the model task-dynamic, and a query-text contrastive loss to establish better inter-task and inter-class distinctions.", "example": "Convert the coordinate to text: [  5.3292 -11.7385]:"}
{"text": "Convert the coordinate to text: [-10.8773  16.566 ]: A new device named TurnAhead is proposed, which uses 3-DoF rotational haptic cues corresponding to camera rotations to improve the comfort, immersion, and enjoyment of FPV.", "target": "A new device named TurnAhead is proposed, which uses 3-DoF rotational haptic cues corresponding to camera rotations to improve the comfort, immersion, and enjoyment of FPV.", "example": "Convert the coordinate to text: [-10.8773  16.566 ]:"}
{"text": "Convert the coordinate to text: [-3.5146 -4.7809]: This paper introduces MatSci-NLP, a natural language benchmark built from publicly available materials science text data for seven different NLP tasks, and MatBERT, a model trained specifically on materials science journals. Additionally, the authors propose a unified text-to-schema method for multitask learning in this domain.", "target": "This paper introduces MatSci-NLP, a natural language benchmark built from publicly available materials science text data for seven different NLP tasks, and MatBERT, a model trained specifically on materials science journals. Additionally, the authors propose a unified text-to-schema method for multitask learning in this domain.", "example": "Convert the coordinate to text: [-3.5146 -4.7809]:"}
{"text": "Convert the coordinate to text: [8.3492 0.8313]: The authors propose Iterative Gradient-Based Projection (IGBP), a method to remove non-linearly encoded concepts from neural representations. IGBP works by iteratively training neural classifiers to predict a specific attribute that needs to be eliminated, and then projects the representation on a hypersurface to make the classifiers oblivious to the target attribute.", "target": "The authors propose Iterative Gradient-Based Projection (IGBP), a method to remove non-linearly encoded concepts from neural representations. IGBP works by iteratively training neural classifiers to predict a specific attribute that needs to be eliminated, and then projects the representation on a hypersurface to make the classifiers oblivious to the target attribute.", "example": "Convert the coordinate to text: [8.3492 0.8313]:"}
{"text": "Convert the coordinate to text: [-4.4255  3.6503]: The authors introduce the SURE (Multimodal Recommendation Dialog with SUbjective PREference) dataset, containing 12K shopping dialogs in complex store scenes, annotated with subjective preferences and recommendation acts proposed by sales experts.", "target": "The authors introduce the SURE (Multimodal Recommendation Dialog with SUbjective PREference) dataset, containing 12K shopping dialogs in complex store scenes, annotated with subjective preferences and recommendation acts proposed by sales experts.", "example": "Convert the coordinate to text: [-4.4255  3.6503]:"}
{"text": "Convert the coordinate to text: [7.1619 8.0059]: The authors propose a solution to these privacy challenges by implementing the DP-Follow-the-Regularized-Leader (DP-FTRL) algorithm to achieve meaningful formal DP guarantees in Gboard\u2019s language models. They also introduce a new client participation criterion to provide better privacy-utility trade-offs and combine quantile-based clip estimation with DP-FTRL to adaptively choose the clip norm in training.", "target": "The authors propose a solution to these privacy challenges by implementing the DP-Follow-the-Regularized-Leader (DP-FTRL) algorithm to achieve meaningful formal DP guarantees in Gboard\u2019s language models. They also introduce a new client participation criterion to provide better privacy-utility trade-offs and combine quantile-based clip estimation with DP-FTRL to adaptively choose the clip norm in training.", "example": "Convert the coordinate to text: [7.1619 8.0059]:"}
{"text": "Convert the coordinate to text: [-2.2276 -3.2026]: This study proposes a method that retrieves the most relevant triplets from KGs and reranks them, which are then concatenated with the questions to be fed into language models.", "target": "This study proposes a method that retrieves the most relevant triplets from KGs and reranks them, which are then concatenated with the questions to be fed into language models.", "example": "Convert the coordinate to text: [-2.2276 -3.2026]:"}
{"text": "Convert the coordinate to text: [-3.245  -5.5647]: The paper presents the task of transforming existing texts into new gap-filling grammar exercises, using only an example exercise, with no explicit instruction or detailed annotation. A novel neural network architecture specifically designed for this gap-filling exercise generation task is proposed.", "target": "The paper presents the task of transforming existing texts into new gap-filling grammar exercises, using only an example exercise, with no explicit instruction or detailed annotation. A novel neural network architecture specifically designed for this gap-filling exercise generation task is proposed.", "example": "Convert the coordinate to text: [-3.245  -5.5647]:"}
{"text": "Convert the coordinate to text: [5.6433 6.3775]: The paper proposes a general framework for MOS prediction based on pairwise comparison (MOSPC) and uses the C-Mixup algorithm to enhance this model's generalization performance.", "target": "The paper proposes a general framework for MOS prediction based on pairwise comparison (MOSPC) and uses the C-Mixup algorithm to enhance this model's generalization performance.", "example": "Convert the coordinate to text: [5.6433 6.3775]:"}
{"text": "Convert the coordinate to text: [18.5606 -3.1634]: The authors have identified the kind of spoiler in a clickbait title and have formulated this as a text classification problem.", "target": "The authors have identified the kind of spoiler in a clickbait title and have formulated this as a text classification problem.", "example": "Convert the coordinate to text: [18.5606 -3.1634]:"}
{"text": "Convert the coordinate to text: [-2.8733 -7.22  ]: The authors introduced an AdapterFusion layer that composes task-adapters from different languages to combine language-exclusive knowledge.", "target": "The authors introduced an AdapterFusion layer that composes task-adapters from different languages to combine language-exclusive knowledge.", "example": "Convert the coordinate to text: [-2.8733 -7.22  ]:"}
{"text": "Convert the coordinate to text: [ 4.3614 -1.2113]: The authors participate only in Sub-Task (A), and propose a method that combines global and local models of label distributions and transitions between labels.", "target": "The authors participate only in Sub-Task (A), and propose a method that combines global and local models of label distributions and transitions between labels.", "example": "Convert the coordinate to text: [ 4.3614 -1.2113]:"}
{"text": "Convert the coordinate to text: [-0.4086 -7.6051]: The authors propose a novel and general Dependency-Aware Decoder (DePA) to enhance target dependency modeling in the decoder of fully NAT models from two perspectives: decoder self-attention and decoder input.", "target": "The authors propose a novel and general Dependency-Aware Decoder (DePA) to enhance target dependency modeling in the decoder of fully NAT models from two perspectives: decoder self-attention and decoder input.", "example": "Convert the coordinate to text: [-0.4086 -7.6051]:"}
{"text": "Convert the coordinate to text: [-4.1465 -8.7567]: The authors introduce the ACL 60/60 evaluation sets designed for multilingual translation of ACL 2022 technical presentations into 10 target languages, which represent real-world, unsegmented audio and domain-specific terminology.", "target": "The authors introduce the ACL 60/60 evaluation sets designed for multilingual translation of ACL 2022 technical presentations into 10 target languages, which represent real-world, unsegmented audio and domain-specific terminology.", "example": "Convert the coordinate to text: [-4.1465 -8.7567]:"}
{"text": "Convert the coordinate to text: [-1.7001 -6.1947]: The authors propose to fine-tune transformer language models with manually annotated biomedical corpora and further enhance these models by integrating knowledge graph embeddings.", "target": "The authors propose to fine-tune transformer language models with manually annotated biomedical corpora and further enhance these models by integrating knowledge graph embeddings.", "example": "Convert the coordinate to text: [-1.7001 -6.1947]:"}
{"text": "Convert the coordinate to text: [-5.7165  0.7789]: The authors approach argument quality estimation from multiple angles, including the exploration of its generalization capabilities across diverse domains and the interplay with related argument mining tasks.", "target": "The authors approach argument quality estimation from multiple angles, including the exploration of its generalization capabilities across diverse domains and the interplay with related argument mining tasks.", "example": "Convert the coordinate to text: [-5.7165  0.7789]:"}
{"text": "Convert the coordinate to text: [-3.0422 -6.7078]: The study proposes a new method that selects peculiar examples from an unlabeled data pool as annotation candidates to improve the performance of few-shot cross-lingual transfer. Specifically, the examples that MMLM cannot solve in a zero-shot cross-lingual transfer setting (high peculiarity examples) are selected.", "target": "The study proposes a new method that selects peculiar examples from an unlabeled data pool as annotation candidates to improve the performance of few-shot cross-lingual transfer. Specifically, the examples that MMLM cannot solve in a zero-shot cross-lingual transfer setting (high peculiarity examples) are selected.", "example": "Convert the coordinate to text: [-3.0422 -6.7078]:"}
{"text": "Convert the coordinate to text: [-6.7629 -2.5982]: The authors propose a two-stage taxonomy-agnostic framework that relies on calculating the semantic relatedness between product titles and category names in a vector space. They also design two plug-in modules - a heuristic mapping scorer and a pretrained contrastive ranking module- with the help of meta concepts, which represent shared keyword knowledge across domains.", "target": "The authors propose a two-stage taxonomy-agnostic framework that relies on calculating the semantic relatedness between product titles and category names in a vector space. They also design two plug-in modules - a heuristic mapping scorer and a pretrained contrastive ranking module- with the help of meta concepts, which represent shared keyword knowledge across domains.", "example": "Convert the coordinate to text: [-6.7629 -2.5982]:"}
{"text": "Convert the coordinate to text: [-5.3747 -9.6158]: The authors propose using regression models to predict the date of Greek papyri based on a dataset of 389 transcriptions.", "target": "The authors propose using regression models to predict the date of Greek papyri based on a dataset of 389 transcriptions.", "example": "Convert the coordinate to text: [-5.3747 -9.6158]:"}
{"text": "Convert the coordinate to text: [ 2.9819 -7.2492]: The authors propose a new architecture that incorporates multiple head classifiers and employs attention-based aggregation, using pairwise feature similarity compute Gramian matrices to enhance class tokens in each attention layer for each head. Furthermore, they introduce a learning algorithm that minimizes correlation for aggregation.", "target": "The authors propose a new architecture that incorporates multiple head classifiers and employs attention-based aggregation, using pairwise feature similarity compute Gramian matrices to enhance class tokens in each attention layer for each head. Furthermore, they introduce a learning algorithm that minimizes correlation for aggregation.", "example": "Convert the coordinate to text: [ 2.9819 -7.2492]:"}
{"text": "Convert the coordinate to text: [  7.1298 -20.9215]: The authors propose a novel many-to-many mapping method, rather than the existing many-to-one mapping used in the ISP process, to learn the mapping from high dynamic range raw images to sRGB images of different illumination levels in order to preserve multi-scale contrast for accurate shadow detection.", "target": "The authors propose a novel many-to-many mapping method, rather than the existing many-to-one mapping used in the ISP process, to learn the mapping from high dynamic range raw images to sRGB images of different illumination levels in order to preserve multi-scale contrast for accurate shadow detection.", "example": "Convert the coordinate to text: [  7.1298 -20.9215]:"}
{"text": "Convert the coordinate to text: [ 6.1892 -8.5595]: The authors propose a new class of interpretable Act models by re-interpreting neural feature Act from the perspective of Multi-Criteria Decision-Making (MCDM) where activation models are viewed as selective feature re-calibrators. The authors also identify the unmined problem of mismatched feature scoring led by differentiated norms of features and filters.", "target": "The authors propose a new class of interpretable Act models by re-interpreting neural feature Act from the perspective of Multi-Criteria Decision-Making (MCDM) where activation models are viewed as selective feature re-calibrators. The authors also identify the unmined problem of mismatched feature scoring led by differentiated norms of features and filters.", "example": "Convert the coordinate to text: [ 6.1892 -8.5595]:"}
{"text": "Convert the coordinate to text: [11.7039 -1.174 ]: The authors challenge this recent concept of double descent, suggesting that the second descent only appears due to multiple implicit complexity axes, rather than being inherently tied to an interpolation threshold.", "target": "The authors challenge this recent concept of double descent, suggesting that the second descent only appears due to multiple implicit complexity axes, rather than being inherently tied to an interpolation threshold.", "example": "Convert the coordinate to text: [11.7039 -1.174 ]:"}
{"text": "Convert the coordinate to text: [0.2287 8.7311]: The authors analyze the structural elements of universal formulas or highly expressive models, introducing a hierarchy of expressiveness classes that links the global approximability property to the property of infinite VC dimension.", "target": "The authors analyze the structural elements of universal formulas or highly expressive models, introducing a hierarchy of expressiveness classes that links the global approximability property to the property of infinite VC dimension.", "example": "Convert the coordinate to text: [0.2287 8.7311]:"}
{"text": "Convert the coordinate to text: [8.5669 9.6909]: The authors of the paper introduce an alternating variant of OLO, in which the learner experiences a different cost function based on the current and previous selections of the adversary. This is a new twist on the existing game-play.", "target": "The authors of the paper introduce an alternating variant of OLO, in which the learner experiences a different cost function based on the current and previous selections of the adversary. This is a new twist on the existing game-play.", "example": "Convert the coordinate to text: [8.5669 9.6909]:"}
{"text": "Convert the coordinate to text: [ 3.9891 -4.0504]: This study proposes to break down the global feature distillation task into N local sub-tasks. Each neuron in the last hidden layer of the teacher network acts as a specialized sub-teacher and each neuron in the student network learns from a corresponding specialized sub-teacher through a one-to-one mapping approach.", "target": "This study proposes to break down the global feature distillation task into N local sub-tasks. Each neuron in the last hidden layer of the teacher network acts as a specialized sub-teacher and each neuron in the student network learns from a corresponding specialized sub-teacher through a one-to-one mapping approach.", "example": "Convert the coordinate to text: [ 3.9891 -4.0504]:"}
{"text": "Convert the coordinate to text: [7.6388 0.017 ]: The authors propose an adaptive metric learning method that allows for hyper-parameter learning based on batch similarity, without the need for fixed or extra-trainable hyper-parameters. The method also includes a symmetric metric learning component to prevent model collapse.", "target": "The authors propose an adaptive metric learning method that allows for hyper-parameter learning based on batch similarity, without the need for fixed or extra-trainable hyper-parameters. The method also includes a symmetric metric learning component to prevent model collapse.", "example": "Convert the coordinate to text: [7.6388 0.017 ]:"}
{"text": "Convert the coordinate to text: [5.8751 1.6594]: The authors introduce the Selective Missing Indicator Method (SMIM), a novel extension to the traditional Missing Indicator Method (MIM) that adds missing indicators only for features that have informative missing patterns.", "target": "The authors introduce the Selective Missing Indicator Method (SMIM), a novel extension to the traditional Missing Indicator Method (MIM) that adds missing indicators only for features that have informative missing patterns.", "example": "Convert the coordinate to text: [5.8751 1.6594]:"}
{"text": "Convert the coordinate to text: [ 4.9975 -6.8934]: The authors propose the Adaptive Task-to-Task Fusion Network (AdaTT) which is a deep fusion network with task-specific and optional shared fusion units. The model uses a residual mechanism and gating mechanism for task-to-task fusion to learn shared and task-specific knowledge adaptively.", "target": "The authors propose the Adaptive Task-to-Task Fusion Network (AdaTT) which is a deep fusion network with task-specific and optional shared fusion units. The model uses a residual mechanism and gating mechanism for task-to-task fusion to learn shared and task-specific knowledge adaptively.", "example": "Convert the coordinate to text: [ 4.9975 -6.8934]:"}
{"text": "Convert the coordinate to text: [-2.1697 -6.5138]: This paper explores the fine-tuning process of multilingual pre-trained language models, aiming to understand when the performance gap changes, which network weights have the most impact, and to what extent reducing forgetting can lessen this gap.", "target": "This paper explores the fine-tuning process of multilingual pre-trained language models, aiming to understand when the performance gap changes, which network weights have the most impact, and to what extent reducing forgetting can lessen this gap.", "example": "Convert the coordinate to text: [-2.1697 -6.5138]:"}
{"text": "Convert the coordinate to text: [-4.6403 -8.3751]: The authors propose a duplex diffusion model that applies diffusion probabilistic models to both ends of a reversible duplex Conformer, which allows for simultaneous input and output of distinct languages' speech. This model enables reversible speech translation by simply flipping the input and output ends.", "target": "The authors propose a duplex diffusion model that applies diffusion probabilistic models to both ends of a reversible duplex Conformer, which allows for simultaneous input and output of distinct languages' speech. This model enables reversible speech translation by simply flipping the input and output ends.", "example": "Convert the coordinate to text: [-4.6403 -8.3751]:"}
{"text": "Convert the coordinate to text: [-5.7301 -4.9904]: The authors present the first XWS-TC benchmark to rigorously compare the SEED and PROMPT approaches on standardized grounds, including datasets, supervisions, and hyperparameter choices.", "target": "The authors present the first XWS-TC benchmark to rigorously compare the SEED and PROMPT approaches on standardized grounds, including datasets, supervisions, and hyperparameter choices.", "example": "Convert the coordinate to text: [-5.7301 -4.9904]:"}
{"text": "Convert the coordinate to text: [ -5.0116 -10.2922]: The authors introduce FluentSpeech, an automatic speech editing model designed for stutter removal. It employs a context-aware diffusion model to refine the altered mel-spectrogram using context features, a stutter predictor module to infuse stutter information into the hidden sequence.", "target": "The authors introduce FluentSpeech, an automatic speech editing model designed for stutter removal. It employs a context-aware diffusion model to refine the altered mel-spectrogram using context features, a stutter predictor module to infuse stutter information into the hidden sequence.", "example": "Convert the coordinate to text: [ -5.0116 -10.2922]:"}
{"text": "Convert the coordinate to text: [ 9.7714 -7.8223]: The authors propose a Denoising Bottleneck Fusion (DBF) model for fine-grained video multimodal fusion. The model uses a bottleneck mechanism to filter out noise and redundancy, while a mutual information maximization module is deployed to regulate noise filtering to preserve key multimodal information.", "target": "The authors propose a Denoising Bottleneck Fusion (DBF) model for fine-grained video multimodal fusion. The model uses a bottleneck mechanism to filter out noise and redundancy, while a mutual information maximization module is deployed to regulate noise filtering to preserve key multimodal information.", "example": "Convert the coordinate to text: [ 9.7714 -7.8223]:"}
{"text": "Convert the coordinate to text: [-10.1616  -1.5835]: The authors conducted a targeted study on LFQA evaluation, focusing on both human and automatic processes for evaluation, and specifically explored new aspects such as the comprehensiveness of an answer.", "target": "The authors conducted a targeted study on LFQA evaluation, focusing on both human and automatic processes for evaluation, and specifically explored new aspects such as the comprehensiveness of an answer.", "example": "Convert the coordinate to text: [-10.1616  -1.5835]:"}
{"text": "Convert the coordinate to text: [-6.4143  4.2564]: The authors propose a simple but flexible model that captures the semantic meanings directly from the texts of social media and compares them with symptom-related descriptions while preserving domain-based interpretability.", "target": "The authors propose a simple but flexible model that captures the semantic meanings directly from the texts of social media and compares them with symptom-related descriptions while preserving domain-based interpretability.", "example": "Convert the coordinate to text: [-6.4143  4.2564]:"}
{"text": "Convert the coordinate to text: [-3.9435 -8.1303]: The authors propose MobileNMT, a system that enables machine translation on mobile devices using only 15MB and executing in 30ms. This system includes principles for model compression when combined with quantization and an implementation of an engine that is INT8 and decoding friendly.", "target": "The authors propose MobileNMT, a system that enables machine translation on mobile devices using only 15MB and executing in 30ms. This system includes principles for model compression when combined with quantization and an implementation of an engine that is INT8 and decoding friendly.", "example": "Convert the coordinate to text: [-3.9435 -8.1303]:"}
{"text": "Convert the coordinate to text: [ 8.6179 -3.0221]: This study proposes a new problem of developing GNNs that are both robust and preserve membership privacy. The authors argue that the Information Bottleneck (IB) can help filter out noisy information and regularize predictions on labeled samples, thereby improving robustness and membership privacy.", "target": "This study proposes a new problem of developing GNNs that are both robust and preserve membership privacy. The authors argue that the Information Bottleneck (IB) can help filter out noisy information and regularize predictions on labeled samples, thereby improving robustness and membership privacy.", "example": "Convert the coordinate to text: [ 8.6179 -3.0221]:"}
{"text": "Convert the coordinate to text: [ 0.1841 -7.0226]: The authors propose two novel ensemble strategies based on Transformer models. These strategies aim to improve robustness to structural constraints while also reducing computational time.", "target": "The authors propose two novel ensemble strategies based on Transformer models. These strategies aim to improve robustness to structural constraints while also reducing computational time.", "example": "Convert the coordinate to text: [ 0.1841 -7.0226]:"}
{"text": "Convert the coordinate to text: [-8.1437 -1.4388]: The authors propose the Fuzzy Span Universal Information Extraction (FSUIE) framework to address the deficiencies of UIE frameworks. The main contributions include two concepts - fuzzy span loss and fuzzy span attention.", "target": "The authors propose the Fuzzy Span Universal Information Extraction (FSUIE) framework to address the deficiencies of UIE frameworks. The main contributions include two concepts - fuzzy span loss and fuzzy span attention.", "example": "Convert the coordinate to text: [-8.1437 -1.4388]:"}
{"text": "Convert the coordinate to text: [-1.9205 -5.3877]: The authors evaluate the ability of large language models, including GPT-4 (few-shot, in-context learning), fine-tuned GPT-2, and fine-tuned DialoGPT, to simulate the role of a knowledgeable teacher by generating informative and helpful insights for students in an educational setting. The Flan-T5 model was also fine-tuned using reinforcement learning for optimization of pedagogical quality.", "target": "The authors evaluate the ability of large language models, including GPT-4 (few-shot, in-context learning), fine-tuned GPT-2, and fine-tuned DialoGPT, to simulate the role of a knowledgeable teacher by generating informative and helpful insights for students in an educational setting. The Flan-T5 model was also fine-tuned using reinforcement learning for optimization of pedagogical quality.", "example": "Convert the coordinate to text: [-1.9205 -5.3877]:"}
{"text": "Convert the coordinate to text: [-5.123  -0.0565]: The authors propose a new dataset based on sentences taken from Wikipedia with varying degrees of abstractness. The dataset includes automatically generated pseudo-implausible events and captures participant responses to these scenarios.", "target": "The authors propose a new dataset based on sentences taken from Wikipedia with varying degrees of abstractness. The dataset includes automatically generated pseudo-implausible events and captures participant responses to these scenarios.", "example": "Convert the coordinate to text: [-5.123  -0.0565]:"}
{"text": "Convert the coordinate to text: [-3.8703 -2.8116]: The paper addresses the inference relationship (entailment or contradiction) in clinical trial reports (CTRs) and extraction of supporting facts from the premises using a new Semantic Rule-based Clinical Data Analysis (SRCDA) method. This includes the creation of an External Knowledge Base (EKB) along with suitable semantic rules based on the input statements.", "target": "The paper addresses the inference relationship (entailment or contradiction) in clinical trial reports (CTRs) and extraction of supporting facts from the premises using a new Semantic Rule-based Clinical Data Analysis (SRCDA) method. This includes the creation of an External Knowledge Base (EKB) along with suitable semantic rules based on the input statements.", "example": "Convert the coordinate to text: [-3.8703 -2.8116]:"}
{"text": "Convert the coordinate to text: [-2.5695 -5.8961]: The study introduces a direct, fine-tuned performance comparison of seven pre-trained language models for discourse parsing using the PDTB-3 dataset.", "target": "The study introduces a direct, fine-tuned performance comparison of seven pre-trained language models for discourse parsing using the PDTB-3 dataset.", "example": "Convert the coordinate to text: [-2.5695 -5.8961]:"}
{"text": "Convert the coordinate to text: [-5.6209  1.7069]: The authors propose NewsMet - a contemporary dataset of news headlines which are hand-annotated with metaphorical verbs, formulated from a variety of platforms such as political, satirical, reliable, and fake sources.", "target": "The authors propose NewsMet - a contemporary dataset of news headlines which are hand-annotated with metaphorical verbs, formulated from a variety of platforms such as political, satirical, reliable, and fake sources.", "example": "Convert the coordinate to text: [-5.6209  1.7069]:"}
{"text": "Convert the coordinate to text: [-5.6044 10.5688]: The authors propose a novel framework for conversation generation that incorporates human knowledge and conversation structures for enhanced controllability and interpretability of conversation generation.", "target": "The authors propose a novel framework for conversation generation that incorporates human knowledge and conversation structures for enhanced controllability and interpretability of conversation generation.", "example": "Convert the coordinate to text: [-5.6044 10.5688]:"}
{"text": "Convert the coordinate to text: [-0.8824  6.8152]: This paper proposes the exploration of symbolic versions of numeric problems to better understand and evaluate the reasoning capabilities of LLMs. They also propose a 'self-prompting' method to ensure the symbolic reasoning is aligned with the numeric answer.", "target": "This paper proposes the exploration of symbolic versions of numeric problems to better understand and evaluate the reasoning capabilities of LLMs. They also propose a 'self-prompting' method to ensure the symbolic reasoning is aligned with the numeric answer.", "example": "Convert the coordinate to text: [-0.8824  6.8152]:"}
{"text": "Convert the coordinate to text: [ 1.6279 -2.8903]: The authors propose the use of a knowledge base with the teacher\u2019s soft labels and predictions as a non-parametric memory to aid in student model generalization. They introduce a new framework and loss function to enable effective retrieval of information from this knowledge base.", "target": "The authors propose the use of a knowledge base with the teacher\u2019s soft labels and predictions as a non-parametric memory to aid in student model generalization. They introduce a new framework and loss function to enable effective retrieval of information from this knowledge base.", "example": "Convert the coordinate to text: [ 1.6279 -2.8903]:"}
{"text": "Convert the coordinate to text: [ -7.7788 -10.1411]: The authors introduce IDRISI-RA, the first publicly available Arabic Location Mention Recognition (LMR) dataset, containing both location mentions and their types in large quantities of tweets.", "target": "The authors introduce IDRISI-RA, the first publicly available Arabic Location Mention Recognition (LMR) dataset, containing both location mentions and their types in large quantities of tweets.", "example": "Convert the coordinate to text: [ -7.7788 -10.1411]:"}
{"text": "Convert the coordinate to text: [-0.1699 -7.0923]: The authors propose a novel multi-modal pre-training model for table structure recognition, named TableVLM, which is a two-stream multi-modal transformer-based encoder-decoder architecture. They also created a dataset, called ComplexTable, for pre-training this model.", "target": "The authors propose a novel multi-modal pre-training model for table structure recognition, named TableVLM, which is a two-stream multi-modal transformer-based encoder-decoder architecture. They also created a dataset, called ComplexTable, for pre-training this model.", "example": "Convert the coordinate to text: [-0.1699 -7.0923]:"}
{"text": "Convert the coordinate to text: [13.7668 -0.0776]: The authors propose Conditional Neural Ordinary Differential Equations Processes (CNDPs), which allow for irregularly-sampled time series modelling, accurate forecasting with sparse past observations, and individual-level progression forecasting.", "target": "The authors propose Conditional Neural Ordinary Differential Equations Processes (CNDPs), which allow for irregularly-sampled time series modelling, accurate forecasting with sparse past observations, and individual-level progression forecasting.", "example": "Convert the coordinate to text: [13.7668 -0.0776]:"}
{"text": "Convert the coordinate to text: [9.6289 3.2374]: In this paper, the authors propose an interactive Generalized Additive Model (GAM) that is interpretable and can incorporate specific domain knowledge in the electric power industry for improved performance.", "target": "In this paper, the authors propose an interactive Generalized Additive Model (GAM) that is interpretable and can incorporate specific domain knowledge in the electric power industry for improved performance.", "example": "Convert the coordinate to text: [9.6289 3.2374]:"}
{"text": "Convert the coordinate to text: [ 5.0394 -2.0215]: The authors introduce a novel open-set SSL framework, IOMatch, that jointly utilizes both inliers and outliers, even when it is difficult to determine which is which. Rather than removing outliers, they propose to treat all outliers as a single new class.", "target": "The authors introduce a novel open-set SSL framework, IOMatch, that jointly utilizes both inliers and outliers, even when it is difficult to determine which is which. Rather than removing outliers, they propose to treat all outliers as a single new class.", "example": "Convert the coordinate to text: [ 5.0394 -2.0215]:"}
{"text": "Convert the coordinate to text: [15.3053  0.11  ]: The authors introduce SHACIRA, a task-agnostic framework for compressing feature grids without needing additional post-hoc pruning/quantization stages by reparameterizing feature grids with quantized latent weights and applying entropy regularization in the latent space.", "target": "The authors introduce SHACIRA, a task-agnostic framework for compressing feature grids without needing additional post-hoc pruning/quantization stages by reparameterizing feature grids with quantized latent weights and applying entropy regularization in the latent space.", "example": "Convert the coordinate to text: [15.3053  0.11  ]:"}
{"text": "Convert the coordinate to text: [ 5.4016 -2.594 ]: The authors propose to reformulate SSL from an information-theoretic perspective, thereby disentangling the goal of instance-level discrimination and promoting compact representations with maximally preserved invariance to distortion.", "target": "The authors propose to reformulate SSL from an information-theoretic perspective, thereby disentangling the goal of instance-level discrimination and promoting compact representations with maximally preserved invariance to distortion.", "example": "Convert the coordinate to text: [ 5.4016 -2.594 ]:"}
{"text": "Convert the coordinate to text: [  7.126  -13.3527]: The paper presents False Positive Rectification (FPR), a method that tackles the co-occurrence problem in CAMs by leveraging the false positives. The authors observe that the CAM-activated regions of absent classes contain class-specific co-occurred background cues.", "target": "The paper presents False Positive Rectification (FPR), a method that tackles the co-occurrence problem in CAMs by leveraging the false positives. The authors observe that the CAM-activated regions of absent classes contain class-specific co-occurred background cues.", "example": "Convert the coordinate to text: [  7.126  -13.3527]:"}
{"text": "Convert the coordinate to text: [ 8.9363 -3.8572]: This paper introduces a new tuning paradigm, called Res-Tuning, that unbinds tuners from the backbone, allowing the design of tuners to be independent from the network architecture.", "target": "This paper introduces a new tuning paradigm, called Res-Tuning, that unbinds tuners from the backbone, allowing the design of tuners to be independent from the network architecture.", "example": "Convert the coordinate to text: [ 8.9363 -3.8572]:"}
{"text": "Convert the coordinate to text: [ 6.1228 12.9538]: The authors propose an efficient approach named Sketched Policy Updating with Imputed Rewards (SPUIR). The approach uses sketching to estimate the unobserved rewards, providing a more complete picture of the feedbacks.", "target": "The authors propose an efficient approach named Sketched Policy Updating with Imputed Rewards (SPUIR). The approach uses sketching to estimate the unobserved rewards, providing a more complete picture of the feedbacks.", "example": "Convert the coordinate to text: [ 6.1228 12.9538]:"}
{"text": "Convert the coordinate to text: [ 2.3858 -8.1704]: The authors propose a character-to-character distillation (CCD) method for self-supervised learning which can deal with diverse character structure and allow flexible augmentations for text representation learning.", "target": "The authors propose a character-to-character distillation (CCD) method for self-supervised learning which can deal with diverse character structure and allow flexible augmentations for text representation learning.", "example": "Convert the coordinate to text: [ 2.3858 -8.1704]:"}
{"text": "Convert the coordinate to text: [  1.4896 -11.2145]: The authors aim to study image retrieval frameworks that can identify resemblances between generated images and their corresponding training samples, thus detecting content replication by diffusion models.", "target": "The authors aim to study image retrieval frameworks that can identify resemblances between generated images and their corresponding training samples, thus detecting content replication by diffusion models.", "example": "Convert the coordinate to text: [  1.4896 -11.2145]:"}
{"text": "Convert the coordinate to text: [-2.0148 -4.9391]: The authors investigate methods for cost-efficient inference and fine-tuning of LLMs, comparing local and distributed strategies, with a focus on how to perform inference and fine-tuning reliably if any device can disconnect abruptly and how to partition LLMs between devices with uneven hardware.", "target": "The authors investigate methods for cost-efficient inference and fine-tuning of LLMs, comparing local and distributed strategies, with a focus on how to perform inference and fine-tuning reliably if any device can disconnect abruptly and how to partition LLMs between devices with uneven hardware.", "example": "Convert the coordinate to text: [-2.0148 -4.9391]:"}
{"text": "Convert the coordinate to text: [-3.4412 -5.1907]: The authors conduct a human-centered study to investigate how language models could potentially assist people in reframing negative thoughts, developing automated metrics to measure defined linguistic attributes.", "target": "The authors conduct a human-centered study to investigate how language models could potentially assist people in reframing negative thoughts, developing automated metrics to measure defined linguistic attributes.", "example": "Convert the coordinate to text: [-3.4412 -5.1907]:"}
{"text": "Convert the coordinate to text: [-10.7908  16.7969]: The authors propose a new method that uses two 6-axe Inertial Measurement Units (IMU) on glasses and the wrist to monitor food intake activities. They introduce the concept of the 'first bite/chew' as a reliable indicator to distinguish between food types.", "target": "The authors propose a new method that uses two 6-axe Inertial Measurement Units (IMU) on glasses and the wrist to monitor food intake activities. They introduce the concept of the 'first bite/chew' as a reliable indicator to distinguish between food types.", "example": "Convert the coordinate to text: [-10.7908  16.7969]:"}
{"text": "Convert the coordinate to text: [-3.0936 -5.9215]: This paper defines the task of constrained language planning for the first time and introduces an overgenerate-then-filter approach to improve large language models (LLMs) on this task.", "target": "This paper defines the task of constrained language planning for the first time and introduces an overgenerate-then-filter approach to improve large language models (LLMs) on this task.", "example": "Convert the coordinate to text: [-3.0936 -5.9215]:"}
{"text": "Convert the coordinate to text: [ -7.0885 -10.2023]: The authors present BanglaBook, a large-scale dataset of Bangla book reviews containing 158,065 samples classified into three broad categories: positive, negative, and neutral.", "target": "The authors present BanglaBook, a large-scale dataset of Bangla book reviews containing 158,065 samples classified into three broad categories: positive, negative, and neutral.", "example": "Convert the coordinate to text: [ -7.0885 -10.2023]:"}
{"text": "Convert the coordinate to text: [ 0.4665 -4.4429]: The authors propose PICL (Pre-training for In-Context Learning), a framework to improve a language model's in-context learning ability by training it on a large collection of 'intrinsic tasks' in the general plain-text corpus using a simple language modeling objective.", "target": "The authors propose PICL (Pre-training for In-Context Learning), a framework to improve a language model's in-context learning ability by training it on a large collection of 'intrinsic tasks' in the general plain-text corpus using a simple language modeling objective.", "example": "Convert the coordinate to text: [ 0.4665 -4.4429]:"}
{"text": "Convert the coordinate to text: [-6.7861 -2.3858]: The authors introduce the Automatic Glossary of Clinical Terminology (AGCT), a large-scale dictionary of biomedical concepts generated by extracting high-quality information from the biomedical knowledge in SnomedCT. An unique definition is generated for every SnomedCT concept using the OpenAI Turbo model, a variant of GPT 3.5.", "target": "The authors introduce the Automatic Glossary of Clinical Terminology (AGCT), a large-scale dictionary of biomedical concepts generated by extracting high-quality information from the biomedical knowledge in SnomedCT. An unique definition is generated for every SnomedCT concept using the OpenAI Turbo model, a variant of GPT 3.5.", "example": "Convert the coordinate to text: [-6.7861 -2.3858]:"}
{"text": "Convert the coordinate to text: [-1.0738  4.2993]: This paper puts forth a data science approach for fraud detection in the Bitcoin network. It introduces the Elliptic++ dataset for fraud detection and utilizes four types of graph data: the transaction-to-transaction graph, address-to-address interaction graph, address-transaction graph, and the user entity graph.", "target": "This paper puts forth a data science approach for fraud detection in the Bitcoin network. It introduces the Elliptic++ dataset for fraud detection and utilizes four types of graph data: the transaction-to-transaction graph, address-to-address interaction graph, address-transaction graph, and the user entity graph.", "example": "Convert the coordinate to text: [-1.0738  4.2993]:"}
{"text": "Convert the coordinate to text: [ 9.266  11.4527]: The authors propose analysis of both the best arm identification with fixed confidence (BAI) and the regret minimization objectives in MF-MAB. Furthermore, a new regret definition is proposed for regret minimization of MF-MAB.", "target": "The authors propose analysis of both the best arm identification with fixed confidence (BAI) and the regret minimization objectives in MF-MAB. Furthermore, a new regret definition is proposed for regret minimization of MF-MAB.", "example": "Convert the coordinate to text: [ 9.266  11.4527]:"}
{"text": "Convert the coordinate to text: [-8.0985 -2.0106]: The authors propose the Lee et al. Protocol (LEAP), a standardized and codified annotation protocol that strictly enforces transparency in the annotation process, ensuring the reproducibility of annotation guidelines.", "target": "The authors propose the Lee et al. Protocol (LEAP), a standardized and codified annotation protocol that strictly enforces transparency in the annotation process, ensuring the reproducibility of annotation guidelines.", "example": "Convert the coordinate to text: [-8.0985 -2.0106]:"}
{"text": "Convert the coordinate to text: [-3.9114 -3.5049]: This paper tackles the Legal Entity Name Recognition (L-NER) and Court judgment Prediction (CPJ) and Explanation (CJPE) tasks. It suggests using different transformer-based models, entity-aware methods for domain-specific entities for L-NER, and hierarchical BERT-based classifiers coupled with local input attribution explainers for CJPE.", "target": "This paper tackles the Legal Entity Name Recognition (L-NER) and Court judgment Prediction (CPJ) and Explanation (CJPE) tasks. It suggests using different transformer-based models, entity-aware methods for domain-specific entities for L-NER, and hierarchical BERT-based classifiers coupled with local input attribution explainers for CJPE.", "example": "Convert the coordinate to text: [-3.9114 -3.5049]:"}
{"text": "Convert the coordinate to text: [-8.8907  0.0826]: The authors propose a multi-stage information retrieval (IR) pipeline to improve the performance of language models for fine-grained NER. The pipeline leverages a combination of a BM25-based IR model and a language model to retrieve relevant passages from a corpus, and trains a model that uses a weighted average of losses.", "target": "The authors propose a multi-stage information retrieval (IR) pipeline to improve the performance of language models for fine-grained NER. The pipeline leverages a combination of a BM25-based IR model and a language model to retrieve relevant passages from a corpus, and trains a model that uses a weighted average of losses.", "example": "Convert the coordinate to text: [-8.8907  0.0826]:"}
{"text": "Convert the coordinate to text: [-6.3954 -9.9666]: To address the lack of integration of other modalities in grammatical error correction, the authors propose a novel framework that uses both speech and text features to enhance GEC.", "target": "To address the lack of integration of other modalities in grammatical error correction, the authors propose a novel framework that uses both speech and text features to enhance GEC.", "example": "Convert the coordinate to text: [-6.3954 -9.9666]:"}
{"text": "Convert the coordinate to text: [14.5403  0.3084]: The authors propose SLIQ, the first open-sourced work for resource-efficient quantum similarity detection networks, to overcome the challenge of porting unsupervised similarity detection tasks to run on quantum computers.", "target": "The authors propose SLIQ, the first open-sourced work for resource-efficient quantum similarity detection networks, to overcome the challenge of porting unsupervised similarity detection tasks to run on quantum computers.", "example": "Convert the coordinate to text: [14.5403  0.3084]:"}
{"text": "Convert the coordinate to text: [ 5.2296 -4.8827]: The authors introduce GraphPatcher, a test-time augmentation framework that aims to improve the generalization of GNNs on low-degree nodes by iteratively generating virtual nodes to patch artificially created low-degree nodes through corruption.", "target": "The authors introduce GraphPatcher, a test-time augmentation framework that aims to improve the generalization of GNNs on low-degree nodes by iteratively generating virtual nodes to patch artificially created low-degree nodes through corruption.", "example": "Convert the coordinate to text: [ 5.2296 -4.8827]:"}
{"text": "Convert the coordinate to text: [-9.7554  4.5329]: The authors propose a new model for automatically generating movie AD that addresses the 'who', 'when', and 'what' aspects of the task. They introduce a character bank for character recognition, investigate models for determining when an AD should be generated based on visual content, and implement a new vision-language model for determining what to describe.", "target": "The authors propose a new model for automatically generating movie AD that addresses the 'who', 'when', and 'what' aspects of the task. They introduce a character bank for character recognition, investigate models for determining when an AD should be generated based on visual content, and implement a new vision-language model for determining what to describe.", "example": "Convert the coordinate to text: [-9.7554  4.5329]:"}
{"text": "Convert the coordinate to text: [10.5899  7.7056]: Contrary to existing understanding, this work shows that optimal reproducibility and near-optimal convergence guarantees can coexist for smooth convex minimization and smooth convex-concave minimax problems under various error-prone oracle settings.", "target": "Contrary to existing understanding, this work shows that optimal reproducibility and near-optimal convergence guarantees can coexist for smooth convex minimization and smooth convex-concave minimax problems under various error-prone oracle settings.", "example": "Convert the coordinate to text: [10.5899  7.7056]:"}
{"text": "Convert the coordinate to text: [-7.504  -3.5788]: The authors propose 'EtiCor', an Etiquettes Corpus that contains texts about social norms from five different regions worldwide. They also introduce a new task called 'Etiquette Sensitivity' that aims to evaluate how well LLMs understand region-specific etiquettes.", "target": "The authors propose 'EtiCor', an Etiquettes Corpus that contains texts about social norms from five different regions worldwide. They also introduce a new task called 'Etiquette Sensitivity' that aims to evaluate how well LLMs understand region-specific etiquettes.", "example": "Convert the coordinate to text: [-7.504  -3.5788]:"}
{"text": "Convert the coordinate to text: [10.9004 -5.5163]: The authors propose a model-agnostic method known as DOSE, which incorporates two efficient condition-augmentation techniques to handle the challenge of incorporating condition information into DDPMs for SE. DOSE prioritizes the condition factor during sample generation via dropout operation and provides an informative adaptive prior to inject condition information into the sampling process.", "target": "The authors propose a model-agnostic method known as DOSE, which incorporates two efficient condition-augmentation techniques to handle the challenge of incorporating condition information into DDPMs for SE. DOSE prioritizes the condition factor during sample generation via dropout operation and provides an informative adaptive prior to inject condition information into the sampling process.", "example": "Convert the coordinate to text: [10.9004 -5.5163]:"}
{"text": "Convert the coordinate to text: [5.7561 5.9093]: The authors propose a one-pass distribution sketch to represent the client data distribution in FL. The sketching algorithm requires a single pass of the client data, making it efficient in terms of time and memory.", "target": "The authors propose a one-pass distribution sketch to represent the client data distribution in FL. The sketching algorithm requires a single pass of the client data, making it efficient in terms of time and memory.", "example": "Convert the coordinate to text: [5.7561 5.9093]:"}
{"text": "Convert the coordinate to text: [-5.2143  1.103 ]: The authors propose a new dataset and a method to highlight oversensitive terms using reactivity analysis and the model's performance.", "target": "The authors propose a new dataset and a method to highlight oversensitive terms using reactivity analysis and the model's performance.", "example": "Convert the coordinate to text: [-5.2143  1.103 ]:"}
{"text": "Convert the coordinate to text: [ 0.4462 -9.1418]: In this work, the authors propose GLIGEN, a novel approach that extends the capabilities of existing pre-trained text-to-image diffusion models by enabling them to also be conditioned on grounding inputs while preserving their pre-trained knowledge.", "target": "In this work, the authors propose GLIGEN, a novel approach that extends the capabilities of existing pre-trained text-to-image diffusion models by enabling them to also be conditioned on grounding inputs while preserving their pre-trained knowledge.", "example": "Convert the coordinate to text: [ 0.4462 -9.1418]:"}
{"text": "Convert the coordinate to text: [-1.1329  0.2312]: A counterfactual evaluation corpus is introduced to study gender and racial/migrant bias in four different languages.", "target": "A counterfactual evaluation corpus is introduced to study gender and racial/migrant bias in four different languages.", "example": "Convert the coordinate to text: [-1.1329  0.2312]:"}
{"text": "Convert the coordinate to text: [-5.7723 -5.6667]: This study tackles the problem of figurative language comprehension across diverse languages and cultures by creating a new dataset, called \\datasetname, for seven different languages (Hindi, Indonesian, Javanese, Kannada, Sundanese, Swahili, and Yoruba).", "target": "This study tackles the problem of figurative language comprehension across diverse languages and cultures by creating a new dataset, called \\datasetname, for seven different languages (Hindi, Indonesian, Javanese, Kannada, Sundanese, Swahili, and Yoruba).", "example": "Convert the coordinate to text: [-5.7723 -5.6667]:"}
{"text": "Convert the coordinate to text: [-4.3689 -6.5274]: The authors introduce XSemPLR, a unified benchmark for cross-lingual semantic parsing that includes 22 natural languages and 8 meaning representations, curated through examining and selecting 9 existing datasets. Six experimental settings were designed to cover various lingual combinations and numbers of learning samples.", "target": "The authors introduce XSemPLR, a unified benchmark for cross-lingual semantic parsing that includes 22 natural languages and 8 meaning representations, curated through examining and selecting 9 existing datasets. Six experimental settings were designed to cover various lingual combinations and numbers of learning samples.", "example": "Convert the coordinate to text: [-4.3689 -6.5274]:"}
{"text": "Convert the coordinate to text: [-1.9319 -6.1381]: The authors present their system that uses a transformer-based language model pretrained on biomedical literature for retrieving the necessary evidence and then employs an ensemble approach to determine the entailment.", "target": "The authors present their system that uses a transformer-based language model pretrained on biomedical literature for retrieving the necessary evidence and then employs an ensemble approach to determine the entailment.", "example": "Convert the coordinate to text: [-1.9319 -6.1381]:"}
{"text": "Convert the coordinate to text: [-1.9194 -6.4898]: The authors propose a method to handle News Genre Categorisation and Framing Detection using RoBERTa and ALBERT models.", "target": "The authors propose a method to handle News Genre Categorisation and Framing Detection using RoBERTa and ALBERT models.", "example": "Convert the coordinate to text: [-1.9194 -6.4898]:"}
{"text": "Convert the coordinate to text: [-1.3023 -7.8948]: The authors propose a sequence-to-sequence approach that utilizes both pre-trained multilingual general domain and monolingual biomedical domain pre-trained language models for radiology report summarization.", "target": "The authors propose a sequence-to-sequence approach that utilizes both pre-trained multilingual general domain and monolingual biomedical domain pre-trained language models for radiology report summarization.", "example": "Convert the coordinate to text: [-1.3023 -7.8948]:"}
{"text": "Convert the coordinate to text: [-0.9983  0.3003]: This study investigates gender and native language (L1) biases in human and automated scores, focusing on differential item functioning (DIF), a specific type of bias that arises when comparing examinees of similar English language proficiency, using an off-the-shelf BERT model.", "target": "This study investigates gender and native language (L1) biases in human and automated scores, focusing on differential item functioning (DIF), a specific type of bias that arises when comparing examinees of similar English language proficiency, using an off-the-shelf BERT model.", "example": "Convert the coordinate to text: [-0.9983  0.3003]:"}
{"text": "Convert the coordinate to text: [-8.5513 -6.8388]: The authors propose BLOCSUM, a block scope-based source code summarization technique utilizing shared block representation to capture the structure of different code blocks, effectively merging code and AST. They also introduce variant ASTs to capture richer information like block and global dependencies within the source code.", "target": "The authors propose BLOCSUM, a block scope-based source code summarization technique utilizing shared block representation to capture the structure of different code blocks, effectively merging code and AST. They also introduce variant ASTs to capture richer information like block and global dependencies within the source code.", "example": "Convert the coordinate to text: [-8.5513 -6.8388]:"}
{"text": "Convert the coordinate to text: [13.8932 -2.5995]: The authors propose defining the elementary units of each hidden dimension as neuron-level artificial neurons (ANs) in Wav2Vec2.0, and using these to couple with their biological-neuron (BN) counterparts in the human brain.", "target": "The authors propose defining the elementary units of each hidden dimension as neuron-level artificial neurons (ANs) in Wav2Vec2.0, and using these to couple with their biological-neuron (BN) counterparts in the human brain.", "example": "Convert the coordinate to text: [13.8932 -2.5995]:"}
{"text": "Convert the coordinate to text: [-3.7282 -2.1375]: The study presents a novel Trigger-Argument based Explanation method (TAE) that leverages event structure knowledge, comprising of an event trigger and a set of arguments, to provide faithful interpretations at the neuron level for existing ED models.", "target": "The study presents a novel Trigger-Argument based Explanation method (TAE) that leverages event structure knowledge, comprising of an event trigger and a set of arguments, to provide faithful interpretations at the neuron level for existing ED models.", "example": "Convert the coordinate to text: [-3.7282 -2.1375]:"}
{"text": "Convert the coordinate to text: [-1.1792 -9.9107]: The authors propose to project the visual signal to the common space with language and acoustic signals using a strong multimodality backbone VATT, and also propose content-oriented features Topic and Speaking style to approach subjectivity issues.", "target": "The authors propose to project the visual signal to the common space with language and acoustic signals using a strong multimodality backbone VATT, and also propose content-oriented features Topic and Speaking style to approach subjectivity issues.", "example": "Convert the coordinate to text: [-1.1792 -9.9107]:"}
{"text": "Convert the coordinate to text: [-7.1716  4.7985]: The paper argues that more concrete risk assessments and strategies for mitigation will be possible when analysis is specialized to specific applications and likely users. It uses the specific case of cooking recipe procedural document question answering (ProcDocQA) as an example.", "target": "The paper argues that more concrete risk assessments and strategies for mitigation will be possible when analysis is specialized to specific applications and likely users. It uses the specific case of cooking recipe procedural document question answering (ProcDocQA) as an example.", "example": "Convert the coordinate to text: [-7.1716  4.7985]:"}
{"text": "Convert the coordinate to text: [-2.0451 11.5177]: The authors propose a method to learn neuro-symbolic world models, leveraging Logical Neural Networks (LNN) and enhancing its internal logic state with a memory of previous actions. This method utilizes the concept of conversation proprioception to guide future actions.", "target": "The authors propose a method to learn neuro-symbolic world models, leveraging Logical Neural Networks (LNN) and enhancing its internal logic state with a memory of previous actions. This method utilizes the concept of conversation proprioception to guide future actions.", "example": "Convert the coordinate to text: [-2.0451 11.5177]:"}
{"text": "Convert the coordinate to text: [-8.4204 -0.2315]: The authors propose a more comprehensive benchmark known as Visually Rich Document Understanding (VRDU). VRDU offers two datasets that showcase several challenges: rich schema, complex templates, and diverse layouts within a single document type.", "target": "The authors propose a more comprehensive benchmark known as Visually Rich Document Understanding (VRDU). VRDU offers two datasets that showcase several challenges: rich schema, complex templates, and diverse layouts within a single document type.", "example": "Convert the coordinate to text: [-8.4204 -0.2315]:"}
{"text": "Convert the coordinate to text: [ 1.5817 -9.2668]: The authors propose the Fine-grained Goal Prompting (FGPrompt) method for image-goal navigation, which uses detailed and high-resolution feature maps from the goal image to inform the observation's encoding.", "target": "The authors propose the Fine-grained Goal Prompting (FGPrompt) method for image-goal navigation, which uses detailed and high-resolution feature maps from the goal image to inform the observation's encoding.", "example": "Convert the coordinate to text: [ 1.5817 -9.2668]:"}
{"text": "Convert the coordinate to text: [  3.3852 -13.5296]: To aid the development of generalized automatic aquatic species monitoring systems, the authors present 'FishNet', a large-scale diverse dataset containing 94,532 images from 17,357 aquatic species, organized according to aquatic biological taxonomy. They also provide functional trait data.", "target": "To aid the development of generalized automatic aquatic species monitoring systems, the authors present 'FishNet', a large-scale diverse dataset containing 94,532 images from 17,357 aquatic species, organized according to aquatic biological taxonomy. They also provide functional trait data.", "example": "Convert the coordinate to text: [  3.3852 -13.5296]:"}
{"text": "Convert the coordinate to text: [ 8.297  -3.1586]: The authors propose a novel framework of explainable GNNs, named Prototype-based Graph Information Bottleneck (PGIB). This framework brings prototype learning within the information bottleneck framework to deliver prototypes containing key subgraphs from the input graph that are critical for the model\u2019s predictions.", "target": "The authors propose a novel framework of explainable GNNs, named Prototype-based Graph Information Bottleneck (PGIB). This framework brings prototype learning within the information bottleneck framework to deliver prototypes containing key subgraphs from the input graph that are critical for the model\u2019s predictions.", "example": "Convert the coordinate to text: [ 8.297  -3.1586]:"}
{"text": "Convert the coordinate to text: [ -0.9029 -12.6232]: The authors propose a model that combines generative and sequential networks to model dynamical systems, effectively integrating deterministic and stochastic predictions. This involves learning compact representations of physical variables using an autoencoder, and using a transformer with a conditional normalizing flow model to model temporal sequences of these representations.", "target": "The authors propose a model that combines generative and sequential networks to model dynamical systems, effectively integrating deterministic and stochastic predictions. This involves learning compact representations of physical variables using an autoencoder, and using a transformer with a conditional normalizing flow model to model temporal sequences of these representations.", "example": "Convert the coordinate to text: [ -0.9029 -12.6232]:"}
{"text": "Convert the coordinate to text: [ 3.4614 -4.6362]: The authors propose a novel framework known as STXD (Structural and Temporal Cross-modal Knowledge Distillation) for multi-view 3DOD that works by reducing redundancy of the feature components of the student, maximizing the similarities of cross-modal features, encoding temporal relations of features across a sequence of frames, and adopting a response distillation method at the output level.", "target": "The authors propose a novel framework known as STXD (Structural and Temporal Cross-modal Knowledge Distillation) for multi-view 3DOD that works by reducing redundancy of the feature components of the student, maximizing the similarities of cross-modal features, encoding temporal relations of features across a sequence of frames, and adopting a response distillation method at the output level.", "example": "Convert the coordinate to text: [ 3.4614 -4.6362]:"}
{"text": "Convert the coordinate to text: [-0.6047 11.4307]: The authors propose \"Describe, Explain, Plan and Select\" (DEPS), an interactive planning approach based on Large Language Models (LLMs) that includes error correction from feedback during planning and intelligent ordering of sub-goals using a learnable goal Selector module.", "target": "The authors propose \"Describe, Explain, Plan and Select\" (DEPS), an interactive planning approach based on Large Language Models (LLMs) that includes error correction from feedback during planning and intelligent ordering of sub-goals using a learnable goal Selector module.", "example": "Convert the coordinate to text: [-0.6047 11.4307]:"}
{"text": "Convert the coordinate to text: [16.0776  1.7359]: The authors experimented with the variational method to find an optimal operation for OOD detection, revealing the importance of suppressing abnormally low and high activations and amplifying intermediate activations. This resulted in the proposal of a new technique called Variational Rectified Activation (VRA) that simulates these operations using piecewise functions.", "target": "The authors experimented with the variational method to find an optimal operation for OOD detection, revealing the importance of suppressing abnormally low and high activations and amplifying intermediate activations. This resulted in the proposal of a new technique called Variational Rectified Activation (VRA) that simulates these operations using piecewise functions.", "example": "Convert the coordinate to text: [16.0776  1.7359]:"}
{"text": "Convert the coordinate to text: [ 2.1921 -4.0813]: The main idea is to explore the interaction between empathy detection and empathy intent recognition by performing joint training for the two tasks, and proposing a novel framework, Cascaded Label Signal Network, which uses cascaded interactive attention and label signal enhancement to capture feature exchange information between empathy and empathy intent representations.", "target": "The main idea is to explore the interaction between empathy detection and empathy intent recognition by performing joint training for the two tasks, and proposing a novel framework, Cascaded Label Signal Network, which uses cascaded interactive attention and label signal enhancement to capture feature exchange information between empathy and empathy intent representations.", "example": "Convert the coordinate to text: [ 2.1921 -4.0813]:"}
{"text": "Convert the coordinate to text: [-5.733   4.6266]: The authors propose BIC, a Twitter bot detection framework that integrates text-graph interaction and semantic consistency. It not only models the two modalities (text and graphs) separately, but also enables information exchange across modalities through a text-graph interaction module. Additionally, it models semantic consistency in tweets using attention weights to augment the decision process, specifically to tackle the evolving behavior of Twitter bots.", "target": "The authors propose BIC, a Twitter bot detection framework that integrates text-graph interaction and semantic consistency. It not only models the two modalities (text and graphs) separately, but also enables information exchange across modalities through a text-graph interaction module. Additionally, it models semantic consistency in tweets using attention weights to augment the decision process, specifically to tackle the evolving behavior of Twitter bots.", "example": "Convert the coordinate to text: [-5.733   4.6266]:"}
{"text": "Convert the coordinate to text: [ 0.5161 -6.6582]: The authors propose TPSR, a Transformer-based Planning strategy for Symbolic Regression that incorporates Monte Carlo Tree Search into the transformer decoding process to integrate non-differentiable feedback, such as fitting accuracy and complexity, into the equation generation process.", "target": "The authors propose TPSR, a Transformer-based Planning strategy for Symbolic Regression that incorporates Monte Carlo Tree Search into the transformer decoding process to integrate non-differentiable feedback, such as fitting accuracy and complexity, into the equation generation process.", "example": "Convert the coordinate to text: [ 0.5161 -6.6582]:"}
{"text": "Convert the coordinate to text: [ 7.2316 -3.7256]: The authors propose a new model, PMTrans, based on game theory that creates an intermediate domain to bridge the source and target domains. This is achieved by using a novel ViT-based module, PatchMix, which samples patches from both domains to form this intermediate domain probability distribution.", "target": "The authors propose a new model, PMTrans, based on game theory that creates an intermediate domain to bridge the source and target domains. This is achieved by using a novel ViT-based module, PatchMix, which samples patches from both domains to form this intermediate domain probability distribution.", "example": "Convert the coordinate to text: [ 7.2316 -3.7256]:"}
{"text": "Convert the coordinate to text: [-5.7475 -0.5706]: DiffuSum is proposed, which is a novel paradigm for extractive summarization that generates the desired summary sentence representations with diffusion models and extracts sentences based on sentence representation matching.", "target": "DiffuSum is proposed, which is a novel paradigm for extractive summarization that generates the desired summary sentence representations with diffusion models and extracts sentences based on sentence representation matching.", "example": "Convert the coordinate to text: [-5.7475 -0.5706]:"}
{"text": "Convert the coordinate to text: [ 1.8996 10.6378]: This paper introduces a machine learning approach for autonomous exploration of state spaces and production of visual aids to assist engineers in understanding and inducing invariant properties for program verification.", "target": "This paper introduces a machine learning approach for autonomous exploration of state spaces and production of visual aids to assist engineers in understanding and inducing invariant properties for program verification.", "example": "Convert the coordinate to text: [ 1.8996 10.6378]:"}
{"text": "Convert the coordinate to text: [-4.1502 -4.6219]: The paper proposes a novel method, BERM, to enhance the generalization of dense retrieval by capturing the matching signal between texts. BERM segments a passage into multiple units and imposes two unit-level requirements for representation\u2014semantic unit balance and essential matching unit extractability\u2014to capture effective matching signals.", "target": "The paper proposes a novel method, BERM, to enhance the generalization of dense retrieval by capturing the matching signal between texts. BERM segments a passage into multiple units and imposes two unit-level requirements for representation\u2014semantic unit balance and essential matching unit extractability\u2014to capture effective matching signals.", "example": "Convert the coordinate to text: [-4.1502 -4.6219]:"}
{"text": "Convert the coordinate to text: [-3.2685 -5.7183]: The BRIO training paradigm is introduced, which uses a non-deterministic distribution to lessen the model's reliance on reference summaries and potentially improve model performance during inference. The technique involves fine-tuning pre-trained language models in conjunction with the BRIO paradigm.", "target": "The BRIO training paradigm is introduced, which uses a non-deterministic distribution to lessen the model's reliance on reference summaries and potentially improve model performance during inference. The technique involves fine-tuning pre-trained language models in conjunction with the BRIO paradigm.", "example": "Convert the coordinate to text: [-3.2685 -5.7183]:"}
{"text": "Convert the coordinate to text: [-0.0493 -4.7675]: This paper proposes a method that uses deep metric learning to tackle the argument clustering task with the aim of improving the acquisition of frame element knowledge. This involves fine-tuning a pre-trained language model to distinguish the frame element roles using frame-annotated data.", "target": "This paper proposes a method that uses deep metric learning to tackle the argument clustering task with the aim of improving the acquisition of frame element knowledge. This involves fine-tuning a pre-trained language model to distinguish the frame element roles using frame-annotated data.", "example": "Convert the coordinate to text: [-0.0493 -4.7675]:"}
{"text": "Convert the coordinate to text: [ 3.8387 -3.4032]: The authors propose Pareto Mutual Distillation (Pareto-MD), a new training framework that aims to push the Pareto frontier outwards, rather than making trade-offs, by collaboratively training two Pareto optimal solutions favoring different languages and allowing them to learn from each other's strengths.", "target": "The authors propose Pareto Mutual Distillation (Pareto-MD), a new training framework that aims to push the Pareto frontier outwards, rather than making trade-offs, by collaboratively training two Pareto optimal solutions favoring different languages and allowing them to learn from each other's strengths.", "example": "Convert the coordinate to text: [ 3.8387 -3.4032]:"}
{"text": "Convert the coordinate to text: [ 5.0126 -2.0332]: This paper proposes a new framework called the Decoupled Prototype Learning (DPL) which separates pseudo label disambiguation and representation learning, both of which are critical aspects of generalized intent discovery.", "target": "This paper proposes a new framework called the Decoupled Prototype Learning (DPL) which separates pseudo label disambiguation and representation learning, both of which are critical aspects of generalized intent discovery.", "example": "Convert the coordinate to text: [ 5.0126 -2.0332]:"}
{"text": "Convert the coordinate to text: [-2.1348 -5.3293]: The authors propose Gradient Ascent Post-training (GAP), a technique of updating pretrained language models with a few steps of gradient ascent on random, unlabeled text corpora to enhance their zero-shot generalization capabilities.", "target": "The authors propose Gradient Ascent Post-training (GAP), a technique of updating pretrained language models with a few steps of gradient ascent on random, unlabeled text corpora to enhance their zero-shot generalization capabilities.", "example": "Convert the coordinate to text: [-2.1348 -5.3293]:"}
{"text": "Convert the coordinate to text: [-5.091   8.3857]: The main idea is to identify limitations in 63 available resources for automated identification of GBV, such as lack of theoretical grounding and stakeholder input, static nature, and focus on certain media platforms, by reviewing them through the lens of the GBV framework.", "target": "The main idea is to identify limitations in 63 available resources for automated identification of GBV, such as lack of theoretical grounding and stakeholder input, static nature, and focus on certain media platforms, by reviewing them through the lens of the GBV framework.", "example": "Convert the coordinate to text: [-5.091   8.3857]:"}
{"text": "Convert the coordinate to text: [-2.8262 -6.6912]: The paper introduces TwiBERT, a new pretrained model trained from scratch that is used to perform sentiment analysis on the Twi language, which is one of the 14 African languages included in the SemEval task.", "target": "The paper introduces TwiBERT, a new pretrained model trained from scratch that is used to perform sentiment analysis on the Twi language, which is one of the 14 African languages included in the SemEval task.", "example": "Convert the coordinate to text: [-2.8262 -6.6912]:"}
{"text": "Convert the coordinate to text: [-1.3866  0.0739]: This study treats these two subtasks as one multi-label hierarchical text classification problem and proposes an integrated sexism detection model to improve the performance of the sexism detection task. This model uses the pre-trained BERT model to encode the text and class label, a hierarchy-relevant structure encoder to model the relationship between classes, and a self-training strategy to address the imbalance in class distribution.", "target": "This study treats these two subtasks as one multi-label hierarchical text classification problem and proposes an integrated sexism detection model to improve the performance of the sexism detection task. This model uses the pre-trained BERT model to encode the text and class label, a hierarchy-relevant structure encoder to model the relationship between classes, and a self-training strategy to address the imbalance in class distribution.", "example": "Convert the coordinate to text: [-1.3866  0.0739]:"}
{"text": "Convert the coordinate to text: [-4.884  -2.2251]: The authors emphasize on the importance of sequence context in performing rhetorical roles prediction of legal documents and propose a BiLSTM-based sentence sequence labeling approach using a local context-incorporated dataset created from the original dataset and legal domain-specific sentence embeddings from a Legal BERT model.", "target": "The authors emphasize on the importance of sequence context in performing rhetorical roles prediction of legal documents and propose a BiLSTM-based sentence sequence labeling approach using a local context-incorporated dataset created from the original dataset and legal domain-specific sentence embeddings from a Legal BERT model.", "example": "Convert the coordinate to text: [-4.884  -2.2251]:"}
{"text": "Convert the coordinate to text: [-9.421 -6.464]: This study investigates the effectiveness of integrating high-level discourse profiling information and surface-level sentence position information into temporal dependency graph parsing.", "target": "This study investigates the effectiveness of integrating high-level discourse profiling information and surface-level sentence position information into temporal dependency graph parsing.", "example": "Convert the coordinate to text: [-9.421 -6.464]:"}
{"text": "Convert the coordinate to text: [-0.9487 -5.9828]: The authors investigate the hidden consequences of various pre-training objectives by doing a set of controlled experiments, and argue that the choice of pre-training objective can affect the downstream controllability of models after fine-tuning.", "target": "The authors investigate the hidden consequences of various pre-training objectives by doing a set of controlled experiments, and argue that the choice of pre-training objective can affect the downstream controllability of models after fine-tuning.", "example": "Convert the coordinate to text: [-0.9487 -5.9828]:"}
{"text": "Convert the coordinate to text: [-2.513 -4.788]: The authors observe that a large language model can serve as a highly effective few-shot semantic parser. It can convert natural language sentences into a logical form that serves as input for answer set programs, a logic-based declarative knowledge representation formalism. The combination results in a robust and general system.", "target": "The authors observe that a large language model can serve as a highly effective few-shot semantic parser. It can convert natural language sentences into a logical form that serves as input for answer set programs, a logic-based declarative knowledge representation formalism. The combination results in a robust and general system.", "example": "Convert the coordinate to text: [-2.513 -4.788]:"}
{"text": "Convert the coordinate to text: [-11.633   -1.0925]: This work challenges the reliance on EMSL, highlighting that it reduces robustness and makes models vulnerable to synonym substitution and typos. They suggest improving question-schema encoding with a pre-trained language model instead of using EMSL for a more robust model. Also, they propose a new linking called grammar linking to align grammar references in the question with the SQL keywords.", "target": "This work challenges the reliance on EMSL, highlighting that it reduces robustness and makes models vulnerable to synonym substitution and typos. They suggest improving question-schema encoding with a pre-trained language model instead of using EMSL for a more robust model. Also, they propose a new linking called grammar linking to align grammar references in the question with the SQL keywords.", "example": "Convert the coordinate to text: [-11.633   -1.0925]:"}
{"text": "Convert the coordinate to text: [-8.3757 -3.7789]: The authors introduce the Unified Interactive Natural Understanding of the Italian Language (UINAUIL), a benchmark consisting of six tasks for Italian Natural Language Understanding.", "target": "The authors introduce the Unified Interactive Natural Understanding of the Italian Language (UINAUIL), a benchmark consisting of six tasks for Italian Natural Language Understanding.", "example": "Convert the coordinate to text: [-8.3757 -3.7789]:"}
{"text": "Convert the coordinate to text: [-17.2225   3.081 ]: The authors propose a hybrid cache that integrates two eviction policies to separately capture global and local entities, effectively reducing cache misses and improving coreference resolution.", "target": "The authors propose a hybrid cache that integrates two eviction policies to separately capture global and local entities, effectively reducing cache misses and improving coreference resolution.", "example": "Convert the coordinate to text: [-17.2225   3.081 ]:"}
{"text": "Convert the coordinate to text: [-1.5464 -4.8772]: The authors propose a simple and efficient tuning network known as the Knowledgeable Parameter Efficient (KPE) tuning network to couple Pretrained Language Models (PLMs) with external knowledge for improved commonsense question answering.", "target": "The authors propose a simple and efficient tuning network known as the Knowledgeable Parameter Efficient (KPE) tuning network to couple Pretrained Language Models (PLMs) with external knowledge for improved commonsense question answering.", "example": "Convert the coordinate to text: [-1.5464 -4.8772]:"}
{"text": "Convert the coordinate to text: [ 5.6592 -5.5025]: Authors propose a novel MPNN space for data-dependent receptive fields (MpnnDRF) which dynamically designs suitable MPNNs to capture the receptive field for the given graph along with several key design dimensions to improve existing designs.", "target": "Authors propose a novel MPNN space for data-dependent receptive fields (MpnnDRF) which dynamically designs suitable MPNNs to capture the receptive field for the given graph along with several key design dimensions to improve existing designs.", "example": "Convert the coordinate to text: [ 5.6592 -5.5025]:"}
{"text": "Convert the coordinate to text: [ 0.1275 -8.6849]: The authors propose RLIPv2, a fast converging model that scales relational pre-training to large-scale pseudo-labelled scene graph data, achieved by introducing Asymmetric Language-Image Fusion (ALIF), and a way to extend object detection datasets with free-form relation labels.", "target": "The authors propose RLIPv2, a fast converging model that scales relational pre-training to large-scale pseudo-labelled scene graph data, achieved by introducing Asymmetric Language-Image Fusion (ALIF), and a way to extend object detection datasets with free-form relation labels.", "example": "Convert the coordinate to text: [ 0.1275 -8.6849]:"}
{"text": "Convert the coordinate to text: [11.0038  2.3509]: This paper explores the question of understanding the behavior of spectral steps in clustering problems, particularly the power of the vanilla-SVD algorithm in the stochastic block model (SBM).", "target": "This paper explores the question of understanding the behavior of spectral steps in clustering problems, particularly the power of the vanilla-SVD algorithm in the stochastic block model (SBM).", "example": "Convert the coordinate to text: [11.0038  2.3509]:"}
{"text": "Convert the coordinate to text: [12.8502  6.5874]: The authors propose a module-wise regularization inspired by the minimizing movement scheme for gradient flows in distribution space, which they named as Transport Regularized Greedy Learning (TRGL), to solve the stagnation problem in module-wise training of neural networks.", "target": "The authors propose a module-wise regularization inspired by the minimizing movement scheme for gradient flows in distribution space, which they named as Transport Regularized Greedy Learning (TRGL), to solve the stagnation problem in module-wise training of neural networks.", "example": "Convert the coordinate to text: [12.8502  6.5874]:"}
{"text": "Convert the coordinate to text: [11.1599 -6.7619]: The authors introduce TexFusion, a new method to synthesize textures for 3D geometries using large-scale text-guided image diffusion models. This method leverages latent diffusion models, applies the diffusion model's denoiser on a set of 2D renders of the 3D object, and aggregates the different denoising predictions on a shared latent texture map.", "target": "The authors introduce TexFusion, a new method to synthesize textures for 3D geometries using large-scale text-guided image diffusion models. This method leverages latent diffusion models, applies the diffusion model's denoiser on a set of 2D renders of the 3D object, and aggregates the different denoising predictions on a shared latent texture map.", "example": "Convert the coordinate to text: [11.1599 -6.7619]:"}
{"text": "Convert the coordinate to text: [ 2.4466 -1.0367]: The authors propose an adaptive bootstrapping approach, where neighbors are selected based on the estimated quality of the latent space, as a small change to the contrastive learning setting, which does not perform well with the naive bootstrapping technique.", "target": "The authors propose an adaptive bootstrapping approach, where neighbors are selected based on the estimated quality of the latent space, as a small change to the contrastive learning setting, which does not perform well with the naive bootstrapping technique.", "example": "Convert the coordinate to text: [ 2.4466 -1.0367]:"}
{"text": "Convert the coordinate to text: [3.1304 0.1625]: The authors propose a novel approach to agnostic active learning, resulting in an algorithm that is competitive with the optimal algorithm for any binary hypothesis class $H$ and distribution $D_X$ over $X$.", "target": "The authors propose a novel approach to agnostic active learning, resulting in an algorithm that is competitive with the optimal algorithm for any binary hypothesis class $H$ and distribution $D_X$ over $X$.", "example": "Convert the coordinate to text: [3.1304 0.1625]:"}
{"text": "Convert the coordinate to text: [1.0189 0.662 ]: The authors propose to interpret models using feature synthesis methods that do not rely on a specific dataset. They also propose the concept of implanting human-interpretable trojans into models and using these as a ground truth to evaluate the effectiveness of interpretability tools.", "target": "The authors propose to interpret models using feature synthesis methods that do not rely on a specific dataset. They also propose the concept of implanting human-interpretable trojans into models and using these as a ground truth to evaluate the effectiveness of interpretability tools.", "example": "Convert the coordinate to text: [1.0189 0.662 ]:"}
{"text": "Convert the coordinate to text: [ 3.881  -0.2914]: The authors propose a sampling strategy that combines feature diversity with low rank correction, formulated in the context of bilinear tensor models, to help select which unlabeled documents should be chosen for annotation.", "target": "The authors propose a sampling strategy that combines feature diversity with low rank correction, formulated in the context of bilinear tensor models, to help select which unlabeled documents should be chosen for annotation.", "example": "Convert the coordinate to text: [ 3.881  -0.2914]:"}
{"text": "Convert the coordinate to text: [  0.2964 -15.3882]: The authors propose a self-supervised learning (SSL) framework, referred to as MBrain, for brain signals that can pre-train either SEEG or EEG data. The study introduces the concept of learning implicit spatial and temporal correlations between different channels corresponding to different brain areas.", "target": "The authors propose a self-supervised learning (SSL) framework, referred to as MBrain, for brain signals that can pre-train either SEEG or EEG data. The study introduces the concept of learning implicit spatial and temporal correlations between different channels corresponding to different brain areas.", "example": "Convert the coordinate to text: [  0.2964 -15.3882]:"}
{"text": "Convert the coordinate to text: [-6.7978 -9.5902]: This paper designs an adversarial attack to test whether morphological information contributes to error propagation or if it can help correct mistakes that parsers which only utilize words make.", "target": "This paper designs an adversarial attack to test whether morphological information contributes to error propagation or if it can help correct mistakes that parsers which only utilize words make.", "example": "Convert the coordinate to text: [-6.7978 -9.5902]:"}
{"text": "Convert the coordinate to text: [-7.557  -4.3773]: This paper proposes a multi-task deep learning framework to detect hyperbole and metaphor simultaneously, hypothesizing that metaphors and hyperboles aid in the detection of each other.", "target": "This paper proposes a multi-task deep learning framework to detect hyperbole and metaphor simultaneously, hypothesizing that metaphors and hyperboles aid in the detection of each other.", "example": "Convert the coordinate to text: [-7.557  -4.3773]:"}
{"text": "Convert the coordinate to text: [15.6128 -0.1518]: The authors propose a solution to the problem by mixing statistics-based quantization for the weights and elastic quantization of the activations and demonstrate ternary and binary transformer models on the downstream tasks of summarization and machine translation.", "target": "The authors propose a solution to the problem by mixing statistics-based quantization for the weights and elastic quantization of the activations and demonstrate ternary and binary transformer models on the downstream tasks of summarization and machine translation.", "example": "Convert the coordinate to text: [15.6128 -0.1518]:"}
{"text": "Convert the coordinate to text: [-0.6698 -3.215 ]: This study proposes ShrinkE, a geometric hyper-relational KG embedding method that explicitly models essential inference patterns of hyper-relational facts such as qualifier monotonicity, qualifier implication, and qualifier mutual exclusion.", "target": "This study proposes ShrinkE, a geometric hyper-relational KG embedding method that explicitly models essential inference patterns of hyper-relational facts such as qualifier monotonicity, qualifier implication, and qualifier mutual exclusion.", "example": "Convert the coordinate to text: [-0.6698 -3.215 ]:"}
{"text": "Convert the coordinate to text: [  3.8691 -11.3358]: The paper introduces ShuttleSet, the largest publicly-available badminton singles dataset with annotated stroke-level records, created using a computer-aided labeling tool to efficiently and effectively label the shot type, hitting locations, and the locations of both players at each stroke.", "target": "The paper introduces ShuttleSet, the largest publicly-available badminton singles dataset with annotated stroke-level records, created using a computer-aided labeling tool to efficiently and effectively label the shot type, hitting locations, and the locations of both players at each stroke.", "example": "Convert the coordinate to text: [  3.8691 -11.3358]:"}
{"text": "Convert the coordinate to text: [ 1.1786 -7.5039]: This study presents the first unified comparison of self-attention-based Transformer variants across text, speech, and vision, aiming to identify input length thresholds at which efficient Transformer variants outperform the vanilla models in terms of various efficiency metrics.", "target": "This study presents the first unified comparison of self-attention-based Transformer variants across text, speech, and vision, aiming to identify input length thresholds at which efficient Transformer variants outperform the vanilla models in terms of various efficiency metrics.", "example": "Convert the coordinate to text: [ 1.1786 -7.5039]:"}
{"text": "Convert the coordinate to text: [9.6854 7.4072]: The authors propose a method of instruction optimization which optimizes training instructions with respect to generalization ability. The authors introduce learnable instructions and optimize these using gradient descent via bilevel optimization.", "target": "The authors propose a method of instruction optimization which optimizes training instructions with respect to generalization ability. The authors introduce learnable instructions and optimize these using gradient descent via bilevel optimization.", "example": "Convert the coordinate to text: [9.6854 7.4072]:"}
{"text": "Convert the coordinate to text: [-5.7592 10.2827]: This study introduces XDailyDialog, a multilingual parallel open-domain dialog dataset, and kNN-Chat, a dialog generation model with a novel kNN-search mechanism to support unified response retrieval for monolingual, multilingual, and cross-lingual dialogue.", "target": "This study introduces XDailyDialog, a multilingual parallel open-domain dialog dataset, and kNN-Chat, a dialog generation model with a novel kNN-search mechanism to support unified response retrieval for monolingual, multilingual, and cross-lingual dialogue.", "example": "Convert the coordinate to text: [-5.7592 10.2827]:"}
{"text": "Convert the coordinate to text: [-8.6338 -5.1381]: The authors propose to model semantic proto-role labeling jointly with predicate-argument extraction, utilizing a deep transformer model.", "target": "The authors propose to model semantic proto-role labeling jointly with predicate-argument extraction, utilizing a deep transformer model.", "example": "Convert the coordinate to text: [-8.6338 -5.1381]:"}
{"text": "Convert the coordinate to text: [ 5.9297 -2.5446]: The authors propose a novel adapter method that decouples general language representation learning and task-specific feature extraction. They also introduce a non-parametric simplex equiangular tight frame classifier (ETF) for improvement.", "target": "The authors propose a novel adapter method that decouples general language representation learning and task-specific feature extraction. They also introduce a non-parametric simplex equiangular tight frame classifier (ETF) for improvement.", "example": "Convert the coordinate to text: [ 5.9297 -2.5446]:"}
{"text": "Convert the coordinate to text: [-1.8238 -6.296 ]: The authors fine-tune two transformer models, the PubMedBERT for the evidence retrieval sub-task and the BioLinkBERT for the textual entailment sub-task. The output from the evidence retrieval model is passed into the textual entailment model.", "target": "The authors fine-tune two transformer models, the PubMedBERT for the evidence retrieval sub-task and the BioLinkBERT for the textual entailment sub-task. The output from the evidence retrieval model is passed into the textual entailment model.", "example": "Convert the coordinate to text: [-1.8238 -6.296 ]:"}
{"text": "Convert the coordinate to text: [-3.4641 -8.2868]: The author proposes an ensemble of two Neural network systems, utilizing OpenAI Clip based models for English, and multilingual text-to-text models for Farsi-to-English and Italian-to-English translation.", "target": "The author proposes an ensemble of two Neural network systems, utilizing OpenAI Clip based models for English, and multilingual text-to-text models for Farsi-to-English and Italian-to-English translation.", "example": "Convert the coordinate to text: [-3.4641 -8.2868]:"}
{"text": "Convert the coordinate to text: [-2.6574 -6.8905]: The proposed system addresses these challenges by extracting contextual representations from the pretrained language models, XLM-T, and implementing various optimization methods, including adversarial training, data augmentation, ordinal regression loss, and a special training strategy.", "target": "The proposed system addresses these challenges by extracting contextual representations from the pretrained language models, XLM-T, and implementing various optimization methods, including adversarial training, data augmentation, ordinal regression loss, and a special training strategy.", "example": "Convert the coordinate to text: [-2.6574 -6.8905]:"}
{"text": "Convert the coordinate to text: [-4.1483 -4.1142]: This paper compares the impact of intermediate training with one versus many tasks in a setup where the choice of datasets is more arbitrary, using all SemEval 2023 text-based tasks.", "target": "This paper compares the impact of intermediate training with one versus many tasks in a setup where the choice of datasets is more arbitrary, using all SemEval 2023 text-based tasks.", "example": "Convert the coordinate to text: [-4.1483 -4.1142]:"}
{"text": "Convert the coordinate to text: [-1.8521 -5.3995]: The paper presents a system that prompts GPT-3.5-turbo to generate initial suggestions for teacher responses, which are then reranked. It suggests multiple strategies for candidate generation, with the focus on using iterative few-shot prompts with negative examples.", "target": "The paper presents a system that prompts GPT-3.5-turbo to generate initial suggestions for teacher responses, which are then reranked. It suggests multiple strategies for candidate generation, with the focus on using iterative few-shot prompts with negative examples.", "example": "Convert the coordinate to text: [-1.8521 -5.3995]:"}
{"text": "Convert the coordinate to text: [-1.9124 -7.4661]: The authors propose a solution to improve tagging-based Grammatical Error Correction models by down-weighting the loss of well-classified labels using Focal Loss and decoupling the error detection layer from the label tagging layer through an extra self-attention-based matching module.", "target": "The authors propose a solution to improve tagging-based Grammatical Error Correction models by down-weighting the loss of well-classified labels using Focal Loss and decoupling the error detection layer from the label tagging layer through an extra self-attention-based matching module.", "example": "Convert the coordinate to text: [-1.9124 -7.4661]:"}
{"text": "Convert the coordinate to text: [ 4.8402 -0.8262]: This study proposes that the distinction between robust and non-robust instances in a training dataset can be a crucial factor in building a highly robust model, and introduces a new method of distinguishing these instances based on the model\u2019s sensitivity to perturbations on individual instances during training.", "target": "This study proposes that the distinction between robust and non-robust instances in a training dataset can be a crucial factor in building a highly robust model, and introduces a new method of distinguishing these instances based on the model\u2019s sensitivity to perturbations on individual instances during training.", "example": "Convert the coordinate to text: [ 4.8402 -0.8262]:"}
{"text": "Convert the coordinate to text: [ 0.962  -2.7252]: The authors have adapted and evaluated various techniques to mitigate the redundancy problem, including negative training, decoding, and classification. Additionally, they propose a straightforward method to generate training data without having to crowdsource human-human or human-bot conversations.", "target": "The authors have adapted and evaluated various techniques to mitigate the redundancy problem, including negative training, decoding, and classification. Additionally, they propose a straightforward method to generate training data without having to crowdsource human-human or human-bot conversations.", "example": "Convert the coordinate to text: [ 0.962  -2.7252]:"}
{"text": "Convert the coordinate to text: [ 4.0923 10.2442]: The authors propose a Dynamic-Tree Driven Theorem Solver (DT-Solver) that guides the search process with state confidence and proof-level values, introducing a dynamic-tree Monte-Carlo search algorithm which allocates computation resources based on state confidences.", "target": "The authors propose a Dynamic-Tree Driven Theorem Solver (DT-Solver) that guides the search process with state confidence and proof-level values, introducing a dynamic-tree Monte-Carlo search algorithm which allocates computation resources based on state confidences.", "example": "Convert the coordinate to text: [ 4.0923 10.2442]:"}
{"text": "Convert the coordinate to text: [ 3.8571 -3.3551]: This work proposes to explore the possibility of directly adopting the teacher model to conduct planning, allowing the student model to focus more on the perception part. It also introduces DriveAdapter, a system to employ adapters with the feature alignment objective function between the student and teacher modules.", "target": "This work proposes to explore the possibility of directly adopting the teacher model to conduct planning, allowing the student model to focus more on the perception part. It also introduces DriveAdapter, a system to employ adapters with the feature alignment objective function between the student and teacher modules.", "example": "Convert the coordinate to text: [ 3.8571 -3.3551]:"}
{"text": "Convert the coordinate to text: [ 7.2379 10.3066]: The authors introduce a probabilistic approach to inverse optimal control for partially observable stochastic non-linear systems with unobserved action signals, which unifies previous approaches to inverse optimal control with maximum causal entropy formulations.", "target": "The authors introduce a probabilistic approach to inverse optimal control for partially observable stochastic non-linear systems with unobserved action signals, which unifies previous approaches to inverse optimal control with maximum causal entropy formulations.", "example": "Convert the coordinate to text: [ 7.2379 10.3066]:"}
{"text": "Convert the coordinate to text: [ 14.7691 -15.0556]: The authors propose a weakly supervised approach to tackle the challenges in 3D open-vocabulary segmentation by distilling open-vocabulary multimodal knowledge and object reasoning capability from pre-trained foundation models \u2014 CLIP and DINO, into a neural radiance field (NeRF) using only open-vocabulary text descriptions of the objects in a scene.", "target": "The authors propose a weakly supervised approach to tackle the challenges in 3D open-vocabulary segmentation by distilling open-vocabulary multimodal knowledge and object reasoning capability from pre-trained foundation models \u2014 CLIP and DINO, into a neural radiance field (NeRF) using only open-vocabulary text descriptions of the objects in a scene.", "example": "Convert the coordinate to text: [ 14.7691 -15.0556]:"}
{"text": "Convert the coordinate to text: [-11.2423  10.6626]: This study aims to better understand the challenges of supporting mental wellbeing at work in the context of software engineering by interviewing 14 software engineers about their lived experiences, strategies for managing mental wellbeing, and recommendations they have for mental wellbeing technologies.", "target": "This study aims to better understand the challenges of supporting mental wellbeing at work in the context of software engineering by interviewing 14 software engineers about their lived experiences, strategies for managing mental wellbeing, and recommendations they have for mental wellbeing technologies.", "example": "Convert the coordinate to text: [-11.2423  10.6626]:"}
{"text": "Convert the coordinate to text: [ 0.3677 -6.4501]: The authors propose a modular retriever, where individual modules correspond to key skills that can be reused across datasets. They introduce a novel parameterization method inspired by the sparse Transformer to mitigate task interference. The model supports flexible skill configurations based on the target domain for performance enhancement.", "target": "The authors propose a modular retriever, where individual modules correspond to key skills that can be reused across datasets. They introduce a novel parameterization method inspired by the sparse Transformer to mitigate task interference. The model supports flexible skill configurations based on the target domain for performance enhancement.", "example": "Convert the coordinate to text: [ 0.3677 -6.4501]:"}
{"text": "Convert the coordinate to text: [1.5927 0.8047]: The authors introduce 'NoveltyTask', a multi-stage task to evaluate a system's performance on the detection and accommodation of novel instances, providing its mathematical formulation. The authors also instantiate it with the authorship attribution task, a task related to identifying the correct author of a given text.", "target": "The authors introduce 'NoveltyTask', a multi-stage task to evaluate a system's performance on the detection and accommodation of novel instances, providing its mathematical formulation. The authors also instantiate it with the authorship attribution task, a task related to identifying the correct author of a given text.", "example": "Convert the coordinate to text: [1.5927 0.8047]:"}
{"text": "Convert the coordinate to text: [-2.5331 -5.1615]: The authors propose a detailed analysis of legal-oriented PLMs, investigating their upstream, probing and downstream performance, and considering both model size and pre-training corpora. Two new resources are released to facilitate this: a multinational English legal corpus (LeXFiles) and a legal knowledge probing benchmark (LegalLAMA).", "target": "The authors propose a detailed analysis of legal-oriented PLMs, investigating their upstream, probing and downstream performance, and considering both model size and pre-training corpora. Two new resources are released to facilitate this: a multinational English legal corpus (LeXFiles) and a legal knowledge probing benchmark (LegalLAMA).", "example": "Convert the coordinate to text: [-2.5331 -5.1615]:"}
{"text": "Convert the coordinate to text: [-1.2478 -5.0102]: A robust model called the prompt- and trait relation-aware cross-prompt essay trait scorer is proposed in this paper, which encodes prompt-aware essay representation by essay-prompt attention and uses the topic-coherence feature extracted by the topic-modeling mechanism.", "target": "A robust model called the prompt- and trait relation-aware cross-prompt essay trait scorer is proposed in this paper, which encodes prompt-aware essay representation by essay-prompt attention and uses the topic-coherence feature extracted by the topic-modeling mechanism.", "example": "Convert the coordinate to text: [-1.2478 -5.0102]:"}
{"text": "Convert the coordinate to text: [-3.8755 -9.3647]: The authors introduce ISLTranslate, a translation dataset for continuous Indian Sign Language (ISL) consisting of 31k ISL-English sentence/phrase pairs.", "target": "The authors introduce ISLTranslate, a translation dataset for continuous Indian Sign Language (ISL) consisting of 31k ISL-English sentence/phrase pairs.", "example": "Convert the coordinate to text: [-3.8755 -9.3647]:"}
{"text": "Convert the coordinate to text: [-2.5137 -6.8023]: Their system iREL employs translation-based augmentation, domain-specific features, and domain-adapted pre-trained models to improve understanding of intimacy in tweets.", "target": "Their system iREL employs translation-based augmentation, domain-specific features, and domain-adapted pre-trained models to improve understanding of intimacy in tweets.", "example": "Convert the coordinate to text: [-2.5137 -6.8023]:"}
{"text": "Convert the coordinate to text: [-9.8967 -0.975 ]: The authors propose a new approach, which includes collecting a large-scale QA dataset with real feedback from a popular Virtual Assistant, and developing two strategies to de-noise the feedback: ranking users with an automatic classifier and aggregating feedback over similar instances.", "target": "The authors propose a new approach, which includes collecting a large-scale QA dataset with real feedback from a popular Virtual Assistant, and developing two strategies to de-noise the feedback: ranking users with an automatic classifier and aggregating feedback over similar instances.", "example": "Convert the coordinate to text: [-9.8967 -0.975 ]:"}
{"text": "Convert the coordinate to text: [-0.3303 -3.4964]: The authors propose a novel Graph Propagated Data Augmentation (GPDA) framework for Named Entity Recognition (NER), where graph propagation is used to build relationships between labeled data and unlabeled natural texts. The annotations from the labeled text are projected onto the unlabeled text, resulting in more diverse partial labels compared to synthetic annotated data.", "target": "The authors propose a novel Graph Propagated Data Augmentation (GPDA) framework for Named Entity Recognition (NER), where graph propagation is used to build relationships between labeled data and unlabeled natural texts. The annotations from the labeled text are projected onto the unlabeled text, resulting in more diverse partial labels compared to synthetic annotated data.", "example": "Convert the coordinate to text: [-0.3303 -3.4964]:"}
{"text": "Convert the coordinate to text: [-4.8023 -0.5114]: This paper expands on prior work by considering metrics that indirectly predict test error, focusing on natural language processing tasks and exploring metrics that do not need access to data for computation.", "target": "This paper expands on prior work by considering metrics that indirectly predict test error, focusing on natural language processing tasks and exploring metrics that do not need access to data for computation.", "example": "Convert the coordinate to text: [-4.8023 -0.5114]:"}
{"text": "Convert the coordinate to text: [13.6523 -4.4976]: The researchers propose an investigation into the security threats posed by malicious PLMs on these emerging databases middleware. They introduce a novel type of Trojan attacks where a malicious designed PLM results in unexpected behavior in the database middleware.", "target": "The researchers propose an investigation into the security threats posed by malicious PLMs on these emerging databases middleware. They introduce a novel type of Trojan attacks where a malicious designed PLM results in unexpected behavior in the database middleware.", "example": "Convert the coordinate to text: [13.6523 -4.4976]:"}
{"text": "Convert the coordinate to text: [ 3.6023 -8.0474]: A new Focused Linear Attention module is proposed, which takes into account factors contributing to the performance degradation of linear attention, i.e., focus ability and feature diversity, and introduces a simple, effective mapping function and an efficient rank restoration module to enhance the expressiveness of self-attention while maintaining low computation complexity.", "target": "A new Focused Linear Attention module is proposed, which takes into account factors contributing to the performance degradation of linear attention, i.e., focus ability and feature diversity, and introduces a simple, effective mapping function and an efficient rank restoration module to enhance the expressiveness of self-attention while maintaining low computation complexity.", "example": "Convert the coordinate to text: [ 3.6023 -8.0474]:"}
{"text": "Convert the coordinate to text: [ 10.8949 -12.4752]: The authors propose that human structure priors offer significant potential in enhancing the effectiveness of MIM. They incorporate an intuitive human structure prior - human parts - into pre-training by using this prior to guide the mask sampling process. The authors also present a structure-invariant alignment loss to capture human characteristics.", "target": "The authors propose that human structure priors offer significant potential in enhancing the effectiveness of MIM. They incorporate an intuitive human structure prior - human parts - into pre-training by using this prior to guide the mask sampling process. The authors also present a structure-invariant alignment loss to capture human characteristics.", "example": "Convert the coordinate to text: [ 10.8949 -12.4752]:"}
{"text": "Convert the coordinate to text: [13.3361 -7.0047]: The authors propose a regularized conditional Wasserstein Generative Adversarial Network (GAN) that strives to rapidly and accurately sample from the posterior distribution rather than just generating one good image estimate. This takes the form of generating multiple high-quality posterior samples every second which includes a regularization of an $\\ell_1$ penalty and an adaptively weighted standard-deviation reward.", "target": "The authors propose a regularized conditional Wasserstein Generative Adversarial Network (GAN) that strives to rapidly and accurately sample from the posterior distribution rather than just generating one good image estimate. This takes the form of generating multiple high-quality posterior samples every second which includes a regularization of an $\\ell_1$ penalty and an adaptively weighted standard-deviation reward.", "example": "Convert the coordinate to text: [13.3361 -7.0047]:"}
{"text": "Convert the coordinate to text: [ 3.6275 -8.1019]: The authors propose an extension to FlashAttention, a lightening-fast implementation from Dao et al. (2022), to enable it to accommodate a wider range of attention sparsity patterns, without adding computational complexity overhead.", "target": "The authors propose an extension to FlashAttention, a lightening-fast implementation from Dao et al. (2022), to enable it to accommodate a wider range of attention sparsity patterns, without adding computational complexity overhead.", "example": "Convert the coordinate to text: [ 3.6275 -8.1019]:"}
{"text": "Convert the coordinate to text: [ 6.7231 12.1779]: The proposal is a novel method for learning a composition of neural network policies in stochastic environments. It includes a formal certificate that guarantees a specification over the policy's behavior to be satisfied with the desired probability.", "target": "The proposal is a novel method for learning a composition of neural network policies in stochastic environments. It includes a formal certificate that guarantees a specification over the policy's behavior to be satisfied with the desired probability.", "example": "Convert the coordinate to text: [ 6.7231 12.1779]:"}
{"text": "Convert the coordinate to text: [9.2787 7.074 ]: The authors empirically demonstrate ERM's tendency to learn both spurious and invariant features, indicating it as a bottleneck in OOD generalization. They propose a method known as Feature Augmented Training (FeAT) to decrease reliance on ERM's feature learning and promote richer feature learning, thereby improving OOD performance.", "target": "The authors empirically demonstrate ERM's tendency to learn both spurious and invariant features, indicating it as a bottleneck in OOD generalization. They propose a method known as Feature Augmented Training (FeAT) to decrease reliance on ERM's feature learning and promote richer feature learning, thereby improving OOD performance.", "example": "Convert the coordinate to text: [9.2787 7.074 ]:"}
{"text": "Convert the coordinate to text: [-0.5825 -9.3735]: The authors introduce a method that learns multimodal alignment between audio and lyrics through contrastive learning, recognizing and accentuating the synergy between audio and lyrics for deeper cross-modal coherence and high-quality captioning.", "target": "The authors introduce a method that learns multimodal alignment between audio and lyrics through contrastive learning, recognizing and accentuating the synergy between audio and lyrics for deeper cross-modal coherence and high-quality captioning.", "example": "Convert the coordinate to text: [-0.5825 -9.3735]:"}
{"text": "Convert the coordinate to text: [6.4313 3.8849]: The paper presents a new approach, Support Decomposition Variational Inference (SDVI), which breaks the program down into sub-programs with static support and automatically builds separate sub-guides for each sub-program.", "target": "The paper presents a new approach, Support Decomposition Variational Inference (SDVI), which breaks the program down into sub-programs with static support and automatically builds separate sub-guides for each sub-program.", "example": "Convert the coordinate to text: [6.4313 3.8849]:"}
{"text": "Convert the coordinate to text: [ 2.7705 -4.5806]: The authors propose 'Information Gating' as a method for learning parsimonious representations. Information gating works by learning masks that capture only the minimal information required to solve a given task. This results in models learning to identify which visual cues are essential for a task.", "target": "The authors propose 'Information Gating' as a method for learning parsimonious representations. Information gating works by learning masks that capture only the minimal information required to solve a given task. This results in models learning to identify which visual cues are essential for a task.", "example": "Convert the coordinate to text: [ 2.7705 -4.5806]:"}
{"text": "Convert the coordinate to text: [-2.8645 -6.8537]: The authors developed an approach using models initialized with AfroXLMR-large, a pre-trained multilingual language model trained on African languages, along with augmented training data. They use a phylogeny-based adapter tuning to create an ensemble of models.", "target": "The authors developed an approach using models initialized with AfroXLMR-large, a pre-trained multilingual language model trained on African languages, along with augmented training data. They use a phylogeny-based adapter tuning to create an ensemble of models.", "example": "Convert the coordinate to text: [-2.8645 -6.8537]:"}
{"text": "Convert the coordinate to text: [-5.4837 10.1724]: The authors propose an 'End-to-end Task-Oriented Dialogue system with Task-Optimized Adapters' which learn independently per task. The model intended is relatively lightweight, fast compared to pre-trained language models and does not require prompt-tuning.", "target": "The authors propose an 'End-to-end Task-Oriented Dialogue system with Task-Optimized Adapters' which learn independently per task. The model intended is relatively lightweight, fast compared to pre-trained language models and does not require prompt-tuning.", "example": "Convert the coordinate to text: [-5.4837 10.1724]:"}
{"text": "Convert the coordinate to text: [-5.0623 10.0555]: The authors propose a coherent dialogue planning approach that uses a stochastic process to model the temporal dynamics of dialogue paths and a Brownian bridge process to capture the coherence of goal-directed behavior.", "target": "The authors propose a coherent dialogue planning approach that uses a stochastic process to model the temporal dynamics of dialogue paths and a Brownian bridge process to capture the coherence of goal-directed behavior.", "example": "Convert the coordinate to text: [-5.0623 10.0555]:"}
{"text": "Convert the coordinate to text: [-0.4451 -4.132 ]: The authors propose an asymmetric feature interaction attribution explanation model that aims to explore asymmetric higher-order feature interactions in the inference of deep neural NLP models.", "target": "The authors propose an asymmetric feature interaction attribution explanation model that aims to explore asymmetric higher-order feature interactions in the inference of deep neural NLP models.", "example": "Convert the coordinate to text: [-0.4451 -4.132 ]:"}
{"text": "Convert the coordinate to text: [-5.5177 10.0026]: The authors propose a new multi-source knowledge fusion method for Cognitive Stimulation dialogue and construct a Chinese CS conversation (CSConv) dataset. This dataset includes around 2.6K groups of dialogues with CS principles and emotional support strategy labels.", "target": "The authors propose a new multi-source knowledge fusion method for Cognitive Stimulation dialogue and construct a Chinese CS conversation (CSConv) dataset. This dataset includes around 2.6K groups of dialogues with CS principles and emotional support strategy labels.", "example": "Convert the coordinate to text: [-5.5177 10.0026]:"}
{"text": "Convert the coordinate to text: [ 4.0662 10.8253]: They propose a new approach, prefix-propagation, that conditions prefixes on previous hidden states in order to better model long sequences while maintaining parameter efficiency.", "target": "They propose a new approach, prefix-propagation, that conditions prefixes on previous hidden states in order to better model long sequences while maintaining parameter efficiency.", "example": "Convert the coordinate to text: [ 4.0662 10.8253]:"}
{"text": "Convert the coordinate to text: [-1.1705 -3.6466]: The authors introduce an adaptive context modeling method to enhance the leading system. This method is incorporated in the encoder and also used as additional guidance in the sampling stage to improve the global consistency of the generated story.", "target": "The authors introduce an adaptive context modeling method to enhance the leading system. This method is incorporated in the encoder and also used as additional guidance in the sampling stage to improve the global consistency of the generated story.", "example": "Convert the coordinate to text: [-1.1705 -3.6466]:"}
{"text": "Convert the coordinate to text: [0.7714 0.927 ]: The authors argue against the filtering approach, insisting it can obscure models' true capabilities to overcome biases. They propose to amplify dataset biases in the training set to promote the development of models robust to subtle biases.", "target": "The authors argue against the filtering approach, insisting it can obscure models' true capabilities to overcome biases. They propose to amplify dataset biases in the training set to promote the development of models robust to subtle biases.", "example": "Convert the coordinate to text: [0.7714 0.927 ]:"}
{"text": "Convert the coordinate to text: [ 1.4592 -7.6844]: The authors hypothesize that interaction between segments can be delayed until later encoding stages and propose Layer-Adjustable Interactions in Transformers (LAIT). LAIT is a hybrid architecture where segmented inputs are first encoded independently then jointly, achieving the pre-computational efficiency of a Dual Encoder and the capacity of a fully self-attentive Transformer to model cross-segment attention.", "target": "The authors hypothesize that interaction between segments can be delayed until later encoding stages and propose Layer-Adjustable Interactions in Transformers (LAIT). LAIT is a hybrid architecture where segmented inputs are first encoded independently then jointly, achieving the pre-computational efficiency of a Dual Encoder and the capacity of a fully self-attentive Transformer to model cross-segment attention.", "example": "Convert the coordinate to text: [ 1.4592 -7.6844]:"}
{"text": "Convert the coordinate to text: [-5.6207 -8.9867]: To bridge the gap between languages with different script systems, the authors propose PhoneXL, an innovative framework leveraging phonemic transcriptions in addition to traditional orthographic transcriptions to enhance cross-lingual transfer.", "target": "To bridge the gap between languages with different script systems, the authors propose PhoneXL, an innovative framework leveraging phonemic transcriptions in addition to traditional orthographic transcriptions to enhance cross-lingual transfer.", "example": "Convert the coordinate to text: [-5.6207 -8.9867]:"}
{"text": "Convert the coordinate to text: [-5.7729 -0.5173]: The authors propose a new dataset called 'ExplainMeetSum', a modified version of QMSum, which includes evidence sentences that 'explain' a summary. They also introduce a novel multiple extractor guided summarization approach, Multi-DYLE, and an explainability-aware task, 'Explainable Evidence Extraction' (E3).", "target": "The authors propose a new dataset called 'ExplainMeetSum', a modified version of QMSum, which includes evidence sentences that 'explain' a summary. They also introduce a novel multiple extractor guided summarization approach, Multi-DYLE, and an explainability-aware task, 'Explainable Evidence Extraction' (E3).", "example": "Convert the coordinate to text: [-5.7729 -0.5173]:"}
{"text": "Convert the coordinate to text: [18.5394 -3.1852]: This paper introduces an ensemble approach to the task of clickbait spoiling at SemEval-2023, which consists of spoiler classification and retrieval on the Webis-Clickbait-22 dataset.", "target": "This paper introduces an ensemble approach to the task of clickbait spoiling at SemEval-2023, which consists of spoiler classification and retrieval on the Webis-Clickbait-22 dataset.", "example": "Convert the coordinate to text: [18.5394 -3.1852]:"}
{"text": "Convert the coordinate to text: [-1.2666 -7.1571]: The authors introduce a new dataset of more than 4,000 manually annotated ECCNPs in German medical text and propose a generative encoder-decoder Transformer model for a simple end-to-end resolution of ECCNPs from raw input strings.", "target": "The authors introduce a new dataset of more than 4,000 manually annotated ECCNPs in German medical text and propose a generative encoder-decoder Transformer model for a simple end-to-end resolution of ECCNPs from raw input strings.", "example": "Convert the coordinate to text: [-1.2666 -7.1571]:"}
{"text": "Convert the coordinate to text: [-0.8177 -5.0171]: The authors propose a more practical scenario for few-shot SLU, which only requires access to a pre-trained language model and a few labeled examples. To accomplish this, they develop a prompt-based intent detection model and reconstruct slot labels to reduce training complexity.", "target": "The authors propose a more practical scenario for few-shot SLU, which only requires access to a pre-trained language model and a few labeled examples. To accomplish this, they develop a prompt-based intent detection model and reconstruct slot labels to reduce training complexity.", "example": "Convert the coordinate to text: [-0.8177 -5.0171]:"}
{"text": "Convert the coordinate to text: [ 2.9165 -0.5018]: The authors propose Reinforced Active Learning (RAL), a Reinforcement Learning policy that utilizes different aspects of the data and the task to dynamically select the most informative unlabeled subset over the course of the active learning procedure.", "target": "The authors propose Reinforced Active Learning (RAL), a Reinforcement Learning policy that utilizes different aspects of the data and the task to dynamically select the most informative unlabeled subset over the course of the active learning procedure.", "example": "Convert the coordinate to text: [ 2.9165 -0.5018]:"}
{"text": "Convert the coordinate to text: [-1.7857 -3.0535]: To overcome these issues, this paper introduces a new method for mKGC that incorporates global and local knowledge constraints. The global constraints help constrain the reasoning of answer entities, and the local constraints are used to enhance the representation of query contexts.", "target": "To overcome these issues, this paper introduces a new method for mKGC that incorporates global and local knowledge constraints. The global constraints help constrain the reasoning of answer entities, and the local constraints are used to enhance the representation of query contexts.", "example": "Convert the coordinate to text: [-1.7857 -3.0535]:"}
{"text": "Convert the coordinate to text: [-9.3951  1.2426]: In this tutorial, the authors aim to provide a comprehensive overview of the current advances in retrieval-based LMs, including their foundations, model architectures, learning approaches, and adaptions to downstream applications.", "target": "In this tutorial, the authors aim to provide a comprehensive overview of the current advances in retrieval-based LMs, including their foundations, model architectures, learning approaches, and adaptions to downstream applications.", "example": "Convert the coordinate to text: [-9.3951  1.2426]:"}
{"text": "Convert the coordinate to text: [-8.5585 -7.3803]: The authors explore the role of syntax in ancient Chinese understanding based on noisy syntax trees derived from unsupervised derivation and modern Chinese syntax parsers. Additionally, they propose a syntax encoding component - confidence-based syntax encoding network (cSEN) - to mitigate adverse effects from unsupervised syntax derivation and incompatibility between ancient and modern Chinese.", "target": "The authors explore the role of syntax in ancient Chinese understanding based on noisy syntax trees derived from unsupervised derivation and modern Chinese syntax parsers. Additionally, they propose a syntax encoding component - confidence-based syntax encoding network (cSEN) - to mitigate adverse effects from unsupervised syntax derivation and incompatibility between ancient and modern Chinese.", "example": "Convert the coordinate to text: [-8.5585 -7.3803]:"}
{"text": "Convert the coordinate to text: [-9.5631 -1.5192]: To address this limitation, the authors propose a model named LI-RAGE that applies late interaction models for a finer-grained interaction between question and table embeddings, incorporates a joint training scheme of the retriever and reader with explicit table-level signals, and embeds a binary relevance token as a prefix to the answer generated by the reader.", "target": "To address this limitation, the authors propose a model named LI-RAGE that applies late interaction models for a finer-grained interaction between question and table embeddings, incorporates a joint training scheme of the retriever and reader with explicit table-level signals, and embeds a binary relevance token as a prefix to the answer generated by the reader.", "example": "Convert the coordinate to text: [-9.5631 -1.5192]:"}
{"text": "Convert the coordinate to text: [15.9917  1.8832]: ETran is proposed, which is an energy-based transferability assessment metric that includes three scores: energy score, classification score, and regression score. The work argues that determining whether the target dataset is in-distribution (IND) or out-of-distribution (OOD) for the pre-trained model is important for transferability estimation and uses energy-based models for this purpose.", "target": "ETran is proposed, which is an energy-based transferability assessment metric that includes three scores: energy score, classification score, and regression score. The work argues that determining whether the target dataset is in-distribution (IND) or out-of-distribution (OOD) for the pre-trained model is important for transferability estimation and uses energy-based models for this purpose.", "example": "Convert the coordinate to text: [15.9917  1.8832]:"}
{"text": "Convert the coordinate to text: [10.4356  4.5209]: The authors address this gap for finite-rank kernel ridge regression (KRR) by deriving sharp non-asymptotic upper and lower bounds for the KRR test error of any finite-rank KRR.", "target": "The authors address this gap for finite-rank kernel ridge regression (KRR) by deriving sharp non-asymptotic upper and lower bounds for the KRR test error of any finite-rank KRR.", "example": "Convert the coordinate to text: [10.4356  4.5209]:"}
{"text": "Convert the coordinate to text: [ 0.3783 -5.7362]: The authors propose Feature Shift Tuning (FST), a method for tuning-based backdoor purification that encourages feature shifts by actively deviating the classifier weights from the originally compromised weights.", "target": "The authors propose Feature Shift Tuning (FST), a method for tuning-based backdoor purification that encourages feature shifts by actively deviating the classifier weights from the originally compromised weights.", "example": "Convert the coordinate to text: [ 0.3783 -5.7362]:"}
{"text": "Convert the coordinate to text: [  8.9558 -13.9487]: The authors propose an efficient ViT-based tracking framework, Aba-ViTrack, for UAV tracking. The framework integrates feature learning and template-search coupling into a single efficient ViT, eliminating the need for a heavy relation modeling module and leveraging an adaptive, background-aware token computation method to reduce inference time.", "target": "The authors propose an efficient ViT-based tracking framework, Aba-ViTrack, for UAV tracking. The framework integrates feature learning and template-search coupling into a single efficient ViT, eliminating the need for a heavy relation modeling module and leveraging an adaptive, background-aware token computation method to reduce inference time.", "example": "Convert the coordinate to text: [  8.9558 -13.9487]:"}
{"text": "Convert the coordinate to text: [ 2.7163 13.9939]: The authors propose that in games that can be approximately decomposed into a set of two-player constant-sum games (referred to as polymatrix games) where global \u20ac-Nash equilibria are boundedly far from Nash-equilibria in each subgame, any no-external-regret algorithm that learns through self-play will produce a strategy with bounded vulnerability.", "target": "The authors propose that in games that can be approximately decomposed into a set of two-player constant-sum games (referred to as polymatrix games) where global \u20ac-Nash equilibria are boundedly far from Nash-equilibria in each subgame, any no-external-regret algorithm that learns through self-play will produce a strategy with bounded vulnerability.", "example": "Convert the coordinate to text: [ 2.7163 13.9939]:"}
{"text": "Convert the coordinate to text: [-10.3578  -1.4907]: The authors propose FANToM, a new benchmark designed to evaluate ToM within conversational contexts with information asymmetry through question-answering.", "target": "The authors propose FANToM, a new benchmark designed to evaluate ToM within conversational contexts with information asymmetry through question-answering.", "example": "Convert the coordinate to text: [-10.3578  -1.4907]:"}
{"text": "Convert the coordinate to text: [-10.8444   6.2808]: The authors propose a simple, modular design to evaluate the use of SSL techniques in WS in a more systematic way.", "target": "The authors propose a simple, modular design to evaluate the use of SSL techniques in WS in a more systematic way.", "example": "Convert the coordinate to text: [-10.8444   6.2808]:"}
{"text": "Convert the coordinate to text: [9.8754 5.1913]: The authors propose a new sketching method for linear model estimation based on data averaging, which reduces the original data to a few averaged observations following the same linear model for estimation of regression coefficients.", "target": "The authors propose a new sketching method for linear model estimation based on data averaging, which reduces the original data to a few averaged observations following the same linear model for estimation of regression coefficients.", "example": "Convert the coordinate to text: [9.8754 5.1913]:"}
{"text": "Convert the coordinate to text: [-0.7806 12.8541]: The authors introduce a novel plug-and-play IL framework called Multi-Agent Network Selection Algorithm (MANSA) that selectively uses CL only at states that require coordination, thereby largely reducing computational burden.", "target": "The authors introduce a novel plug-and-play IL framework called Multi-Agent Network Selection Algorithm (MANSA) that selectively uses CL only at states that require coordination, thereby largely reducing computational burden.", "example": "Convert the coordinate to text: [-0.7806 12.8541]:"}
{"text": "Convert the coordinate to text: [-2.0813 -4.2875]: This study explores how well LMs can make inferences based on injected facts, testing their ability to 'propagate' knowledge; for instance, if an LM learns that an entity is a TV show, can it infer and predict that you can watch it?", "target": "This study explores how well LMs can make inferences based on injected facts, testing their ability to 'propagate' knowledge; for instance, if an LM learns that an entity is a TV show, can it infer and predict that you can watch it?", "example": "Convert the coordinate to text: [-2.0813 -4.2875]:"}
{"text": "Convert the coordinate to text: [-1.1842  8.2266]: The paper introduces FAME (FAithful question answering with MontE-carlo planning), a tool for answering questions based on faithful reasoning steps, which are organized as a structured entailment tree to show how premises are utilized to create intermediate conclusions and prove the correctness of the answer. ", "target": "The paper introduces FAME (FAithful question answering with MontE-carlo planning), a tool for answering questions based on faithful reasoning steps, which are organized as a structured entailment tree to show how premises are utilized to create intermediate conclusions and prove the correctness of the answer. ", "example": "Convert the coordinate to text: [-1.1842  8.2266]:"}
{"text": "Convert the coordinate to text: [ 1.694  -7.9413]: The authors introduce a novel contrastive learning encoded transformer, CLE-ViT, to address the fundamental problem in ultra-FGVC. The key component of this model is a self-supervised module that performs self-shuffling and masking and then distinguishes these transformed images from other images.", "target": "The authors introduce a novel contrastive learning encoded transformer, CLE-ViT, to address the fundamental problem in ultra-FGVC. The key component of this model is a self-supervised module that performs self-shuffling and masking and then distinguishes these transformed images from other images.", "example": "Convert the coordinate to text: [ 1.694  -7.9413]:"}
{"text": "Convert the coordinate to text: [ 4.9859 -5.3602]: In this paper, a new metric, the Spatial Diversity Score, is proposed to measure the spatial heterophily and how it can influence the performance of GNNs. To address the struggle of existing heterophilic GNNs to handle urban graphs with high Spatial Diversity Scores, the authors propose a Spatial Heterophily Aware Graph Neural Network (SHGNN).", "target": "In this paper, a new metric, the Spatial Diversity Score, is proposed to measure the spatial heterophily and how it can influence the performance of GNNs. To address the struggle of existing heterophilic GNNs to handle urban graphs with high Spatial Diversity Scores, the authors propose a Spatial Heterophily Aware Graph Neural Network (SHGNN).", "example": "Convert the coordinate to text: [ 4.9859 -5.3602]:"}
{"text": "Convert the coordinate to text: [-6.5574 13.1021]: PsyAM, a novel framework, is proposed that incorporates adaptor modules in a sequential multi-task learning setup to model hedonic well-being in text in terms of its psychological antecedents using novel feature fusion methods.", "target": "PsyAM, a novel framework, is proposed that incorporates adaptor modules in a sequential multi-task learning setup to model hedonic well-being in text in terms of its psychological antecedents using novel feature fusion methods.", "example": "Convert the coordinate to text: [-6.5574 13.1021]:"}
{"text": "Convert the coordinate to text: [-3.7106 -9.6117]: The authors propose a simultaneous dubbing prototype that translates and replaces the original speech of a live video stream in a synchronised way.", "target": "The authors propose a simultaneous dubbing prototype that translates and replaces the original speech of a live video stream in a synchronised way.", "example": "Convert the coordinate to text: [-3.7106 -9.6117]:"}
{"text": "Convert the coordinate to text: [-7.3749 -6.8331]: The authors propose a diverse set of freely available linguistic resources for Turkish natural language processing, including corpora, pretrained models and education material.", "target": "The authors propose a diverse set of freely available linguistic resources for Turkish natural language processing, including corpora, pretrained models and education material.", "example": "Convert the coordinate to text: [-7.3749 -6.8331]:"}
{"text": "Convert the coordinate to text: [ 3.7392 -5.7656]: This paper presents the Event-aware Adaptive Clustering Uplift Network (EACU-Net) designed for the POM scenario. This model introduces three modules: event-aware graph cascading learning for embedding user attributes, event categories, and creative elements; an adaptive clustering uplift network to learn user sensitivity to creatives in the same context; and an event-aware information gain network to learn more from event-affected samples.", "target": "This paper presents the Event-aware Adaptive Clustering Uplift Network (EACU-Net) designed for the POM scenario. This model introduces three modules: event-aware graph cascading learning for embedding user attributes, event categories, and creative elements; an adaptive clustering uplift network to learn user sensitivity to creatives in the same context; and an event-aware information gain network to learn more from event-affected samples.", "example": "Convert the coordinate to text: [ 3.7392 -5.7656]:"}
{"text": "Convert the coordinate to text: [-15.6441  16.5763]: The SEND/RETURN (S/R) project was created to explore this context using the k-means clustering algorithm and fast pattern matching (FPM) to recommend similar-sounding songs to users, dynamically changing effects in an Unreal Engine 5 (UE5) virtual environment based on the audio features of the recommended songs, adding a multiplayer component, and extending this system by using a convolutional neural network to predict the mood of a song from its Mel-spectrogram which then orchestrates post-processing effects in the UE5 environment.", "target": "The SEND/RETURN (S/R) project was created to explore this context using the k-means clustering algorithm and fast pattern matching (FPM) to recommend similar-sounding songs to users, dynamically changing effects in an Unreal Engine 5 (UE5) virtual environment based on the audio features of the recommended songs, adding a multiplayer component, and extending this system by using a convolutional neural network to predict the mood of a song from its Mel-spectrogram which then orchestrates post-processing effects in the UE5 environment.", "example": "Convert the coordinate to text: [-15.6441  16.5763]:"}
{"text": "Convert the coordinate to text: [ 8.5665 -3.0682]: The authors propose a new model called VIBE (Variational Information Bottleneck for Evolutions). This model reflects feature change by modeling latent topic evolution using two Information Bottleneck (IB) regularizers to distinguish past and future topics.", "target": "The authors propose a new model called VIBE (Variational Information Bottleneck for Evolutions). This model reflects feature change by modeling latent topic evolution using two Information Bottleneck (IB) regularizers to distinguish past and future topics.", "example": "Convert the coordinate to text: [ 8.5665 -3.0682]:"}
{"text": "Convert the coordinate to text: [-1.2688 -9.0151]: The authors propose CoLLAT (Contrastive Locked Language and Audio Tuning), a framework that learns an audio understanding model with a locked language model. This is facilitated by a novel pretraining objective for audio-to-text grounding, which results in fine-grained audio understanding.", "target": "The authors propose CoLLAT (Contrastive Locked Language and Audio Tuning), a framework that learns an audio understanding model with a locked language model. This is facilitated by a novel pretraining objective for audio-to-text grounding, which results in fine-grained audio understanding.", "example": "Convert the coordinate to text: [-1.2688 -9.0151]:"}
{"text": "Convert the coordinate to text: [ 14.7275 -15.1579]: The authors propose using Neural Radiance Fields as an implicit map of a given scene and introducing a camera relocalization algorithm tailored for this representation, which computes local features via volumetric rendering with a self-supervised objective.", "target": "The authors propose using Neural Radiance Fields as an implicit map of a given scene and introducing a camera relocalization algorithm tailored for this representation, which computes local features via volumetric rendering with a self-supervised objective.", "example": "Convert the coordinate to text: [ 14.7275 -15.1579]:"}
{"text": "Convert the coordinate to text: [-10.0341  -1.6126]: This paper proposes a binary classification approach to UCR, transforming the downstream multiple choice question answering task into a simpler binary classification task by ranking all candidate answers according to their reasonableness. Additionally, knowledge graph triples are converted into reasonable and unreasonable texts for training the model.", "target": "This paper proposes a binary classification approach to UCR, transforming the downstream multiple choice question answering task into a simpler binary classification task by ranking all candidate answers according to their reasonableness. Additionally, knowledge graph triples are converted into reasonable and unreasonable texts for training the model.", "example": "Convert the coordinate to text: [-10.0341  -1.6126]:"}
{"text": "Convert the coordinate to text: [-5.9486 10.3981]: The authors introduce the LiveChat dataset, composed of 1.33 million real-life Chinese dialogues across 351 personas with detailed profiles. LiveChat is unique because it was created by processing numerous live internet videos and falls within the scope of multi-party conversations.", "target": "The authors introduce the LiveChat dataset, composed of 1.33 million real-life Chinese dialogues across 351 personas with detailed profiles. LiveChat is unique because it was created by processing numerous live internet videos and falls within the scope of multi-party conversations.", "example": "Convert the coordinate to text: [-5.9486 10.3981]:"}
{"text": "Convert the coordinate to text: [-5.3111 -7.1776]: To study compositional generalization across different languages, the authors create a rule-based translation of the MCWQ dataset from English to Chinese and Japanese that minimizes distortion, referred to as MCWQ-R.", "target": "To study compositional generalization across different languages, the authors create a rule-based translation of the MCWQ dataset from English to Chinese and Japanese that minimizes distortion, referred to as MCWQ-R.", "example": "Convert the coordinate to text: [-5.3111 -7.1776]:"}
{"text": "Convert the coordinate to text: [-8.0539  7.8203]: This study uses quantitative text and network analysis to examine how incels discuss different identity groups on their largest black-pill forum, incels.is.", "target": "This study uses quantitative text and network analysis to examine how incels discuss different identity groups on their largest black-pill forum, incels.is.", "example": "Convert the coordinate to text: [-8.0539  7.8203]:"}
{"text": "Convert the coordinate to text: [-6.2384  7.1115]: The authors introduce a new approach to identify inappropriate communication by explicitly modeling the social relationship between individuals. They also introduce a new dataset of contextually situated judgments of appropriateness.", "target": "The authors introduce a new approach to identify inappropriate communication by explicitly modeling the social relationship between individuals. They also introduce a new dataset of contextually situated judgments of appropriateness.", "example": "Convert the coordinate to text: [-6.2384  7.1115]:"}
{"text": "Convert the coordinate to text: [ 5.4728 -0.2104]: The authors propose a solution employing a multi-label classification model and utilizing a class-balanced loss function to tackle the issues of this task.", "target": "The authors propose a solution employing a multi-label classification model and utilizing a class-balanced loss function to tackle the issues of this task.", "example": "Convert the coordinate to text: [ 5.4728 -0.2104]:"}
{"text": "Convert the coordinate to text: [-3.6564 -8.7347]: The authors propose an end-to-end multilingual speech translation system that uses large-scale pre-trained speech and text models with added Inter-connections. They also enhance the simultaneity of the offline speech translation model using Bilingual Prefix Alignment for prefix-to-prefix text data augmentation.", "target": "The authors propose an end-to-end multilingual speech translation system that uses large-scale pre-trained speech and text models with added Inter-connections. They also enhance the simultaneity of the offline speech translation model using Bilingual Prefix Alignment for prefix-to-prefix text data augmentation.", "example": "Convert the coordinate to text: [-3.6564 -8.7347]:"}
{"text": "Convert the coordinate to text: [-1.1712 -8.1883]: The authors propose a challenge, RadSum, focused on radiology report summarization but this time including a new dataset of eleven different modalities and anatomies pairs and a multimodal report summarization dataset.", "target": "The authors propose a challenge, RadSum, focused on radiology report summarization but this time including a new dataset of eleven different modalities and anatomies pairs and a multimodal report summarization dataset.", "example": "Convert the coordinate to text: [-1.1712 -8.1883]:"}
{"text": "Convert the coordinate to text: [ 4.3185 13.9177]: The authors propose a self-learning geometry problem solving framework called GeoDRL that integrates logic graph deduction and Deep Reinforcement Learning (DRL) to optimize geometry reasoning. It employs a Graph Neural Network on a Geometry Logic Graph, updating the problem state using a symbolic system and therefore, maintains correctness while achieving unsupervised self-learning.", "target": "The authors propose a self-learning geometry problem solving framework called GeoDRL that integrates logic graph deduction and Deep Reinforcement Learning (DRL) to optimize geometry reasoning. It employs a Graph Neural Network on a Geometry Logic Graph, updating the problem state using a symbolic system and therefore, maintains correctness while achieving unsupervised self-learning.", "example": "Convert the coordinate to text: [ 4.3185 13.9177]:"}
{"text": "Convert the coordinate to text: [-2.4671 -6.2593]: The study explores the extent to which BERT's meaning representations correlate with known constructions from linguistic literature through two proposed tasks. The first involves predicting words that can be used in the open slots of constructions to observe the meaning associations of more lexicalized constructions, while the second involves finding similar sequences using BERT's output embeddings and manually reviewing the resulting sentences.", "target": "The study explores the extent to which BERT's meaning representations correlate with known constructions from linguistic literature through two proposed tasks. The first involves predicting words that can be used in the open slots of constructions to observe the meaning associations of more lexicalized constructions, while the second involves finding similar sequences using BERT's output embeddings and manually reviewing the resulting sentences.", "example": "Convert the coordinate to text: [-2.4671 -6.2593]:"}
{"text": "Convert the coordinate to text: [-2.6545  0.2288]: The authors suggest a community resource named 'PrOf' along with a Python module aimed at standardizing the process of profanity obfuscation across different languages.", "target": "The authors suggest a community resource named 'PrOf' along with a Python module aimed at standardizing the process of profanity obfuscation across different languages.", "example": "Convert the coordinate to text: [-2.6545  0.2288]:"}
{"text": "Convert the coordinate to text: [ 0.3593 -2.5934]: In contrast to previous methods, the authors propose a reranking-based approach within the Seq2Seq formulation that redistributes likelihood among candidate sequences based on their performance via a contrastive loss, to reduce bias.", "target": "In contrast to previous methods, the authors propose a reranking-based approach within the Seq2Seq formulation that redistributes likelihood among candidate sequences based on their performance via a contrastive loss, to reduce bias.", "example": "Convert the coordinate to text: [ 0.3593 -2.5934]:"}
{"text": "Convert the coordinate to text: [13.2526 -6.3392]: To overcome the limitations of density-based estimation methods, a score-based generative method is proposed that implicitly models the data distribution. This approach employs the gradient of the log-density data distribution and calculates the distribution gap between adversarial and normal samples using multi-step iterations and Langevin dynamics. It also uses supervised contrastive learning to guide the gradient estimation with label information.", "target": "To overcome the limitations of density-based estimation methods, a score-based generative method is proposed that implicitly models the data distribution. This approach employs the gradient of the log-density data distribution and calculates the distribution gap between adversarial and normal samples using multi-step iterations and Langevin dynamics. It also uses supervised contrastive learning to guide the gradient estimation with label information.", "example": "Convert the coordinate to text: [13.2526 -6.3392]:"}
{"text": "Convert the coordinate to text: [-15.2376   1.5216]: The authors propose to integrate SQL/PGQ support into the DuckDB system, an RDBMS, by using an extension module called DuckPGQ. The DuckDB extensibility mechanism allows the addition of new functions, data types, operators, optimizer rules, storage systems, and parsers.", "target": "The authors propose to integrate SQL/PGQ support into the DuckDB system, an RDBMS, by using an extension module called DuckPGQ. The DuckDB extensibility mechanism allows the addition of new functions, data types, operators, optimizer rules, storage systems, and parsers.", "example": "Convert the coordinate to text: [-15.2376   1.5216]:"}
{"text": "Convert the coordinate to text: [2.4512 1.1114]: The authors propose a methodology for visualizing the changes in latent representations when deep learning models are trained incrementally under concept drift.", "target": "The authors propose a methodology for visualizing the changes in latent representations when deep learning models are trained incrementally under concept drift.", "example": "Convert the coordinate to text: [2.4512 1.1114]:"}
{"text": "Convert the coordinate to text: [-1.0238 -4.5657]: A novel framework for dialogue management, CP-Rec, is proposed. This framework uses contextual prompting by optimizing prompts based on context, topics, and user profiles. It includes a topic controller for sequential subtask planning, and a prompt search module for context-aware prompts.", "target": "A novel framework for dialogue management, CP-Rec, is proposed. This framework uses contextual prompting by optimizing prompts based on context, topics, and user profiles. It includes a topic controller for sequential subtask planning, and a prompt search module for context-aware prompts.", "example": "Convert the coordinate to text: [-1.0238 -4.5657]:"}
{"text": "Convert the coordinate to text: [  8.912  -13.3668]: This paper proposes the Motorcycle Helmet Object Detection (MHOD) framework that uses an ensemble model within an object detection network to predict object locations and classifications in video data, while a Passenger Recall Module (PRM) and Category Refine Module (CRM) improve recall of the passenger category and refine the prediction using temporal video information.", "target": "This paper proposes the Motorcycle Helmet Object Detection (MHOD) framework that uses an ensemble model within an object detection network to predict object locations and classifications in video data, while a Passenger Recall Module (PRM) and Category Refine Module (CRM) improve recall of the passenger category and refine the prediction using temporal video information.", "example": "Convert the coordinate to text: [  8.912  -13.3668]:"}
{"text": "Convert the coordinate to text: [16.1294  1.8221]: The paper proposes a novel method for OOD detection that combines feature norm and Mahalanobis distance acquired from classification models trained with cosine-based softmax loss.", "target": "The paper proposes a novel method for OOD detection that combines feature norm and Mahalanobis distance acquired from classification models trained with cosine-based softmax loss.", "example": "Convert the coordinate to text: [16.1294  1.8221]:"}
{"text": "Convert the coordinate to text: [ 1.0827 -8.8304]: The authors propose a Hybrid Temporal-scale Multimodal Learning (HTML) framework that can effectively align lingual and visual features, from different temporal scales, to discover core object semantics in videos.", "target": "The authors propose a Hybrid Temporal-scale Multimodal Learning (HTML) framework that can effectively align lingual and visual features, from different temporal scales, to discover core object semantics in videos.", "example": "Convert the coordinate to text: [ 1.0827 -8.8304]:"}
{"text": "Convert the coordinate to text: [ 3.7174 13.2212]: The authors propose a zero-shot agent that is capable of learning and improving control on a computer in the absence of expert trace examples. The agent plans for executable actions on a partially observed environment and iteratively progresses a task by identifying and learning from its mistakes via self-reflection and structured thought management.", "target": "The authors propose a zero-shot agent that is capable of learning and improving control on a computer in the absence of expert trace examples. The agent plans for executable actions on a partially observed environment and iteratively progresses a task by identifying and learning from its mistakes via self-reflection and structured thought management.", "example": "Convert the coordinate to text: [ 3.7174 13.2212]:"}
{"text": "Convert the coordinate to text: [-8.0169 -1.6347]: The authors introduce the term 'annotation sensitivity' and argue that design choices made when creating an annotation instrument can impact not just the annotations but also downstream model performance and predictions.", "target": "The authors introduce the term 'annotation sensitivity' and argue that design choices made when creating an annotation instrument can impact not just the annotations but also downstream model performance and predictions.", "example": "Convert the coordinate to text: [-8.0169 -1.6347]:"}
{"text": "Convert the coordinate to text: [ 3.0249 -8.8418]: The authors propose a novel sparse 3D detector called Query Contrast Voxel-DETR (ConQueR) to eliminate false positives and achieve more accurate and sparse predictions. They introduce a Query Contrast mechanism to enhance queries towards their best matched GTs over all unmatched query predictions.", "target": "The authors propose a novel sparse 3D detector called Query Contrast Voxel-DETR (ConQueR) to eliminate false positives and achieve more accurate and sparse predictions. They introduce a Query Contrast mechanism to enhance queries towards their best matched GTs over all unmatched query predictions.", "example": "Convert the coordinate to text: [ 3.0249 -8.8418]:"}
{"text": "Convert the coordinate to text: [-1.894  -5.3306]: The authors suggest an alternate method for pretraining language models that incorporates human feedback, to guide these models to align generated text with human preferences.", "target": "The authors suggest an alternate method for pretraining language models that incorporates human feedback, to guide these models to align generated text with human preferences.", "example": "Convert the coordinate to text: [-1.894  -5.3306]:"}
{"text": "Convert the coordinate to text: [-2.7117  2.8311]: The authors address the training instability of real-world multitask ranking models in recommendation systems. They focus on a specific model used for YouTube recommendations and provide insights into the model properties that lead to unstable training, the reasons behind the failure of existing solutions, and propose a new algorithm to improve stability.", "target": "The authors address the training instability of real-world multitask ranking models in recommendation systems. They focus on a specific model used for YouTube recommendations and provide insights into the model properties that lead to unstable training, the reasons behind the failure of existing solutions, and propose a new algorithm to improve stability.", "example": "Convert the coordinate to text: [-2.7117  2.8311]:"}
{"text": "Convert the coordinate to text: [-10.3263   2.2008]: The authors present the ROOTS Search Tool, a search engine that operates over the entire ROOTS corpus, offering both fuzzy and exact search capabilities.", "target": "The authors present the ROOTS Search Tool, a search engine that operates over the entire ROOTS corpus, offering both fuzzy and exact search capabilities.", "example": "Convert the coordinate to text: [-10.3263   2.2008]:"}
{"text": "Convert the coordinate to text: [ 3.554  -1.4001]: The authors propose PASA, an approach that uses discrete latent variables to capture the range of different behaviors represented in large pre-training datasets. It then uses knowledge distillation to distil the posterior probability distribution into a student model.", "target": "The authors propose PASA, an approach that uses discrete latent variables to capture the range of different behaviors represented in large pre-training datasets. It then uses knowledge distillation to distil the posterior probability distribution into a student model.", "example": "Convert the coordinate to text: [ 3.554  -1.4001]:"}
{"text": "Convert the coordinate to text: [-7.1296 -0.3608]: The authors propose multiple systems that use document context within the simplification process itself, either by iterating over larger text units or by extending the system architecture to attend over a high-level representation of document context.", "target": "The authors propose multiple systems that use document context within the simplification process itself, either by iterating over larger text units or by extending the system architecture to attend over a high-level representation of document context.", "example": "Convert the coordinate to text: [-7.1296 -0.3608]:"}
{"text": "Convert the coordinate to text: [ 0.0281 -8.8714]: The paper presents VisionLLM, an LLM-based framework for vision-centric tasks. This framework treats images as a foreign language and aligns vision-centric tasks with language tasks that can be flexibly defined and managed using language instructions.", "target": "The paper presents VisionLLM, an LLM-based framework for vision-centric tasks. This framework treats images as a foreign language and aligns vision-centric tasks with language tasks that can be flexibly defined and managed using language instructions.", "example": "Convert the coordinate to text: [ 0.0281 -8.8714]:"}
{"text": "Convert the coordinate to text: [-5.9654  2.7274]: This paper focuses on the impact of ordering news stories on audience perception, and introduces problems of detecting cherry-picked news orderings and maximizing neutrality in news orderings.", "target": "This paper focuses on the impact of ordering news stories on audience perception, and introduces problems of detecting cherry-picked news orderings and maximizing neutrality in news orderings.", "example": "Convert the coordinate to text: [-5.9654  2.7274]:"}
{"text": "Convert the coordinate to text: [-7.8985  8.0784]: This study aims to bridge this knowledge gap by systematically assessing the effect of scaling on NAT behaviors.", "target": "This study aims to bridge this knowledge gap by systematically assessing the effect of scaling on NAT behaviors.", "example": "Convert the coordinate to text: [-7.8985  8.0784]:"}
{"text": "Convert the coordinate to text: [ 3.6062 -4.7615]: The authors propose a Multi-View Enhanced Distillation (MVD) framework that can effectively transfer knowledge of multiple fine-grained and mention-relevant parts within entities from cross-encoders to dual-encoders. This framework splits each entity into multiple views to prevent irrelevant information from obscuring the mention-relevant view.", "target": "The authors propose a Multi-View Enhanced Distillation (MVD) framework that can effectively transfer knowledge of multiple fine-grained and mention-relevant parts within entities from cross-encoders to dual-encoders. This framework splits each entity into multiple views to prevent irrelevant information from obscuring the mention-relevant view.", "example": "Convert the coordinate to text: [ 3.6062 -4.7615]:"}
{"text": "Convert the coordinate to text: [  2.3608 -10.5483]: The authors introduce a new spatial relationship categorization task that assigns a spatial relationship category for every character and location co-mention within a window of text, taking into account linguistic context, narrative tense, and temporal scope.", "target": "The authors introduce a new spatial relationship categorization task that assigns a spatial relationship category for every character and location co-mention within a window of text, taking into account linguistic context, narrative tense, and temporal scope.", "example": "Convert the coordinate to text: [  2.3608 -10.5483]:"}
{"text": "Convert the coordinate to text: [-1.7101 -8.7915]: The authors introduce HaluEval, a large collection of generated and human-annotated hallucinated samples designed for evaluating the performance of large language models in recognizing hallucination. They use a two-step framework for generating these samples: sampling and then filtering.", "target": "The authors introduce HaluEval, a large collection of generated and human-annotated hallucinated samples designed for evaluating the performance of large language models in recognizing hallucination. They use a two-step framework for generating these samples: sampling and then filtering.", "example": "Convert the coordinate to text: [-1.7101 -8.7915]:"}
{"text": "Convert the coordinate to text: [ 0.1312 -9.4113]: A new concept, Grounded Open Vocabulary Acquisition (GOVA), is introduced to explore grounding and bootstrapping in open-world language learning. Additionally, a novel visually-grounded language model called object-oriented BERT (OctoBERT) is proposed, which is pre-trained on image-text pairs with grounding as an objective.", "target": "A new concept, Grounded Open Vocabulary Acquisition (GOVA), is introduced to explore grounding and bootstrapping in open-world language learning. Additionally, a novel visually-grounded language model called object-oriented BERT (OctoBERT) is proposed, which is pre-trained on image-text pairs with grounding as an objective.", "example": "Convert the coordinate to text: [ 0.1312 -9.4113]:"}
{"text": "Convert the coordinate to text: [ 0.4883 -8.3705]: The authors propose Contrastive Knowledge Injection (ConKI) for multimodal sentiment analysis, where specific-knowledge representations for each modality are learned along general knowledge representations via knowledge injection based on an adapter architecture.", "target": "The authors propose Contrastive Knowledge Injection (ConKI) for multimodal sentiment analysis, where specific-knowledge representations for each modality are learned along general knowledge representations via knowledge injection based on an adapter architecture.", "example": "Convert the coordinate to text: [ 0.4883 -8.3705]:"}
{"text": "Convert the coordinate to text: [11.759   3.7906]: The authors leverage cryptographic assumptions to design robust algorithms for tasks such as sparse recovery of vectors, low rank recovery of matrices and tensors, and robust PCA, as well as some new problems in numerical linear algebra and combinatorial optimization.", "target": "The authors leverage cryptographic assumptions to design robust algorithms for tasks such as sparse recovery of vectors, low rank recovery of matrices and tensors, and robust PCA, as well as some new problems in numerical linear algebra and combinatorial optimization.", "example": "Convert the coordinate to text: [11.759   3.7906]:"}
{"text": "Convert the coordinate to text: [ 0.7675 -0.5712]: The authors introduce DiscoFlan, a multilingual discourse relation classifier that addresses issue of mismatches in seq2seq models by using label distribution information for label generation. They also propose a novel label generation mechanism that anchors the labels to a fixed set by selectively enhancing training on the decoder model, eliminating the need for hand-crafted features.", "target": "The authors introduce DiscoFlan, a multilingual discourse relation classifier that addresses issue of mismatches in seq2seq models by using label distribution information for label generation. They also propose a novel label generation mechanism that anchors the labels to a fixed set by selectively enhancing training on the decoder model, eliminating the need for hand-crafted features.", "example": "Convert the coordinate to text: [ 0.7675 -0.5712]:"}
{"text": "Convert the coordinate to text: [-1.1136 -7.8723]: The authors propose a novel Dual Supervised Pre-trained Model for a few-shot Natural Language Generation (DSPM-NLG) to regularize the pre-training process. This model uses a joint model with a dual supervised framework to learn the dual correlation between NLG and SLU from the perspective of probability.", "target": "The authors propose a novel Dual Supervised Pre-trained Model for a few-shot Natural Language Generation (DSPM-NLG) to regularize the pre-training process. This model uses a joint model with a dual supervised framework to learn the dual correlation between NLG and SLU from the perspective of probability.", "example": "Convert the coordinate to text: [-1.1136 -7.8723]:"}
{"text": "Convert the coordinate to text: [-4.4574 -5.0204]: The paper proposes to enhance the existing model by leveraging pre-trained distributed contextual word and phrase representations and by decomposing sentences into fragments for unsupervised semantic parsing.", "target": "The paper proposes to enhance the existing model by leveraging pre-trained distributed contextual word and phrase representations and by decomposing sentences into fragments for unsupervised semantic parsing.", "example": "Convert the coordinate to text: [-4.4574 -5.0204]:"}
{"text": "Convert the coordinate to text: [-10.0957  -1.743 ]: The authors propose an efficient approach for temporal relation classification (TRC) using a boolean question answering (QA) model which is fine-tuned on carefully designed questions based on the TRC annotation guidelines.", "target": "The authors propose an efficient approach for temporal relation classification (TRC) using a boolean question answering (QA) model which is fine-tuned on carefully designed questions based on the TRC annotation guidelines.", "example": "Convert the coordinate to text: [-10.0957  -1.743 ]:"}
{"text": "Convert the coordinate to text: [ 0.2513 -9.5827]: The paper introduces a new vision-language task, Multi-modal Action chain abductive Reasoning (MAR), and a large-scale Abductive Reasoning dataset. The task involves imagining the most plausible event by spatio-temporal grounding in past video and then inferring the hypothesis of a subsequent action chain to explain the language premise.", "target": "The paper introduces a new vision-language task, Multi-modal Action chain abductive Reasoning (MAR), and a large-scale Abductive Reasoning dataset. The task involves imagining the most plausible event by spatio-temporal grounding in past video and then inferring the hypothesis of a subsequent action chain to explain the language premise.", "example": "Convert the coordinate to text: [ 0.2513 -9.5827]:"}
{"text": "Convert the coordinate to text: [ 5.6996 -5.2346]: This paper re-examines the problem of over-correlation in deep GNN. The authors propose a 'decorrelated propagation scheme' (DeProp) which can address the over-correlation problem in feature learning.", "target": "This paper re-examines the problem of over-correlation in deep GNN. The authors propose a 'decorrelated propagation scheme' (DeProp) which can address the over-correlation problem in feature learning.", "example": "Convert the coordinate to text: [ 5.6996 -5.2346]:"}
{"text": "Convert the coordinate to text: [  3.5095 -11.1687]: The authors propose the first large and challenging multimodal dataset, Chaotic World, which provides dense and fine-grained annotations of sounds, individual actions, group interaction graphs, and text descriptions for each scene in every video, enabling a thorough analysis of complex behaviors in crowds and chaos.", "target": "The authors propose the first large and challenging multimodal dataset, Chaotic World, which provides dense and fine-grained annotations of sounds, individual actions, group interaction graphs, and text descriptions for each scene in every video, enabling a thorough analysis of complex behaviors in crowds and chaos.", "example": "Convert the coordinate to text: [  3.5095 -11.1687]:"}
{"text": "Convert the coordinate to text: [ 9.1164 -6.1846]: The authors introduce a new paradigm for reducing neural network representational similarity to filter subspace distance. This is achieved by decomposing convolutional filters as a linear combination of a set of filter subspace elements, or filter atoms, and sharing those decomposed atom coefficients across networks.", "target": "The authors introduce a new paradigm for reducing neural network representational similarity to filter subspace distance. This is achieved by decomposing convolutional filters as a linear combination of a set of filter subspace elements, or filter atoms, and sharing those decomposed atom coefficients across networks.", "example": "Convert the coordinate to text: [ 9.1164 -6.1846]:"}
{"text": "Convert the coordinate to text: [ 4.3735 -2.2228]: This paper presents Adversarial Self-Training (AST), which replaces traditional self-training in the gradual self-training method. AST predicts labels on unlabeled data and then trains the model adversarially on the distribution of these pseudo-labels.", "target": "This paper presents Adversarial Self-Training (AST), which replaces traditional self-training in the gradual self-training method. AST predicts labels on unlabeled data and then trains the model adversarially on the distribution of these pseudo-labels.", "example": "Convert the coordinate to text: [ 4.3735 -2.2228]:"}
{"text": "Convert the coordinate to text: [0.0496 1.3961]: A new approach, FairBalance, is proposed for advancing bias neutralization. Key features include a cycle consistent adversarial network for neutralizing bias without parallel text, a model design that retains bias-independent content, and auxiliary guidance which helps highlight bias-inducing word sequences offering better bias neutralization quality.", "target": "A new approach, FairBalance, is proposed for advancing bias neutralization. Key features include a cycle consistent adversarial network for neutralizing bias without parallel text, a model design that retains bias-independent content, and auxiliary guidance which helps highlight bias-inducing word sequences offering better bias neutralization quality.", "example": "Convert the coordinate to text: [0.0496 1.3961]:"}
{"text": "Convert the coordinate to text: [ 3.7395 -3.7111]: The authors propose a novel embedding constraint on multi-task knowledge distillation which enforces similarity in the embedding space between teachers (single-task models) and a student (multi-task model).", "target": "The authors propose a novel embedding constraint on multi-task knowledge distillation which enforces similarity in the embedding space between teachers (single-task models) and a student (multi-task model).", "example": "Convert the coordinate to text: [ 3.7395 -3.7111]:"}
{"text": "Convert the coordinate to text: [-11.2192  17.009 ]: The authors propose a technique to change the perceived stiffness of objects in virtual reality based on a visuo-haptic illusion, which is achieved by manipulating the Control to Display (C/D) ratio while pressing down on an object with fixed stiffness.", "target": "The authors propose a technique to change the perceived stiffness of objects in virtual reality based on a visuo-haptic illusion, which is achieved by manipulating the Control to Display (C/D) ratio while pressing down on an object with fixed stiffness.", "example": "Convert the coordinate to text: [-11.2192  17.009 ]:"}
{"text": "Convert the coordinate to text: [-4.0496 -6.9014]: The authors propose to train ranking models on artificially code-switched data, which are generated by utilizing bilingual lexicons.", "target": "The authors propose to train ranking models on artificially code-switched data, which are generated by utilizing bilingual lexicons.", "example": "Convert the coordinate to text: [-4.0496 -6.9014]:"}
{"text": "Convert the coordinate to text: [-10.8719  -1.6687]: This paper introduces Open-WikiTable, the first ODQA dataset that demands complex reasoning over tables. It is built upon WikiSQL and WikiTableQuestions to be applicable in an open-domain scenario.", "target": "This paper introduces Open-WikiTable, the first ODQA dataset that demands complex reasoning over tables. It is built upon WikiSQL and WikiTableQuestions to be applicable in an open-domain scenario.", "example": "Convert the coordinate to text: [-10.8719  -1.6687]:"}
{"text": "Convert the coordinate to text: [-4.265  -4.6773]: The authors propose a new method that uses the entire cohort of contextualized embeddings of a target word, which they refer to as the sibling distribution, to predict semantic variations of words.", "target": "The authors propose a new method that uses the entire cohort of contextualized embeddings of a target word, which they refer to as the sibling distribution, to predict semantic variations of words.", "example": "Convert the coordinate to text: [-4.265  -4.6773]:"}
{"text": "Convert the coordinate to text: [-7.3465 10.0761]: This paper introduces MeetingBank, a benchmark dataset of city council meetings that uses a divide-and-conquer approach to break down the process of summarizing a lengthy meeting into smaller tasks.", "target": "This paper introduces MeetingBank, a benchmark dataset of city council meetings that uses a divide-and-conquer approach to break down the process of summarizing a lengthy meeting into smaller tasks.", "example": "Convert the coordinate to text: [-7.3465 10.0761]:"}
{"text": "Convert the coordinate to text: [-5.0461 -4.025 ]: The authors propose a model to exploit coreference knowledge from parallel data, with an additional unsupervised module to capture cross-lingual coreference knowledge.", "target": "The authors propose a model to exploit coreference knowledge from parallel data, with an additional unsupervised module to capture cross-lingual coreference knowledge.", "example": "Convert the coordinate to text: [-5.0461 -4.025 ]:"}
{"text": "Convert the coordinate to text: [-12.0306  10.6154]: This study surveys the existing literature on ethical considerations for the documentation, translation, and general natural language processing for Indigenous languages and conducts an interview study to grasp the views of community leaders, teachers, and language activists regarding these ethical issues.", "target": "This study surveys the existing literature on ethical considerations for the documentation, translation, and general natural language processing for Indigenous languages and conducts an interview study to grasp the views of community leaders, teachers, and language activists regarding these ethical issues.", "example": "Convert the coordinate to text: [-12.0306  10.6154]:"}
{"text": "Convert the coordinate to text: [-5.5682 -6.3039]: The paper introduces a novel and high-quality multilingual simile dialogue (MSD) dataset to facilitate the study of complex simile phenomena. The MSD is the largest manually annotated simile data and includes both English and Chinese data.", "target": "The paper introduces a novel and high-quality multilingual simile dialogue (MSD) dataset to facilitate the study of complex simile phenomena. The MSD is the largest manually annotated simile data and includes both English and Chinese data.", "example": "Convert the coordinate to text: [-5.5682 -6.3039]:"}
{"text": "Convert the coordinate to text: [-3.8955 16.1353]: The study identifies two recurring biases in nearly all state-of-the-art methods that are critical for driving system progress on CARLA: (1) lateral recovery via a strong inductive bias towards target point following, and (2) longitudinal averaging of multimodal waypoint predictions for slowing down. The study also proposes principled alternatives to these biases.", "target": "The study identifies two recurring biases in nearly all state-of-the-art methods that are critical for driving system progress on CARLA: (1) lateral recovery via a strong inductive bias towards target point following, and (2) longitudinal averaging of multimodal waypoint predictions for slowing down. The study also proposes principled alternatives to these biases.", "example": "Convert the coordinate to text: [-3.8955 16.1353]:"}
{"text": "Convert the coordinate to text: [-7.0666 -6.1593]: The authors propose a novel approach of using narrative chain embeddings to model narratives for both German and English.", "target": "The authors propose a novel approach of using narrative chain embeddings to model narratives for both German and English.", "example": "Convert the coordinate to text: [-7.0666 -6.1593]:"}
{"text": "Convert the coordinate to text: [ 2.1266 -1.0459]: The paper proposes a system that considers multiple annotators' opinions instead of a single gold label. Techniques like ensemble learning, multi-task learning, and Gaussian processes are applied, using large-language models as the backbone.", "target": "The paper proposes a system that considers multiple annotators' opinions instead of a single gold label. Techniques like ensemble learning, multi-task learning, and Gaussian processes are applied, using large-language models as the backbone.", "example": "Convert the coordinate to text: [ 2.1266 -1.0459]:"}
{"text": "Convert the coordinate to text: [-4.851  -7.8867]: The authors propose a web-based platform called the OPUS-MT dashboard, focused on systematic collection of benchmark results with verifiable translation performance across a wide range of languages and domains.", "target": "The authors propose a web-based platform called the OPUS-MT dashboard, focused on systematic collection of benchmark results with verifiable translation performance across a wide range of languages and domains.", "example": "Convert the coordinate to text: [-4.851  -7.8867]:"}
{"text": "Convert the coordinate to text: [-1.2922  9.5087]: The authors introduce a new chain reasoning paradigm to identify event arguments at the document level which uses decomposable first-order logic rules for reasoning and T-norm fuzzy logic for optimization. This paradigm captures long-range interdependence while improving the interpretability of the model.", "target": "The authors introduce a new chain reasoning paradigm to identify event arguments at the document level which uses decomposable first-order logic rules for reasoning and T-norm fuzzy logic for optimization. This paradigm captures long-range interdependence while improving the interpretability of the model.", "example": "Convert the coordinate to text: [-1.2922  9.5087]:"}
{"text": "Convert the coordinate to text: [5.7222 8.4494]: The authors introduce the Greedy Rejection Coding (GRC), a generalization of the rejection based-algorithm that works for arbitrary probability spaces and partitioning schemes, aiming to address the limitations of existing REC algorithms.", "target": "The authors introduce the Greedy Rejection Coding (GRC), a generalization of the rejection based-algorithm that works for arbitrary probability spaces and partitioning schemes, aiming to address the limitations of existing REC algorithms.", "example": "Convert the coordinate to text: [5.7222 8.4494]:"}
{"text": "Convert the coordinate to text: [-0.419 -5.322]: This study introduces a new method integrating parameter-efficient fine-tuning (PEFT) and in-context tuning (ICT) for training a continual table semantic parser. The authors propose a task-adaptive PEFT framework to fully circumvent catastrophic forgetting and a teacher-student framework-based solution to address the few-shot problem using ICT.", "target": "This study introduces a new method integrating parameter-efficient fine-tuning (PEFT) and in-context tuning (ICT) for training a continual table semantic parser. The authors propose a task-adaptive PEFT framework to fully circumvent catastrophic forgetting and a teacher-student framework-based solution to address the few-shot problem using ICT.", "example": "Convert the coordinate to text: [-0.419 -5.322]:"}
{"text": "Convert the coordinate to text: [-0.2015 -9.0396]: The authors introduce the Lecture Presentations Multimodal (LPM) Dataset as a large-scale benchmark for testing vision-and-language models in understanding educational videos. They also introduce three research tasks grounded in multimedia learning and psychology principles which can test a vision-language model\u2019s understanding of multimodal content.", "target": "The authors introduce the Lecture Presentations Multimodal (LPM) Dataset as a large-scale benchmark for testing vision-and-language models in understanding educational videos. They also introduce three research tasks grounded in multimedia learning and psychology principles which can test a vision-language model\u2019s understanding of multimodal content.", "example": "Convert the coordinate to text: [-0.2015 -9.0396]:"}
{"text": "Convert the coordinate to text: [ 8.7974 -3.0179]: The authors seek to address the problems of existing pruning methods by introducing a unified framework based on Information Bottleneck (IB) theory for automatic network pruning, which is implemented by solving a Hilbert-Schmidt Independence Criterion (HSIC) Lasso problem under specific conditions.", "target": "The authors seek to address the problems of existing pruning methods by introducing a unified framework based on Information Bottleneck (IB) theory for automatic network pruning, which is implemented by solving a Hilbert-Schmidt Independence Criterion (HSIC) Lasso problem under specific conditions.", "example": "Convert the coordinate to text: [ 8.7974 -3.0179]:"}
{"text": "Convert the coordinate to text: [10.5059 -8.3279]: The paper introduces CycleNet, a simple method that introduces cycle consistency into diffusion models to regularize image manipulation.", "target": "The paper introduces CycleNet, a simple method that introduces cycle consistency into diffusion models to regularize image manipulation.", "example": "Convert the coordinate to text: [10.5059 -8.3279]:"}
{"text": "Convert the coordinate to text: [-10.3826  -0.6493]: The authors propose the novel task of multi-user contextual query rewriting, which rewrites a task-oriented chat between two users into a concise task-oriented query that retains only task-relevant information and is directly consumable by the dialogue system.", "target": "The authors propose the novel task of multi-user contextual query rewriting, which rewrites a task-oriented chat between two users into a concise task-oriented query that retains only task-relevant information and is directly consumable by the dialogue system.", "example": "Convert the coordinate to text: [-10.3826  -0.6493]:"}
{"text": "Convert the coordinate to text: [4.882 0.841]: The authors propose a new framework to achieve tight generalization bounds by embedding any given learning algorithm into a suitably-constructed meta-algorithm, known as Pick-to-Learn (P2L), thereby instilling desirable compression properties.", "target": "The authors propose a new framework to achieve tight generalization bounds by embedding any given learning algorithm into a suitably-constructed meta-algorithm, known as Pick-to-Learn (P2L), thereby instilling desirable compression properties.", "example": "Convert the coordinate to text: [4.882 0.841]:"}
{"text": "Convert the coordinate to text: [ 3.9953 12.4476]: The authors propose a rehearsal learning framework that identifies and recommends decisions that can persuasively prevent undesired outcomes.", "target": "The authors propose a rehearsal learning framework that identifies and recommends decisions that can persuasively prevent undesired outcomes.", "example": "Convert the coordinate to text: [ 3.9953 12.4476]:"}
{"text": "Convert the coordinate to text: [10.8028  4.9833]: This paper investigates the sample complexity of tuning regularization parameters in linear and logistic regressions under $\\ell_1$ and $\\ell_2$-constraints in the data-driven setting.", "target": "This paper investigates the sample complexity of tuning regularization parameters in linear and logistic regressions under $\\ell_1$ and $\\ell_2$-constraints in the data-driven setting.", "example": "Convert the coordinate to text: [10.8028  4.9833]:"}
{"text": "Convert the coordinate to text: [-8.9454  0.7267]: The authors propose a method named ALLIES that uses LLMs to iteratively generate new queries related to an original query, thereby capturing hidden knowledge that may not be directly obtainable through retrieval.", "target": "The authors propose a method named ALLIES that uses LLMs to iteratively generate new queries related to an original query, thereby capturing hidden knowledge that may not be directly obtainable through retrieval.", "example": "Convert the coordinate to text: [-8.9454  0.7267]:"}
{"text": "Convert the coordinate to text: [-0.7149  6.7386]: The paper proposes a neuro-symbolic approach to self-learn rules that serve as interpretable knowledge to perform relation linking in knowledge base question answering systems, where the rules define natural language text predicates as a weighted mixture of knowledge base paths.", "target": "The paper proposes a neuro-symbolic approach to self-learn rules that serve as interpretable knowledge to perform relation linking in knowledge base question answering systems, where the rules define natural language text predicates as a weighted mixture of knowledge base paths.", "example": "Convert the coordinate to text: [-0.7149  6.7386]:"}
{"text": "Convert the coordinate to text: [ 1.9277 -8.0849]: The authors introduce a new transformer-based model called DarSwin that automatically adapts to the distortion produced by wide-angle lenses. The model uses a radial patch partitioning, a distortion-based sampling technique for creating token embeddings, and an angular position encoding for radial patch merging.", "target": "The authors introduce a new transformer-based model called DarSwin that automatically adapts to the distortion produced by wide-angle lenses. The model uses a radial patch partitioning, a distortion-based sampling technique for creating token embeddings, and an angular position encoding for radial patch merging.", "example": "Convert the coordinate to text: [ 1.9277 -8.0849]:"}
{"text": "Convert the coordinate to text: [-13.5853   8.0952]: The paper presents a unified view of ED models, performs a thorough empirical study, and proposes a better unified baseline. The authors also put forward a unified framework that breaks down the design of prototype-based methods.", "target": "The paper presents a unified view of ED models, performs a thorough empirical study, and proposes a better unified baseline. The authors also put forward a unified framework that breaks down the design of prototype-based methods.", "example": "Convert the coordinate to text: [-13.5853   8.0952]:"}
{"text": "Convert the coordinate to text: [-9.181  15.2934]: The authors present 'Speak in Public', a system that combines virtual reality (VR), biosensors, and speech emotion recognition to provide objective measures of patients\u2019 stress and emotional state during ET sessions.", "target": "The authors present 'Speak in Public', a system that combines virtual reality (VR), biosensors, and speech emotion recognition to provide objective measures of patients\u2019 stress and emotional state during ET sessions.", "example": "Convert the coordinate to text: [-9.181  15.2934]:"}
{"text": "Convert the coordinate to text: [-10.7806  10.9668]: This paper investigates how relationships are maintained when younger helpers offer and older adults receive tech support across three different cultures: North American, South Asian, and Middle Eastern.", "target": "This paper investigates how relationships are maintained when younger helpers offer and older adults receive tech support across three different cultures: North American, South Asian, and Middle Eastern.", "example": "Convert the coordinate to text: [-10.7806  10.9668]:"}
{"text": "Convert the coordinate to text: [-1.7752 -6.3968]: This study suggests moving away from syntax trees and graph convolutional networks, and instead fully embracing BERT wordpieces for TOWE models. It also proposes to address the loss of aspect representation by using sentence-aspect pairs in addition to single sentences.", "target": "This study suggests moving away from syntax trees and graph convolutional networks, and instead fully embracing BERT wordpieces for TOWE models. It also proposes to address the loss of aspect representation by using sentence-aspect pairs in addition to single sentences.", "example": "Convert the coordinate to text: [-1.7752 -6.3968]:"}
{"text": "Convert the coordinate to text: [-0.5442 -3.3643]: Inspired by the chain-of-thought (CoT) idea, the authors introduce a Three-hop Reasoning (THOR) CoT framework to mimic the human-like reasoning process for ISA, with a three-step prompting principle to step-by-step induce the implicit aspect, opinion, and finally, the sentiment polarity.", "target": "Inspired by the chain-of-thought (CoT) idea, the authors introduce a Three-hop Reasoning (THOR) CoT framework to mimic the human-like reasoning process for ISA, with a three-step prompting principle to step-by-step induce the implicit aspect, opinion, and finally, the sentiment polarity.", "example": "Convert the coordinate to text: [-0.5442 -3.3643]:"}
{"text": "Convert the coordinate to text: [-2.6866 -8.3654]: The authors propose to exploit Abstract Meaning Representation (AMR) graphs to improve understanding of complex semantic information in Open-Domain Question Answering. They introduce a method called Graph-as-Token (GST) to incorporate AMRs into Pretrained Language Models.", "target": "The authors propose to exploit Abstract Meaning Representation (AMR) graphs to improve understanding of complex semantic information in Open-Domain Question Answering. They introduce a method called Graph-as-Token (GST) to incorporate AMRs into Pretrained Language Models.", "example": "Convert the coordinate to text: [-2.6866 -8.3654]:"}
{"text": "Convert the coordinate to text: [-5.6942  1.9523]: The authors introduce Check-COVID, a new fact-checking benchmark containing 1,504 expert-annotated news claims about coronavirus paired with sentence-level evidence from scientific journal articles and veracity labels.", "target": "The authors introduce Check-COVID, a new fact-checking benchmark containing 1,504 expert-annotated news claims about coronavirus paired with sentence-level evidence from scientific journal articles and veracity labels.", "example": "Convert the coordinate to text: [-5.6942  1.9523]:"}
{"text": "Convert the coordinate to text: [ 0.1469 -8.9794]: This paper proposes Language augmented CLIP (LaCLIP), a new approach to enhance CLIP training through language rewrites. By leveraging large language models, text descriptions associated with each image are rewritten to exhibit diversity in sentence structure and vocabulary while keeping the original meanings preserved.", "target": "This paper proposes Language augmented CLIP (LaCLIP), a new approach to enhance CLIP training through language rewrites. By leveraging large language models, text descriptions associated with each image are rewritten to exhibit diversity in sentence structure and vocabulary while keeping the original meanings preserved.", "example": "Convert the coordinate to text: [ 0.1469 -8.9794]:"}
{"text": "Convert the coordinate to text: [-4.5782  3.5058]: The authors propose a dedicated fresh content recommendation stack that includes a multi-funnel nomination system. This system combines a two-tower model for coverage and a sequence model for relevance, and considers prediction uncertainty for less exposed content.", "target": "The authors propose a dedicated fresh content recommendation stack that includes a multi-funnel nomination system. This system combines a two-tower model for coverage and a sequence model for relevance, and considers prediction uncertainty for less exposed content.", "example": "Convert the coordinate to text: [-4.5782  3.5058]:"}
{"text": "Convert the coordinate to text: [-2.4111 -5.639 ]: This study explores the impact of different datasets on model performance for the crowd-annotated CODA-19 research aspect classification task and evaluates the effectiveness of large language models (LLMs), such as LLaMA, GPT-3, ChatGPT, and GPT-4.", "target": "This study explores the impact of different datasets on model performance for the crowd-annotated CODA-19 research aspect classification task and evaluates the effectiveness of large language models (LLMs), such as LLaMA, GPT-3, ChatGPT, and GPT-4.", "example": "Convert the coordinate to text: [-2.4111 -5.639 ]:"}
{"text": "Convert the coordinate to text: [-2.1856  2.8719]: The authors propose a framework called Controllable Multi-Objective Re-ranking (CMR), which uses a hypernetwork to generate parameters for a re-ranking model according to different preference weights, enabling the model to adapt online to environment changes without retraining.", "target": "The authors propose a framework called Controllable Multi-Objective Re-ranking (CMR), which uses a hypernetwork to generate parameters for a re-ranking model according to different preference weights, enabling the model to adapt online to environment changes without retraining.", "example": "Convert the coordinate to text: [-2.1856  2.8719]:"}
{"text": "Convert the coordinate to text: [-0.224 -8.073]: The authors introduce FedMultimodal, the first FL benchmark for multimodal learning. It covers five representative multimodal applications from ten commonly used datasets with a total of eight unique modalities.", "target": "The authors introduce FedMultimodal, the first FL benchmark for multimodal learning. It covers five representative multimodal applications from ten commonly used datasets with a total of eight unique modalities.", "example": "Convert the coordinate to text: [-0.224 -8.073]:"}
{"text": "Convert the coordinate to text: [-3.8951 -5.7383]: The authors conduct psycholinguistic and computational experiments to assess the ability of humans and several pre-trained masked language models in correctly identifying control dependencies in Spanish sentences, shedding light on lexically-guided antecedent retrieval processes.", "target": "The authors conduct psycholinguistic and computational experiments to assess the ability of humans and several pre-trained masked language models in correctly identifying control dependencies in Spanish sentences, shedding light on lexically-guided antecedent retrieval processes.", "example": "Convert the coordinate to text: [-3.8951 -5.7383]:"}
{"text": "Convert the coordinate to text: [-7.8603 -3.6294]: The authors introduce a new annotated dataset that captures the 'address' vs. 'reference' distinction in English and propose an automatic tagger for determining this distinction in text.", "target": "The authors introduce a new annotated dataset that captures the 'address' vs. 'reference' distinction in English and propose an automatic tagger for determining this distinction in text.", "example": "Convert the coordinate to text: [-7.8603 -3.6294]:"}
{"text": "Convert the coordinate to text: [ -0.5457 -10.0579]: The authors propose a unified multi-modal AVE framework called DEFLATE, which is designed to handle implicit attribute values that are typically embedded in image information and implied text meanings, in addition to explicit attribute values.", "target": "The authors propose a unified multi-modal AVE framework called DEFLATE, which is designed to handle implicit attribute values that are typically embedded in image information and implied text meanings, in addition to explicit attribute values.", "example": "Convert the coordinate to text: [ -0.5457 -10.0579]:"}
{"text": "Convert the coordinate to text: [-0.0916 -5.6447]: This paper proposes a fine-tuned model for the VWSD task, which fine-tunes a pre-trained model using ITC and ITM losses and employs a candidate selection approach for faster inference.", "target": "This paper proposes a fine-tuned model for the VWSD task, which fine-tunes a pre-trained model using ITC and ITM losses and employs a candidate selection approach for faster inference.", "example": "Convert the coordinate to text: [-0.0916 -5.6447]:"}
{"text": "Convert the coordinate to text: [-5.1582  2.3882]: This study explores the use of transfer learning from media bias detection to persuasion techniques in online news to improve performance.", "target": "This study explores the use of transfer learning from media bias detection to persuasion techniques in online news to improve performance.", "example": "Convert the coordinate to text: [-5.1582  2.3882]:"}
{"text": "Convert the coordinate to text: [  1.3955 -10.0891]: The paper revolves around exploring the impact of vision features in news image captioning and posits that vision features assist in generating improved results.", "target": "The paper revolves around exploring the impact of vision features in news image captioning and posits that vision features assist in generating improved results.", "example": "Convert the coordinate to text: [  1.3955 -10.0891]:"}
{"text": "Convert the coordinate to text: [-2.9288 -3.7304]: The authors investigate the use of entity contrastive learning in joint IC and NER models, a method that aims to cluster similar entities together in a learned representation space.", "target": "The authors investigate the use of entity contrastive learning in joint IC and NER models, a method that aims to cluster similar entities together in a learned representation space.", "example": "Convert the coordinate to text: [-2.9288 -3.7304]:"}
{"text": "Convert the coordinate to text: [ 5.4254 14.474 ]: The authors propose a learning approach called SEAR (Structured Environment-Agent Representations) that leverages visual knowledge of the agent (such as its shape or mask), which is often inexpensive to obtain, to form effective representations for RL algorithms.", "target": "The authors propose a learning approach called SEAR (Structured Environment-Agent Representations) that leverages visual knowledge of the agent (such as its shape or mask), which is often inexpensive to obtain, to form effective representations for RL algorithms.", "example": "Convert the coordinate to text: [ 5.4254 14.474 ]:"}
{"text": "Convert the coordinate to text: [ 6.0249 -4.9004]: The authors introduce cellular sheaves for hypergraphs, enhancing the conventional hypergraph representation while maintaining higher-order connectivity. They develop two unique formulations of sheaf hypergraph Laplacians: linear and non-linear, which provide a more expressive inductive bias than standard hypergraph diffusion.", "target": "The authors introduce cellular sheaves for hypergraphs, enhancing the conventional hypergraph representation while maintaining higher-order connectivity. They develop two unique formulations of sheaf hypergraph Laplacians: linear and non-linear, which provide a more expressive inductive bias than standard hypergraph diffusion.", "example": "Convert the coordinate to text: [ 6.0249 -4.9004]:"}
{"text": "Convert the coordinate to text: [-1.8538 -5.3705]: The authors proposed the use of a large language model, specifically GPT4, guided by targeted prompts for generating code-tracing questions based on code snippets and descriptions.", "target": "The authors proposed the use of a large language model, specifically GPT4, guided by targeted prompts for generating code-tracing questions based on code snippets and descriptions.", "example": "Convert the coordinate to text: [-1.8538 -5.3705]:"}
{"text": "Convert the coordinate to text: [ 8.4083 -3.755 ]: The authors propose HAIDNet, a neural-network-based optimization framework for information design that can adapt to multiple human behavior patterns beyond the Bayesian rational assumption.", "target": "The authors propose HAIDNet, a neural-network-based optimization framework for information design that can adapt to multiple human behavior patterns beyond the Bayesian rational assumption.", "example": "Convert the coordinate to text: [ 8.4083 -3.755 ]:"}
{"text": "Convert the coordinate to text: [11.5696  6.4273]: The authors propose an innovative amortization strategy combined with a recently derived reparametrization of expectations under linear SDEs to eliminate the necessity to solve differential equations when approximating gradients.", "target": "The authors propose an innovative amortization strategy combined with a recently derived reparametrization of expectations under linear SDEs to eliminate the necessity to solve differential equations when approximating gradients.", "example": "Convert the coordinate to text: [11.5696  6.4273]:"}
{"text": "Convert the coordinate to text: [ 1.2733 -8.4772]: This paper introduces a novel Pathological Graph-driven Cross-modal Alignment (PGCA) model for accurate and robust Brain CT report generation, which decouples cross-modal alignment by creating a Pathological Graph that enables learning of fine-grained visual cues and their alignment with textual words.", "target": "This paper introduces a novel Pathological Graph-driven Cross-modal Alignment (PGCA) model for accurate and robust Brain CT report generation, which decouples cross-modal alignment by creating a Pathological Graph that enables learning of fine-grained visual cues and their alignment with textual words.", "example": "Convert the coordinate to text: [ 1.2733 -8.4772]:"}
{"text": "Convert the coordinate to text: [-12.2633   5.3363]: The authors introduce SAGEViz, a modular tool that leverages human-AI collaboration for creating and updating complex schema graphs efficiently, involving simultaneous work by multiple annotators.", "target": "The authors introduce SAGEViz, a modular tool that leverages human-AI collaboration for creating and updating complex schema graphs efficiently, involving simultaneous work by multiple annotators.", "example": "Convert the coordinate to text: [-12.2633   5.3363]:"}
{"text": "Convert the coordinate to text: [ 9.326 -1.816]: The authors propose a binary embedding-based retrieval (BEBR) engine that uses a recurrent binarization algorithm to enable customized bits per dimension, which allows tailoring the number of bits for different applications to trade off accuracy loss and cost savings.", "target": "The authors propose a binary embedding-based retrieval (BEBR) engine that uses a recurrent binarization algorithm to enable customized bits per dimension, which allows tailoring the number of bits for different applications to trade off accuracy loss and cost savings.", "example": "Convert the coordinate to text: [ 9.326 -1.816]:"}
{"text": "Convert the coordinate to text: [ 4.4856 -5.3357]: The authors propose a novel automated graph neural network on heterophilic graphs, Auto-HeG, to autonomously craft heterophilic GNN models with substantial learning abilities. All stages of automatic heterophilic graph learning, including search space design, supernet training, and architecture selection are incorporated into heterophily.", "target": "The authors propose a novel automated graph neural network on heterophilic graphs, Auto-HeG, to autonomously craft heterophilic GNN models with substantial learning abilities. All stages of automatic heterophilic graph learning, including search space design, supernet training, and architecture selection are incorporated into heterophily.", "example": "Convert the coordinate to text: [ 4.4856 -5.3357]:"}
{"text": "Convert the coordinate to text: [-10.6829  17.2306]: The authors propose WhisperMask, a wearable electret condenser microphone designed to acquire speech even in noisy environments. The mask-shaped microphone allows hands-free input and is unobtrusive and lightweight.", "target": "The authors propose WhisperMask, a wearable electret condenser microphone designed to acquire speech even in noisy environments. The mask-shaped microphone allows hands-free input and is unobtrusive and lightweight.", "example": "Convert the coordinate to text: [-10.6829  17.2306]:"}
{"text": "Convert the coordinate to text: [-4.241  -6.8882]: The authors discover that an inadequate encoding of discriminative target language signals leads to off-target translations. To address this problem, they propose a Language Aware Vocabulary Sharing (LAVS) method to construct a multilingual vocabulary that enhances the divergence between languages.", "target": "The authors discover that an inadequate encoding of discriminative target language signals leads to off-target translations. To address this problem, they propose a Language Aware Vocabulary Sharing (LAVS) method to construct a multilingual vocabulary that enhances the divergence between languages.", "example": "Convert the coordinate to text: [-4.241  -6.8882]:"}
{"text": "Convert the coordinate to text: [-1.0415  6.9578]: The authors propose an 'ABductive Learning with Knowledge Graph' (ABL-KG) approach to automatically mine logic rules from knowledge graphs, using a knowledge forgetting mechanism to filter out irrelevant information.", "target": "The authors propose an 'ABductive Learning with Knowledge Graph' (ABL-KG) approach to automatically mine logic rules from knowledge graphs, using a knowledge forgetting mechanism to filter out irrelevant information.", "example": "Convert the coordinate to text: [-1.0415  6.9578]:"}
{"text": "Convert the coordinate to text: [-5.8318  1.4984]: The authors propose Program-Guided Fact-Checking (ProgramFC), which decomposes complex claims into simpler sub-tasks that are tackled using a shared library of specialized functions, bringing more efficiency and interpretability.", "target": "The authors propose Program-Guided Fact-Checking (ProgramFC), which decomposes complex claims into simpler sub-tasks that are tackled using a shared library of specialized functions, bringing more efficiency and interpretability.", "example": "Convert the coordinate to text: [-5.8318  1.4984]:"}
{"text": "Convert the coordinate to text: [-1.1306 -5.2252]: The paper proposes LM-CPPF, a contrastive paraphrasing-guided, prompt-based fine-tuning of language models. It leverages prompt-based few-shot paraphrasing using generative language models for data augmentation.", "target": "The paper proposes LM-CPPF, a contrastive paraphrasing-guided, prompt-based fine-tuning of language models. It leverages prompt-based few-shot paraphrasing using generative language models for data augmentation.", "example": "Convert the coordinate to text: [-1.1306 -5.2252]:"}
{"text": "Convert the coordinate to text: [-0.3312 -6.4355]: The authors propose a retrieval-enhanced approach for personalized response generation that includes a hierarchical transformer retriever and a context-aware prefix encoder to effectively fuse retrieved information to the decoder.", "target": "The authors propose a retrieval-enhanced approach for personalized response generation that includes a hierarchical transformer retriever and a context-aware prefix encoder to effectively fuse retrieved information to the decoder.", "example": "Convert the coordinate to text: [-0.3312 -6.4355]:"}
{"text": "Convert the coordinate to text: [-7.8321 -6.7139]: The authors present Jamp, a Japanese NLI benchmark focused on temporal inference, which includes various temporal inference patterns and thus can facilitate a detailed analysis.", "target": "The authors present Jamp, a Japanese NLI benchmark focused on temporal inference, which includes various temporal inference patterns and thus can facilitate a detailed analysis.", "example": "Convert the coordinate to text: [-7.8321 -6.7139]:"}
{"text": "Convert the coordinate to text: [ 0.0658 -4.7746]: The authors introduce a new post-training paradigm called 'SSP' that uses three self-supervised tasks to efficiently initialise the conversational search model and improve its understanding of dialogue structure and contextual semantics.", "target": "The authors introduce a new post-training paradigm called 'SSP' that uses three self-supervised tasks to efficiently initialise the conversational search model and improve its understanding of dialogue structure and contextual semantics.", "example": "Convert the coordinate to text: [ 0.0658 -4.7746]:"}
{"text": "Convert the coordinate to text: [-6.4304 -8.7862]: This paper proposes an approach for obtaining multi-dialectal representations of Sinitic syllables, through constructing a knowledge graph from structured phonological data, and applying the BoxE technique from knowledge base learning.", "target": "This paper proposes an approach for obtaining multi-dialectal representations of Sinitic syllables, through constructing a knowledge graph from structured phonological data, and applying the BoxE technique from knowledge base learning.", "example": "Convert the coordinate to text: [-6.4304 -8.7862]:"}
{"text": "Convert the coordinate to text: [-10.8578  -1.9145]: This study introduces the concept of multi-granularity temporal question answering over knowledge graphs and presents a large scale dataset for this purpose, named MultiTQ.", "target": "This study introduces the concept of multi-granularity temporal question answering over knowledge graphs and presents a large scale dataset for this purpose, named MultiTQ.", "example": "Convert the coordinate to text: [-10.8578  -1.9145]:"}
{"text": "Convert the coordinate to text: [-2.0426 -6.5538]: The authors, team JUSTONE, introduce their contributions to three sub-tasks of the challenge using pre-trained language models BERT and RoBERTa, alongside a selective ensemble method.", "target": "The authors, team JUSTONE, introduce their contributions to three sub-tasks of the challenge using pre-trained language models BERT and RoBERTa, alongside a selective ensemble method.", "example": "Convert the coordinate to text: [-2.0426 -6.5538]:"}
{"text": "Convert the coordinate to text: [-1.4953 -6.6236]: The authors adopt an ensemble approach leveraging transformer models for Task A, with the majority vote system being employed. For Task B, a model based on the 'deBERTa transformer' is developed, using the hyperparameters identified from Task A.", "target": "The authors adopt an ensemble approach leveraging transformer models for Task A, with the majority vote system being employed. For Task B, a model based on the 'deBERTa transformer' is developed, using the hyperparameters identified from Task A.", "example": "Convert the coordinate to text: [-1.4953 -6.6236]:"}
{"text": "Convert the coordinate to text: [-3.1051 -5.1459]: This paper introduces controllable simile generation (CSG), a task that requires a model to generate a simile by incorporating pre-specified constraints including multiple simile elements such as context and vehicle.", "target": "This paper introduces controllable simile generation (CSG), a task that requires a model to generate a simile by incorporating pre-specified constraints including multiple simile elements such as context and vehicle.", "example": "Convert the coordinate to text: [-3.1051 -5.1459]:"}
{"text": "Convert the coordinate to text: [-3.8437  3.2063]: The authors propose Time-Aware Meta-Learning (TAML), a novel framework for news recommendation systems focusing on cold-start users. TAML factorizes user preferences into time-specific and time-shift representations that jointly influence users' news preferences.", "target": "The authors propose Time-Aware Meta-Learning (TAML), a novel framework for news recommendation systems focusing on cold-start users. TAML factorizes user preferences into time-specific and time-shift representations that jointly influence users' news preferences.", "example": "Convert the coordinate to text: [-3.8437  3.2063]:"}
{"text": "Convert the coordinate to text: [2.4101 7.6572]: The paper generalizes the Confidence constraint, previously restricted to a conjunction of binary inequalities, to any constraint. A new implementation is proposed based on Multivalued Decision Diagrams (MDDs). Here, the probability for a given constraint to be satisfied by a sample of the random variables should be greater than a certain threshold to ensure robustness.", "target": "The paper generalizes the Confidence constraint, previously restricted to a conjunction of binary inequalities, to any constraint. A new implementation is proposed based on Multivalued Decision Diagrams (MDDs). Here, the probability for a given constraint to be satisfied by a sample of the random variables should be greater than a certain threshold to ensure robustness.", "example": "Convert the coordinate to text: [2.4101 7.6572]:"}
{"text": "Convert the coordinate to text: [  6.6101 -12.2883]: The paper introduces an object-aware decoder that enhances object-awareness during training by predicting hand positions, object positions, and semantic object labels using paired captions when available.", "target": "The paper introduces an object-aware decoder that enhances object-awareness during training by predicting hand positions, object positions, and semantic object labels using paired captions when available.", "example": "Convert the coordinate to text: [  6.6101 -12.2883]:"}
{"text": "Convert the coordinate to text: [ 2.2153 15.7973]: The research proposes the use of Liquid Democracy (LD) as a solution to the issue of low voter attention in social choice scenarios.", "target": "The research proposes the use of Liquid Democracy (LD) as a solution to the issue of low voter attention in social choice scenarios.", "example": "Convert the coordinate to text: [ 2.2153 15.7973]:"}
{"text": "Convert the coordinate to text: [ 3.8477 -7.4749]: The authors present a generic pooling framework, and through it, introduce 'SimPool', a simple attention-based pooling mechanism that serves as a replacement for default methods in both convolutional and transformer encoders.", "target": "The authors present a generic pooling framework, and through it, introduce 'SimPool', a simple attention-based pooling mechanism that serves as a replacement for default methods in both convolutional and transformer encoders.", "example": "Convert the coordinate to text: [ 3.8477 -7.4749]:"}
{"text": "Convert the coordinate to text: [7.6618 8.9793]: Correlated latent space Bayesian Optimization (CoBO) is proposed, focusing on learning correlated latent spaces, which are characterized by a tight correlation between the distances in the latent space and distances within the objective function, to minimize the inherent gap.", "target": "Correlated latent space Bayesian Optimization (CoBO) is proposed, focusing on learning correlated latent spaces, which are characterized by a tight correlation between the distances in the latent space and distances within the objective function, to minimize the inherent gap.", "example": "Convert the coordinate to text: [7.6618 8.9793]:"}
{"text": "Convert the coordinate to text: [8.2676 0.4327]: The authors propose InfoCD, a contrastive Chamfer distance loss that spreads the matched points for better distribution alignments between point clouds and includes a surface similarity estimator.", "target": "The authors propose InfoCD, a contrastive Chamfer distance loss that spreads the matched points for better distribution alignments between point clouds and includes a surface similarity estimator.", "example": "Convert the coordinate to text: [8.2676 0.4327]:"}
{"text": "Convert the coordinate to text: [-2.2469 -5.3265]: The paper provides a comprehensive analysis of in-context sample selection methods for entity extraction from scientific documents using GPT-3.5.", "target": "The paper provides a comprehensive analysis of in-context sample selection methods for entity extraction from scientific documents using GPT-3.5.", "example": "Convert the coordinate to text: [-2.2469 -5.3265]:"}
{"text": "Convert the coordinate to text: [-5.5525 -0.3657]: The paper reveals that existing summarization metrics exhibit a bias towards the length of generated summaries. To address this, it introduces a Bayesian normalization technique that significantly diminishes this bias.", "target": "The paper reveals that existing summarization metrics exhibit a bias towards the length of generated summaries. To address this, it introduces a Bayesian normalization technique that significantly diminishes this bias.", "example": "Convert the coordinate to text: [-5.5525 -0.3657]:"}
{"text": "Convert the coordinate to text: [10.9208 -6.2273]: The authors propose a novel generative model named LayoutDiffusion for automatic layout generation, that models layout generation as a discrete denoising diffusion process that is based on three factors: legality, coordinate proximity, and type disruption.", "target": "The authors propose a novel generative model named LayoutDiffusion for automatic layout generation, that models layout generation as a discrete denoising diffusion process that is based on three factors: legality, coordinate proximity, and type disruption.", "example": "Convert the coordinate to text: [10.9208 -6.2273]:"}
{"text": "Convert the coordinate to text: [-9.6992 14.8045]: The authors have created Tutor In-sight, a Mixed Reality (MR) system which enhances education by representing the teacher as an avatar integrated into the student's workspace. The system incorporates features like blending virtual and physical spaces, utilizing auto-generated body language to direct attention, and offering a user-friendly workflow for teachers.", "target": "The authors have created Tutor In-sight, a Mixed Reality (MR) system which enhances education by representing the teacher as an avatar integrated into the student's workspace. The system incorporates features like blending virtual and physical spaces, utilizing auto-generated body language to direct attention, and offering a user-friendly workflow for teachers.", "example": "Convert the coordinate to text: [-9.6992 14.8045]:"}
{"text": "Convert the coordinate to text: [-4.2165 10.3168]: The paper aims to investigate how a cognitive assistant can be designed to facilitate tacit knowledge transfer between users of dynamic complex systems.", "target": "The paper aims to investigate how a cognitive assistant can be designed to facilitate tacit knowledge transfer between users of dynamic complex systems.", "example": "Convert the coordinate to text: [-4.2165 10.3168]:"}
{"text": "Convert the coordinate to text: [-0.3903  1.066 ]: This study develops new methods to measure media biases in LMs trained on diverse data sources along the social and economic axes, and to measure the fairness of downstream NLP models trained on top of such biased LMs.", "target": "This study develops new methods to measure media biases in LMs trained on diverse data sources along the social and economic axes, and to measure the fairness of downstream NLP models trained on top of such biased LMs.", "example": "Convert the coordinate to text: [-0.3903  1.066 ]:"}
{"text": "Convert the coordinate to text: [-1.2206 -3.4386]: The authors propose a structure-modeled textual encoding framework for inductive logical reasoning over knowledge graphs. It uses pre-trained language models for encoding linearized query structures and entities, and uses stepwise instructions for modeling the logical structures of the queries.", "target": "The authors propose a structure-modeled textual encoding framework for inductive logical reasoning over knowledge graphs. It uses pre-trained language models for encoding linearized query structures and entities, and uses stepwise instructions for modeling the logical structures of the queries.", "example": "Convert the coordinate to text: [-1.2206 -3.4386]:"}
{"text": "Convert the coordinate to text: [ 0.8738 -4.7067]: The authors define a path-based few-shot setting and propose a multi-verbalizer framework called Hierarchical Verbalizer (HierVerb). The HierVerb, constrained by hierarchical structure and hierarchical contrastive learning, treats HTC as a single- or multi-label classification problem at multiple layers and learns vectors as verbalizers.", "target": "The authors define a path-based few-shot setting and propose a multi-verbalizer framework called Hierarchical Verbalizer (HierVerb). The HierVerb, constrained by hierarchical structure and hierarchical contrastive learning, treats HTC as a single- or multi-label classification problem at multiple layers and learns vectors as verbalizers.", "example": "Convert the coordinate to text: [ 0.8738 -4.7067]:"}
{"text": "Convert the coordinate to text: [-5.6253 10.3025]: The authors propose an end-to-end framework in this study, designed for reliable model-agnostic change-point detection and interpretation in large, task-oriented dialogue systems.", "target": "The authors propose an end-to-end framework in this study, designed for reliable model-agnostic change-point detection and interpretation in large, task-oriented dialogue systems.", "example": "Convert the coordinate to text: [-5.6253 10.3025]:"}
{"text": "Convert the coordinate to text: [  9.9006 -11.926 ]: This paper presents the novel concept of neural geodesic fields (NeuroGFs), which are learned to represent the all-pairs geodesics of a given mesh, allowing for efficient and accurate queries of arbitrary point-to-point geodesic distances and paths.", "target": "This paper presents the novel concept of neural geodesic fields (NeuroGFs), which are learned to represent the all-pairs geodesics of a given mesh, allowing for efficient and accurate queries of arbitrary point-to-point geodesic distances and paths.", "example": "Convert the coordinate to text: [  9.9006 -11.926 ]:"}
{"text": "Convert the coordinate to text: [-5.4276  6.154 ]: This study addresses CLIPP by collecting large-scale, multi-modal datasets from online YouTube videos shared on Reddit, and uses this data to analyze and construct community influence graphs (CIGs) and develop a novel dynamic graph framework, INPAC (Information Pathway Across Online Communities), which incorporates CIGs to capture the temporal variability and multi-modal nature of video propagation across communities.", "target": "This study addresses CLIPP by collecting large-scale, multi-modal datasets from online YouTube videos shared on Reddit, and uses this data to analyze and construct community influence graphs (CIGs) and develop a novel dynamic graph framework, INPAC (Information Pathway Across Online Communities), which incorporates CIGs to capture the temporal variability and multi-modal nature of video propagation across communities.", "example": "Convert the coordinate to text: [-5.4276  6.154 ]:"}
{"text": "Convert the coordinate to text: [-0.9606  8.4613]: To enable more trusted and rigorous reasoning, the authors propose a novel system called Natural Program. This is a natural language-based deductive reasoning format that allows models to deduce logically by decomposing a reasoning verification process into step-by-step subprocesses.", "target": "To enable more trusted and rigorous reasoning, the authors propose a novel system called Natural Program. This is a natural language-based deductive reasoning format that allows models to deduce logically by decomposing a reasoning verification process into step-by-step subprocesses.", "example": "Convert the coordinate to text: [-0.9606  8.4613]:"}
{"text": "Convert the coordinate to text: [-7.2952 -7.3857]: The authors propose to conduct a comprehensive study of all possible pairs of a morphological analyzer and a subword tokenizer as they are often used in tokenizers for scriptio continua languages.", "target": "The authors propose to conduct a comprehensive study of all possible pairs of a morphological analyzer and a subword tokenizer as they are often used in tokenizers for scriptio continua languages.", "example": "Convert the coordinate to text: [-7.2952 -7.3857]:"}
{"text": "Convert the coordinate to text: [-6.3275 -0.9421]: The authors propose an annotation schema that reflects the interests of healthcare professionals and use it to manually annotate data related to low carbohydrate diets from the Reddit social network.", "target": "The authors propose an annotation schema that reflects the interests of healthcare professionals and use it to manually annotate data related to low carbohydrate diets from the Reddit social network.", "example": "Convert the coordinate to text: [-6.3275 -0.9421]:"}
{"text": "Convert the coordinate to text: [18.5259 -3.1779]: The paper presents an analysis of different machine learning and deep learning approaches for identifying clickbait spoiling types in the context of the SemEval-2023 Clickbait Challenge.", "target": "The paper presents an analysis of different machine learning and deep learning approaches for identifying clickbait spoiling types in the context of the SemEval-2023 Clickbait Challenge.", "example": "Convert the coordinate to text: [18.5259 -3.1779]:"}
{"text": "Convert the coordinate to text: [ 0.7067 -9.9562]: The team proposes a model that uses contrastive learning to learn the matching relationship between text-image pairs. This model utilises the concept of visual word sense disambiguation.", "target": "The team proposes a model that uses contrastive learning to learn the matching relationship between text-image pairs. This model utilises the concept of visual word sense disambiguation.", "example": "Convert the coordinate to text: [ 0.7067 -9.9562]:"}
{"text": "Convert the coordinate to text: [-3.3247 -9.1633]: Self-supervised pretrained speech models such as Wav2vec 2.0, XLSR-53, and Hubert were explored and finetuned on speech translation downstream tasks for low-resource languages and dialects.", "target": "Self-supervised pretrained speech models such as Wav2vec 2.0, XLSR-53, and Hubert were explored and finetuned on speech translation downstream tasks for low-resource languages and dialects.", "example": "Convert the coordinate to text: [-3.3247 -9.1633]:"}
{"text": "Convert the coordinate to text: [ 2.7497 -3.9636]: This paper proposes VMCL, a Contrastive Learning (CL) framework with graph guided Variational autoencoder on Meta-KGs in the inductive setting and representation generation to capture encoded and generated representations of entities.", "target": "This paper proposes VMCL, a Contrastive Learning (CL) framework with graph guided Variational autoencoder on Meta-KGs in the inductive setting and representation generation to capture encoded and generated representations of entities.", "example": "Convert the coordinate to text: [ 2.7497 -3.9636]:"}
{"text": "Convert the coordinate to text: [-1.4733  0.4984]: The authors propose an integrated approach to characterize textual biases that considers structural differences in addition to lexical cues, offering a more efficient method for analyzing long texts.", "target": "The authors propose an integrated approach to characterize textual biases that considers structural differences in addition to lexical cues, offering a more efficient method for analyzing long texts.", "example": "Convert the coordinate to text: [-1.4733  0.4984]:"}
{"text": "Convert the coordinate to text: [-6.1057 -1.1194]: This study focuses on evaluating methods and metrics for the automatic generation of clinical notes from medical conversation, proposing new task-specific metrics and comparing them with state of the art evaluation metrics in text summarization and generation.", "target": "This study focuses on evaluating methods and metrics for the automatic generation of clinical notes from medical conversation, proposing new task-specific metrics and comparing them with state of the art evaluation metrics in text summarization and generation.", "example": "Convert the coordinate to text: [-6.1057 -1.1194]:"}
{"text": "Convert the coordinate to text: [3.5884 1.4126]: The paper proposes a solution to reduce the burden of redundant computation by eliminating duplicates at the batch level without altering the data distribution observed by the model, making it model-agnostic and easy to use as a plug-and-play module.", "target": "The paper proposes a solution to reduce the burden of redundant computation by eliminating duplicates at the batch level without altering the data distribution observed by the model, making it model-agnostic and easy to use as a plug-and-play module.", "example": "Convert the coordinate to text: [3.5884 1.4126]:"}
{"text": "Convert the coordinate to text: [  4.1089 -11.664 ]: The authors propose a large-scale SlowTV dataset containing 1.7M images from diverse environments and use it to train an SS-MDE model. They also introduce a collection of best-practices to maximize performance and generalization, including aspect ratio augmentation, camera intrinsic estimation, support frame randomization, and flexible motion estimation.", "target": "The authors propose a large-scale SlowTV dataset containing 1.7M images from diverse environments and use it to train an SS-MDE model. They also introduce a collection of best-practices to maximize performance and generalization, including aspect ratio augmentation, camera intrinsic estimation, support frame randomization, and flexible motion estimation.", "example": "Convert the coordinate to text: [  4.1089 -11.664 ]:"}
{"text": "Convert the coordinate to text: [ 2.2121 -3.302 ]: The authors propose the General Sequential Episodic Memory Models (GSEMM) that, in the adiabatic limit, exhibit a dynamic energy surface leading to a series of meta-stable states capable of encoding memory sequences.", "target": "The authors propose the General Sequential Episodic Memory Models (GSEMM) that, in the adiabatic limit, exhibit a dynamic energy surface leading to a series of meta-stable states capable of encoding memory sequences.", "example": "Convert the coordinate to text: [ 2.2121 -3.302 ]:"}
{"text": "Convert the coordinate to text: [  7.2182 -14.7901]: The authors tackle these challenges using a combination of the Shi-Tomasi detector, a stability score for assessing the quality of keypoints, and a neural network. They name this method as NeSS-ST, which incorporates the knowledge from the training targets through a neural stability score.", "target": "The authors tackle these challenges using a combination of the Shi-Tomasi detector, a stability score for assessing the quality of keypoints, and a neural network. They name this method as NeSS-ST, which incorporates the knowledge from the training targets through a neural stability score.", "example": "Convert the coordinate to text: [  7.2182 -14.7901]:"}
{"text": "Convert the coordinate to text: [ 5.8518 -8.5229]: To address the highlighted challenges in TAD, the authors proposed a Movement Enhance Network (MENet) that integrates two innovations: a Movement Enhance Module (MEM) to highlight movement feature for better action location, and a Scale Feature Pyramid Network (SFPN) to detect multi-scale actions in videos.", "target": "To address the highlighted challenges in TAD, the authors proposed a Movement Enhance Network (MENet) that integrates two innovations: a Movement Enhance Module (MEM) to highlight movement feature for better action location, and a Scale Feature Pyramid Network (SFPN) to detect multi-scale actions in videos.", "example": "Convert the coordinate to text: [ 5.8518 -8.5229]:"}
{"text": "Convert the coordinate to text: [ -3.5793 -11.8306]: This paper proposes to learn vector fonts from pixelated font images utilizing a joint neural representation that consists of a signed distance field (SDF) and a probabilistic corner field (CF) to capture shape corner details.", "target": "This paper proposes to learn vector fonts from pixelated font images utilizing a joint neural representation that consists of a signed distance field (SDF) and a probabilistic corner field (CF) to capture shape corner details.", "example": "Convert the coordinate to text: [ -3.5793 -11.8306]:"}
{"text": "Convert the coordinate to text: [ 6.538  -3.8343]: The authors propose to continue using the pre-trained network during the target adaptation process instead of discarding it after initializing the source models. The approach is to distil useful target domain information through a co-learning strategy for refining the source model.", "target": "The authors propose to continue using the pre-trained network during the target adaptation process instead of discarding it after initializing the source models. The approach is to distil useful target domain information through a co-learning strategy for refining the source model.", "example": "Convert the coordinate to text: [ 6.538  -3.8343]:"}
{"text": "Convert the coordinate to text: [  7.2058 -12.2445]: This paper introduces a proactive approach to enhance object detection performance. A wrapper named PrObeD is proposed which learns a signal, called a template, to encrypt input images which then highlight semantics useful for the object detector.", "target": "This paper introduces a proactive approach to enhance object detection performance. A wrapper named PrObeD is proposed which learns a signal, called a template, to encrypt input images which then highlight semantics useful for the object detector.", "example": "Convert the coordinate to text: [  7.2058 -12.2445]:"}
{"text": "Convert the coordinate to text: [ 6.3697 13.4294]: The authors introduce a model-based reinforcement learning algorithm that represents continuous-time dynamics using nonlinear ordinary differential equations (ODEs). They use well-calibrated probabilistic models to capture epistemic uncertainty, and base their exploration strategy on the optimistic principle.", "target": "The authors introduce a model-based reinforcement learning algorithm that represents continuous-time dynamics using nonlinear ordinary differential equations (ODEs). They use well-calibrated probabilistic models to capture epistemic uncertainty, and base their exploration strategy on the optimistic principle.", "example": "Convert the coordinate to text: [ 6.3697 13.4294]:"}
{"text": "Convert the coordinate to text: [ 2.0751 -4.0547]: The authors argue that the discrepancy in granularity arises from the lack of elaborate supervision for each group token and propose to bridge this gap by exploring explicit supervision from prototypical knowledge. They develop non-learnable prototypical regularization (NPR) where non-learnable prototypes are estimated from source features to serve as supervision and enable contrastive matching of the group tokens.", "target": "The authors argue that the discrepancy in granularity arises from the lack of elaborate supervision for each group token and propose to bridge this gap by exploring explicit supervision from prototypical knowledge. They develop non-learnable prototypical regularization (NPR) where non-learnable prototypes are estimated from source features to serve as supervision and enable contrastive matching of the group tokens.", "example": "Convert the coordinate to text: [ 2.0751 -4.0547]:"}
{"text": "Convert the coordinate to text: [13.5719 -4.915 ]: This study proposes a unified inference-stage detection framework to defend against backdoor attacks. It provides provable guarantees on the false positive rate and maximizes the detection power.", "target": "This study proposes a unified inference-stage detection framework to defend against backdoor attacks. It provides provable guarantees on the false positive rate and maximizes the detection power.", "example": "Convert the coordinate to text: [13.5719 -4.915 ]:"}
{"text": "Convert the coordinate to text: [-6.1907 -0.2406]: The authors challenge the validity of this standard evaluation methodology when multiple QCs are taken into account - specifically for text summarization. They argue that metrics believed to perform best for certain QCs may not actually perform well and fail to detect drastic summary corruptions with respect to the considered QC.", "target": "The authors challenge the validity of this standard evaluation methodology when multiple QCs are taken into account - specifically for text summarization. They argue that metrics believed to perform best for certain QCs may not actually perform well and fail to detect drastic summary corruptions with respect to the considered QC.", "example": "Convert the coordinate to text: [-6.1907 -0.2406]:"}
{"text": "Convert the coordinate to text: [ 0.1187 -8.2957]: The authors propose an effective yet straightforward scheme named PTUnifier to unify the fusion-encoder type and the dual-encoder type Med-VLPs. The unification is achieved by introducing visual and textual prompts that serve as a feature bank to store the most representative images/texts, allowing a single model to process various tasks with different input formats.", "target": "The authors propose an effective yet straightforward scheme named PTUnifier to unify the fusion-encoder type and the dual-encoder type Med-VLPs. The unification is achieved by introducing visual and textual prompts that serve as a feature bank to store the most representative images/texts, allowing a single model to process various tasks with different input formats.", "example": "Convert the coordinate to text: [ 0.1187 -8.2957]:"}
{"text": "Convert the coordinate to text: [  5.9871 -10.0765]: The authors propose to make use of pre-change semantic information for change detection in bi-temporal images and introduce the new task of Conditional Change Detection. They present MapFormer, a novel architecture based on a multi-modal feature fusion module, that processes features conditioned on the available semantic information.", "target": "The authors propose to make use of pre-change semantic information for change detection in bi-temporal images and introduce the new task of Conditional Change Detection. They present MapFormer, a novel architecture based on a multi-modal feature fusion module, that processes features conditioned on the available semantic information.", "example": "Convert the coordinate to text: [  5.9871 -10.0765]:"}
{"text": "Convert the coordinate to text: [11.5786  6.2471]: The study proposes a Sparsified Online Newton (SONew) algorithm, a computationally efficient sparse preconditioner for DNN training, which can tolerate low precision computation. It is based on the combination of the LogDet matrix divergence measure and sparsity constraints to minimize regret in the online convex optimization framework.", "target": "The study proposes a Sparsified Online Newton (SONew) algorithm, a computationally efficient sparse preconditioner for DNN training, which can tolerate low precision computation. It is based on the combination of the LogDet matrix divergence measure and sparsity constraints to minimize regret in the online convex optimization framework.", "example": "Convert the coordinate to text: [11.5786  6.2471]:"}
{"text": "Convert the coordinate to text: [-0.3689 -6.1547]: The paper proposes a parameter-efficient fine-tuning method, HiFi, where only the highly informative and strongly correlated attention heads for the specific task are fine-tuned.", "target": "The paper proposes a parameter-efficient fine-tuning method, HiFi, where only the highly informative and strongly correlated attention heads for the specific task are fine-tuned.", "example": "Convert the coordinate to text: [-0.3689 -6.1547]:"}
{"text": "Convert the coordinate to text: [-5.4242  7.6059]: The authors proposed an evaluation tool, FinTrust, to assess the logical consistency in financial text to build user trust.", "target": "The authors proposed an evaluation tool, FinTrust, to assess the logical consistency in financial text to build user trust.", "example": "Convert the coordinate to text: [-5.4242  7.6059]:"}
{"text": "Convert the coordinate to text: [-1.8405 -5.5096]: The paper introduces PlugLM, a pre-trained language model with differentiable plug-in memory (DPM). The key idea is to separate knowledge storage from model parameters using an editable and scalable key-value memory, and to utilize knowledge in an explainable way through knowledge retrieval in the DPM.", "target": "The paper introduces PlugLM, a pre-trained language model with differentiable plug-in memory (DPM). The key idea is to separate knowledge storage from model parameters using an editable and scalable key-value memory, and to utilize knowledge in an explainable way through knowledge retrieval in the DPM.", "example": "Convert the coordinate to text: [-1.8405 -5.5096]:"}
{"text": "Convert the coordinate to text: [-6.1736 -6.2892]: This study introduces the 'WYWEB' evaluation benchmark, which offers nine NLP tasks in classical Chinese, including sentence classification, sequence labeling, reading comprehension, and machine translation.", "target": "This study introduces the 'WYWEB' evaluation benchmark, which offers nine NLP tasks in classical Chinese, including sentence classification, sequence labeling, reading comprehension, and machine translation.", "example": "Convert the coordinate to text: [-6.1736 -6.2892]:"}
{"text": "Convert the coordinate to text: [-3.6694 -5.6306]: The authors introduce GlobalBench, an ever-expanding collection designed to dynamically track progress on all NLP datasets in all languages. It measures not only accuracy, but also the estimated per-speaker utility and equity of technology across all languages.", "target": "The authors introduce GlobalBench, an ever-expanding collection designed to dynamically track progress on all NLP datasets in all languages. It measures not only accuracy, but also the estimated per-speaker utility and equity of technology across all languages.", "example": "Convert the coordinate to text: [-3.6694 -5.6306]:"}
{"text": "Convert the coordinate to text: [ 0.8027 -9.7116]: The study proposes a method to retrieve both textual and visual evidence at the object, sentence, and whole image levels. It also introduces an approach for synthesizing information across these levels for improved reasoning between the same and different modalities.", "target": "The study proposes a method to retrieve both textual and visual evidence at the object, sentence, and whole image levels. It also introduces an approach for synthesizing information across these levels for improved reasoning between the same and different modalities.", "example": "Convert the coordinate to text: [ 0.8027 -9.7116]:"}
{"text": "Convert the coordinate to text: [-12.7016   7.1457]: The authors introduce and study the problem of buggy code completion, inspired by the real-time code suggestion scenario where the code context contains potential bugs which can become bugs in the completed program.", "target": "The authors introduce and study the problem of buggy code completion, inspired by the real-time code suggestion scenario where the code context contains potential bugs which can become bugs in the completed program.", "example": "Convert the coordinate to text: [-12.7016   7.1457]:"}
{"text": "Convert the coordinate to text: [-4.3519 -9.7652]: This study presents the ReadAlong Studio Web App, an open-source, web-based interface for performing text-speech alignment and creating interactive 'read-along audio books'. It extends a Python library for zero-shot multilingual text-speech alignment and rewrites the underlying speech recognition engine to run in the browser.", "target": "This study presents the ReadAlong Studio Web App, an open-source, web-based interface for performing text-speech alignment and creating interactive 'read-along audio books'. It extends a Python library for zero-shot multilingual text-speech alignment and rewrites the underlying speech recognition engine to run in the browser.", "example": "Convert the coordinate to text: [-4.3519 -9.7652]:"}
{"text": "Convert the coordinate to text: [-4.3504 -4.569 ]: A new model of contextual word representation is proposed, derived not from a neural perspective, but from a purely syntactic and probabilistic perspective. It uses a conditional random field that models discrete latent representations of all words in a sentence as well as dependency arcs between them, and utilizes mean field variational inference for approximate inference.", "target": "A new model of contextual word representation is proposed, derived not from a neural perspective, but from a purely syntactic and probabilistic perspective. It uses a conditional random field that models discrete latent representations of all words in a sentence as well as dependency arcs between them, and utilizes mean field variational inference for approximate inference.", "example": "Convert the coordinate to text: [-4.3504 -4.569 ]:"}
{"text": "Convert the coordinate to text: [0.9788 0.1754]: The authors propose a novel method for mitigating bias in VQA tasks by subtracting bias score from the VQA base score. This method is supplemented by two bias learning branches designed to detect more bias information and a dynamical constraint loss to avoid over-correction or insufficient debiasing.", "target": "The authors propose a novel method for mitigating bias in VQA tasks by subtracting bias score from the VQA base score. This method is supplemented by two bias learning branches designed to detect more bias information and a dynamical constraint loss to avoid over-correction or insufficient debiasing.", "example": "Convert the coordinate to text: [0.9788 0.1754]:"}
{"text": "Convert the coordinate to text: [ 7.0705 -4.0543]: This study proposes an adapter-guided domain adaptation method, PC-Adapter, in light of the recognized importance of the global geometry of source data and trends of target pseudo-labels biased towards the source label distribution. This method preserves the global shape information of the source domain using an attention-based adapter and learns the local characteristics of the target domain using another adapter equipped with graph convolution.", "target": "This study proposes an adapter-guided domain adaptation method, PC-Adapter, in light of the recognized importance of the global geometry of source data and trends of target pseudo-labels biased towards the source label distribution. This method preserves the global shape information of the source domain using an attention-based adapter and learns the local characteristics of the target domain using another adapter equipped with graph convolution.", "example": "Convert the coordinate to text: [ 7.0705 -4.0543]:"}
{"text": "Convert the coordinate to text: [ 2.6238 -9.1977]: A novel approach called inverse compositional learning (ICL) is introduced for weakly-supervised video relation grounding, which represents relations at both the holistic and partial levels, formulating VRG as a joint optimization problem.", "target": "A novel approach called inverse compositional learning (ICL) is introduced for weakly-supervised video relation grounding, which represents relations at both the holistic and partial levels, formulating VRG as a joint optimization problem.", "example": "Convert the coordinate to text: [ 2.6238 -9.1977]:"}
{"text": "Convert the coordinate to text: [  6.9026 -17.2606]: The introduction of the curvature similarity extractor (CSE) method, which calculates the curvature of the local 3D surface patch for each detected feature point in a viewpoint-invariant manner, and uses this as a guide for feature matching.", "target": "The introduction of the curvature similarity extractor (CSE) method, which calculates the curvature of the local 3D surface patch for each detected feature point in a viewpoint-invariant manner, and uses this as a guide for feature matching.", "example": "Convert the coordinate to text: [  6.9026 -17.2606]:"}
{"text": "Convert the coordinate to text: [  8.7922 -11.3941]: The paper proposes a novel perspective of treating circuit components as point clouds and using Transformer-based point cloud perception methods to extract features from the circuit. This approach enables direct feature extraction from raw data without preprocessing, allows for end-to-end training, and results in enhanced performance of EDA algorithms.", "target": "The paper proposes a novel perspective of treating circuit components as point clouds and using Transformer-based point cloud perception methods to extract features from the circuit. This approach enables direct feature extraction from raw data without preprocessing, allows for end-to-end training, and results in enhanced performance of EDA algorithms.", "example": "Convert the coordinate to text: [  8.7922 -11.3941]:"}
{"text": "Convert the coordinate to text: [ 4.8368 -4.9288]: The authors propose a novel active learning (AL) method for GNNs by extending the Expected Model Change Maximization (EMCM) principle to improve prediction performance on unlabeled data. Furthermore, they provide a Bayesian interpretation for the node embeddings generated by GNNs under a semi-supervised setting.", "target": "The authors propose a novel active learning (AL) method for GNNs by extending the Expected Model Change Maximization (EMCM) principle to improve prediction performance on unlabeled data. Furthermore, they provide a Bayesian interpretation for the node embeddings generated by GNNs under a semi-supervised setting.", "example": "Convert the coordinate to text: [ 4.8368 -4.9288]:"}
{"text": "Convert the coordinate to text: [0.0528 7.9464]: The authors introduce the concept of DeepSoftLog, based on probabilistic semantics, to address the limitations of the existing Neural Theorem Prover system and enhance the performance of soft-unification.", "target": "The authors introduce the concept of DeepSoftLog, based on probabilistic semantics, to address the limitations of the existing Neural Theorem Prover system and enhance the performance of soft-unification.", "example": "Convert the coordinate to text: [0.0528 7.9464]:"}
{"text": "Convert the coordinate to text: [ 6.9522 12.5437]: This work introduces a novel approach called Multi-Agent First Order Constrained Optimization in Policy Space (MAFOCOPS), which aims to achieve satisfactory performance and enforce safety constraints simultaneously.", "target": "This work introduces a novel approach called Multi-Agent First Order Constrained Optimization in Policy Space (MAFOCOPS), which aims to achieve satisfactory performance and enforce safety constraints simultaneously.", "example": "Convert the coordinate to text: [ 6.9522 12.5437]:"}
{"text": "Convert the coordinate to text: [-14.6762  -3.5083]: The authors propose Petals, a system for inference and fine-tuning of large models collaboratively by combining the resources of multiple parties, running inference of BLOOM-176B on consumer GPUs.", "target": "The authors propose Petals, a system for inference and fine-tuning of large models collaboratively by combining the resources of multiple parties, running inference of BLOOM-176B on consumer GPUs.", "example": "Convert the coordinate to text: [-14.6762  -3.5083]:"}
{"text": "Convert the coordinate to text: [-3.4079  3.3789]: The paper introduces a new framework that can perform model quantization of sequential recommenders without access to any real private data. The key component of the framework is a generator that creates fake sequence samples to train the quantized sequential recommendation model, under a min-max game strategy.", "target": "The paper introduces a new framework that can perform model quantization of sequential recommenders without access to any real private data. The key component of the framework is a generator that creates fake sequence samples to train the quantized sequential recommendation model, under a min-max game strategy.", "example": "Convert the coordinate to text: [-3.4079  3.3789]:"}
{"text": "Convert the coordinate to text: [-1.7403 -4.8297]: The authors address the problem of the transferability of actively acquired datasets in text classification and explore whether active learning gains persist when a dataset built with a specific PLM through active learning is used for training a different PLM.", "target": "The authors address the problem of the transferability of actively acquired datasets in text classification and explore whether active learning gains persist when a dataset built with a specific PLM through active learning is used for training a different PLM.", "example": "Convert the coordinate to text: [-1.7403 -4.8297]:"}
{"text": "Convert the coordinate to text: [-3.6978 -9.5292]: The study investigates the use of data augmentation techniques, specifically self-training and text-to-speech (TTS) systems, to improve low-resource Automatic Speech Recognition (ASR) performance on four typologically diverse minority languages or language variants.", "target": "The study investigates the use of data augmentation techniques, specifically self-training and text-to-speech (TTS) systems, to improve low-resource Automatic Speech Recognition (ASR) performance on four typologically diverse minority languages or language variants.", "example": "Convert the coordinate to text: [-3.6978 -9.5292]:"}
{"text": "Convert the coordinate to text: [-0.7256 -4.4057]: The authors propose a simple but effective two-stage SimOAP strategy for persona-based dialogue generation task, with an over-sampling stage that takes large-scale responses from existing trained models efficiently via off-the-shelf distilling and compressing methods, and a post-evaluation stage that selects a good response based on multiple well-designed evaluation metrics from large-scale candidates.", "target": "The authors propose a simple but effective two-stage SimOAP strategy for persona-based dialogue generation task, with an over-sampling stage that takes large-scale responses from existing trained models efficiently via off-the-shelf distilling and compressing methods, and a post-evaluation stage that selects a good response based on multiple well-designed evaluation metrics from large-scale candidates.", "example": "Convert the coordinate to text: [-0.7256 -4.4057]:"}
{"text": "Convert the coordinate to text: [-0.5244 -6.2311]: The paper introduces PaCE, a unified, flexible, and structured pre-training framework for multi-modal dialogue that can accommodate multiple dialogue-related tasks using a combination of fundamental experts, and can be trained with limited dialogue data and extensive non-dialogue multi-modal data.", "target": "The paper introduces PaCE, a unified, flexible, and structured pre-training framework for multi-modal dialogue that can accommodate multiple dialogue-related tasks using a combination of fundamental experts, and can be trained with limited dialogue data and extensive non-dialogue multi-modal data.", "example": "Convert the coordinate to text: [-0.5244 -6.2311]:"}
{"text": "Convert the coordinate to text: [-1.8208  8.378 ]: This position paper identifies two types of researcher degrees of freedom and proposes a framework called 'validity argument', containing a series of validation criteria across test components, to address the issue.", "target": "This position paper identifies two types of researcher degrees of freedom and proposes a framework called 'validity argument', containing a series of validation criteria across test components, to address the issue.", "example": "Convert the coordinate to text: [-1.8208  8.378 ]:"}
{"text": "Convert the coordinate to text: [-7.4742 -7.3792]: The authors investigate the causes of high performance and high variability in morphological inflection, implying flaws in data set creation and evaluation processes.", "target": "The authors investigate the causes of high performance and high variability in morphological inflection, implying flaws in data set creation and evaluation processes.", "example": "Convert the coordinate to text: [-7.4742 -7.3792]:"}
{"text": "Convert the coordinate to text: [ 1.9673 -4.1752]: In response to the challenges in the DG task, this study proposes a novel method called Heterogeneity-based Two-stage Contrastive Learning (HTCL). This approach generates a highly diverse dividing pattern via contrastive learning, then employs invariance-aimed contrastive learning in the second stage.", "target": "In response to the challenges in the DG task, this study proposes a novel method called Heterogeneity-based Two-stage Contrastive Learning (HTCL). This approach generates a highly diverse dividing pattern via contrastive learning, then employs invariance-aimed contrastive learning in the second stage.", "example": "Convert the coordinate to text: [ 1.9673 -4.1752]:"}
{"text": "Convert the coordinate to text: [-3.522 -7.808]: The authors investigate multilingual TTI (mTTI) and the potential of neural machine translation (NMT) to bootstrap mTTI systems. They propose Ensemble Adapter (EnsAd), a novel parameter-efficient approach that consolidates the multilingual text knowledge within the mTTI framework, aiming to improve mTTI performance.", "target": "The authors investigate multilingual TTI (mTTI) and the potential of neural machine translation (NMT) to bootstrap mTTI systems. They propose Ensemble Adapter (EnsAd), a novel parameter-efficient approach that consolidates the multilingual text knowledge within the mTTI framework, aiming to improve mTTI performance.", "example": "Convert the coordinate to text: [-3.522 -7.808]:"}
{"text": "Convert the coordinate to text: [ 2.1528 -1.6261]: The authors propose a lightweight contrastive clustering-based bootstrapping method for fine-grained classification, which refines the labels of passages iteratively under the guidance of the mapping from both global and local perspectives.", "target": "The authors propose a lightweight contrastive clustering-based bootstrapping method for fine-grained classification, which refines the labels of passages iteratively under the guidance of the mapping from both global and local perspectives.", "example": "Convert the coordinate to text: [ 2.1528 -1.6261]:"}
{"text": "Convert the coordinate to text: [-1.9072  2.9874]: The authors propose a novel Learning-to-Rank model, called RankFormer, which is designed to optimize a new listwide assessment objective along with the traditional listwise Learning-to-Rank objective, thus taking into account both relative and absolute user feedback.", "target": "The authors propose a novel Learning-to-Rank model, called RankFormer, which is designed to optimize a new listwide assessment objective along with the traditional listwise Learning-to-Rank objective, thus taking into account both relative and absolute user feedback.", "example": "Convert the coordinate to text: [-1.9072  2.9874]:"}
{"text": "Convert the coordinate to text: [-2.4467 -7.218 ]: This paper proposes an approach to adapt VLP to unseen languages using multilingual pre-trained language models and a cross-lingual contextualized token embeddings alignment for training text encoders in non-English languages.", "target": "This paper proposes an approach to adapt VLP to unseen languages using multilingual pre-trained language models and a cross-lingual contextualized token embeddings alignment for training text encoders in non-English languages.", "example": "Convert the coordinate to text: [-2.4467 -7.218 ]:"}
{"text": "Convert the coordinate to text: [-8.3229 -1.9832]: The authors propose Autodive, an integrated onsite scientific literature annotation tool designed for natural scientists and Natural Language Processing (NLP) researchers. It includes six core functions of annotation supporting the corpus generation lifecycle.", "target": "The authors propose Autodive, an integrated onsite scientific literature annotation tool designed for natural scientists and Natural Language Processing (NLP) researchers. It includes six core functions of annotation supporting the corpus generation lifecycle.", "example": "Convert the coordinate to text: [-8.3229 -1.9832]:"}
{"text": "Convert the coordinate to text: [-2.4492 -5.6502]: The authors conduct experiments using several Open-Source Large Language Models (LLMs) and explore fine-tuning techniques along with prompting strategies including Few-Shot and Chain-of-Thought approaches.", "target": "The authors conduct experiments using several Open-Source Large Language Models (LLMs) and explore fine-tuning techniques along with prompting strategies including Few-Shot and Chain-of-Thought approaches.", "example": "Convert the coordinate to text: [-2.4492 -5.6502]:"}
{"text": "Convert the coordinate to text: [ 1.4127 -4.2727]: This paper proposes a self-supervised regularization method called Similarizing the Influence of Words with Contrastive Learning (SIWCon), which encourages the model to learn sentence representations where words of varying importance have more uniform influence on prediction.", "target": "This paper proposes a self-supervised regularization method called Similarizing the Influence of Words with Contrastive Learning (SIWCon), which encourages the model to learn sentence representations where words of varying importance have more uniform influence on prediction.", "example": "Convert the coordinate to text: [ 1.4127 -4.2727]:"}
{"text": "Convert the coordinate to text: [-5.7147 -6.1431]: A new dataset enriched with discourse annotations built upon the large-scale BWB parallel corpus is presented by the authors in response to the limitations of sentence-level benchmarks for document-level machine translation systems.", "target": "A new dataset enriched with discourse annotations built upon the large-scale BWB parallel corpus is presented by the authors in response to the limitations of sentence-level benchmarks for document-level machine translation systems.", "example": "Convert the coordinate to text: [-5.7147 -6.1431]:"}
{"text": "Convert the coordinate to text: [ 12.2344 -14.5623]: The authors introduce a novel object-centric contact representation known as ContactGen, which includes three components: a contact map, a part map, and a direction map. They propose a conditional generative model to predict ContactGen and employ model-based optimization to predict diverse and geometrically feasible grasps.", "target": "The authors introduce a novel object-centric contact representation known as ContactGen, which includes three components: a contact map, a part map, and a direction map. They propose a conditional generative model to predict ContactGen and employ model-based optimization to predict diverse and geometrically feasible grasps.", "example": "Convert the coordinate to text: [ 12.2344 -14.5623]:"}
{"text": "Convert the coordinate to text: [-3.4693 -9.4197]: The authors propose DASpeech, a non-autoregressive direct S2ST model. It adopts a two-pass architecture, utilizing a linguistic decoder (DA-Transformer) to generate the target text, followed by an acoustic decoder (FastSpeech 2) to generate the target speech. The approach is designed to better capture the complex distribution of target speech.", "target": "The authors propose DASpeech, a non-autoregressive direct S2ST model. It adopts a two-pass architecture, utilizing a linguistic decoder (DA-Transformer) to generate the target text, followed by an acoustic decoder (FastSpeech 2) to generate the target speech. The approach is designed to better capture the complex distribution of target speech.", "example": "Convert the coordinate to text: [-3.4693 -9.4197]:"}
{"text": "Convert the coordinate to text: [ 0.3469 -9.0646]: The authors propose a Language-Image COnsistency model (LICO) for explainable image classification that correlates learnable linguistic prompts with corresponding visual features in a coarse-to-fine manner, improving explainability while delivering high performance.", "target": "The authors propose a Language-Image COnsistency model (LICO) for explainable image classification that correlates learnable linguistic prompts with corresponding visual features in a coarse-to-fine manner, improving explainability while delivering high performance.", "example": "Convert the coordinate to text: [ 0.3469 -9.0646]:"}
{"text": "Convert the coordinate to text: [ 7.1118 12.4828]: The authors propose a new value-based algorithm with PAC guarantees that does not require full coverage of the offline data. Instead, it operates under partial coverage against a single policy, and realizability of soft Q-function and another function defined as a solution to a minimax optimization problem.", "target": "The authors propose a new value-based algorithm with PAC guarantees that does not require full coverage of the offline data. Instead, it operates under partial coverage against a single policy, and realizability of soft Q-function and another function defined as a solution to a minimax optimization problem.", "example": "Convert the coordinate to text: [ 7.1118 12.4828]:"}
{"text": "Convert the coordinate to text: [1.8732 9.7968]: The authors introduce ASPEN, a parallel computation solution for DNNs that achieves fine-grained dynamic execution by (1) removing operator barriers and expressing DNNs in dataflow graphs of fine-grained tiles to expose parallel computation opportunities across operators, and (2) exploiting these opportunities through dynamic location and scheduling in runtime.", "target": "The authors introduce ASPEN, a parallel computation solution for DNNs that achieves fine-grained dynamic execution by (1) removing operator barriers and expressing DNNs in dataflow graphs of fine-grained tiles to expose parallel computation opportunities across operators, and (2) exploiting these opportunities through dynamic location and scheduling in runtime.", "example": "Convert the coordinate to text: [1.8732 9.7968]:"}
{"text": "Convert the coordinate to text: [6.8638 7.7853]: The authors propose offline RL algorithms with differential privacy guarantees that can effectively mitigate these privacy risks while still providing valuable insights.", "target": "The authors propose offline RL algorithms with differential privacy guarantees that can effectively mitigate these privacy risks while still providing valuable insights.", "example": "Convert the coordinate to text: [6.8638 7.7853]:"}
{"text": "Convert the coordinate to text: [-7.2979 -8.5072]: The authors introduce SanskritShala, a neural Sanskrit Natural Language Processing (NLP) toolkit that offers state-of-the-art tools for word segmentation, morphological tagging, dependency parsing, and compound type identification and is designed to facilitate real-time analyses and data annotation features.", "target": "The authors introduce SanskritShala, a neural Sanskrit Natural Language Processing (NLP) toolkit that offers state-of-the-art tools for word segmentation, morphological tagging, dependency parsing, and compound type identification and is designed to facilitate real-time analyses and data annotation features.", "example": "Convert the coordinate to text: [-7.2979 -8.5072]:"}
{"text": "Convert the coordinate to text: [  5.095 -12.778]: The paper presents a new technique for image segmentation where the models are trained in the latent space of the latent diffusion models (LDMs), which is proved to be a better representation compared to RGB images or CLIP encodings. This approach also solves the problem of the domain gap between real and AI-generated images.", "target": "The paper presents a new technique for image segmentation where the models are trained in the latent space of the latent diffusion models (LDMs), which is proved to be a better representation compared to RGB images or CLIP encodings. This approach also solves the problem of the domain gap between real and AI-generated images.", "example": "Convert the coordinate to text: [  5.095 -12.778]:"}
{"text": "Convert the coordinate to text: [0.8473 1.7827]: The authors propose CounterNet, an end-to-end learning framework which integrates the training of the predictive model and the generation of counterfactual (CF) explanations into a single pipeline, thereby addressing the limitations of existing CF explanation techniques.", "target": "The authors propose CounterNet, an end-to-end learning framework which integrates the training of the predictive model and the generation of counterfactual (CF) explanations into a single pipeline, thereby addressing the limitations of existing CF explanation techniques.", "example": "Convert the coordinate to text: [0.8473 1.7827]:"}
{"text": "Convert the coordinate to text: [-1.5143  0.098 ]: The study investigates the effects of transferring two language models, XLM-T (sentiment classification) and HateBERT (same domain -- Reddit) for multi-level classification into Sexist or not Sexist. The study uses synthetic classification of an unlabelled dataset and intermediary class information to maximize model performance.", "target": "The study investigates the effects of transferring two language models, XLM-T (sentiment classification) and HateBERT (same domain -- Reddit) for multi-level classification into Sexist or not Sexist. The study uses synthetic classification of an unlabelled dataset and intermediary class information to maximize model performance.", "example": "Convert the coordinate to text: [-1.5143  0.098 ]:"}
{"text": "Convert the coordinate to text: [-11.0406  14.358 ]: To address the above issue, a Pondside Visualisation System using Google Glass Enterprise Edition 2 was created that allows farmers to access visualised historical and real-time water data during field operations. This new system makes use of a new data visualization style optimized for small near-eye displays.", "target": "To address the above issue, a Pondside Visualisation System using Google Glass Enterprise Edition 2 was created that allows farmers to access visualised historical and real-time water data during field operations. This new system makes use of a new data visualization style optimized for small near-eye displays.", "example": "Convert the coordinate to text: [-11.0406  14.358 ]:"}
{"text": "Convert the coordinate to text: [ 0.8067 -9.6249]: IMAGEBIND is presented as a strategy for learning a joint embedding across multiple different modalities, utilizing large-scale vision-language models. The authors claim that all combinations of paired data are not necessary to train such a joint embedding, and only image-paired data is sufficient.", "target": "IMAGEBIND is presented as a strategy for learning a joint embedding across multiple different modalities, utilizing large-scale vision-language models. The authors claim that all combinations of paired data are not necessary to train such a joint embedding, and only image-paired data is sufficient.", "example": "Convert the coordinate to text: [ 0.8067 -9.6249]:"}
{"text": "Convert the coordinate to text: [-2.2921 -5.2392]: The study tasks GPT-3 with generating summaries and syntheses of biomedical articles describing randomized controlled trials without supervision. The goal is to evaluate the performance of the model in both the single and multi-document settings.", "target": "The study tasks GPT-3 with generating summaries and syntheses of biomedical articles describing randomized controlled trials without supervision. The goal is to evaluate the performance of the model in both the single and multi-document settings.", "example": "Convert the coordinate to text: [-2.2921 -5.2392]:"}
{"text": "Convert the coordinate to text: [-1.0629 -5.1668]: The authors propose a generative multimodal prompt (GMP) model for MABSA, which specifically captures the prompt for each aspect term in a few-shot scenario.", "target": "The authors propose a generative multimodal prompt (GMP) model for MABSA, which specifically captures the prompt for each aspect term in a few-shot scenario.", "example": "Convert the coordinate to text: [-1.0629 -5.1668]:"}
{"text": "Convert the coordinate to text: [-1.5703 -5.3257]: This study aims to improve the understanding of prompts by large language models, thus enhancing their translation using translation memories.", "target": "This study aims to improve the understanding of prompts by large language models, thus enhancing their translation using translation memories.", "example": "Convert the coordinate to text: [-1.5703 -5.3257]:"}
{"text": "Convert the coordinate to text: [-1.2531  0.1925]: The authors propose a localized social bias dataset, KO SB I, which consists of pairs of contexts and sentences in Korean across different demographic groups to ensure the safe and effective deployment of LLMs in South Korea.", "target": "The authors propose a localized social bias dataset, KO SB I, which consists of pairs of contexts and sentences in Korean across different demographic groups to ensure the safe and effective deployment of LLMs in South Korea.", "example": "Convert the coordinate to text: [-1.2531  0.1925]:"}
{"text": "Convert the coordinate to text: [  9.1822 -21.381 ]: The authors propose a benchmark for inverse design of nanophotonic devices, which can be computationally verified.", "target": "The authors propose a benchmark for inverse design of nanophotonic devices, which can be computationally verified.", "example": "Convert the coordinate to text: [  9.1822 -21.381 ]:"}
{"text": "Convert the coordinate to text: [-4.3887 -7.6937]: The paper introduces a novel adaptation of the QE framework to extract high-quality parallel data from a pseudo-parallel corpus for improving Machine Translation (MT). The authors also demonstrate the potential of transfer learning with their Few-shot QE model, which is trained on significantly fewer instances than traditional requirements.", "target": "The paper introduces a novel adaptation of the QE framework to extract high-quality parallel data from a pseudo-parallel corpus for improving Machine Translation (MT). The authors also demonstrate the potential of transfer learning with their Few-shot QE model, which is trained on significantly fewer instances than traditional requirements.", "example": "Convert the coordinate to text: [-4.3887 -7.6937]:"}
{"text": "Convert the coordinate to text: [-6.2961 -2.8843]: This work introduces the task of organizing a given set of key points into a hierarchy, according to their specificity. This is tantamount to a novel type of Textual Entailment Graph", "target": "This work introduces the task of organizing a given set of key points into a hierarchy, according to their specificity. This is tantamount to a novel type of Textual Entailment Graph", "example": "Convert the coordinate to text: [-6.2961 -2.8843]:"}
{"text": "Convert the coordinate to text: [-6.8779 -6.8264]: This paper serves to alleviate this limitation by introducing CSS, a new dataset for assessing sentence simplification in Chinese, with manual simplifications collected from human annotators.", "target": "This paper serves to alleviate this limitation by introducing CSS, a new dataset for assessing sentence simplification in Chinese, with manual simplifications collected from human annotators.", "example": "Convert the coordinate to text: [-6.8779 -6.8264]:"}
{"text": "Convert the coordinate to text: [-7.9361 11.7329]: This study aims to create a new experience for users where they can refer to certain elements like phone numbers, addresses, email addresses, URLs, and dates on their phone screens using voice assistants, focusing on reference understanding especially when multiple similar texts are present on screen.", "target": "This study aims to create a new experience for users where they can refer to certain elements like phone numbers, addresses, email addresses, URLs, and dates on their phone screens using voice assistants, focusing on reference understanding especially when multiple similar texts are present on screen.", "example": "Convert the coordinate to text: [-7.9361 11.7329]:"}
{"text": "Convert the coordinate to text: [ 0.7397 -9.2963]: The authors propose a robustness evaluation strategy, Cross-Modal Attribute Insertions, which inserts visual attributes of the objects in the image into the corresponding text as a realistic perturbation for multimodal vision-and-language data.", "target": "The authors propose a robustness evaluation strategy, Cross-Modal Attribute Insertions, which inserts visual attributes of the objects in the image into the corresponding text as a realistic perturbation for multimodal vision-and-language data.", "example": "Convert the coordinate to text: [ 0.7397 -9.2963]:"}
{"text": "Convert the coordinate to text: [ 3.5608 -3.9359]: The paper introduces Symbolic Chain-of-Thought Distillation (SCoTD), a method to train a smaller student model on rationalizations sampled from a significantly larger teacher model, demonstrating that even smaller models can benefit from chain-of-thought prompting.", "target": "The paper introduces Symbolic Chain-of-Thought Distillation (SCoTD), a method to train a smaller student model on rationalizations sampled from a significantly larger teacher model, demonstrating that even smaller models can benefit from chain-of-thought prompting.", "example": "Convert the coordinate to text: [ 3.5608 -3.9359]:"}
{"text": "Convert the coordinate to text: [-6.1854 -5.2222]: The key idea in this paper is the introduction of the Visual Word Sense Disambiguation (Visual-WSD) task, which aims to identify the intended meaning of a given ambiguous word using image data, presented in three different languages: English, Italian, and Farsi.", "target": "The key idea in this paper is the introduction of the Visual Word Sense Disambiguation (Visual-WSD) task, which aims to identify the intended meaning of a given ambiguous word using image data, presented in three different languages: English, Italian, and Farsi.", "example": "Convert the coordinate to text: [-6.1854 -5.2222]:"}
{"text": "Convert the coordinate to text: [  1.0873 -10.3242]: The authors propose three new approaches for task resolution: (1) an unsupervised approach considering similarities between word senses and image captions, (2) a supervised approach using a Siamese neural network, and (3) a self-supervised approach using a Bayesian personalized ranking framework.", "target": "The authors propose three new approaches for task resolution: (1) an unsupervised approach considering similarities between word senses and image captions, (2) a supervised approach using a Siamese neural network, and (3) a self-supervised approach using a Bayesian personalized ranking framework.", "example": "Convert the coordinate to text: [  1.0873 -10.3242]:"}
{"text": "Convert the coordinate to text: [ 6.9397 -4.0792]: Two objectives are proposed: to evaluate the efficacy of self-training-based Domain Adaptation (DA) in predicting the helpfulness of peer reviews and overcoming the distributional gap, and to propose an improved self-training framework incorporating knowledge distillation and noise injection to enhance performance and address the distributional gap more effectively.", "target": "Two objectives are proposed: to evaluate the efficacy of self-training-based Domain Adaptation (DA) in predicting the helpfulness of peer reviews and overcoming the distributional gap, and to propose an improved self-training framework incorporating knowledge distillation and noise injection to enhance performance and address the distributional gap more effectively.", "example": "Convert the coordinate to text: [ 6.9397 -4.0792]:"}
{"text": "Convert the coordinate to text: [-11.4296  -0.853 ]: The authors conduct a study on the observed ambiguous and unanswerable cases in text-to-SQL and propose requirements for handling ambiguous and unanswerable questions. They also propose a counterfactual example generation method to automatically produce ambiguous and unanswerable text-to-SQL examples.", "target": "The authors conduct a study on the observed ambiguous and unanswerable cases in text-to-SQL and propose requirements for handling ambiguous and unanswerable questions. They also propose a counterfactual example generation method to automatically produce ambiguous and unanswerable text-to-SQL examples.", "example": "Convert the coordinate to text: [-11.4296  -0.853 ]:"}
{"text": "Convert the coordinate to text: [ 0.1804 -8.997 ]: The authors propose a novel paradigm for zero-shot text classification - CLIPText, which reformulates such tasks into a text-image matching problem that CLIP can be applied to. They also develop a version of this system that incorporates prompts (Prompt-CLIPText).", "target": "The authors propose a novel paradigm for zero-shot text classification - CLIPText, which reformulates such tasks into a text-image matching problem that CLIP can be applied to. They also develop a version of this system that incorporates prompts (Prompt-CLIPText).", "example": "Convert the coordinate to text: [ 0.1804 -8.997 ]:"}
{"text": "Convert the coordinate to text: [-1.1939 -9.9976]: The authors propose a Transferable Audio-Visual Text Generation (TAVT) framework which uses audio-visual correlation to mitigate domain discrepancies. The framework consists of two key components: Audio-Visual Meta-Mapper (AVMM) and Dual Counterfactual Contrastive Learning (DCCL).", "target": "The authors propose a Transferable Audio-Visual Text Generation (TAVT) framework which uses audio-visual correlation to mitigate domain discrepancies. The framework consists of two key components: Audio-Visual Meta-Mapper (AVMM) and Dual Counterfactual Contrastive Learning (DCCL).", "example": "Convert the coordinate to text: [-1.1939 -9.9976]:"}
{"text": "Convert the coordinate to text: [-4.2274 -0.7951]: The authors propose 'Tomea', a new method to compare a supervised classifier\u2019s representation of moral rhetoric across different domains, thus enabling both quantitative and qualitative comparisons of moral rhetoric.", "target": "The authors propose 'Tomea', a new method to compare a supervised classifier\u2019s representation of moral rhetoric across different domains, thus enabling both quantitative and qualitative comparisons of moral rhetoric.", "example": "Convert the coordinate to text: [-4.2274 -0.7951]:"}
{"text": "Convert the coordinate to text: [-2.5436 -0.9515]: The paper introduces NSEM-GMHTM, a deep topic model with a Gaussian mixture prior distribution designed to enhance the model's adaptability to sparse data. This model explicitly caters to hierarchical and symmetric relations between topics through the dependency matrices and nonlinear structural equations.", "target": "The paper introduces NSEM-GMHTM, a deep topic model with a Gaussian mixture prior distribution designed to enhance the model's adaptability to sparse data. This model explicitly caters to hierarchical and symmetric relations between topics through the dependency matrices and nonlinear structural equations.", "example": "Convert the coordinate to text: [-2.5436 -0.9515]:"}
{"text": "Convert the coordinate to text: [-2.9261 13.6609]: The authors propose the Skill Transformer, a monolithic policy that combines conditional sequence modeling and skill modularity. It is designed to predict both high-level skills (e.g., navigation, picking, placing) and low-level actions (e.g., base and arm motion) of a robot.", "target": "The authors propose the Skill Transformer, a monolithic policy that combines conditional sequence modeling and skill modularity. It is designed to predict both high-level skills (e.g., navigation, picking, placing) and low-level actions (e.g., base and arm motion) of a robot.", "example": "Convert the coordinate to text: [-2.9261 13.6609]:"}
{"text": "Convert the coordinate to text: [ 5.4449 -6.6854]: The authors propose a novel spatial event ranking approach called SpatialRank. It features adaptive graph convolution layers that dynamically learn the spatiotemporal dependencies across locations, and the model optimizes a hybrid NDCG loss with a spatial component to better rank neighboring locations.", "target": "The authors propose a novel spatial event ranking approach called SpatialRank. It features adaptive graph convolution layers that dynamically learn the spatiotemporal dependencies across locations, and the model optimizes a hybrid NDCG loss with a spatial component to better rank neighboring locations.", "example": "Convert the coordinate to text: [ 5.4449 -6.6854]:"}
{"text": "Convert the coordinate to text: [ 9.0763 -7.1069]: This paper identifies three fundamental issues with the use of FFC in image inpainting; spectrum shifting, unexpected spatial activation, and limited frequency receptive field, leading to difficulties in generating complex texture and faithful reconstruction. To rectify these issues, an Unbiased Fast Fourier Convolution (UFFC) module is proposed.", "target": "This paper identifies three fundamental issues with the use of FFC in image inpainting; spectrum shifting, unexpected spatial activation, and limited frequency receptive field, leading to difficulties in generating complex texture and faithful reconstruction. To rectify these issues, an Unbiased Fast Fourier Convolution (UFFC) module is proposed.", "example": "Convert the coordinate to text: [ 9.0763 -7.1069]:"}
{"text": "Convert the coordinate to text: [ 7.0925 -4.4935]: The authors propose domain-generalized unsupervised cross-domain image retrieval (DG-UCDIR), aiming to facilitate image retrieval between two unseen domains in an unsupervised way. They also introduce a new two-stage domain augmentation technique for diversified training data generation, and utilize phase image as a proxy to mitigate the domain gap.", "target": "The authors propose domain-generalized unsupervised cross-domain image retrieval (DG-UCDIR), aiming to facilitate image retrieval between two unseen domains in an unsupervised way. They also introduce a new two-stage domain augmentation technique for diversified training data generation, and utilize phase image as a proxy to mitigate the domain gap.", "example": "Convert the coordinate to text: [ 7.0925 -4.4935]:"}
{"text": "Convert the coordinate to text: [ 3.3116 13.9844]: The authors propose two new algorithms - Team-PSRO, an extension of PSRO from two-player games to team games, and Team-PSRO Mix-and-Match which better uses population policies. Both algorithms involve teams learning a joint best response to the opponent's meta-strategy via reinforcement learning.", "target": "The authors propose two new algorithms - Team-PSRO, an extension of PSRO from two-player games to team games, and Team-PSRO Mix-and-Match which better uses population policies. Both algorithms involve teams learning a joint best response to the opponent's meta-strategy via reinforcement learning.", "example": "Convert the coordinate to text: [ 3.3116 13.9844]:"}
{"text": "Convert the coordinate to text: [ 2.2058 -4.0871]: The authors propose the SACL-XD scheme, which consists of Slimmed Asymmetrical Contrastive Learning (SACL) and Cross-Distillation (XD), enabling efficient CL with compact models. These components train CL models from scratch and do not require a strong pre-trained model as a teacher.", "target": "The authors propose the SACL-XD scheme, which consists of Slimmed Asymmetrical Contrastive Learning (SACL) and Cross-Distillation (XD), enabling efficient CL with compact models. These components train CL models from scratch and do not require a strong pre-trained model as a teacher.", "example": "Convert the coordinate to text: [ 2.2058 -4.0871]:"}
{"text": "Convert the coordinate to text: [ 5.6718 -3.0126]: The authors propose a framework for understanding how data augmentation interacts with class-level learning dynamics in image classification tasks.", "target": "The authors propose a framework for understanding how data augmentation interacts with class-level learning dynamics in image classification tasks.", "example": "Convert the coordinate to text: [ 5.6718 -3.0126]:"}
{"text": "Convert the coordinate to text: [13.24   -2.6394]: The authors propose a novel training method for SNNs that utilizes the zeroth-order technique at the local or neuron level. This method is motivated by its potential regularizing and energy-efficient effects.", "target": "The authors propose a novel training method for SNNs that utilizes the zeroth-order technique at the local or neuron level. This method is motivated by its potential regularizing and energy-efficient effects.", "example": "Convert the coordinate to text: [13.24   -2.6394]:"}
{"text": "Convert the coordinate to text: [-3.4652 -6.5158]: The authors propose RETVec, a multilingual text vectorizer that combines character encoding with a small optional embedding model to embed words into a 256-dimensional vector space. It is also resistant to typos and character-level adversarial attacks due to pre-training using pairwise metric learning.", "target": "The authors propose RETVec, a multilingual text vectorizer that combines character encoding with a small optional embedding model to embed words into a 256-dimensional vector space. It is also resistant to typos and character-level adversarial attacks due to pre-training using pairwise metric learning.", "example": "Convert the coordinate to text: [-3.4652 -6.5158]:"}
{"text": "Convert the coordinate to text: [-11.0793  -1.1529]: The authors propose QUEST, a new dataset of natural language queries with implicit set operations that map to a set of entities corresponding to Wikipedia documents.", "target": "The authors propose QUEST, a new dataset of natural language queries with implicit set operations that map to a set of entities corresponding to Wikipedia documents.", "example": "Convert the coordinate to text: [-11.0793  -1.1529]:"}
{"text": "Convert the coordinate to text: [-1.0249 -5.2589]: The authors propose Information Theoretic Adversarial Prompt Tuning (INTapt), which introduces prompts concatenated to the input to re-modulate a pre-trained model's attention, making the input resemble native English speech without having to update the backbone weights.", "target": "The authors propose Information Theoretic Adversarial Prompt Tuning (INTapt), which introduces prompts concatenated to the input to re-modulate a pre-trained model's attention, making the input resemble native English speech without having to update the backbone weights.", "example": "Convert the coordinate to text: [-1.0249 -5.2589]:"}
{"text": "Convert the coordinate to text: [ 0.4313 -3.3986]: The authors propose a novel approach to boost the datastore retrieval of $k$NN-MT by reconstructing the datastore using a reviser to revise key representations to make them more compatible with the downstream domain.", "target": "The authors propose a novel approach to boost the datastore retrieval of $k$NN-MT by reconstructing the datastore using a reviser to revise key representations to make them more compatible with the downstream domain.", "example": "Convert the coordinate to text: [ 0.4313 -3.3986]:"}
{"text": "Convert the coordinate to text: [-1.573  -7.3287]: The paper suggests that randomly masking 20% non-error tokens from the input sequence during fine-tuning is a more effective strategy for learning a better language model without sacrificing the quality of the error model. This is a simple method that can be applied to any model architecture.", "target": "The paper suggests that randomly masking 20% non-error tokens from the input sequence during fine-tuning is a more effective strategy for learning a better language model without sacrificing the quality of the error model. This is a simple method that can be applied to any model architecture.", "example": "Convert the coordinate to text: [-1.573  -7.3287]:"}
{"text": "Convert the coordinate to text: [-0.7673  7.2107]: This paper advances a new approach to math story problems by developing a graph-based semantic formalism named MathWorld, to categorize, represent, and better understand math story problems and their underlying mathematical relationships.", "target": "This paper advances a new approach to math story problems by developing a graph-based semantic formalism named MathWorld, to categorize, represent, and better understand math story problems and their underlying mathematical relationships.", "example": "Convert the coordinate to text: [-0.7673  7.2107]:"}
{"text": "Convert the coordinate to text: [-0.0322 -3.8619]: The authors propose IDOL (InDicator-Oriented Logic Pre-training), an intuitive yet effective pre-training task that strengthens pre-trained models with help of six types of logical indicators and a logically rich dataset, LGP (LoGic Pre-training).", "target": "The authors propose IDOL (InDicator-Oriented Logic Pre-training), an intuitive yet effective pre-training task that strengthens pre-trained models with help of six types of logical indicators and a logically rich dataset, LGP (LoGic Pre-training).", "example": "Convert the coordinate to text: [-0.0322 -3.8619]:"}
{"text": "Convert the coordinate to text: [-2.1025 -4.9251]: The authors propose PairSpanBERT, an enhanced SpanBERT-based model, that uses a novel pre-training objective to learn connections between two implicitly linked mentions. This is achieved through data automatically generated either heuristically or via distance supervision with a knowledge graph.", "target": "The authors propose PairSpanBERT, an enhanced SpanBERT-based model, that uses a novel pre-training objective to learn connections between two implicitly linked mentions. This is achieved through data automatically generated either heuristically or via distance supervision with a knowledge graph.", "example": "Convert the coordinate to text: [-2.1025 -4.9251]:"}
{"text": "Convert the coordinate to text: [-1.7758  5.8484]: The authors propose solutions for both subtasks leveraging the eXplainable Artificial Intelligence (XAI) method, Shapley Additive Explanations (SHAP). For Subtask 1, SHAP was used to explore what led to model failures, while for Subtask 3, a recalibration of the Attention Mechanism was realized by extracting critical tokens for each persuasion technique, aiming to counter model overfitting and improve performance with limited samples in the training data.", "target": "The authors propose solutions for both subtasks leveraging the eXplainable Artificial Intelligence (XAI) method, Shapley Additive Explanations (SHAP). For Subtask 1, SHAP was used to explore what led to model failures, while for Subtask 3, a recalibration of the Attention Mechanism was realized by extracting critical tokens for each persuasion technique, aiming to counter model overfitting and improve performance with limited samples in the training data.", "example": "Convert the coordinate to text: [-1.7758  5.8484]:"}
{"text": "Convert the coordinate to text: [-1.7117 -6.6809]: The authors introduce and evaluate a large, 170M-parameter, BERT encoder that shares representations across languages, domains, and tasks compared to the usage of smaller, decoupled 17M-parameter BERT encoders.", "target": "The authors introduce and evaluate a large, 170M-parameter, BERT encoder that shares representations across languages, domains, and tasks compared to the usage of smaller, decoupled 17M-parameter BERT encoders.", "example": "Convert the coordinate to text: [-1.7117 -6.6809]:"}
{"text": "Convert the coordinate to text: [-4.479 -3.923]: The authors propose a deep language model-based contrastive weighting model, CWPRF, that learns to select the most useful embeddings for query expansion by discriminating between relevant and non-relevant documents for semantic search.", "target": "The authors propose a deep language model-based contrastive weighting model, CWPRF, that learns to select the most useful embeddings for query expansion by discriminating between relevant and non-relevant documents for semantic search.", "example": "Convert the coordinate to text: [-4.479 -3.923]:"}
{"text": "Convert the coordinate to text: [-2.8516  0.2623]: The authors propose a new multilingual dataset called SOA for detecting online attacks. This dataset includes online attacks in code-mixed languages, and rich metadata for detailed analysis.", "target": "The authors propose a new multilingual dataset called SOA for detecting online attacks. This dataset includes online attacks in code-mixed languages, and rich metadata for detailed analysis.", "example": "Convert the coordinate to text: [-2.8516  0.2623]:"}
{"text": "Convert the coordinate to text: [-5.3894  9.9847]: The authors propose a DialPost method called Dialog-Post, which uses multi-level self-supervised objectives and a hierarchical model to better capture dialogue characteristics.", "target": "The authors propose a DialPost method called Dialog-Post, which uses multi-level self-supervised objectives and a hierarchical model to better capture dialogue characteristics.", "example": "Convert the coordinate to text: [-5.3894  9.9847]:"}
{"text": "Convert the coordinate to text: [-10.8624  -1.7982]: The authors construct a new TQA dataset, IM-TQA, which requires models to understand tables without directly available header annotations and to handle multi-type tables, including previously neglected complex tables.", "target": "The authors construct a new TQA dataset, IM-TQA, which requires models to understand tables without directly available header annotations and to handle multi-type tables, including previously neglected complex tables.", "example": "Convert the coordinate to text: [-10.8624  -1.7982]:"}
{"text": "Convert the coordinate to text: [ 4.3705 -8.3741]: The authors propose the Cross-Class Query Network (CCQ), which contains an image encoder, a cross-class query learning module, and an attentive refinement segmentation module in order to efficiently perform multi-organ segmentation on partially-labeled datasets.", "target": "The authors propose the Cross-Class Query Network (CCQ), which contains an image encoder, a cross-class query learning module, and an attentive refinement segmentation module in order to efficiently perform multi-organ segmentation on partially-labeled datasets.", "example": "Convert the coordinate to text: [ 4.3705 -8.3741]:"}
{"text": "Convert the coordinate to text: [ 13.012  -10.3243]: The authors introduce FreeMask, a method that uses synthetic images from generative models to ease the burden of data collection and annotation processes.", "target": "The authors introduce FreeMask, a method that uses synthetic images from generative models to ease the burden of data collection and annotation processes.", "example": "Convert the coordinate to text: [ 13.012  -10.3243]:"}
{"text": "Convert the coordinate to text: [2.3696 2.0872]: The authors propose using causal inference tools to increase the resilience of anomaly detection models to different kinds of distribution shifts, illustrated by the derivation of a regularization term conducive to partial distribution invariance across environments.", "target": "The authors propose using causal inference tools to increase the resilience of anomaly detection models to different kinds of distribution shifts, illustrated by the derivation of a regularization term conducive to partial distribution invariance across environments.", "example": "Convert the coordinate to text: [2.3696 2.0872]:"}
{"text": "Convert the coordinate to text: [ 2.8062 -6.127 ]: This study proposes a novel Gestalt Enhanced Markup (GEM) Language Model that hosts heterogeneous visual information from the render tree directly into the language model without requiring additional visual input, inspired by Gestalt psychological theory.", "target": "This study proposes a novel Gestalt Enhanced Markup (GEM) Language Model that hosts heterogeneous visual information from the render tree directly into the language model without requiring additional visual input, inspired by Gestalt psychological theory.", "example": "Convert the coordinate to text: [ 2.8062 -6.127 ]:"}
{"text": "Convert the coordinate to text: [-3.4814  0.9457]: The researchers present a novel benchmark dataset called BullyExplain for explainable cyberbullying detection in code-mixed languages, and propose an innovative generative framework, GenEx, that reimagines the multi-task problem as a text-to-text generation task.", "target": "The researchers present a novel benchmark dataset called BullyExplain for explainable cyberbullying detection in code-mixed languages, and propose an innovative generative framework, GenEx, that reimagines the multi-task problem as a text-to-text generation task.", "example": "Convert the coordinate to text: [-3.4814  0.9457]:"}
{"text": "Convert the coordinate to text: [ 1.8617 -9.3921]: This paper proposes an approach that utilizes knowledge graphs to model diverse entities, their semantic connections within traffic scenes, and presents the nuScenes Knowledge Graph (nSKG) that models all scene participants, road elements, and their semantic and spatial relationships.", "target": "This paper proposes an approach that utilizes knowledge graphs to model diverse entities, their semantic connections within traffic scenes, and presents the nuScenes Knowledge Graph (nSKG) that models all scene participants, road elements, and their semantic and spatial relationships.", "example": "Convert the coordinate to text: [ 1.8617 -9.3921]:"}
{"text": "Convert the coordinate to text: [ 1.069  -7.5831]: The authors propose two non-parametric operators for accelerating Vision Transformers for dense prediction without the need for fine-tuning. One operator, a token clustering layer, reduces the number of tokens for increasing speed, and the other, a token reconstruction layer, recovers high-resolution by increasing the number of tokens.", "target": "The authors propose two non-parametric operators for accelerating Vision Transformers for dense prediction without the need for fine-tuning. One operator, a token clustering layer, reduces the number of tokens for increasing speed, and the other, a token reconstruction layer, recovers high-resolution by increasing the number of tokens.", "example": "Convert the coordinate to text: [ 1.069  -7.5831]:"}
{"text": "Convert the coordinate to text: [0.7174 1.1238]: The authors propose CPACE, a Concept-centric Prompt-bAsed Contrastive Explanation Generation model, which converts obtained symbolic knowledge into a contrastive explanation. The generated contrastive explanation distinguishes differences among given candidates.", "target": "The authors propose CPACE, a Concept-centric Prompt-bAsed Contrastive Explanation Generation model, which converts obtained symbolic knowledge into a contrastive explanation. The generated contrastive explanation distinguishes differences among given candidates.", "example": "Convert the coordinate to text: [0.7174 1.1238]:"}
{"text": "Convert the coordinate to text: [10.9051 -3.0525]: The authors introduce two new transformer architectures, Pre-RMSNorm and Pre-CRMSNorm Transformers that use modifications to the normalization process of LayerNorm to unify with RMSNorm. In addition, a Compressed RMSNorm (CRMSNorm) is introduced based on a lossless compression of the zero-mean vectors.", "target": "The authors introduce two new transformer architectures, Pre-RMSNorm and Pre-CRMSNorm Transformers that use modifications to the normalization process of LayerNorm to unify with RMSNorm. In addition, a Compressed RMSNorm (CRMSNorm) is introduced based on a lossless compression of the zero-mean vectors.", "example": "Convert the coordinate to text: [10.9051 -3.0525]:"}
{"text": "Convert the coordinate to text: [-3.2413 -8.6334]: The authors propose a method to train a SimulST model using combined SI and offline data. The model is trained with style tags that indicate whether to generate SI- or offline-style outputs.", "target": "The authors propose a method to train a SimulST model using combined SI and offline data. The model is trained with style tags that indicate whether to generate SI- or offline-style outputs.", "example": "Convert the coordinate to text: [-3.2413 -8.6334]:"}
{"text": "Convert the coordinate to text: [-1.4779 -4.0844]: The authors propose 'meta-training with demonstration retrieval', a method which uses a dense passage retriever to fetch semantically similar labeled demonstrations for each example, providing more diverse supervision. The idea lies in separating external knowledge from model parameters, thus enabling the training of parameter-efficient models generalizing well across tasks.", "target": "The authors propose 'meta-training with demonstration retrieval', a method which uses a dense passage retriever to fetch semantically similar labeled demonstrations for each example, providing more diverse supervision. The idea lies in separating external knowledge from model parameters, thus enabling the training of parameter-efficient models generalizing well across tasks.", "example": "Convert the coordinate to text: [-1.4779 -4.0844]:"}
{"text": "Convert the coordinate to text: [-2.7442 -6.4385]: The authors use a recently developed Hebrew PLM, aleph-BERT, for automated short answer grading of high school biology items, and explore its potential of automatically assessing new items without item-specific fine-tuning.", "target": "The authors use a recently developed Hebrew PLM, aleph-BERT, for automated short answer grading of high school biology items, and explore its potential of automatically assessing new items without item-specific fine-tuning.", "example": "Convert the coordinate to text: [-2.7442 -6.4385]:"}
{"text": "Convert the coordinate to text: [ 8.0853 -2.2351]: This study proposes a solution, Embedding Interval Bound Constraint (EIBC) triplet loss, which is optimized to train robustness-aware word embeddings for better certified robustness.", "target": "This study proposes a solution, Embedding Interval Bound Constraint (EIBC) triplet loss, which is optimized to train robustness-aware word embeddings for better certified robustness.", "example": "Convert the coordinate to text: [ 8.0853 -2.2351]:"}
{"text": "Convert the coordinate to text: [-1.4807 -4.4793]: The authors propose a simple and efficient IUR method called MIUR, which employs a one-layer MLP architecture to mine latent semantic information between joint utterances.", "target": "The authors propose a simple and efficient IUR method called MIUR, which employs a one-layer MLP architecture to mine latent semantic information between joint utterances.", "example": "Convert the coordinate to text: [-1.4807 -4.4793]:"}
{"text": "Convert the coordinate to text: [-1.2972 -5.2448]: The authors introduce PATRON, a data selection method for fine-tuning pre-trained language models in cold-start scenarios. PATRON employs a prompt-based uncertainty propagation approach to estimate data importance, as well as a partition-then-rewrite (PTR) strategy for promoting sample diversity in query annotations.", "target": "The authors introduce PATRON, a data selection method for fine-tuning pre-trained language models in cold-start scenarios. PATRON employs a prompt-based uncertainty propagation approach to estimate data importance, as well as a partition-then-rewrite (PTR) strategy for promoting sample diversity in query annotations.", "example": "Convert the coordinate to text: [-1.2972 -5.2448]:"}
{"text": "Convert the coordinate to text: [ 1.1966 -2.376 ]: This paper presents Attribute Tree, a unified formulation for closed-world, open-world, and semi-open attribute extraction tasks, and AtTGen, a text-to-tree generation model to learn annotations from different scenarios efficiently and consistently.", "target": "This paper presents Attribute Tree, a unified formulation for closed-world, open-world, and semi-open attribute extraction tasks, and AtTGen, a text-to-tree generation model to learn annotations from different scenarios efficiently and consistently.", "example": "Convert the coordinate to text: [ 1.1966 -2.376 ]:"}
{"text": "Convert the coordinate to text: [ 1.6673 11.607 ]: This paper examines both non-preemptive and preemptive problems and designs algorithms within scenarios where job types are not known in advance. Emphasis is placed on understanding the impact of the differentiation in durations between job types when the job's characteristics are unknown.", "target": "This paper examines both non-preemptive and preemptive problems and designs algorithms within scenarios where job types are not known in advance. Emphasis is placed on understanding the impact of the differentiation in durations between job types when the job's characteristics are unknown.", "example": "Convert the coordinate to text: [ 1.6673 11.607 ]:"}
{"text": "Convert the coordinate to text: [1.3432 6.7282]: The paper proposes SCOPE, a collaborative perception framework that combines spatio-temporal awareness characteristics across on-road agents in an end-to-end manner. SCOPE uses semantic cues of the temporal context, spatial information from various agents, and multi-source representations of the target agent fused adaptively.", "target": "The paper proposes SCOPE, a collaborative perception framework that combines spatio-temporal awareness characteristics across on-road agents in an end-to-end manner. SCOPE uses semantic cues of the temporal context, spatial information from various agents, and multi-source representations of the target agent fused adaptively.", "example": "Convert the coordinate to text: [1.3432 6.7282]:"}
{"text": "Convert the coordinate to text: [5.47   1.2643]: The authors propose a theory that indicates a robust classifier's existence is determined by the data distribution's key property of concentration on small-volume subsets of the input space.", "target": "The authors propose a theory that indicates a robust classifier's existence is determined by the data distribution's key property of concentration on small-volume subsets of the input space.", "example": "Convert the coordinate to text: [5.47   1.2643]:"}
{"text": "Convert the coordinate to text: [ -0.6248 -12.7041]: The authors propose a physics-augmented autoencoder (PAA) framework for 3D gait recognition that uses a graph-convolution-based encoder and a physics-based decoder, creating physically plausible and discriminative intermediate representations.", "target": "The authors propose a physics-augmented autoencoder (PAA) framework for 3D gait recognition that uses a graph-convolution-based encoder and a physics-based decoder, creating physically plausible and discriminative intermediate representations.", "example": "Convert the coordinate to text: [ -0.6248 -12.7041]:"}
{"text": "Convert the coordinate to text: [ 9.2647 11.3741]: The authors propose an oracle-efficient relaxation for the adversarial contextual bandits problem that aims to improve the existing regret bounds.", "target": "The authors propose an oracle-efficient relaxation for the adversarial contextual bandits problem that aims to improve the existing regret bounds.", "example": "Convert the coordinate to text: [ 9.2647 11.3741]:"}
{"text": "Convert the coordinate to text: [  1.919 -11.848]: The authors present a new method, called spuriosity rankings, which utilizes existing data more efficiently by ranking images within their classes based on spuriosity, measured via deep neural features of an interpretable network.", "target": "The authors present a new method, called spuriosity rankings, which utilizes existing data more efficiently by ranking images within their classes based on spuriosity, measured via deep neural features of an interpretable network.", "example": "Convert the coordinate to text: [  1.919 -11.848]:"}
{"text": "Convert the coordinate to text: [-3.9029 -6.8585]: The proposed solution, SelectNoise, is an unsupervised approach based on selective candidate extraction and noise injection that improves cross-lingual signals from closely related HRLs to enable MT for ELRLs.", "target": "The proposed solution, SelectNoise, is an unsupervised approach based on selective candidate extraction and noise injection that improves cross-lingual signals from closely related HRLs to enable MT for ELRLs.", "example": "Convert the coordinate to text: [-3.9029 -6.8585]:"}
{"text": "Convert the coordinate to text: [10.2086 -4.1217]: The authors propose Alternating Updates (AltUp), a method to increase a model's capacity without increasing the computational burden. AltUp widens the learned representation without increasing the computation time by working on a subblock of the representation at each layer.", "target": "The authors propose Alternating Updates (AltUp), a method to increase a model's capacity without increasing the computational burden. AltUp widens the learned representation without increasing the computation time by working on a subblock of the representation at each layer.", "example": "Convert the coordinate to text: [10.2086 -4.1217]:"}
{"text": "Convert the coordinate to text: [ 3.1061 -1.4242]: A novel weak-labeling strategy for data augmentation in text regression tasks called WADER is proposed to handle data scarcity and imbalance, particularly for cross-lingual, zero-shot tasks.", "target": "A novel weak-labeling strategy for data augmentation in text regression tasks called WADER is proposed to handle data scarcity and imbalance, particularly for cross-lingual, zero-shot tasks.", "example": "Convert the coordinate to text: [ 3.1061 -1.4242]:"}
{"text": "Convert the coordinate to text: [-9.3161 -4.5259]: The authors introduce a semantic-aware dynamic retrospective-prospective reasoning approach for video-based question answering that utilizes the Semantic Role Labeling (SRL) structure of a question in the dynamic reasoning process.", "target": "The authors introduce a semantic-aware dynamic retrospective-prospective reasoning approach for video-based question answering that utilizes the Semantic Role Labeling (SRL) structure of a question in the dynamic reasoning process.", "example": "Convert the coordinate to text: [-9.3161 -4.5259]:"}
{"text": "Convert the coordinate to text: [-1.3457  0.0768]: The authors propose the application of data augmentation, loss alteration techniques, and the use of ensembles of Transformer models trained on various datasets to address class imbalance in sexism detection.", "target": "The authors propose the application of data augmentation, loss alteration techniques, and the use of ensembles of Transformer models trained on various datasets to address class imbalance in sexism detection.", "example": "Convert the coordinate to text: [-1.3457  0.0768]:"}
{"text": "Convert the coordinate to text: [-4.3787 -7.9322]: The authors propose using intermediate sequences from the 'source-like' structure to the 'target-like' structure as intermediate signals for NMT, thereby introducing a domain-agnostic principle of translation to reduce harmful spurious correlations.", "target": "The authors propose using intermediate sequences from the 'source-like' structure to the 'target-like' structure as intermediate signals for NMT, thereby introducing a domain-agnostic principle of translation to reduce harmful spurious correlations.", "example": "Convert the coordinate to text: [-4.3787 -7.9322]:"}
{"text": "Convert the coordinate to text: [-5.7446 -6.7996]: The authors introduce SeeTRUE: a comprehensive evaluation set, with human judgements for whether a given text-image pair is semantically aligned, and describe two automatic methods to determine alignment: a pipeline based on question generation and visual question answering models, and an end-to-end classification approach by finetuning multimodal pretrained models.", "target": "The authors introduce SeeTRUE: a comprehensive evaluation set, with human judgements for whether a given text-image pair is semantically aligned, and describe two automatic methods to determine alignment: a pipeline based on question generation and visual question answering models, and an end-to-end classification approach by finetuning multimodal pretrained models.", "example": "Convert the coordinate to text: [-5.7446 -6.7996]:"}
{"text": "Convert the coordinate to text: [-10.6497  -1.2703]: This paper proposes ConvGQR, a generative Query Reformulation framework for conversational search that leverages pre-trained language models (PLMs) for query rewriting and answer generation. It also introduces a knowledge infusion mechanism to optimize both query reformulation and retrieval.", "target": "This paper proposes ConvGQR, a generative Query Reformulation framework for conversational search that leverages pre-trained language models (PLMs) for query rewriting and answer generation. It also introduces a knowledge infusion mechanism to optimize both query reformulation and retrieval.", "example": "Convert the coordinate to text: [-10.6497  -1.2703]:"}
{"text": "Convert the coordinate to text: [ 1.9133 -9.3945]: The authors propose a new challenging task of non-sequential graph script induction, to capture optional and interchangeable steps in procedural planning. Additionally, they propose to use loosely aligned videos of people performing tasks to automate the induction of graph scripts.", "target": "The authors propose a new challenging task of non-sequential graph script induction, to capture optional and interchangeable steps in procedural planning. Additionally, they propose to use loosely aligned videos of people performing tasks to automate the induction of graph scripts.", "example": "Convert the coordinate to text: [ 1.9133 -9.3945]:"}
{"text": "Convert the coordinate to text: [-3.9723 -1.7137]: This paper proposes an alternative approach for document-level multi-event extraction, introducing 'event proxy nodes' representing pseudo-events, and Hausdorff distance minimization. These event proxy nodes can connect with others, encapsulating global information. By minimizing Hausdorff distance, the model is trained directly towards the global optimum.", "target": "This paper proposes an alternative approach for document-level multi-event extraction, introducing 'event proxy nodes' representing pseudo-events, and Hausdorff distance minimization. These event proxy nodes can connect with others, encapsulating global information. By minimizing Hausdorff distance, the model is trained directly towards the global optimum.", "example": "Convert the coordinate to text: [-3.9723 -1.7137]:"}
{"text": "Convert the coordinate to text: [-3.5    -3.8305]: The authors propose automating the assignment of labels to numeral spans in a sentence through the task of Financial Numeric Extreme Labelling (FNXL).", "target": "The authors propose automating the assignment of labels to numeral spans in a sentence through the task of Financial Numeric Extreme Labelling (FNXL).", "example": "Convert the coordinate to text: [-3.5    -3.8305]:"}
{"text": "Convert the coordinate to text: [-3.42    1.7383]: The authors propose a statistical model for text generation evaluation that accounts for the error-proneness of automated metrics when used to generate preference rankings between system outputs and efficiently combines human and automated ratings.", "target": "The authors propose a statistical model for text generation evaluation that accounts for the error-proneness of automated metrics when used to generate preference rankings between system outputs and efficiently combines human and automated ratings.", "example": "Convert the coordinate to text: [-3.42    1.7383]:"}
{"text": "Convert the coordinate to text: [-9.4077 -6.1939]: This paper purports to explain this tendency through the theory of Dependency Length Minimization, in which shorter dependencies are considered more efficient, and relates it to symmetrical dependency structures of coordination.", "target": "This paper purports to explain this tendency through the theory of Dependency Length Minimization, in which shorter dependencies are considered more efficient, and relates it to symmetrical dependency structures of coordination.", "example": "Convert the coordinate to text: [-9.4077 -6.1939]:"}
{"text": "Convert the coordinate to text: [-1.1318 -5.5768]: The authors propose a method that employs various pretrained VLMs in a zero-shot fashion, coupled with multiple approaches using external knowledge sources for context enrichment.", "target": "The authors propose a method that employs various pretrained VLMs in a zero-shot fashion, coupled with multiple approaches using external knowledge sources for context enrichment.", "example": "Convert the coordinate to text: [-1.1318 -5.5768]:"}
{"text": "Convert the coordinate to text: [ 5.162  -3.4551]: This paper proposes AutoMoE, a new framework for designing heterogeneous MoE models under computational constraints. It leverages Neural Architecture Search (NAS) to create efficient sparse MoE sub-transformers.", "target": "This paper proposes AutoMoE, a new framework for designing heterogeneous MoE models under computational constraints. It leverages Neural Architecture Search (NAS) to create efficient sparse MoE sub-transformers.", "example": "Convert the coordinate to text: [ 5.162  -3.4551]:"}
{"text": "Convert the coordinate to text: [-2.8615  1.7292]: The authors introduce a novel task of predicting earnings surprises from earnings call transcripts and contribute a long document dataset that tests financial understanding with complex signals.", "target": "The authors introduce a novel task of predicting earnings surprises from earnings call transcripts and contribute a long document dataset that tests financial understanding with complex signals.", "example": "Convert the coordinate to text: [-2.8615  1.7292]:"}
{"text": "Convert the coordinate to text: [ 7.0822 -4.2744]: The authors propose to decompose the SSDA framework for emotion-related tasks into two subcomponents: Unsupervised Domain Adaptation (UDA) from the source to the target domain, and Semi-Supervised Learning (SSL) in the target domain, where the two models iteratively teach each other by interchanging their high confidence predictions. They also introduce a novel data cartography-based regularization technique for pseudo-label denoising that employs training dynamics.", "target": "The authors propose to decompose the SSDA framework for emotion-related tasks into two subcomponents: Unsupervised Domain Adaptation (UDA) from the source to the target domain, and Semi-Supervised Learning (SSL) in the target domain, where the two models iteratively teach each other by interchanging their high confidence predictions. They also introduce a novel data cartography-based regularization technique for pseudo-label denoising that employs training dynamics.", "example": "Convert the coordinate to text: [ 7.0822 -4.2744]:"}
{"text": "Convert the coordinate to text: [-10.4604  -1.4163]: The authors present ClarifyDelphi, an interactive system that learns to ask clarification questions in order to elicit additional salient contexts of a social or moral situation, positing that the most informative questions are those whose potential answers lead to diverging moral judgments.", "target": "The authors present ClarifyDelphi, an interactive system that learns to ask clarification questions in order to elicit additional salient contexts of a social or moral situation, positing that the most informative questions are those whose potential answers lead to diverging moral judgments.", "example": "Convert the coordinate to text: [-10.4604  -1.4163]:"}
{"text": "Convert the coordinate to text: [-0.8781 -6.9817]: The authors question if transformer-based language models can efficiently learn to solve RAC problems and propose four essential RAC tasks as a comprehensive textual benchmark to focus on RAC.", "target": "The authors question if transformer-based language models can efficiently learn to solve RAC problems and propose four essential RAC tasks as a comprehensive textual benchmark to focus on RAC.", "example": "Convert the coordinate to text: [-0.8781 -6.9817]:"}
{"text": "Convert the coordinate to text: [ 3.5654 -8.0074]: The authors propose a composite multi-attention (CMA) framework that enables short-term predictions on user-definable IOH events using vital signals in a low sampling rate with demographic characteristics.", "target": "The authors propose a composite multi-attention (CMA) framework that enables short-term predictions on user-definable IOH events using vital signals in a low sampling rate with demographic characteristics.", "example": "Convert the coordinate to text: [ 3.5654 -8.0074]:"}
{"text": "Convert the coordinate to text: [ 1.7073 -9.4919]: The study proposes a new end-to-end model called SeRum (Selective Region Understanding Model) that converts document image understanding and recognition tasks into a local decoding process of visual tokens of interest, using a content-aware token merge module to concentrate on key regions.", "target": "The study proposes a new end-to-end model called SeRum (Selective Region Understanding Model) that converts document image understanding and recognition tasks into a local decoding process of visual tokens of interest, using a content-aware token merge module to concentrate on key regions.", "example": "Convert the coordinate to text: [ 1.7073 -9.4919]:"}
{"text": "Convert the coordinate to text: [  7.5556 -11.5814]: The paper proposes a Box Decouple-Couple(BDC) strategy which decouples corner points of overlapping boxes and couples them according to each corner's score, in order to select the most accurate corner pairs. Accordingly, a novel model named the Anchor-Intermediate Detector(AID) is designed.", "target": "The paper proposes a Box Decouple-Couple(BDC) strategy which decouples corner points of overlapping boxes and couples them according to each corner's score, in order to select the most accurate corner pairs. Accordingly, a novel model named the Anchor-Intermediate Detector(AID) is designed.", "example": "Convert the coordinate to text: [  7.5556 -11.5814]:"}
{"text": "Convert the coordinate to text: [12.0125  3.6025]: The study presents spectral-based matrix estimation approaches for low-rank reinforcement learning, aiming to efficiently recover the singular subspaces of the matrix while maintaining nearly-minimal entry-wise error.", "target": "The study presents spectral-based matrix estimation approaches for low-rank reinforcement learning, aiming to efficiently recover the singular subspaces of the matrix while maintaining nearly-minimal entry-wise error.", "example": "Convert the coordinate to text: [12.0125  3.6025]:"}
{"text": "Convert the coordinate to text: [12.7563  6.3935]: In this study, the authors focus on the role of GD in inducing implicit regularization for tensor optimization, particularly within the context of the lifted matrix sensing framework.", "target": "In this study, the authors focus on the role of GD in inducing implicit regularization for tensor optimization, particularly within the context of the lifted matrix sensing framework.", "example": "Convert the coordinate to text: [12.7563  6.3935]:"}
{"text": "Convert the coordinate to text: [ 4.0781 -0.5551]: The authors aim to investigate the effectiveness of re-sampling and observe that re-sampling can improve generalization when the training images do not contain irrelevant contexts. In certain scenarios, however, it can lead to the learning of spurious correlations between irrelevant contexts and target labels.", "target": "The authors aim to investigate the effectiveness of re-sampling and observe that re-sampling can improve generalization when the training images do not contain irrelevant contexts. In certain scenarios, however, it can lead to the learning of spurious correlations between irrelevant contexts and target labels.", "example": "Convert the coordinate to text: [ 4.0781 -0.5551]:"}
{"text": "Convert the coordinate to text: [ 5.7454 11.3062]: The authors propose a Partially Observable Markov Decision Process (POMDP) formulation with a growing state space for object search in a 3D region, a perception module, and a planning algorithm called GPOMCP, based on online Monte-Carlo tree search and belief tree reuse with a novel upper confidence bound.", "target": "The authors propose a Partially Observable Markov Decision Process (POMDP) formulation with a growing state space for object search in a 3D region, a perception module, and a planning algorithm called GPOMCP, based on online Monte-Carlo tree search and belief tree reuse with a novel upper confidence bound.", "example": "Convert the coordinate to text: [ 5.7454 11.3062]:"}
{"text": "Convert the coordinate to text: [ 1.5421 13.6639]: The authors introduce a new type of strategic behavior called adversarial interaction attack. It occurs when agents returning to the market like schools can manipulate future predictions by making short-term non-optimal interactions with their matches.", "target": "The authors introduce a new type of strategic behavior called adversarial interaction attack. It occurs when agents returning to the market like schools can manipulate future predictions by making short-term non-optimal interactions with their matches.", "example": "Convert the coordinate to text: [ 1.5421 13.6639]:"}
{"text": "Convert the coordinate to text: [-3.6235  4.0244]: The paper introduces two social attribute-aware IGF metrics which aim at ensuring similar user social attributes across the exposed items of different item groups. It also formulates a new multi-objective optimization problem to train recommender models while balancing the trade-off between the direct utility and social utility, and ensuring controllable accuracy.", "target": "The paper introduces two social attribute-aware IGF metrics which aim at ensuring similar user social attributes across the exposed items of different item groups. It also formulates a new multi-objective optimization problem to train recommender models while balancing the trade-off between the direct utility and social utility, and ensuring controllable accuracy.", "example": "Convert the coordinate to text: [-3.6235  4.0244]:"}
{"text": "Convert the coordinate to text: [-4.0279 -7.5911]: The authors propose an effective method for improving neural machine translation via source context enhancement, which plays a crucial role in both retrieving superior examples and determining more suitable interpolation coefficients.", "target": "The authors propose an effective method for improving neural machine translation via source context enhancement, which plays a crucial role in both retrieving superior examples and determining more suitable interpolation coefficients.", "example": "Convert the coordinate to text: [-4.0279 -7.5911]:"}
{"text": "Convert the coordinate to text: [-5.7536 10.2673]: The authors introduce the Harry Potter Dialogue (HPD) dataset to advance the study of dialogue agents and character alignment. The dataset consists of all dialogue sessions from the Harry Potter series in both English and Chinese, annotated with background information like dialogue scenes, speakers, character relationships, and attributes.", "target": "The authors introduce the Harry Potter Dialogue (HPD) dataset to advance the study of dialogue agents and character alignment. The dataset consists of all dialogue sessions from the Harry Potter series in both English and Chinese, annotated with background information like dialogue scenes, speakers, character relationships, and attributes.", "example": "Convert the coordinate to text: [-5.7536 10.2673]:"}
{"text": "Convert the coordinate to text: [ 1.9198 -6.2021]: The authors propose a new method that employs a novel meta-learning strategy to enhance modality-agnostic representations, even when full modality patients' data is partially available. The proposed method enhances partial modality representations to full modality representations by meta-training on partial modality data and meta-testing on limited full modality samples.", "target": "The authors propose a new method that employs a novel meta-learning strategy to enhance modality-agnostic representations, even when full modality patients' data is partially available. The proposed method enhances partial modality representations to full modality representations by meta-training on partial modality data and meta-testing on limited full modality samples.", "example": "Convert the coordinate to text: [ 1.9198 -6.2021]:"}
{"text": "Convert the coordinate to text: [13.3643 -7.2478]: The paper proposes Directed Chain GANs (DC-GANs), an innovative time series generator that inserts a time series dataset (the 'neighborhood process' of the directed chain or input) into the drift and diffusion coefficients of the directed chain SDEs with distributional constraints. The neighborhood process provides the key step in learning and generating multimodal distributed time series.", "target": "The paper proposes Directed Chain GANs (DC-GANs), an innovative time series generator that inserts a time series dataset (the 'neighborhood process' of the directed chain or input) into the drift and diffusion coefficients of the directed chain SDEs with distributional constraints. The neighborhood process provides the key step in learning and generating multimodal distributed time series.", "example": "Convert the coordinate to text: [13.3643 -7.2478]:"}
{"text": "Convert the coordinate to text: [-1.4044  0.0499]: The authors explored several models for classifying sexism, including novel approaches using GloVe embeddings as a baseline, transformer-based models such as BERT, RoBERTa, and DeBERTa, ensemble models, and model blending, coupled with data cleaning and augmentation methods.", "target": "The authors explored several models for classifying sexism, including novel approaches using GloVe embeddings as a baseline, transformer-based models such as BERT, RoBERTa, and DeBERTa, ensemble models, and model blending, coupled with data cleaning and augmentation methods.", "example": "Convert the coordinate to text: [-1.4044  0.0499]:"}
{"text": "Convert the coordinate to text: [-1.0763  0.3389]: The paper hypothesizes and demonstrates that gender bias affects human naming choices for people engaged in sports, with speakers more often using names indicating the sport when it is a man or a boy than when it is a woman or a girl.", "target": "The paper hypothesizes and demonstrates that gender bias affects human naming choices for people engaged in sports, with speakers more often using names indicating the sport when it is a man or a boy than when it is a woman or a girl.", "example": "Convert the coordinate to text: [-1.0763  0.3389]:"}
{"text": "Convert the coordinate to text: [ -4.9799 -10.985 ]: The authors propose ActiveAED, an AED method that enhances error detection accuracy by repeatedly querying a human for error corrections within its prediction loop.", "target": "The authors propose ActiveAED, an AED method that enhances error detection accuracy by repeatedly querying a human for error corrections within its prediction loop.", "example": "Convert the coordinate to text: [ -4.9799 -10.985 ]:"}
{"text": "Convert the coordinate to text: [-4.0182  4.9056]: The authors propose a solution modelled as a directed graph, studying the problem of reducing the exposure to harmful content via edge rewiring instead of blocking harmful content outright.", "target": "The authors propose a solution modelled as a directed graph, studying the problem of reducing the exposure to harmful content via edge rewiring instead of blocking harmful content outright.", "example": "Convert the coordinate to text: [-4.0182  4.9056]:"}
{"text": "Convert the coordinate to text: [-1.5785 -3.6667]: The authors propose KnowledgeDA, a service aimed at enhancing the task-specific training procedure with domain knowledge graphs, in order to generate a domain-specific language model given task-specific texts as input.", "target": "The authors propose KnowledgeDA, a service aimed at enhancing the task-specific training procedure with domain knowledge graphs, in order to generate a domain-specific language model given task-specific texts as input.", "example": "Convert the coordinate to text: [-1.5785 -3.6667]:"}
{"text": "Convert the coordinate to text: [-8.0383 -8.1091]: The study examines the sensitivity of machine translation systems and their evaluation metrics to punctuation, specifically the insertion and deletion of sentence-final punctuation marks such as full stops, exclamation marks, and question marks.", "target": "The study examines the sensitivity of machine translation systems and their evaluation metrics to punctuation, specifically the insertion and deletion of sentence-final punctuation marks such as full stops, exclamation marks, and question marks.", "example": "Convert the coordinate to text: [-8.0383 -8.1091]:"}
{"text": "Convert the coordinate to text: [-2.6648 -6.8372]: The paper details the systems and approaches of the Arizonans team and their use of a fine-tuned Multilingual RoBERTa model trained with about 200M tweets, XLM-T.", "target": "The paper details the systems and approaches of the Arizonans team and their use of a fine-tuned Multilingual RoBERTa model trained with about 200M tweets, XLM-T.", "example": "Convert the coordinate to text: [-2.6648 -6.8372]:"}
{"text": "Convert the coordinate to text: [-1.5326  0.1743]: The authors describe their work on SemEval-2023 Task 10, where they experimented with and compared several approaches for sexist language detection.", "target": "The authors describe their work on SemEval-2023 Task 10, where they experimented with and compared several approaches for sexist language detection.", "example": "Convert the coordinate to text: [-1.5326  0.1743]:"}
{"text": "Convert the coordinate to text: [-1.6756  0.1065]: The SINAI team proposes a system for these three subtasks that integratively leverages information related to emotions, sentiments, and irony to enhance the detection of sexist content.", "target": "The SINAI team proposes a system for these three subtasks that integratively leverages information related to emotions, sentiments, and irony to enhance the detection of sexist content.", "example": "Convert the coordinate to text: [-1.6756  0.1065]:"}
{"text": "Convert the coordinate to text: [-10.7421  -1.8524]: The authors created a new question answering benchmark database for Hungarian called MILQA, introducing a number of innovations beyond SQuAD such as yes/no-questions, list-like answers, long answers, questions requiring calculation and others that cannot simply be copied from the text.", "target": "The authors created a new question answering benchmark database for Hungarian called MILQA, introducing a number of innovations beyond SQuAD such as yes/no-questions, list-like answers, long answers, questions requiring calculation and others that cannot simply be copied from the text.", "example": "Convert the coordinate to text: [-10.7421  -1.8524]:"}
{"text": "Convert the coordinate to text: [ 7.2963 -2.4909]: The authors propose Client-Customized Adaptation (C2A), a hypernetwork-based FL framework that generates client-specific adapters by conditioning the client information, to address the heterogeneity among clients in FL.", "target": "The authors propose Client-Customized Adaptation (C2A), a hypernetwork-based FL framework that generates client-specific adapters by conditioning the client information, to address the heterogeneity among clients in FL.", "example": "Convert the coordinate to text: [ 7.2963 -2.4909]:"}
{"text": "Convert the coordinate to text: [ 2.0576 -4.0316]: The authors design a new N-way-K-shot Continual Relation Extraction (NK-CRE) learning task. They propose a novel few-shot continual relation extraction method with Consistent Prototype Learning (ConPL) to mitigate issues of overfitting and confusion of similar classes.", "target": "The authors design a new N-way-K-shot Continual Relation Extraction (NK-CRE) learning task. They propose a novel few-shot continual relation extraction method with Consistent Prototype Learning (ConPL) to mitigate issues of overfitting and confusion of similar classes.", "example": "Convert the coordinate to text: [ 2.0576 -4.0316]:"}
{"text": "Convert the coordinate to text: [  0.1287 -17.6182]: The key idea is to develop a robust multi-bit watermarking framework for natural language content. This model embeds adequate bits of information and extracts the watermarks despite possible corruption. The authors identify invariant features in natural language that resist minor corruption, akin to image watermarking principles.", "target": "The key idea is to develop a robust multi-bit watermarking framework for natural language content. This model embeds adequate bits of information and extracts the watermarks despite possible corruption. The authors identify invariant features in natural language that resist minor corruption, akin to image watermarking principles.", "example": "Convert the coordinate to text: [  0.1287 -17.6182]:"}
{"text": "Convert the coordinate to text: [ 2.2696 12.5272]: The authors propose a new representation, the Team Belief DAG (TB-DAG), which describes team strategies as a convex set, providing new complexity results on computing optimal strategies for teams.", "target": "The authors propose a new representation, the Team Belief DAG (TB-DAG), which describes team strategies as a convex set, providing new complexity results on computing optimal strategies for teams.", "example": "Convert the coordinate to text: [ 2.2696 12.5272]:"}
{"text": "Convert the coordinate to text: [ 1.2465 -4.0801]: This work proposes a novel approach to handling the aforementioned problems by leveraging a lightweight Bayesian method and incorporating off-the-shelf zero-shot predictors built on large-scale pre-trained models. This is a more principled approach to data selection that doesn't require clean holdout data.", "target": "This work proposes a novel approach to handling the aforementioned problems by leveraging a lightweight Bayesian method and incorporating off-the-shelf zero-shot predictors built on large-scale pre-trained models. This is a more principled approach to data selection that doesn't require clean holdout data.", "example": "Convert the coordinate to text: [ 1.2465 -4.0801]:"}
{"text": "Convert the coordinate to text: [1.3721 0.7323]: The authors propose a method that leverages web search and generative models to improve deficiencies in discriminative models, particularly in addressing weak decision boundaries and population bias.", "target": "The authors propose a method that leverages web search and generative models to improve deficiencies in discriminative models, particularly in addressing weak decision boundaries and population bias.", "example": "Convert the coordinate to text: [1.3721 0.7323]:"}
{"text": "Convert the coordinate to text: [ 7.8992 -3.2941]: The authors propose a new scheme called Order-preserving Consistency Regularization (OCR) that is designed to enhance performance in cross-domain tasks. The idea of this method is to make the model robust to task-irrelevant transformations by enforcing an order-preserving property for its predictions.", "target": "The authors propose a new scheme called Order-preserving Consistency Regularization (OCR) that is designed to enhance performance in cross-domain tasks. The idea of this method is to make the model robust to task-irrelevant transformations by enforcing an order-preserving property for its predictions.", "example": "Convert the coordinate to text: [ 7.8992 -3.2941]:"}
{"text": "Convert the coordinate to text: [ 4.1772 13.7763]: The study introduces RoboCLIP, an online imitation learning method that can use a single video demonstration or a textual task description to generate rewards without manual reward function design, and can utilize out-of-domain demonstrations, like videos of humans, for reward generation.", "target": "The study introduces RoboCLIP, an online imitation learning method that can use a single video demonstration or a textual task description to generate rewards without manual reward function design, and can utilize out-of-domain demonstrations, like videos of humans, for reward generation.", "example": "Convert the coordinate to text: [ 4.1772 13.7763]:"}
{"text": "Convert the coordinate to text: [0.8259 1.6016]: The authors propose the use of counterfactual data augmentation, guided by the knowledge of the causal structure of the data, to simulate interventions on spurious features and to develop robust text classifiers.", "target": "The authors propose the use of counterfactual data augmentation, guided by the knowledge of the causal structure of the data, to simulate interventions on spurious features and to develop robust text classifiers.", "example": "Convert the coordinate to text: [0.8259 1.6016]:"}
{"text": "Convert the coordinate to text: [ 3.6461 -8.0359]: This paper introduces a novel method for ICL, called 'Repeated Demonstration with Sliding Causal Attention (RdSca)'. The method involves duplicating later demonstrations and concatenating them at the start and introduces adjustable causal attention to avoid information leakage.", "target": "This paper introduces a novel method for ICL, called 'Repeated Demonstration with Sliding Causal Attention (RdSca)'. The method involves duplicating later demonstrations and concatenating them at the start and introduces adjustable causal attention to avoid information leakage.", "example": "Convert the coordinate to text: [ 3.6461 -8.0359]:"}
{"text": "Convert the coordinate to text: [ 1.1973 -7.509 ]: The authors propose a novel architecture called Energy Transformer (ET), that utilizes a sequence of attention layers specifically designed to minimize an engineered energy function which is responsible for representing relationships between tokens.", "target": "The authors propose a novel architecture called Energy Transformer (ET), that utilizes a sequence of attention layers specifically designed to minimize an engineered energy function which is responsible for representing relationships between tokens.", "example": "Convert the coordinate to text: [ 1.1973 -7.509 ]:"}
{"text": "Convert the coordinate to text: [12.6405 -4.9644]: The authors propose a positive mining method for targeted adversarial attack to generate effective adversaries for adversarial SSL frameworks. Specifically, an algorithm is introduced that selects the most confusing yet similar target example for a given instance based on entropy and similarity, and then perturbs the given instance towards the selected target.", "target": "The authors propose a positive mining method for targeted adversarial attack to generate effective adversaries for adversarial SSL frameworks. Specifically, an algorithm is introduced that selects the most confusing yet similar target example for a given instance based on entropy and similarity, and then perturbs the given instance towards the selected target.", "example": "Convert the coordinate to text: [12.6405 -4.9644]:"}
{"text": "Convert the coordinate to text: [3.2117 1.915 ]: The authors propose an auxiliary feature perturbation stream to supplement the weak-to-strong consistency framework and present a dual-stream perturbation technique, together forming a unified Dual-Stream Perturbations approach (UniMatch).", "target": "The authors propose an auxiliary feature perturbation stream to supplement the weak-to-strong consistency framework and present a dual-stream perturbation technique, together forming a unified Dual-Stream Perturbations approach (UniMatch).", "example": "Convert the coordinate to text: [3.2117 1.915 ]:"}
{"text": "Convert the coordinate to text: [ 7.5872 -2.101 ]: The authors investigate whether increased personalization could improve robustness against backdoor attacks in personalization of Federated Learning (pFL) context. They also propose a defense method named Simple-Tuning.", "target": "The authors investigate whether increased personalization could improve robustness against backdoor attacks in personalization of Federated Learning (pFL) context. They also propose a defense method named Simple-Tuning.", "example": "Convert the coordinate to text: [ 7.5872 -2.101 ]:"}
{"text": "Convert the coordinate to text: [ 7.6928 -4.0782]: The authors propose an Imperceptible DocumEnt Manipulation (IDEM) framework, a system for producing adversarial documents that are difficult for both algorithms and humans to notice. IDEM relies on generating connection sentences without introducing recognizable errors and handling balanced relevance and coherence in merged text.", "target": "The authors propose an Imperceptible DocumEnt Manipulation (IDEM) framework, a system for producing adversarial documents that are difficult for both algorithms and humans to notice. IDEM relies on generating connection sentences without introducing recognizable errors and handling balanced relevance and coherence in merged text.", "example": "Convert the coordinate to text: [ 7.6928 -4.0782]:"}
{"text": "Convert the coordinate to text: [-13.8832  16.862 ]: The study proposes a solution of cursor warping to the left and right sides of the notch in order to decrease the movement time caused by the notch.", "target": "The study proposes a solution of cursor warping to the left and right sides of the notch in order to decrease the movement time caused by the notch.", "example": "Convert the coordinate to text: [-13.8832  16.862 ]:"}
{"text": "Convert the coordinate to text: [-3.3825 -3.2094]: This paper introduces intermediate pre-training specifically for RE, taking advantage of the affinity between syntactic structure and semantic RE. The authors identify the syntactic relations which are on the shortest dependency path between two entities that are closely related to RE.", "target": "This paper introduces intermediate pre-training specifically for RE, taking advantage of the affinity between syntactic structure and semantic RE. The authors identify the syntactic relations which are on the shortest dependency path between two entities that are closely related to RE.", "example": "Convert the coordinate to text: [-3.3825 -3.2094]:"}
{"text": "Convert the coordinate to text: [ 6.8812 -0.241 ]: The authors find that the softmax layer sometimes prevents LMs from predicting the desired distribution, and propose several softmax alternatives by simplifying pointer networks and accelerating word-by-word rerankers.", "target": "The authors find that the softmax layer sometimes prevents LMs from predicting the desired distribution, and propose several softmax alternatives by simplifying pointer networks and accelerating word-by-word rerankers.", "example": "Convert the coordinate to text: [ 6.8812 -0.241 ]:"}
{"text": "Convert the coordinate to text: [ 4.3463 -1.7898]: The authors propose a Robust Short Text Clustering (RSTC) model which includes two modules: a pseudo-label generation module and a robust representation learning module. The paper introduces self-adaptive optimal transport to counterbalance data imbalance and class-wise and instance-wise contrastive learning to enhance resistance to data noise.", "target": "The authors propose a Robust Short Text Clustering (RSTC) model which includes two modules: a pseudo-label generation module and a robust representation learning module. The paper introduces self-adaptive optimal transport to counterbalance data imbalance and class-wise and instance-wise contrastive learning to enhance resistance to data noise.", "example": "Convert the coordinate to text: [ 4.3463 -1.7898]:"}
{"text": "Convert the coordinate to text: [-3.6094 -7.5024]: This study proposes a method to handle the script normalization problem for under-resourced languages written in a different script in bilingual communities, using synthetic data with various noise levels and a transformer-based model.", "target": "This study proposes a method to handle the script normalization problem for under-resourced languages written in a different script in bilingual communities, using synthetic data with various noise levels and a transformer-based model.", "example": "Convert the coordinate to text: [-3.6094 -7.5024]:"}
{"text": "Convert the coordinate to text: [-2.579   0.3127]: The authors provide GOTHate, a large-scale, neutrally-seeded, code-mixed, and crowd-sourced dataset for detecting hate speech that includes diverse languages and topics. They also propose a solution, HEN-mBERT, which enriches the linguistic subspace with latent endogenous signals from history, topology, and exemplars.", "target": "The authors provide GOTHate, a large-scale, neutrally-seeded, code-mixed, and crowd-sourced dataset for detecting hate speech that includes diverse languages and topics. They also propose a solution, HEN-mBERT, which enriches the linguistic subspace with latent endogenous signals from history, topology, and exemplars.", "example": "Convert the coordinate to text: [-2.579   0.3127]:"}
{"text": "Convert the coordinate to text: [-5.0886  1.4659]: The paper presents three approaches to model the controversiality of a text by explicitly representing annotators, combining their judgments in a pairwise fashion, and comparing their responses to a static document representation.", "target": "The paper presents three approaches to model the controversiality of a text by explicitly representing annotators, combining their judgments in a pairwise fashion, and comparing their responses to a static document representation.", "example": "Convert the coordinate to text: [-5.0886  1.4659]:"}
{"text": "Convert the coordinate to text: [11.2223 -6.2425]: The study proposes to combine the advantages of GANs and diffusion models, resulting in two models: FastDiff 2 (DiffGAN), a diffusion model with a denoising process parameterized by conditional GANs, and FastDiff 2 (GANDiff), a generative adversarial network constructed with multiple denoising diffusion iterations for better sample diversity.", "target": "The study proposes to combine the advantages of GANs and diffusion models, resulting in two models: FastDiff 2 (DiffGAN), a diffusion model with a denoising process parameterized by conditional GANs, and FastDiff 2 (GANDiff), a generative adversarial network constructed with multiple denoising diffusion iterations for better sample diversity.", "example": "Convert the coordinate to text: [11.2223 -6.2425]:"}
{"text": "Convert the coordinate to text: [-10.7329  -1.8886]: This paper introduces PragmatiCQA, a large-scale, open-domain QA dataset that aims to explore the concept of pragmatic reasoning in a diverse range of conversation topics.", "target": "This paper introduces PragmatiCQA, a large-scale, open-domain QA dataset that aims to explore the concept of pragmatic reasoning in a diverse range of conversation topics.", "example": "Convert the coordinate to text: [-10.7329  -1.8886]:"}
{"text": "Convert the coordinate to text: [-2.0005 -8.9119]: The authors propose a simple unified cross-modal ST method that concatenates speech and text as the input, and constructs a teacher model that can utilize both cross-modal information simultaneously.", "target": "The authors propose a simple unified cross-modal ST method that concatenates speech and text as the input, and constructs a teacher model that can utilize both cross-modal information simultaneously.", "example": "Convert the coordinate to text: [-2.0005 -8.9119]:"}
{"text": "Convert the coordinate to text: [-10.7517  -1.6423]: The authors propose the Inner Table Retriever (ITR), a method to handle long tables in TableQA by extracting the most relevant sub-tables for a given question.", "target": "The authors propose the Inner Table Retriever (ITR), a method to handle long tables in TableQA by extracting the most relevant sub-tables for a given question.", "example": "Convert the coordinate to text: [-10.7517  -1.6423]:"}
{"text": "Convert the coordinate to text: [11.0559 -9.5862]: The authors propose a simple image inpainting baseline called Mobile Inpainting GAN (MI-GAN) that is about an order of magnitude computationally smaller and cheaper than previous methods, making it efficient for mobile devices.", "target": "The authors propose a simple image inpainting baseline called Mobile Inpainting GAN (MI-GAN) that is about an order of magnitude computationally smaller and cheaper than previous methods, making it efficient for mobile devices.", "example": "Convert the coordinate to text: [11.0559 -9.5862]:"}
{"text": "Convert the coordinate to text: [  6.4548 -20.7183]: The researchers propose a novel neural approach for image harmonization that operates in a camera-independent color space. The approach utilizes the fact image colors are essentially the camera ISP projection of the scene radiance.", "target": "The researchers propose a novel neural approach for image harmonization that operates in a camera-independent color space. The approach utilizes the fact image colors are essentially the camera ISP projection of the scene radiance.", "example": "Convert the coordinate to text: [  6.4548 -20.7183]:"}
{"text": "Convert the coordinate to text: [ 11.1255 -12.5889]: The authors propose a novel Pose-Constrained Latent Diffusion model (PoCoLD) which shifts away from using the skeleton as a sparse pose representation to the use of DensePose that provides richer body structure information.", "target": "The authors propose a novel Pose-Constrained Latent Diffusion model (PoCoLD) which shifts away from using the skeleton as a sparse pose representation to the use of DensePose that provides richer body structure information.", "example": "Convert the coordinate to text: [ 11.1255 -12.5889]:"}
{"text": "Convert the coordinate to text: [12.7271 -1.2607]: The authors propose training neural models to generate a spectrum of discrete representations and control the complexity of these representations via tuning the entropy of the distribution over representations.", "target": "The authors propose training neural models to generate a spectrum of discrete representations and control the complexity of these representations via tuning the entropy of the distribution over representations.", "example": "Convert the coordinate to text: [12.7271 -1.2607]:"}
{"text": "Convert the coordinate to text: [ 2.6397 11.01  ]: The authors propose a method to refine unreliable plans generated by diffusion models by providing refining guidance to error-prone plans. This includes a new metric called restoration gap, which evaluates the quality of individual plans generated by the diffusion model.", "target": "The authors propose a method to refine unreliable plans generated by diffusion models by providing refining guidance to error-prone plans. This includes a new metric called restoration gap, which evaluates the quality of individual plans generated by the diffusion model.", "example": "Convert the coordinate to text: [ 2.6397 11.01  ]:"}
{"text": "Convert the coordinate to text: [ 4.1341 -3.5339]: This paper proposes ZipLM, a novel structured compression approach for LLMs that aims at achieving state-of-the-art accuracy-vs-speedup while meeting a set of target runtime speedups in any given inference environment.", "target": "This paper proposes ZipLM, a novel structured compression approach for LLMs that aims at achieving state-of-the-art accuracy-vs-speedup while meeting a set of target runtime speedups in any given inference environment.", "example": "Convert the coordinate to text: [ 4.1341 -3.5339]:"}
{"text": "Convert the coordinate to text: [ 5.2685 -3.8671]: The authors aim to provide a systematic understanding of the landscape of graph neural networks for knowledge graphs specifically for the task of link prediction, by providing a unifying perspective on diverse models and characterizing their expressivity via the relational Weisfeiler-Leman algorithm.", "target": "The authors aim to provide a systematic understanding of the landscape of graph neural networks for knowledge graphs specifically for the task of link prediction, by providing a unifying perspective on diverse models and characterizing their expressivity via the relational Weisfeiler-Leman algorithm.", "example": "Convert the coordinate to text: [ 5.2685 -3.8671]:"}
{"text": "Convert the coordinate to text: [14.0289 -1.9762]: The authors propose the filter Simulation-Based Inference (SBI) method, a tool for sequentially filtering plasticity rules through an increasingly fine mesh of constraints that can be modified on-the-fly. This allows the inference of entire families of complex and co-active plasticity rules in spiking networks.", "target": "The authors propose the filter Simulation-Based Inference (SBI) method, a tool for sequentially filtering plasticity rules through an increasingly fine mesh of constraints that can be modified on-the-fly. This allows the inference of entire families of complex and co-active plasticity rules in spiking networks.", "example": "Convert the coordinate to text: [14.0289 -1.9762]:"}
{"text": "Convert the coordinate to text: [-1.6657 -4.4056]: The authors propose a framework named KnowEE which explores multi-source multi-type knowledge from large language models (LLMs) by leveraging diverse datasets and then exploits the obtained knowledge for response generation.", "target": "The authors propose a framework named KnowEE which explores multi-source multi-type knowledge from large language models (LLMs) by leveraging diverse datasets and then exploits the obtained knowledge for response generation.", "example": "Convert the coordinate to text: [-1.6657 -4.4056]:"}
{"text": "Convert the coordinate to text: [10.4064 -2.9816]: This paper proposes tackling the issues of VLP compression and OOD robustness simultaneously by searching for sparse and robust subnetworks within a VLP.", "target": "This paper proposes tackling the issues of VLP compression and OOD robustness simultaneously by searching for sparse and robust subnetworks within a VLP.", "example": "Convert the coordinate to text: [10.4064 -2.9816]:"}
{"text": "Convert the coordinate to text: [-2.4654 16.2637]: This paper introduces a preference-aware meta-optimization framework (Meta-Pec) for personalized vehicle energy consumption estimation. This model captures driver preferences from historical trips, predicts driver-specific driving patterns for a given route based on these preferences, and uses a driver-specific meta-optimization scheme for fast model adaptation.", "target": "This paper introduces a preference-aware meta-optimization framework (Meta-Pec) for personalized vehicle energy consumption estimation. This model captures driver preferences from historical trips, predicts driver-specific driving patterns for a given route based on these preferences, and uses a driver-specific meta-optimization scheme for fast model adaptation.", "example": "Convert the coordinate to text: [-2.4654 16.2637]:"}
{"text": "Convert the coordinate to text: [-4.1058  0.8581]: This study executes sentiment analysis using various deep learning and traditional models paired with a vectorizer for data classification and preprocessing, and employs oversampling techniques for managing the issue of imbalanced text data.", "target": "This study executes sentiment analysis using various deep learning and traditional models paired with a vectorizer for data classification and preprocessing, and employs oversampling techniques for managing the issue of imbalanced text data.", "example": "Convert the coordinate to text: [-4.1058  0.8581]:"}
{"text": "Convert the coordinate to text: [-1.8414 -6.4431]: The authors propose two systems. System 1 uses RoBERTa to encode sentences and features obtained from training models for two auxiliary tasks. System 2 combines RoBERTa with topic modeling to generate sentence representation.", "target": "The authors propose two systems. System 1 uses RoBERTa to encode sentences and features obtained from training models for two auxiliary tasks. System 2 combines RoBERTa with topic modeling to generate sentence representation.", "example": "Convert the coordinate to text: [-1.8414 -6.4431]:"}
{"text": "Convert the coordinate to text: [ 3.9895 -1.1715]: The authors propose a semi-supervised text classifier that mitigates the issues related to self-training with neural networks by reshaping the role of pseudo-labels using a hierarchical order of information and replacing the plain confidence measurement with a hybrid metric that includes prediction uncertainty through a subsampling technique.", "target": "The authors propose a semi-supervised text classifier that mitigates the issues related to self-training with neural networks by reshaping the role of pseudo-labels using a hierarchical order of information and replacing the plain confidence measurement with a hybrid metric that includes prediction uncertainty through a subsampling technique.", "example": "Convert the coordinate to text: [ 3.9895 -1.1715]:"}
{"text": "Convert the coordinate to text: [-6.122  -4.1481]: The authors propose a new method to test the understanding of the hypernymy relationship by measuring its antisymmetry according to the models and extend this method to test the understanding of logical words that encode an entailment-like relation.", "target": "The authors propose a new method to test the understanding of the hypernymy relationship by measuring its antisymmetry according to the models and extend this method to test the understanding of logical words that encode an entailment-like relation.", "example": "Convert the coordinate to text: [-6.122  -4.1481]:"}
{"text": "Convert the coordinate to text: [-7.7697 -1.5003]: The paper proposes a natural language processing pipeline that identifies, extracts, and links RI used in scientific publications, thereby creating associations between the scientific equipment and the published research.", "target": "The paper proposes a natural language processing pipeline that identifies, extracts, and links RI used in scientific publications, thereby creating associations between the scientific equipment and the published research.", "example": "Convert the coordinate to text: [-7.7697 -1.5003]:"}
{"text": "Convert the coordinate to text: [-3.5753 -3.7762]: The authors propose a two-step approach to NER, Split-NER, which divides the task into two logical subtasks: Span Detection for extracting entity mention spans and Span Classification for assigning these spans to their respective entity types. These sub-tasks are formulated as question-answering problems.", "target": "The authors propose a two-step approach to NER, Split-NER, which divides the task into two logical subtasks: Span Detection for extracting entity mention spans and Span Classification for assigning these spans to their respective entity types. These sub-tasks are formulated as question-answering problems.", "example": "Convert the coordinate to text: [-3.5753 -3.7762]:"}
{"text": "Convert the coordinate to text: [ 3.7581 -3.9219]: In this work, the authors propose a method called continual knowledge distillation, which sequentially transfers knowledge from each trained model to a single distilled model in order to improve it.", "target": "In this work, the authors propose a method called continual knowledge distillation, which sequentially transfers knowledge from each trained model to a single distilled model in order to improve it.", "example": "Convert the coordinate to text: [ 3.7581 -3.9219]:"}
{"text": "Convert the coordinate to text: [ -7.822  -10.0397]: This paper presents a novel approach for automatically learning morphophonological rules of Arabic from a corpus, where rules that are memorized for individual items are generalized cautiously only if they are sufficiently reliable in the training data.", "target": "This paper presents a novel approach for automatically learning morphophonological rules of Arabic from a corpus, where rules that are memorized for individual items are generalized cautiously only if they are sufficiently reliable in the training data.", "example": "Convert the coordinate to text: [ -7.822  -10.0397]:"}
{"text": "Convert the coordinate to text: [ 8.1881 -2.3343]: The authors propose a novel method that explores the interaction between local and global latent configurations to adjust the reconstruction and embedding clustering tasks. They also introduce a topological and probabilistic filter to mitigate Feature Randomness and a cell-cell graph structure and content correction mechanism to counteract Feature Drift.", "target": "The authors propose a novel method that explores the interaction between local and global latent configurations to adjust the reconstruction and embedding clustering tasks. They also introduce a topological and probabilistic filter to mitigate Feature Randomness and a cell-cell graph structure and content correction mechanism to counteract Feature Drift.", "example": "Convert the coordinate to text: [ 8.1881 -2.3343]:"}
{"text": "Convert the coordinate to text: [ 3.9081 -6.416 ]: This paper proposes a novel class-incremental grouping network (CIGN) that can learn category-wise semantic features to achieve continual audio-visual learning. The CIGN uses learnable audio-visual class tokens and audio-visual grouping to aggregate class-aware features.", "target": "This paper proposes a novel class-incremental grouping network (CIGN) that can learn category-wise semantic features to achieve continual audio-visual learning. The CIGN uses learnable audio-visual class tokens and audio-visual grouping to aggregate class-aware features.", "example": "Convert the coordinate to text: [ 3.9081 -6.416 ]:"}
{"text": "Convert the coordinate to text: [-3.1587 -6.7608]: The authors propose UReader, an approach for universal OCR-free, visually-situated language understanding using a Multimodal Large Language Model (MLLM), which leverages the shallow text recognition ability of the MLLM and only requires finetuning of 1.2% parameters, reducing training cost.", "target": "The authors propose UReader, an approach for universal OCR-free, visually-situated language understanding using a Multimodal Large Language Model (MLLM), which leverages the shallow text recognition ability of the MLLM and only requires finetuning of 1.2% parameters, reducing training cost.", "example": "Convert the coordinate to text: [-3.1587 -6.7608]:"}
{"text": "Convert the coordinate to text: [ 9.7837 12.0807]: This paper presents BanditPAM++, an accelerated version of BanditPAM that leverages the special structure of BanditPAM to reuse clustering information both within and across iterations, speeding up computations.", "target": "This paper presents BanditPAM++, an accelerated version of BanditPAM that leverages the special structure of BanditPAM to reuse clustering information both within and across iterations, speeding up computations.", "example": "Convert the coordinate to text: [ 9.7837 12.0807]:"}
{"text": "Convert the coordinate to text: [ 2.7027 -8.5806]: The authors aim to address this gap by proposing a calibration mechanism for detection transformers (Cal-DETR), specifically for Deformable-DETR, UP-DETR and DINO, introducing an approach for quantifying uncertainty in transformer-based object detectors, an uncertainty-guided logit modulation mechanism, and a logit mixing approach.", "target": "The authors aim to address this gap by proposing a calibration mechanism for detection transformers (Cal-DETR), specifically for Deformable-DETR, UP-DETR and DINO, introducing an approach for quantifying uncertainty in transformer-based object detectors, an uncertainty-guided logit modulation mechanism, and a logit mixing approach.", "example": "Convert the coordinate to text: [ 2.7027 -8.5806]:"}
{"text": "Convert the coordinate to text: [ -0.8209 -12.4295]: The authors propose Cross-Scale MAE, a self-supervised model built upon the Masked Auto-Encoder (MAE), for remote sensing image understanding. The model employs scale augmentation techniques and enforces cross-scale consistency constraints during pre-training.", "target": "The authors propose Cross-Scale MAE, a self-supervised model built upon the Masked Auto-Encoder (MAE), for remote sensing image understanding. The model employs scale augmentation techniques and enforces cross-scale consistency constraints during pre-training.", "example": "Convert the coordinate to text: [ -0.8209 -12.4295]:"}
{"text": "Convert the coordinate to text: [4.946  0.9356]: The authors introduce STAR, a system that stores a compact prototype and necessary statistical data for each past class to align the class distribution of single-step training samples with that of the complete dataset, addressing the overrepresentation issue in CISS.", "target": "The authors introduce STAR, a system that stores a compact prototype and necessary statistical data for each past class to align the class distribution of single-step training samples with that of the complete dataset, addressing the overrepresentation issue in CISS.", "example": "Convert the coordinate to text: [4.946  0.9356]:"}
{"text": "Convert the coordinate to text: [-3.2023 -4.3066]: The authors aim to understand the robustness of LLM in-context learning with respect to named entity replacements, exploring how model accuracy varies based on the choice of named entities within given datasets.", "target": "The authors aim to understand the robustness of LLM in-context learning with respect to named entity replacements, exploring how model accuracy varies based on the choice of named entities within given datasets.", "example": "Convert the coordinate to text: [-3.2023 -4.3066]:"}
{"text": "Convert the coordinate to text: [ 4.0584 -8.7405]: The paper proposes an efficient method to ablate concepts in the pretrained model, i.e., preventing the generation of a target concept. The algorithm learns to match the image distribution for a target style, instance, or text prompt we wish to ablate to the distribution corresponding to an anchor concept.", "target": "The paper proposes an efficient method to ablate concepts in the pretrained model, i.e., preventing the generation of a target concept. The algorithm learns to match the image distribution for a target style, instance, or text prompt we wish to ablate to the distribution corresponding to an anchor concept.", "example": "Convert the coordinate to text: [ 4.0584 -8.7405]:"}
{"text": "Convert the coordinate to text: [-9.9903  9.1058]: The authors propose designing a persuasive game to improve user awareness about smartphone security and privacy that is tailored to the user\u2019s motivational orientation using Regulatory Focus Theory.", "target": "The authors propose designing a persuasive game to improve user awareness about smartphone security and privacy that is tailored to the user\u2019s motivational orientation using Regulatory Focus Theory.", "example": "Convert the coordinate to text: [-9.9903  9.1058]:"}
{"text": "Convert the coordinate to text: [-3.3567 -6.6993]: The team introduced an approach to provide insight into how a multilingual large language model can be a resource for sentiment analysis in languages not seen during pretraining.", "target": "The team introduced an approach to provide insight into how a multilingual large language model can be a resource for sentiment analysis in languages not seen during pretraining.", "example": "Convert the coordinate to text: [-3.3567 -6.6993]:"}
{"text": "Convert the coordinate to text: [10.405  -3.9686]: The study proposes PruMUX, a method that combines structured pruning and data multiplexing to compound the speedup gains, and Auto-PruMUX, a meta-level model that predicts high-performance parameters for pruning and multiplexing given a desired accuracy loss budget.", "target": "The study proposes PruMUX, a method that combines structured pruning and data multiplexing to compound the speedup gains, and Auto-PruMUX, a meta-level model that predicts high-performance parameters for pruning and multiplexing given a desired accuracy loss budget.", "example": "Convert the coordinate to text: [10.405  -3.9686]:"}
{"text": "Convert the coordinate to text: [ 1.2107 -4.3673]: The authors propose learning with MixCE, an objective that combines the forward and reverse cross-entropies to better reflect how a human would evaluate text generated by a model.", "target": "The authors propose learning with MixCE, an objective that combines the forward and reverse cross-entropies to better reflect how a human would evaluate text generated by a model.", "example": "Convert the coordinate to text: [ 1.2107 -4.3673]:"}
{"text": "Convert the coordinate to text: [ 1.0996 -9.7277]: The authors propose a novel language model guided captioning approach, LAMOC. This approach generates captions for visual content to serve as context to a pre-trained Language Model (PLM) for answer prediction, and further leverages feedback from the PLM to improve the captioning model's task awareness and information needs.", "target": "The authors propose a novel language model guided captioning approach, LAMOC. This approach generates captions for visual content to serve as context to a pre-trained Language Model (PLM) for answer prediction, and further leverages feedback from the PLM to improve the captioning model's task awareness and information needs.", "example": "Convert the coordinate to text: [ 1.0996 -9.7277]:"}
{"text": "Convert the coordinate to text: [-6.1294 -9.7414]: The authors propose a byte-level encoding model for the task of GEC, and they suggest initial training on synthetic corpora followed by finetuning on a relatively small parallel corpus of real-world errors.", "target": "The authors propose a byte-level encoding model for the task of GEC, and they suggest initial training on synthetic corpora followed by finetuning on a relatively small parallel corpus of real-world errors.", "example": "Convert the coordinate to text: [-6.1294 -9.7414]:"}
{"text": "Convert the coordinate to text: [ -0.3713 -10.6004]: The authors propose a new VQA pipeline called RASO that adopts a generate-then-select strategy for answers; it first uses a PLM to generate all possible answers, and then trains a lightweight model to select the correct answer.", "target": "The authors propose a new VQA pipeline called RASO that adopts a generate-then-select strategy for answers; it first uses a PLM to generate all possible answers, and then trains a lightweight model to select the correct answer.", "example": "Convert the coordinate to text: [ -0.3713 -10.6004]:"}
{"text": "Convert the coordinate to text: [2.1775 1.6889]: The authors propose AnoFusion, an unsupervised instance failure detection approach that leverages multimodal data in microservice systems. The aim is to proactively detect instance failures and address the shortcomings of single-modal data-based methods.", "target": "The authors propose AnoFusion, an unsupervised instance failure detection approach that leverages multimodal data in microservice systems. The aim is to proactively detect instance failures and address the shortcomings of single-modal data-based methods.", "example": "Convert the coordinate to text: [2.1775 1.6889]:"}
{"text": "Convert the coordinate to text: [ 2.0242 -5.6775]: The paper proposes DynEformer, an end-to-end framework with global pooling and static content awareness, aiming to provide a unified workload prediction scheme for dynamic MT-ECP. The framework uses global application patterns to drive local workload predictions and incorporates static content-aware mechanisms for increased robustness.", "target": "The paper proposes DynEformer, an end-to-end framework with global pooling and static content awareness, aiming to provide a unified workload prediction scheme for dynamic MT-ECP. The framework uses global application patterns to drive local workload predictions and incorporates static content-aware mechanisms for increased robustness.", "example": "Convert the coordinate to text: [ 2.0242 -5.6775]:"}
{"text": "Convert the coordinate to text: [-7.3115  3.9489]: The paper introduces the Hebrew Geo-Location (HeGeL) corpus, a novel dataset comprising literal place descriptions in Hebrew.", "target": "The paper introduces the Hebrew Geo-Location (HeGeL) corpus, a novel dataset comprising literal place descriptions in Hebrew.", "example": "Convert the coordinate to text: [-7.3115  3.9489]:"}
{"text": "Convert the coordinate to text: [-1.3458 -4.9133]: The authors propose 'Ethicist', a method for targeted training data extraction that aims to recover the suffix in the training data given a prefix through loss smoothed soft prompting and calibrated confidence estimation.", "target": "The authors propose 'Ethicist', a method for targeted training data extraction that aims to recover the suffix in the training data given a prefix through loss smoothed soft prompting and calibrated confidence estimation.", "example": "Convert the coordinate to text: [-1.3458 -4.9133]:"}
{"text": "Convert the coordinate to text: [ 1.6489 -4.3044]: The paper proposes a Multi-Objective Joint Learning System (MOJLS) for NER. The MOJLS enhances the representation of entities and improves label predictions through the joint implementation of a set of learning objectives.", "target": "The paper proposes a Multi-Objective Joint Learning System (MOJLS) for NER. The MOJLS enhances the representation of entities and improves label predictions through the joint implementation of a set of learning objectives.", "example": "Convert the coordinate to text: [ 1.6489 -4.3044]:"}
{"text": "Convert the coordinate to text: [-2.6157 -5.6964]: The authors suggest using an instruction-finetuned Large Language Models (LLMs) for the NLI4CT task, particularly focusing on the Flan-T5 model.", "target": "The authors suggest using an instruction-finetuned Large Language Models (LLMs) for the NLI4CT task, particularly focusing on the Flan-T5 model.", "example": "Convert the coordinate to text: [-2.6157 -5.6964]:"}
{"text": "Convert the coordinate to text: [ 1.7181 -4.3641]: The Fine-grained Contrastive Language-Image Learning (FCLL) model is proposed, which learns fine-grained image-text knowledge through a new fine-grained contrastive learning mechanism and enriches the contextual information by establishing relationship between concepts and sentences. Also, a new multimodal-multilingual knowledge base involving ambiguous target words is constructed for visual WSD.", "target": "The Fine-grained Contrastive Language-Image Learning (FCLL) model is proposed, which learns fine-grained image-text knowledge through a new fine-grained contrastive learning mechanism and enriches the contextual information by establishing relationship between concepts and sentences. Also, a new multimodal-multilingual knowledge base involving ambiguous target words is constructed for visual WSD.", "example": "Convert the coordinate to text: [ 1.7181 -4.3641]:"}
{"text": "Convert the coordinate to text: [12.2731 -5.1531]: The authors propose a new white-box approach called layerwise UATs (LUATs) to construct adversarial triggers, which function by perturbing the hidden layers of a network.", "target": "The authors propose a new white-box approach called layerwise UATs (LUATs) to construct adversarial triggers, which function by perturbing the hidden layers of a network.", "example": "Convert the coordinate to text: [12.2731 -5.1531]:"}
{"text": "Convert the coordinate to text: [0.5772 1.4508]: This paper presents a framework Causal Intervention and Counterfactual Reasoning based Debiasing (CCD) for multi-modal fake news detection. CCD utilizes causal intervention to remove the psycholinguistic bias and applies counterfactual reasoning to estimate the direct effect of images, thereby mitigating biases in multi-modal fake news detection.", "target": "This paper presents a framework Causal Intervention and Counterfactual Reasoning based Debiasing (CCD) for multi-modal fake news detection. CCD utilizes causal intervention to remove the psycholinguistic bias and applies counterfactual reasoning to estimate the direct effect of images, thereby mitigating biases in multi-modal fake news detection.", "example": "Convert the coordinate to text: [0.5772 1.4508]:"}
{"text": "Convert the coordinate to text: [4.1029 6.4326]: The authors propose a maximum likelihood solution to this problem, known as CASCADEMLE, which is shown to be a variation of the classical Steiner subgraph problem. This connects a subset of observed infections and deviates in structure from solutions based on the standard Steiner tree objective.", "target": "The authors propose a maximum likelihood solution to this problem, known as CASCADEMLE, which is shown to be a variation of the classical Steiner subgraph problem. This connects a subset of observed infections and deviates in structure from solutions based on the standard Steiner tree objective.", "example": "Convert the coordinate to text: [4.1029 6.4326]:"}
{"text": "Convert the coordinate to text: [ -0.7994 -12.4955]: The authors propose a paradigm for low-light image enhancement that uses customized learnable priors, specifically Masked Autoencoder (MAE)-based illumination and noise priors, to enhance the transparency of the deep unfolding paradigm.", "target": "The authors propose a paradigm for low-light image enhancement that uses customized learnable priors, specifically Masked Autoencoder (MAE)-based illumination and noise priors, to enhance the transparency of the deep unfolding paradigm.", "example": "Convert the coordinate to text: [ -0.7994 -12.4955]:"}
{"text": "Convert the coordinate to text: [  4.8458 -12.1664]: The authors propose a new task, Multi-view Amodal Instance Segmentation (MAIS), and introduce the MUVA dataset, the first Multi-View AIS dataset, taking shopping scenarios as the specific context.", "target": "The authors propose a new task, Multi-view Amodal Instance Segmentation (MAIS), and introduce the MUVA dataset, the first Multi-View AIS dataset, taking shopping scenarios as the specific context.", "example": "Convert the coordinate to text: [  4.8458 -12.1664]:"}
{"text": "Convert the coordinate to text: [ 7.1298 12.0983]: The authors investigate this issue and propose a corruption-robust algorithm for offline RL that accounts for corruption and aims to minimize the suboptimality gap concerning the optimal policy for uncorrupted Markov decision processes (MDPs).", "target": "The authors investigate this issue and propose a corruption-robust algorithm for offline RL that accounts for corruption and aims to minimize the suboptimality gap concerning the optimal policy for uncorrupted Markov decision processes (MDPs).", "example": "Convert the coordinate to text: [ 7.1298 12.0983]:"}
{"text": "Convert the coordinate to text: [10.7887  0.3443]: The authors introduce a framework, called Sparse Parameterization for Epitomic datasEt Distillation (SPEED), that uses dictionary learning and sparse coding to distill essential information from datasets into epitomes. Key features of SPEED include Spatial-Agnostic Epitomic Tokens (SAETs) and Sparse Coding Matrices (SCMs) for efficient feature representation and selection, and a Feature-Recurrent Network (FReeNet) for generating hierarchical features.", "target": "The authors introduce a framework, called Sparse Parameterization for Epitomic datasEt Distillation (SPEED), that uses dictionary learning and sparse coding to distill essential information from datasets into epitomes. Key features of SPEED include Spatial-Agnostic Epitomic Tokens (SAETs) and Sparse Coding Matrices (SCMs) for efficient feature representation and selection, and a Feature-Recurrent Network (FReeNet) for generating hierarchical features.", "example": "Convert the coordinate to text: [10.7887  0.3443]:"}
{"text": "Convert the coordinate to text: [-2.6931  0.5715]: This study explores the disagreement between machine and human moderators on what constitutes offensive speech. It introduces the concepts of a large-scale 'noise audit' and a 'vicarious offense' dataset.", "target": "This study explores the disagreement between machine and human moderators on what constitutes offensive speech. It introduces the concepts of a large-scale 'noise audit' and a 'vicarious offense' dataset.", "example": "Convert the coordinate to text: [-2.6931  0.5715]:"}
{"text": "Convert the coordinate to text: [-0.6356  8.137 ]: The authors propose LogicAttack, a method to evaluate the logical consistency of these NLI models using diverse logical forms of premise and hypothesis.", "target": "The authors propose LogicAttack, a method to evaluate the logical consistency of these NLI models using diverse logical forms of premise and hypothesis.", "example": "Convert the coordinate to text: [-0.6356  8.137 ]:"}
{"text": "Convert the coordinate to text: [ 5.8598 -0.0629]: This study proposes a Joint optimization of Ranking and Calibration abilities (JRC) approach that improves ranking by contrasting the logit value for different labels and constrains the predicted probability to be a function of logit subtraction.", "target": "This study proposes a Joint optimization of Ranking and Calibration abilities (JRC) approach that improves ranking by contrasting the logit value for different labels and constrains the predicted probability to be a function of logit subtraction.", "example": "Convert the coordinate to text: [ 5.8598 -0.0629]:"}
{"text": "Convert the coordinate to text: [ 2.3031 -2.3807]: The authors propose Toolformer, a model that learns to use external tools via APIs in a self-supervised way, requiring nothing more than a handful of demonstrations for each API.", "target": "The authors propose Toolformer, a model that learns to use external tools via APIs in a self-supervised way, requiring nothing more than a handful of demonstrations for each API.", "example": "Convert the coordinate to text: [ 2.3031 -2.3807]:"}
{"text": "Convert the coordinate to text: [-9.4841 10.7002]: The authors aim to understand how students track and make sense of their learning data from non-classroom learning activities and which types of learning data are personally meaningful for them. This study was conducted with the help of 'Timing', a mobile learning tracking application.", "target": "The authors aim to understand how students track and make sense of their learning data from non-classroom learning activities and which types of learning data are personally meaningful for them. This study was conducted with the help of 'Timing', a mobile learning tracking application.", "example": "Convert the coordinate to text: [-9.4841 10.7002]:"}
{"text": "Convert the coordinate to text: [ 1.8941 -4.2972]: The authors propose a novel continual extraction model for analogous relations which are designed with memory-insensitive relation prototypes and memory augmentation to overcome overfitting.", "target": "The authors propose a novel continual extraction model for analogous relations which are designed with memory-insensitive relation prototypes and memory augmentation to overcome overfitting.", "example": "Convert the coordinate to text: [ 1.8941 -4.2972]:"}
{"text": "Convert the coordinate to text: [ 1.818  -6.4938]: The authors propose a new multimodal contrastive learning method which captures task-related unimodal representations and unimodal predictions. The unimodal representations are then aligned by a novel multimodal contrastive learning method under the supervision of these unimodal predictions.", "target": "The authors propose a new multimodal contrastive learning method which captures task-related unimodal representations and unimodal predictions. The unimodal representations are then aligned by a novel multimodal contrastive learning method under the supervision of these unimodal predictions.", "example": "Convert the coordinate to text: [ 1.818  -6.4938]:"}
{"text": "Convert the coordinate to text: [-5.5717 10.1361]: The paper introduces a new dialogue pre-training model, FutureTOD, which uses a self-training framework to transfer the future knowledge to the representation of the previous dialogue context, fulfilling the dual roles of learning local context information and predicting future information.", "target": "The paper introduces a new dialogue pre-training model, FutureTOD, which uses a self-training framework to transfer the future knowledge to the representation of the previous dialogue context, fulfilling the dual roles of learning local context information and predicting future information.", "example": "Convert the coordinate to text: [-5.5717 10.1361]:"}
{"text": "Convert the coordinate to text: [12.1657 -1.5186]: The authors note that the gradient computation of a model is a special case of a generalized formulation using semirings. This understanding allows the backpropagation algorithm to be generalized to efficiently compute other interpretable statistics about the gradient graph of a neural network, such as the highest-weighted path and entropy.", "target": "The authors note that the gradient computation of a model is a special case of a generalized formulation using semirings. This understanding allows the backpropagation algorithm to be generalized to efficiently compute other interpretable statistics about the gradient graph of a neural network, such as the highest-weighted path and entropy.", "example": "Convert the coordinate to text: [12.1657 -1.5186]:"}
{"text": "Convert the coordinate to text: [ 5.2996 -2.8817]: The authors propose a data augmentation technique that generates additional examples using metadata describing labels in the dataset.", "target": "The authors propose a data augmentation technique that generates additional examples using metadata describing labels in the dataset.", "example": "Convert the coordinate to text: [ 5.2996 -2.8817]:"}
{"text": "Convert the coordinate to text: [-1.3623 -6.3185]: The authors proposed the use of an ensemble of weakly supervised question detection and fine-tuned Transformer-based models for subtask 1, and a combination of deep representation learning and a rule-based approach for subtask 2.", "target": "The authors proposed the use of an ensemble of weakly supervised question detection and fine-tuned Transformer-based models for subtask 1, and a combination of deep representation learning and a rule-based approach for subtask 2.", "example": "Convert the coordinate to text: [-1.3623 -6.3185]:"}
{"text": "Convert the coordinate to text: [-5.2039  2.2187]: The authors hypothesize that the usage and contextual appearance of moral adjectives can vary based on the political orientation of a newspaper, particularly in relation to articles on police brutality.", "target": "The authors hypothesize that the usage and contextual appearance of moral adjectives can vary based on the political orientation of a newspaper, particularly in relation to articles on police brutality.", "example": "Convert the coordinate to text: [-5.2039  2.2187]:"}
{"text": "Convert the coordinate to text: [-2.3268 -0.8877]: The paper proposes a scale-invariant infinite hierarchical topic model (ihLDA) to deal with the issue of fragmented topics and overlapping themes. It adaptively adjusts the topic creation to slow down the decay of expected topic probability.", "target": "The paper proposes a scale-invariant infinite hierarchical topic model (ihLDA) to deal with the issue of fragmented topics and overlapping themes. It adaptively adjusts the topic creation to slow down the decay of expected topic probability.", "example": "Convert the coordinate to text: [-2.3268 -0.8877]:"}
{"text": "Convert the coordinate to text: [-6.0625 10.6613]: The authors propose a cloud-based conversational smart compose system which uses heuristics, a decoder-only model and a novel phrase tokenizer. The system is designed to optimize trade-offs between response quality and latency.", "target": "The authors propose a cloud-based conversational smart compose system which uses heuristics, a decoder-only model and a novel phrase tokenizer. The system is designed to optimize trade-offs between response quality and latency.", "example": "Convert the coordinate to text: [-6.0625 10.6613]:"}
{"text": "Convert the coordinate to text: [ 2.3597 -4.6029]: This paper proposes ConFEDE, a learning framework that conducts contrastive representation learning and contrastive feature decomposition to enhance the representation of multimodal information. It decomposes the text, video frames, and audio modalities of a video sample into a similarity feature and a dissimilarity feature.", "target": "This paper proposes ConFEDE, a learning framework that conducts contrastive representation learning and contrastive feature decomposition to enhance the representation of multimodal information. It decomposes the text, video frames, and audio modalities of a video sample into a similarity feature and a dissimilarity feature.", "example": "Convert the coordinate to text: [ 2.3597 -4.6029]:"}
{"text": "Convert the coordinate to text: [-2.1832 -7.408 ]: The authors investigate various masked language modeling (MLM) pretraining techniques for code-switched text that take into account language boundaries before masking, and propose an MLM variant that introduces a residual connection from an earlier layer in the pretrained model, which enhances the performance on downstream tasks.", "target": "The authors investigate various masked language modeling (MLM) pretraining techniques for code-switched text that take into account language boundaries before masking, and propose an MLM variant that introduces a residual connection from an earlier layer in the pretrained model, which enhances the performance on downstream tasks.", "example": "Convert the coordinate to text: [-2.1832 -7.408 ]:"}
{"text": "Convert the coordinate to text: [12.7927 -4.9852]: The authors introduce a novel adversarial purification method for defending against textual adversarial attacks, utilizing language models to inject noise by masking input texts and subsequently reconstructing them based on the masked language models.", "target": "The authors introduce a novel adversarial purification method for defending against textual adversarial attacks, utilizing language models to inject noise by masking input texts and subsequently reconstructing them based on the masked language models.", "example": "Convert the coordinate to text: [12.7927 -4.9852]:"}
{"text": "Convert the coordinate to text: [1.9636 3.2813]: This paper proposes estimating possible causal effects via covariate adjustment given a PAG and provides a new graphical characterization for possible adjustment sets.", "target": "This paper proposes estimating possible causal effects via covariate adjustment given a PAG and provides a new graphical characterization for possible adjustment sets.", "example": "Convert the coordinate to text: [1.9636 3.2813]:"}
{"text": "Convert the coordinate to text: [ 1.2811 -7.4468]: The paper proposes an Adaptive Disentangled Transformer (ADT) framework that can adaptively determine the optimal degree of disentanglement for attention heads within different layers of a Transformer.", "target": "The paper proposes an Adaptive Disentangled Transformer (ADT) framework that can adaptively determine the optimal degree of disentanglement for attention heads within different layers of a Transformer.", "example": "Convert the coordinate to text: [ 1.2811 -7.4468]:"}
{"text": "Convert the coordinate to text: [  6.3866 -12.9764]: A new method called prior-guided expansion framework is proposed to predict occluded parts of an object in amodal instance segmentation. This method builds on a two-stage segmentation model and performs expansion at the box and pixel level by retrieving transformations from memory bank of expansion prior.", "target": "A new method called prior-guided expansion framework is proposed to predict occluded parts of an object in amodal instance segmentation. This method builds on a two-stage segmentation model and performs expansion at the box and pixel level by retrieving transformations from memory bank of expansion prior.", "example": "Convert the coordinate to text: [  6.3866 -12.9764]:"}
{"text": "Convert the coordinate to text: [  4.1478 -12.4122]: The paper proposes a novel scheme called AttrSeg, an attribute decomposition-aggregation framework, which first decomposes class names into diverse attribute descriptions and then groups these attributes into an integrated global description. The design of AttrSeg is inspired by the process of human cognition in understanding new concepts.", "target": "The paper proposes a novel scheme called AttrSeg, an attribute decomposition-aggregation framework, which first decomposes class names into diverse attribute descriptions and then groups these attributes into an integrated global description. The design of AttrSeg is inspired by the process of human cognition in understanding new concepts.", "example": "Convert the coordinate to text: [  4.1478 -12.4122]:"}
{"text": "Convert the coordinate to text: [ 12.7001 -13.8776]: The authors propose DeepSimHO, a novel deep-learning pipeline that combines forward physics simulation and backward gradient approximation with a neural network for the estimation of stable hand-object poses.", "target": "The authors propose DeepSimHO, a novel deep-learning pipeline that combines forward physics simulation and backward gradient approximation with a neural network for the estimation of stable hand-object poses.", "example": "Convert the coordinate to text: [ 12.7001 -13.8776]:"}
{"text": "Convert the coordinate to text: [ 2.4356 -9.9809]: The authors propose a new task called group video captioning, which aims to infer the desired content among a group of target videos and describe it with another group of related reference videos. They also introduce an efficient relational approximation (ERA) to identify shared content among videos and a contextual feature refinery with intra-group self-supervision to capture contextual information and refine the common properties.", "target": "The authors propose a new task called group video captioning, which aims to infer the desired content among a group of target videos and describe it with another group of related reference videos. They also introduce an efficient relational approximation (ERA) to identify shared content among videos and a contextual feature refinery with intra-group self-supervision to capture contextual information and refine the common properties.", "example": "Convert the coordinate to text: [ 2.4356 -9.9809]:"}
{"text": "Convert the coordinate to text: [  9.8885 -21.1513]: The authors propose a low-light video enhancement method using hybrid inputs of events and frames, leveraging the high temporal resolution of event cameras to improve video quality in low-light conditions.", "target": "The authors propose a low-light video enhancement method using hybrid inputs of events and frames, leveraging the high temporal resolution of event cameras to improve video quality in low-light conditions.", "example": "Convert the coordinate to text: [  9.8885 -21.1513]:"}
{"text": "Convert the coordinate to text: [ 7.289  -3.4355]: The paper proposes a different approach to DOV, where watermarked models (trained on the protected dataset) correctly classify some 'hard' samples that would be misclassified by benign models. The method centers around a 'hardly-generalized domain' that can be learned with the protected dataset that contains modified samples.", "target": "The paper proposes a different approach to DOV, where watermarked models (trained on the protected dataset) correctly classify some 'hard' samples that would be misclassified by benign models. The method centers around a 'hardly-generalized domain' that can be learned with the protected dataset that contains modified samples.", "example": "Convert the coordinate to text: [ 7.289  -3.4355]:"}
{"text": "Convert the coordinate to text: [1.3245 2.4293]: The authors theoretically clarified the relationship between SRS predictions and instance reliability and proposed two error-bounded strategies to rectify unreliable targets and input.", "target": "The authors theoretically clarified the relationship between SRS predictions and instance reliability and proposed two error-bounded strategies to rectify unreliable targets and input.", "example": "Convert the coordinate to text: [1.3245 2.4293]:"}
{"text": "Convert the coordinate to text: [-2.7412 -5.285 ]: The authors delve into the abilities of various large language models to convert table data into text using four datasets, two existing and two newly-developed, encompassing two real-world scenarios of information retrieval. They examine how these models perform as generators, evaluators, and feedback providers.", "target": "The authors delve into the abilities of various large language models to convert table data into text using four datasets, two existing and two newly-developed, encompassing two real-world scenarios of information retrieval. They examine how these models perform as generators, evaluators, and feedback providers.", "example": "Convert the coordinate to text: [-2.7412 -5.285 ]:"}
{"text": "Convert the coordinate to text: [ 6.2409 12.357 ]: The authors introduce a novel online learning framework based on deterministic Markov decision processes with dynamic state transition and reward functions to overcome the lack of vanishing regret in the DRACC problem.", "target": "The authors introduce a novel online learning framework based on deterministic Markov decision processes with dynamic state transition and reward functions to overcome the lack of vanishing regret in the DRACC problem.", "example": "Convert the coordinate to text: [ 6.2409 12.357 ]:"}
{"text": "Convert the coordinate to text: [ 1.6351 12.5448]: The authors introduce a novel framework developed in Amazon for continuous monitoring to maximize customer experience and control opportunity cost. The problem is formulated as a Bayesian optimal sequential decision making problem with a unified utility function.", "target": "The authors introduce a novel framework developed in Amazon for continuous monitoring to maximize customer experience and control opportunity cost. The problem is formulated as a Bayesian optimal sequential decision making problem with a unified utility function.", "example": "Convert the coordinate to text: [ 1.6351 12.5448]:"}
{"text": "Convert the coordinate to text: [ 11.7212 -10.4337]: This paper proposes a diffusion-based architecture that unifies two UNets referred to as Parallel-UNet, which enables preservation of garment details and warping the garment for significant pose and body change in a single network.", "target": "This paper proposes a diffusion-based architecture that unifies two UNets referred to as Parallel-UNet, which enables preservation of garment details and warping the garment for significant pose and body change in a single network.", "example": "Convert the coordinate to text: [ 11.7212 -10.4337]:"}
{"text": "Convert the coordinate to text: [-4.5694 -7.9182]: An active learning approach is proposed to balance the strengths of both human and machine translations by iteratively adding small batches of human translations into the machine-translated training set. Novel aggregated acquisition criteria are also proposed for optimal utterance selection.", "target": "An active learning approach is proposed to balance the strengths of both human and machine translations by iteratively adding small batches of human translations into the machine-translated training set. Novel aggregated acquisition criteria are also proposed for optimal utterance selection.", "example": "Convert the coordinate to text: [-4.5694 -7.9182]:"}
{"text": "Convert the coordinate to text: [ 1.2914 -3.9296]: The authors introduce Self-Evolution learning (SE), a token masking and learning method that aims to fully exploit knowledge from data by focusing on under-explored tokens and by adaptively regularizing the training using a novel Token-specific Label Smoothing approach.", "target": "The authors introduce Self-Evolution learning (SE), a token masking and learning method that aims to fully exploit knowledge from data by focusing on under-explored tokens and by adaptively regularizing the training using a novel Token-specific Label Smoothing approach.", "example": "Convert the coordinate to text: [ 1.2914 -3.9296]:"}
{"text": "Convert the coordinate to text: [-10.5564  -1.9485]: The authors introduce NeQA, a dataset consisting of questions with negation in which language models do not exhibit straightforward positive scaling, and hypothesize that solving NeQA depends on two subtasks: question answering and negation understanding.", "target": "The authors introduce NeQA, a dataset consisting of questions with negation in which language models do not exhibit straightforward positive scaling, and hypothesize that solving NeQA depends on two subtasks: question answering and negation understanding.", "example": "Convert the coordinate to text: [-10.5564  -1.9485]:"}
{"text": "Convert the coordinate to text: [-5.873  -4.1929]: The authors propose deriving word significance from models trained on semantic tasks, specifically Natural Language Inference and Paraphrase Identification, using an attribution method designed to explain the predictions of these models.", "target": "The authors propose deriving word significance from models trained on semantic tasks, specifically Natural Language Inference and Paraphrase Identification, using an attribution method designed to explain the predictions of these models.", "example": "Convert the coordinate to text: [-5.873  -4.1929]:"}
{"text": "Convert the coordinate to text: [14.1851  5.1788]: This paper aims to combine the computational efficiency of low-rank solvers and the flexibility of unbalanced variants into a versatile and scalable unbalanced low-rank optimal transport solver.", "target": "This paper aims to combine the computational efficiency of low-rank solvers and the flexibility of unbalanced variants into a versatile and scalable unbalanced low-rank optimal transport solver.", "example": "Convert the coordinate to text: [14.1851  5.1788]:"}
{"text": "Convert the coordinate to text: [-4.5644 -7.461 ]: This work applies the concept of neutralizing the implicit language model to machine translation and compares its performance with back-translation, a popular method for utilizing additional monolingual data.", "target": "This work applies the concept of neutralizing the implicit language model to machine translation and compares its performance with back-translation, a popular method for utilizing additional monolingual data.", "example": "Convert the coordinate to text: [-4.5644 -7.461 ]:"}
{"text": "Convert the coordinate to text: [ -7.6953 -10.1629]: In this work, the authors present AraMUS, the largest Arabic Pre-trained Language Model to date, with 11 billion parameters trained on 529GB of high-quality Arabic textual data.", "target": "In this work, the authors present AraMUS, the largest Arabic Pre-trained Language Model to date, with 11 billion parameters trained on 529GB of high-quality Arabic textual data.", "example": "Convert the coordinate to text: [ -7.6953 -10.1629]:"}
{"text": "Convert the coordinate to text: [-3.2467 -9.8321]: The authors introduce Voicebox, a non-autoregressive flow-matching model designed to infill speech, given any audio context and text, with the aim to be more versatile in text-guided generative model for speech at scale.", "target": "The authors introduce Voicebox, a non-autoregressive flow-matching model designed to infill speech, given any audio context and text, with the aim to be more versatile in text-guided generative model for speech at scale.", "example": "Convert the coordinate to text: [-3.2467 -9.8321]:"}
{"text": "Convert the coordinate to text: [ 6.5192 -4.0306]: The paper proposes Collaborative Cross-Domain Transfer Learning Framework (CCTL). The key idea is to evaluate the information gain of the source domain on the target domain using a symmetric companion network and adjust the information transfer weight of each source domain sample using the information flow network. Additionally, a representation enhancement network is used to preserve domain-specific features.", "target": "The paper proposes Collaborative Cross-Domain Transfer Learning Framework (CCTL). The key idea is to evaluate the information gain of the source domain on the target domain using a symmetric companion network and adjust the information transfer weight of each source domain sample using the information flow network. Additionally, a representation enhancement network is used to preserve domain-specific features.", "example": "Convert the coordinate to text: [ 6.5192 -4.0306]:"}
{"text": "Convert the coordinate to text: [ 2.7413 -6.1387]: The authors propose an Implicit Memory Transformer, a new computational model that implicitly retains memory through a novel left context method. This removes the need for explicit memory representation via memory banks.", "target": "The authors propose an Implicit Memory Transformer, a new computational model that implicitly retains memory through a novel left context method. This removes the need for explicit memory representation via memory banks.", "example": "Convert the coordinate to text: [ 2.7413 -6.1387]:"}
{"text": "Convert the coordinate to text: [ 0.702  -4.4946]: The authors propose self-contrastive training as a solution to repetition problems in pretrained language models. The new method penalizes the output of a premature checkpoint of the same model when it incorrectly predicts repetition.", "target": "The authors propose self-contrastive training as a solution to repetition problems in pretrained language models. The new method penalizes the output of a premature checkpoint of the same model when it incorrectly predicts repetition.", "example": "Convert the coordinate to text: [ 0.702  -4.4946]:"}
{"text": "Convert the coordinate to text: [-11.9236   5.7943]: The authors introduce VisText, a dataset of 12,441 pairs of charts and captions that describe the charts' construction, report key statistics, and identify perceptual and cognitive phenomena. A chart in VisText is available as three representations: a rasterized image, a backing data table, and a scene graph.", "target": "The authors introduce VisText, a dataset of 12,441 pairs of charts and captions that describe the charts' construction, report key statistics, and identify perceptual and cognitive phenomena. A chart in VisText is available as three representations: a rasterized image, a backing data table, and a scene graph.", "example": "Convert the coordinate to text: [-11.9236   5.7943]:"}
{"text": "Convert the coordinate to text: [2.9556 1.4919]: The authors propose that model overconfidence is not the only cause of high-confidence predictions for seemingly nonsensical inputs and suggest that these inputs may contain valid statistical patterns from the utilized dataset.", "target": "The authors propose that model overconfidence is not the only cause of high-confidence predictions for seemingly nonsensical inputs and suggest that these inputs may contain valid statistical patterns from the utilized dataset.", "example": "Convert the coordinate to text: [2.9556 1.4919]:"}
{"text": "Convert the coordinate to text: [-4.4103 -5.188 ]: The authors propose an ensemble-based approach for multilingual framing detection that combines three methods: a classifier based on large language models, a classifier based on static word embeddings, and an approach that uses ConceptNet, an external commonsense knowledge graph.", "target": "The authors propose an ensemble-based approach for multilingual framing detection that combines three methods: a classifier based on large language models, a classifier based on static word embeddings, and an approach that uses ConceptNet, an external commonsense knowledge graph.", "example": "Convert the coordinate to text: [-4.4103 -5.188 ]:"}
{"text": "Convert the coordinate to text: [ 9.3705 -2.415 ]: The authors propose a simple yet elegant input-hint-based MCCWS model and a novel criterion-denoising objective.", "target": "The authors propose a simple yet elegant input-hint-based MCCWS model and a novel criterion-denoising objective.", "example": "Convert the coordinate to text: [ 9.3705 -2.415 ]:"}
{"text": "Convert the coordinate to text: [ 2.2636 -2.1427]: The authors introduce a new problem called curriculum discovery and propose a framework for curriculum learning capable of discovering effective curricula based on prior knowledge about sample difficulty, using annotation entropy and loss as measures of difficulty.", "target": "The authors introduce a new problem called curriculum discovery and propose a framework for curriculum learning capable of discovering effective curricula based on prior knowledge about sample difficulty, using annotation entropy and loss as measures of difficulty.", "example": "Convert the coordinate to text: [ 2.2636 -2.1427]:"}
{"text": "Convert the coordinate to text: [-0.9927 -5.1817]: This paper proposes a learning strategy called \u201cprompt-mapping\u201d to learn about more consistent representations of source and target prompts. In this way, more shared features between the two prompts can be obtained and used to better represent the essays for the target prompt", "target": "This paper proposes a learning strategy called \u201cprompt-mapping\u201d to learn about more consistent representations of source and target prompts. In this way, more shared features between the two prompts can be obtained and used to better represent the essays for the target prompt", "example": "Convert the coordinate to text: [-0.9927 -5.1817]:"}
{"text": "Convert the coordinate to text: [11.5675  0.3954]: The paper introduces DeepPCR, a novel algorithm which interprets a sequence of operations as the solution of a specific system of equations and uses the Parallel Cyclic Reduction algorithm to recover it, thus parallelizing typically sequential operations used in inference and training of neural networks.", "target": "The paper introduces DeepPCR, a novel algorithm which interprets a sequence of operations as the solution of a specific system of equations and uses the Parallel Cyclic Reduction algorithm to recover it, thus parallelizing typically sequential operations used in inference and training of neural networks.", "example": "Convert the coordinate to text: [11.5675  0.3954]:"}
{"text": "Convert the coordinate to text: [  6.1139 -11.4566]: The authors make a pioneering effort to introduce a weakly-supervised benchmark on Video State-Changing Object Segmentation (VSCOS). The VSCOS benchmark is created by selecting state-changing videos from existing datasets, and the annotation procedure differs from conventional VOS by annotating only the first and last frames of training videos.", "target": "The authors make a pioneering effort to introduce a weakly-supervised benchmark on Video State-Changing Object Segmentation (VSCOS). The VSCOS benchmark is created by selecting state-changing videos from existing datasets, and the annotation procedure differs from conventional VOS by annotating only the first and last frames of training videos.", "example": "Convert the coordinate to text: [  6.1139 -11.4566]:"}
{"text": "Convert the coordinate to text: [16.0772  1.8812]: The authors propose a new framework that allows for better categorization of uncertain instances identified by UQ methods. This is accomplished by introducing the concept of a confusion density matrix, a kernel-based approximation of the misclassification density, which categorizes suspicious cases into out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM).", "target": "The authors propose a new framework that allows for better categorization of uncertain instances identified by UQ methods. This is accomplished by introducing the concept of a confusion density matrix, a kernel-based approximation of the misclassification density, which categorizes suspicious cases into out-of-distribution (OOD) examples, boundary (Bnd) examples, and examples in regions of high in-distribution misclassification (IDM).", "example": "Convert the coordinate to text: [16.0772  1.8812]:"}
{"text": "Convert the coordinate to text: [12.8775 -7.5123]: The authors propose a GAN-based LAtent Space Search attack (GLASS), a first-of-its-kind DRA against SI using advanced StyleGAN technologies. In addition, they introduce GLASS++ to enhance reconstruction stability.", "target": "The authors propose a GAN-based LAtent Space Search attack (GLASS), a first-of-its-kind DRA against SI using advanced StyleGAN technologies. In addition, they introduce GLASS++ to enhance reconstruction stability.", "example": "Convert the coordinate to text: [12.8775 -7.5123]:"}
{"text": "Convert the coordinate to text: [11.4267  2.1459]: The authors introduce a novel formulation for dictionary learning that minimizes the determinant of the dictionary matrix, or its volume, while ensuring each row of the sparse coefficient matrix maintains unit $\\ell_1$ norm. This method guarantees global identifiability of the dictionary and sparse coefficient matrices.", "target": "The authors introduce a novel formulation for dictionary learning that minimizes the determinant of the dictionary matrix, or its volume, while ensuring each row of the sparse coefficient matrix maintains unit $\\ell_1$ norm. This method guarantees global identifiability of the dictionary and sparse coefficient matrices.", "example": "Convert the coordinate to text: [11.4267  2.1459]:"}
{"text": "Convert the coordinate to text: [  8.7105 -10.9796]: To address the gap, the authors propose E2PNet, the first learning-based method for event-to-point cloud registration, which encodes event data into a 2D grid-shaped feature tensor through a novel feature representation network named Event-Points-to-Tensor (EP2T).", "target": "To address the gap, the authors propose E2PNet, the first learning-based method for event-to-point cloud registration, which encodes event data into a 2D grid-shaped feature tensor through a novel feature representation network named Event-Points-to-Tensor (EP2T).", "example": "Convert the coordinate to text: [  8.7105 -10.9796]:"}
{"text": "Convert the coordinate to text: [ 0.0188 -7.045 ]: The authors propose to analyze the memory values and attention heads of language models to reveal patterns of information flow inside the transformer mechanism and to use these insights to visualize a forward pass of Generative Pre-trained Transformers (GPTs) as an interactive flow graph.", "target": "The authors propose to analyze the memory values and attention heads of language models to reveal patterns of information flow inside the transformer mechanism and to use these insights to visualize a forward pass of Generative Pre-trained Transformers (GPTs) as an interactive flow graph.", "example": "Convert the coordinate to text: [ 0.0188 -7.045 ]:"}
{"text": "Convert the coordinate to text: [13.133  -7.4392]: The authors propose the Structure-Aware Generative Adversarial Network (SA-GAN) model to capture multiple topological structure information for more accurate BLI. It makes use of two lightweight graph convolutional networks (GCNs) for generating source and target embeddings and uses a GAN model for international mapping. The model also includes a pair-wised local mapping (PLM) strategy for word-specific transformations.", "target": "The authors propose the Structure-Aware Generative Adversarial Network (SA-GAN) model to capture multiple topological structure information for more accurate BLI. It makes use of two lightweight graph convolutional networks (GCNs) for generating source and target embeddings and uses a GAN model for international mapping. The model also includes a pair-wised local mapping (PLM) strategy for word-specific transformations.", "example": "Convert the coordinate to text: [13.133  -7.4392]:"}
{"text": "Convert the coordinate to text: [-2.596  -5.6135]: The authors introduced Pythia, a suite of 16 LLMs ranging in size from 70M to 12B parameters, all trained on public data seen in the exact same order.", "target": "The authors introduced Pythia, a suite of 16 LLMs ranging in size from 70M to 12B parameters, all trained on public data seen in the exact same order.", "example": "Convert the coordinate to text: [-2.596  -5.6135]:"}
{"text": "Convert the coordinate to text: [ 1.7135 -0.7778]: The authors propose a combined approach that uses a multi-task architecture to predict individual annotator perspectives as an interim step towards predicting annotator disagreement.", "target": "The authors propose a combined approach that uses a multi-task architecture to predict individual annotator perspectives as an interim step towards predicting annotator disagreement.", "example": "Convert the coordinate to text: [ 1.7135 -0.7778]:"}
{"text": "Convert the coordinate to text: [-0.7979 -3.5952]: This study proposes the use of new expert-writing Element-aware test sets based on the Lasswell Communication Model for more objective and comprehensive evaluation. The study also introduces a Summary Chain-of-Thought (SumCoT) technique to improve the ability of Large Language Models (LLMs) to generate more detailed summaries step by step.", "target": "This study proposes the use of new expert-writing Element-aware test sets based on the Lasswell Communication Model for more objective and comprehensive evaluation. The study also introduces a Summary Chain-of-Thought (SumCoT) technique to improve the ability of Large Language Models (LLMs) to generate more detailed summaries step by step.", "example": "Convert the coordinate to text: [-0.7979 -3.5952]:"}
{"text": "Convert the coordinate to text: [-12.9224   6.0352]: This study focuses on the translation of mathematical formulae from LaTeX to Mathematica and LaTeX to semantic LaTeX, examining the performance of recurrent, recursive, and transformer networks.", "target": "This study focuses on the translation of mathematical formulae from LaTeX to Mathematica and LaTeX to semantic LaTeX, examining the performance of recurrent, recursive, and transformer networks.", "example": "Convert the coordinate to text: [-12.9224   6.0352]:"}
{"text": "Convert the coordinate to text: [-1.2451 -5.0438]: The authors propose to explore the instance-level prompt and their generalizability. They posit that for every instance, there is a 'lottery prompt' that can induce the correct prediction from the PLM at a low cost.", "target": "The authors propose to explore the instance-level prompt and their generalizability. They posit that for every instance, there is a 'lottery prompt' that can induce the correct prediction from the PLM at a low cost.", "example": "Convert the coordinate to text: [-1.2451 -5.0438]:"}
{"text": "Convert the coordinate to text: [ 0.3802 -8.1167]: The authors introduce ManagerTower, a novel VL model architecture that can gather and combine the insights of pre-trained uni-modal experts at different levels, with an adaptive 'managers' introduced in each cross-modal layer to aggregate uni-modal semantic knowledge for more comprehensive cross-modal alignment and fusion.", "target": "The authors introduce ManagerTower, a novel VL model architecture that can gather and combine the insights of pre-trained uni-modal experts at different levels, with an adaptive 'managers' introduced in each cross-modal layer to aggregate uni-modal semantic knowledge for more comprehensive cross-modal alignment and fusion.", "example": "Convert the coordinate to text: [ 0.3802 -8.1167]:"}
{"text": "Convert the coordinate to text: [12.2633 -5.1147]: The authors propose a novel approach called 'Diffusion Enhanced Adversarial Training' (DEAT) that manipulates the diffusion term of a continuous-time Stochastic Differential Equation (SDE) approximating the dynamics of PGD-AT to improve robust generalization.", "target": "The authors propose a novel approach called 'Diffusion Enhanced Adversarial Training' (DEAT) that manipulates the diffusion term of a continuous-time Stochastic Differential Equation (SDE) approximating the dynamics of PGD-AT to improve robust generalization.", "example": "Convert the coordinate to text: [12.2633 -5.1147]:"}
{"text": "Convert the coordinate to text: [ 1.0622 -0.266 ]: The authors critique these practices and propose a more rigorous approach that aims to disentangle and properly assign credit to different factors of model improvements in pre-training research.", "target": "The authors critique these practices and propose a more rigorous approach that aims to disentangle and properly assign credit to different factors of model improvements in pre-training research.", "example": "Convert the coordinate to text: [ 1.0622 -0.266 ]:"}
{"text": "Convert the coordinate to text: [ 4.2175 -5.4046]: The authors propose Virtual Node Tuning (VNT), a method that utilizes a pretrained graph transformer as the encoder and injects virtual nodes as soft prompts in the embedding space. These can be optimized with few-shot labels in novel classes to modulate node embeddings for each specific FSNC task.", "target": "The authors propose Virtual Node Tuning (VNT), a method that utilizes a pretrained graph transformer as the encoder and injects virtual nodes as soft prompts in the embedding space. These can be optimized with few-shot labels in novel classes to modulate node embeddings for each specific FSNC task.", "example": "Convert the coordinate to text: [ 4.2175 -5.4046]:"}
{"text": "Convert the coordinate to text: [ 4.9474 -5.1974]: The paper proposes a universal structure learning model that can generalize across graph datasets in what the authors call an open world. This is achieved with a general framework that coordinates a single graph-shared structure learner and multiple graph-specific GNNs to capture generalizable patterns of optimal message-passing topology.", "target": "The paper proposes a universal structure learning model that can generalize across graph datasets in what the authors call an open world. This is achieved with a general framework that coordinates a single graph-shared structure learner and multiple graph-specific GNNs to capture generalizable patterns of optimal message-passing topology.", "example": "Convert the coordinate to text: [ 4.9474 -5.1974]:"}
{"text": "Convert the coordinate to text: [-2.4441 -4.5622]: The paper introduces a novel approach towards automatic data wrangling with a retrieval augmented self-trained transformer model. The strategy involves randomly ablating tables from the corpus and training the model to reconstruct the original values or headers given the partial tables as input.", "target": "The paper introduces a novel approach towards automatic data wrangling with a retrieval augmented self-trained transformer model. The strategy involves randomly ablating tables from the corpus and training the model to reconstruct the original values or headers given the partial tables as input.", "example": "Convert the coordinate to text: [-2.4441 -4.5622]:"}
{"text": "Convert the coordinate to text: [-0.7879 -7.157 ]: The authors propose a constraint-aware and ranking-distilled token pruning method (ToP), which selectively removes unnecessary tokens as input sequence passes through layers, thus improving online inference speed while preserving accuracy. ToP also introduces a coarse-to-fine pruning approach that automatically selects the optimal subset of transformer layers.", "target": "The authors propose a constraint-aware and ranking-distilled token pruning method (ToP), which selectively removes unnecessary tokens as input sequence passes through layers, thus improving online inference speed while preserving accuracy. ToP also introduces a coarse-to-fine pruning approach that automatically selects the optimal subset of transformer layers.", "example": "Convert the coordinate to text: [-0.7879 -7.157 ]:"}
{"text": "Convert the coordinate to text: [-1.7197 -6.1682]: For Subtask 1, a strategy based on prompt learning and ChatGPT is measured against a baseline constructed using BERT. For Subtask 2, DeBERTaV3 is fine-tuned without dependence on the outcomes of Subtask 1, under observation that early stopping can preclude model overfitting.", "target": "For Subtask 1, a strategy based on prompt learning and ChatGPT is measured against a baseline constructed using BERT. For Subtask 2, DeBERTaV3 is fine-tuned without dependence on the outcomes of Subtask 1, under observation that early stopping can preclude model overfitting.", "example": "Convert the coordinate to text: [-1.7197 -6.1682]:"}
{"text": "Convert the coordinate to text: [-6.5531 -9.8765]: A novel method for automatically extracting morphosyntactical error patterns is proposed to address the challenge of locating errors in datasets resulted from automatic morphosyntactical annotation.", "target": "A novel method for automatically extracting morphosyntactical error patterns is proposed to address the challenge of locating errors in datasets resulted from automatic morphosyntactical annotation.", "example": "Convert the coordinate to text: [-6.5531 -9.8765]:"}
{"text": "Convert the coordinate to text: [-4.0956  0.1331]: This study aims to investigate the effectiveness of different SPT approaches for ABSA. It does this through creating a knowledge-mining method to build a large-scale SPT corpus, and through analyzing the impact of different types of sentiment knowledge in pre-training.", "target": "This study aims to investigate the effectiveness of different SPT approaches for ABSA. It does this through creating a knowledge-mining method to build a large-scale SPT corpus, and through analyzing the impact of different types of sentiment knowledge in pre-training.", "example": "Convert the coordinate to text: [-4.0956  0.1331]:"}
{"text": "Convert the coordinate to text: [-0.3763 -6.5456]: The authors proposed an inference framework with a post-training strategy, that builds upon any pre-trained transformer-based response selection models. The framework accelerates inference by progressively selecting and eliminating unimportant content based on context-response dual-attention.", "target": "The authors proposed an inference framework with a post-training strategy, that builds upon any pre-trained transformer-based response selection models. The framework accelerates inference by progressively selecting and eliminating unimportant content based on context-response dual-attention.", "example": "Convert the coordinate to text: [-0.3763 -6.5456]:"}
{"text": "Convert the coordinate to text: [-1.0321 -6.7453]: To advance pre-training efficiency, this paper proposes an extension of the RTD task into a task of ranking input tokens according to different quality levels. The binary classifier in the ELECTRA is generalized into a K-level ranker for a more detailed task with negligible additional computation cost.", "target": "To advance pre-training efficiency, this paper proposes an extension of the RTD task into a task of ranking input tokens according to different quality levels. The binary classifier in the ELECTRA is generalized into a K-level ranker for a more detailed task with negligible additional computation cost.", "example": "Convert the coordinate to text: [-1.0321 -6.7453]:"}
{"text": "Convert the coordinate to text: [-4.459  -4.0806]: The authors propose to use theoretical linguistics for language clustering for multilingual Named Entity Recognition (NER), introducing two types of language groupings: one based on morpho-syntactic features in a nominal domain and one based on a head parameter.", "target": "The authors propose to use theoretical linguistics for language clustering for multilingual Named Entity Recognition (NER), introducing two types of language groupings: one based on morpho-syntactic features in a nominal domain and one based on a head parameter.", "example": "Convert the coordinate to text: [-4.459  -4.0806]:"}
{"text": "Convert the coordinate to text: [-1.8573  5.988 ]: This paper explores the gap between real-world motivations described in NLP papers and the simplified models and evaluation settings that comprise the proposed solution.", "target": "This paper explores the gap between real-world motivations described in NLP papers and the simplified models and evaluation settings that comprise the proposed solution.", "example": "Convert the coordinate to text: [-1.8573  5.988 ]:"}
{"text": "Convert the coordinate to text: [12.3805  8.4142]: This paper proposes PDAS, a Practical Distributed ADMM System, that uses a variant of the Alternating Direction Method of Multipliers (ADMM) algorithm to solve large-scale LP problems. PDAS provides user-friendly interfaces and a near-linear speedup due to its high scalability and excellent performance.", "target": "This paper proposes PDAS, a Practical Distributed ADMM System, that uses a variant of the Alternating Direction Method of Multipliers (ADMM) algorithm to solve large-scale LP problems. PDAS provides user-friendly interfaces and a near-linear speedup due to its high scalability and excellent performance.", "example": "Convert the coordinate to text: [12.3805  8.4142]:"}
{"text": "Convert the coordinate to text: [ 0.5453 -3.9303]: The authors introduce Hybrid Species Embedding (HSE), a new method that makes use of mixed sample data augmentations to create hybrid species and provide extra training signals.", "target": "The authors introduce Hybrid Species Embedding (HSE), a new method that makes use of mixed sample data augmentations to create hybrid species and provide extra training signals.", "example": "Convert the coordinate to text: [ 0.5453 -3.9303]:"}
{"text": "Convert the coordinate to text: [ 4.9357 -2.8715]: The authors propose a Category Aware Group Self-Support Learning framework (GSS) to address the information deficit among modalities in the individual modal feature extraction phase. This technique selects a prediction with the most significant sensitivity as a group leader and then collaborative efforts between group leaders and members identify the learning target.", "target": "The authors propose a Category Aware Group Self-Support Learning framework (GSS) to address the information deficit among modalities in the individual modal feature extraction phase. This technique selects a prediction with the most significant sensitivity as a group leader and then collaborative efforts between group leaders and members identify the learning target.", "example": "Convert the coordinate to text: [ 4.9357 -2.8715]:"}
{"text": "Convert the coordinate to text: [16.1507  1.8536]: The paper introduces a novel framework called Diversified Outlier Exposure (DivOE) for effective OOD detection through informative extrapolation based off given auxiliary outliers.", "target": "The paper introduces a novel framework called Diversified Outlier Exposure (DivOE) for effective OOD detection through informative extrapolation based off given auxiliary outliers.", "example": "Convert the coordinate to text: [16.1507  1.8536]:"}
{"text": "Convert the coordinate to text: [ 9.9124 12.059 ]: The authors propose an algorithm called B-LATTICE (Blocked Latent bAndiTs via maTrIx ComplEtion) that collaborates across users while simultaneously satisfying budget constraints to maximize their cumulative rewards.", "target": "The authors propose an algorithm called B-LATTICE (Blocked Latent bAndiTs via maTrIx ComplEtion) that collaborates across users while simultaneously satisfying budget constraints to maximize their cumulative rewards.", "example": "Convert the coordinate to text: [ 9.9124 12.059 ]:"}
{"text": "Convert the coordinate to text: [ 0.1009 -6.9993]: From the observation that lower layers of the Transformer encoder contain more syntactic information and the top ones contain more semantic information, the authors propose an extension to sequence-to-sequence models, CompoSition, that composes representations of different encoder layers dynamically for different tasks.", "target": "From the observation that lower layers of the Transformer encoder contain more syntactic information and the top ones contain more semantic information, the authors propose an extension to sequence-to-sequence models, CompoSition, that composes representations of different encoder layers dynamically for different tasks.", "example": "Convert the coordinate to text: [ 0.1009 -6.9993]:"}
{"text": "Convert the coordinate to text: [ 0.1709 -8.323 ]: The authors introduce a novel Cross-modal Cross-lingual Interactive Model (CCIM) to incorporate source language information. It does this by generating source and target language results simultaneously through an interactive attention mechanism between two language decoders.", "target": "The authors introduce a novel Cross-modal Cross-lingual Interactive Model (CCIM) to incorporate source language information. It does this by generating source and target language results simultaneously through an interactive attention mechanism between two language decoders.", "example": "Convert the coordinate to text: [ 0.1709 -8.323 ]:"}
{"text": "Convert the coordinate to text: [ 0.6139 15.7117]: The authors develop an algorithm for online ad allocation that incorporates machine-learned predictions to improve the performance beyond the worst-case scenario.", "target": "The authors develop an algorithm for online ad allocation that incorporates machine-learned predictions to improve the performance beyond the worst-case scenario.", "example": "Convert the coordinate to text: [ 0.6139 15.7117]:"}
{"text": "Convert the coordinate to text: [ 0.1006 -8.285 ]: The authors propose a Cross-modal prediCate boosting (CaCao) framework, where a visually-prompted language model is used to generate diverse fine-grained predicates in a low-resource way. Additionally, they introduce a novel approach, Entangled cross-modal prompt (Epic), for open-world predicate scene graph generation, allowing models to generalize to unseen predicates.", "target": "The authors propose a Cross-modal prediCate boosting (CaCao) framework, where a visually-prompted language model is used to generate diverse fine-grained predicates in a low-resource way. Additionally, they introduce a novel approach, Entangled cross-modal prompt (Epic), for open-world predicate scene graph generation, allowing models to generalize to unseen predicates.", "example": "Convert the coordinate to text: [ 0.1006 -8.285 ]:"}
{"text": "Convert the coordinate to text: [ 2.0179 -4.0592]: The authors propose a method called Multi-Perspective Course Learning (MCL) which seeks to utilize multiple perspectives in pre-training language models and better leverage the relationship between the generator and discriminator.", "target": "The authors propose a method called Multi-Perspective Course Learning (MCL) which seeks to utilize multiple perspectives in pre-training language models and better leverage the relationship between the generator and discriminator.", "example": "Convert the coordinate to text: [ 2.0179 -4.0592]:"}
{"text": "Convert the coordinate to text: [ 6.3751 -3.5786]: The paper proposes a lightweight method for adapting large LMs to new domains and tasks without access to their weights or intermediate activations by combining a small fine-tuned white-box LM with the large black-box LM at the probability level through a small network.", "target": "The paper proposes a lightweight method for adapting large LMs to new domains and tasks without access to their weights or intermediate activations by combining a small fine-tuned white-box LM with the large black-box LM at the probability level through a small network.", "example": "Convert the coordinate to text: [ 6.3751 -3.5786]:"}
{"text": "Convert the coordinate to text: [-4.9767 -2.4158]: The paper introduces ScoNe-NLI benchmark, a carefully designed evaluative tool with contrast sets of examples featuring up to two negations that can accurately test a model's understanding of negation morpheme's semantic scope.", "target": "The paper introduces ScoNe-NLI benchmark, a carefully designed evaluative tool with contrast sets of examples featuring up to two negations that can accurately test a model's understanding of negation morpheme's semantic scope.", "example": "Convert the coordinate to text: [-4.9767 -2.4158]:"}
{"text": "Convert the coordinate to text: [-3.4777 -5.1681]: The authors explore leveraging current language models to produce a virtually unlimited quantity of practice material illustrating unhelpful thought patterns and suitable positive reframing proposals.", "target": "The authors explore leveraging current language models to produce a virtually unlimited quantity of practice material illustrating unhelpful thought patterns and suitable positive reframing proposals.", "example": "Convert the coordinate to text: [-3.4777 -5.1681]:"}
{"text": "Convert the coordinate to text: [-9.41   -5.2307]: The authors propose to annotate the discourse and non-discourse connective occurrences of dA in Turkish using the PDTB principles for the first time, and develop binary classifiers to distinguish its discourse connective usage from its other usages.", "target": "The authors propose to annotate the discourse and non-discourse connective occurrences of dA in Turkish using the PDTB principles for the first time, and develop binary classifiers to distinguish its discourse connective usage from its other usages.", "example": "Convert the coordinate to text: [-9.41   -5.2307]:"}
{"text": "Convert the coordinate to text: [ 1.7937 -0.8549]: The paper proposes re-annotation as a method to examine the robustness of already existing labeled datasets for harmful language detection. The intrinsically subjective and variable nature of this task is highlighted.", "target": "The paper proposes re-annotation as a method to examine the robustness of already existing labeled datasets for harmful language detection. The intrinsically subjective and variable nature of this task is highlighted.", "example": "Convert the coordinate to text: [ 1.7937 -0.8549]:"}
{"text": "Convert the coordinate to text: [-2.8087 -6.6523]: The key idea proposed in this paper is to use a pre-trained roBERTa model, which is pretrained on 100 languages, for sentiment classification in Hausa language tweets. They also propose using the AfriBERTa model specifically pretrained on African languages to tokenize the text.", "target": "The key idea proposed in this paper is to use a pre-trained roBERTa model, which is pretrained on 100 languages, for sentiment classification in Hausa language tweets. They also propose using the AfriBERTa model specifically pretrained on African languages to tokenize the text.", "example": "Convert the coordinate to text: [-2.8087 -6.6523]:"}
{"text": "Convert the coordinate to text: [ 1.3794 -6.5874]: The authors propose Heterformer, a Heterogeneous Network-Empowered Transformer that performs contextualized text encoding and heterogeneous structure encoding in an integrated role, taking into account node and edge type diversity and accommodating nodes with absent or abundant textual data.", "target": "The authors propose Heterformer, a Heterogeneous Network-Empowered Transformer that performs contextualized text encoding and heterogeneous structure encoding in an integrated role, taking into account node and edge type diversity and accommodating nodes with absent or abundant textual data.", "example": "Convert the coordinate to text: [ 1.3794 -6.5874]:"}
{"text": "Convert the coordinate to text: [ 5.6613 14.3672]: The paper introduces GEAR, a distributed, GPU-centric experience replay system optimized for scalable reinforcement learning with large sequence models. It enhances memory efficiency by relying on the memory resources of GPU servers and facilitates decentralized GPUs to quicken various trajectory selection strategies.", "target": "The paper introduces GEAR, a distributed, GPU-centric experience replay system optimized for scalable reinforcement learning with large sequence models. It enhances memory efficiency by relying on the memory resources of GPU servers and facilitates decentralized GPUs to quicken various trajectory selection strategies.", "example": "Convert the coordinate to text: [ 5.6613 14.3672]:"}
{"text": "Convert the coordinate to text: [5.0747 4.986 ]: The authors address this uncertainty, demonstrating that an O(1)-IP stable clustering is obtainable for general metrics. They propose an efficient algorithm to produce such a clustering.", "target": "The authors address this uncertainty, demonstrating that an O(1)-IP stable clustering is obtainable for general metrics. They propose an efficient algorithm to produce such a clustering.", "example": "Convert the coordinate to text: [5.0747 4.986 ]:"}
{"text": "Convert the coordinate to text: [5.4983 0.0235]: The authors propose analyzing the spanned space of each class, not just the number of samples, and redefine reweighting by estimating the size of the spanned space, or effective area, based on a class's sample distribution.", "target": "The authors propose analyzing the spanned space of each class, not just the number of samples, and redefine reweighting by estimating the size of the spanned space, or effective area, based on a class's sample distribution.", "example": "Convert the coordinate to text: [5.4983 0.0235]:"}
{"text": "Convert the coordinate to text: [ 13.0781 -12.6203]: The authors propose a new unsupervised face animation approach that learns both coarse and finer motions simultaneously. They exploit the local affine motion model for global coarse facial motion and introduce a novel motion refinement module to compensate for local finer facial motions.", "target": "The authors propose a new unsupervised face animation approach that learns both coarse and finer motions simultaneously. They exploit the local affine motion model for global coarse facial motion and introduce a novel motion refinement module to compensate for local finer facial motions.", "example": "Convert the coordinate to text: [ 13.0781 -12.6203]:"}
{"text": "Convert the coordinate to text: [3.1432 9.8775]: The authors propose a novel curriculum method to alleviate the issue. This method automatically defines a semantic goal space which contains vital information for the curriculum process and suggests curriculum goals.", "target": "The authors propose a novel curriculum method to alleviate the issue. This method automatically defines a semantic goal space which contains vital information for the curriculum process and suggests curriculum goals.", "example": "Convert the coordinate to text: [3.1432 9.8775]:"}
{"text": "Convert the coordinate to text: [ 0.1507 -0.6991]: The key idea of the study is the proposed novel approach named Temporal Motifs Explainer (TempME) that uncovers the most pivotal temporal motifs guiding the predictions of TGNNs. TempME utilizes the information bottleneck principle to extract the most interaction-related motifs while minimizing the amount of contained information, thus preserving the sparsity and succinctness of the explanation.", "target": "The key idea of the study is the proposed novel approach named Temporal Motifs Explainer (TempME) that uncovers the most pivotal temporal motifs guiding the predictions of TGNNs. TempME utilizes the information bottleneck principle to extract the most interaction-related motifs while minimizing the amount of contained information, thus preserving the sparsity and succinctness of the explanation.", "example": "Convert the coordinate to text: [ 0.1507 -0.6991]:"}
{"text": "Convert the coordinate to text: [ 2.1773 15.227 ]: The paper tackles several open questions from Brandt (2017) and Aziz et al. (2015) regarding the application of PC preference extension in SDS, including its strategyproofness, efficiency, and strict PC-participation under different sets of constraints.", "target": "The paper tackles several open questions from Brandt (2017) and Aziz et al. (2015) regarding the application of PC preference extension in SDS, including its strategyproofness, efficiency, and strict PC-participation under different sets of constraints.", "example": "Convert the coordinate to text: [ 2.1773 15.227 ]:"}
{"text": "Convert the coordinate to text: [ 8.907  -2.9001]: The authors introduce a novel model architecture based around a discrete bottleneck, featuring learnable key-value codes, allowing the model to encode an input, process the representation via a discrete bottleneck, and decode the output.", "target": "The authors introduce a novel model architecture based around a discrete bottleneck, featuring learnable key-value codes, allowing the model to encode an input, process the representation via a discrete bottleneck, and decode the output.", "example": "Convert the coordinate to text: [ 8.907  -2.9001]:"}
{"text": "Convert the coordinate to text: [ 0.0889 -3.2195]: The paper introduces a series of modifications to language models to represent and generate math and text together. Changes involve representing mathematical expressions as sequences of node tokens in their operator tree format, incorporating math symbol and tree position embeddings, and utilizing a constrained decoding method to generate valid mathematical expressions.", "target": "The paper introduces a series of modifications to language models to represent and generate math and text together. Changes involve representing mathematical expressions as sequences of node tokens in their operator tree format, incorporating math symbol and tree position embeddings, and utilizing a constrained decoding method to generate valid mathematical expressions.", "example": "Convert the coordinate to text: [ 0.0889 -3.2195]:"}
{"text": "Convert the coordinate to text: [-4.8698 12.2467]: The authors introduce CB2, a multi-agent platform designed to study collaborative natural language interaction in a grounded task-oriented scenario. The platform combines a backend server for serving trained models to human agents, a 3D game environment, and tools to scale studies.", "target": "The authors introduce CB2, a multi-agent platform designed to study collaborative natural language interaction in a grounded task-oriented scenario. The platform combines a backend server for serving trained models to human agents, a 3D game environment, and tools to scale studies.", "example": "Convert the coordinate to text: [-4.8698 12.2467]:"}
{"text": "Convert the coordinate to text: [-8.3798 13.3008]: The authors propose a taxonomy for classifying collaborative interaction in games, which builds on the MDA framework and Activity Theory (AT), and includes the top-level attributes of WHAT, WHO, WHEN and HOW to assess different levels of interaction.", "target": "The authors propose a taxonomy for classifying collaborative interaction in games, which builds on the MDA framework and Activity Theory (AT), and includes the top-level attributes of WHAT, WHO, WHEN and HOW to assess different levels of interaction.", "example": "Convert the coordinate to text: [-8.3798 13.3008]:"}
{"text": "Convert the coordinate to text: [-1.0761 -4.8554]: The authors propose a prompting strategy that formulates a wide range of NLU tasks as contextual entailment, which improves the zero-shot adaptation of pretrained entailment models. Additionally, they propose the Simple Pseudo-Label Editing (SimPLE) algorithm to better pseudo-label quality in self-training using unlabeled data.", "target": "The authors propose a prompting strategy that formulates a wide range of NLU tasks as contextual entailment, which improves the zero-shot adaptation of pretrained entailment models. Additionally, they propose the Simple Pseudo-Label Editing (SimPLE) algorithm to better pseudo-label quality in self-training using unlabeled data.", "example": "Convert the coordinate to text: [-1.0761 -4.8554]:"}
{"text": "Convert the coordinate to text: [-10.7771  -2.2432]: This paper introduces AutoQG, an online service for multilingual QAG, and lmqg, a comprehensive Python package for model fine-tuning, generation, and evaluation.", "target": "This paper introduces AutoQG, an online service for multilingual QAG, and lmqg, a comprehensive Python package for model fine-tuning, generation, and evaluation.", "example": "Convert the coordinate to text: [-10.7771  -2.2432]:"}
{"text": "Convert the coordinate to text: [-10.1645  -1.5664]: This study introduces an automated methodology to detect uncertainty in LLMs' responses, providing a novel measure of their self-knowledge. Additionally, a unique dataset, SelfAware, is introduced, consisting of unanswerable questions from five diverse categories and their answerable counterparts.", "target": "This study introduces an automated methodology to detect uncertainty in LLMs' responses, providing a novel measure of their self-knowledge. Additionally, a unique dataset, SelfAware, is introduced, consisting of unanswerable questions from five diverse categories and their answerable counterparts.", "example": "Convert the coordinate to text: [-10.1645  -1.5664]:"}
{"text": "Convert the coordinate to text: [-5.959  -0.2974]: The authors propose an approach for summarizing long legal opinions that uses argument role information to generate multiple candidate summaries, which are then reranked based on alignment with the document's argument structure.", "target": "The authors propose an approach for summarizing long legal opinions that uses argument role information to generate multiple candidate summaries, which are then reranked based on alignment with the document's argument structure.", "example": "Convert the coordinate to text: [-5.959  -0.2974]:"}
{"text": "Convert the coordinate to text: [ 4.9728 14.2871]: The authors propose Neurally gUided Differentiable loGic policiEs (NUDGE), a method which leverages pre-trained neural network-based agents to guide the search of candidate-weighted logic rules, and then employs differentiable logic for the training of logic agents, aiming to create policies that are both interpretable and explainable.", "target": "The authors propose Neurally gUided Differentiable loGic policiEs (NUDGE), a method which leverages pre-trained neural network-based agents to guide the search of candidate-weighted logic rules, and then employs differentiable logic for the training of logic agents, aiming to create policies that are both interpretable and explainable.", "example": "Convert the coordinate to text: [ 4.9728 14.2871]:"}
{"text": "Convert the coordinate to text: [-2.2614 -5.3448]: A novel method, ProToCo, is proposed to prompt pre-trained language models (PLMs) to be consistent, which works by generating multiple variants of a claim with different relations and use a consistency mechanism as constraints for making compatible predictions across these variants.", "target": "A novel method, ProToCo, is proposed to prompt pre-trained language models (PLMs) to be consistent, which works by generating multiple variants of a claim with different relations and use a consistency mechanism as constraints for making compatible predictions across these variants.", "example": "Convert the coordinate to text: [-2.2614 -5.3448]:"}
{"text": "Convert the coordinate to text: [ 3.349  -2.3253]: The authors propose a self-training approach leveraging both labeled and unlabeled data to improve few-shot models, under the assumption that neither written rationales nor annotated task labels are available at scale. They introduce a dual-teacher learning framework and a new loss function called Masked Label Regularization (MLR) to condition explanations on predicted labels.", "target": "The authors propose a self-training approach leveraging both labeled and unlabeled data to improve few-shot models, under the assumption that neither written rationales nor annotated task labels are available at scale. They introduce a dual-teacher learning framework and a new loss function called Masked Label Regularization (MLR) to condition explanations on predicted labels.", "example": "Convert the coordinate to text: [ 3.349  -2.3253]:"}
{"text": "Convert the coordinate to text: [-2.0332 -6.5746]: The authors propose a two-fold strategy: a second-phase pre-training method to adapt a RoBERTa Language Model (LM), and a One-Versus-All approach to classification. Predictions are determined by majority voting from an ensemble of three sets of per-label models.", "target": "The authors propose a two-fold strategy: a second-phase pre-training method to adapt a RoBERTa Language Model (LM), and a One-Versus-All approach to classification. Predictions are determined by majority voting from an ensemble of three sets of per-label models.", "example": "Convert the coordinate to text: [-2.0332 -6.5746]:"}
{"text": "Convert the coordinate to text: [ 1.2649 -7.4769]: This work introduces a novel multi-headed attention mechanism on top of a pre-trained transformer encoder, aiming to allow the learning process to attend to multiple aspects of the contextualized embeddings.", "target": "This work introduces a novel multi-headed attention mechanism on top of a pre-trained transformer encoder, aiming to allow the learning process to attend to multiple aspects of the contextualized embeddings.", "example": "Convert the coordinate to text: [ 1.2649 -7.4769]:"}
{"text": "Convert the coordinate to text: [-2.7168 -5.7187]: The authors propose a unified model trained in a multi-task learning framework for both the sentence-level and word-level Quality Estimation tasks.", "target": "The authors propose a unified model trained in a multi-task learning framework for both the sentence-level and word-level Quality Estimation tasks.", "example": "Convert the coordinate to text: [-2.7168 -5.7187]:"}
{"text": "Convert the coordinate to text: [-9.5195 -5.1388]: The authors propose a new challenge called ellipsis-dependent reasoning, where an ellipsis example is matched to its non-ellipsis counterpart, and a question is posed that requires the resolution of the ellipsis.", "target": "The authors propose a new challenge called ellipsis-dependent reasoning, where an ellipsis example is matched to its non-ellipsis counterpart, and a question is posed that requires the resolution of the ellipsis.", "example": "Convert the coordinate to text: [-9.5195 -5.1388]:"}
{"text": "Convert the coordinate to text: [5.3844 8.9958]: This study introduces a novel method, Cognitive EvoLutionary Search (CELS), which allows the model to select the appropriate operations to interact on feature pairs, inspired by natural evolution. This method conceptualizes interactions as genomes, models as organisms, and tasks as natural environments, and utilizes this concept to assess the fitness of models and simulate survival rates for natural selection.", "target": "This study introduces a novel method, Cognitive EvoLutionary Search (CELS), which allows the model to select the appropriate operations to interact on feature pairs, inspired by natural evolution. This method conceptualizes interactions as genomes, models as organisms, and tasks as natural environments, and utilizes this concept to assess the fitness of models and simulate survival rates for natural selection.", "example": "Convert the coordinate to text: [5.3844 8.9958]:"}
{"text": "Convert the coordinate to text: [ 5.667  11.9164]: The authors present a generalized safe exploration (GSE) problem as a unified formulation of common safe exploration problems. They also propose a meta-algorithm for safe exploration, MASE, which combines an unconstrained RL algorithm with an uncertainty quantifier.", "target": "The authors present a generalized safe exploration (GSE) problem as a unified formulation of common safe exploration problems. They also propose a meta-algorithm for safe exploration, MASE, which combines an unconstrained RL algorithm with an uncertainty quantifier.", "example": "Convert the coordinate to text: [ 5.667  11.9164]:"}
{"text": "Convert the coordinate to text: [  7.2986 -15.729 ]: The study presents a new image geometric abstraction paradigm based on assembly out of a pool of pre-defined simple parametric primitives, which allows for controllable shape editing in images. This approach is reformulated within a token translation neural framework that outputs primitive assignments and corresponding transformation and color parameters in an image-to-set manner.", "target": "The study presents a new image geometric abstraction paradigm based on assembly out of a pool of pre-defined simple parametric primitives, which allows for controllable shape editing in images. This approach is reformulated within a token translation neural framework that outputs primitive assignments and corresponding transformation and color parameters in an image-to-set manner.", "example": "Convert the coordinate to text: [  7.2986 -15.729 ]:"}
{"text": "Convert the coordinate to text: [  8.6535 -12.7437]: The paper proposes a holistic 3D scene parsing/reconstruction system called Uni-3D for a single RGB image, which combines both object instance and scene layout prediction. A novel single Transformer for 2D depth-aware panoptic segmentation is also introduced.", "target": "The paper proposes a holistic 3D scene parsing/reconstruction system called Uni-3D for a single RGB image, which combines both object instance and scene layout prediction. A novel single Transformer for 2D depth-aware panoptic segmentation is also introduced.", "example": "Convert the coordinate to text: [  8.6535 -12.7437]:"}
{"text": "Convert the coordinate to text: [ 5.5729 -5.1323]: This paper introduces a new deep autoregressive model for phylogenetic inference called ARTree based on graph neural networks (GNNs) that can provide a rich family of distributions over the entire tree topology space without using heuristic features", "target": "This paper introduces a new deep autoregressive model for phylogenetic inference called ARTree based on graph neural networks (GNNs) that can provide a rich family of distributions over the entire tree topology space without using heuristic features", "example": "Convert the coordinate to text: [ 5.5729 -5.1323]:"}
{"text": "Convert the coordinate to text: [ 7.1332 12.6078]: Inspired by the generalized reduced gradient (GRG) algorithm, the authors propose a reduced policy optimization (RPO) algorithm that combines RL with GRG to manage general hard constraints efficiently. RPO partitions actions into basic and nonbasic actions, while outputting the basic actions via a policy network.", "target": "Inspired by the generalized reduced gradient (GRG) algorithm, the authors propose a reduced policy optimization (RPO) algorithm that combines RL with GRG to manage general hard constraints efficiently. RPO partitions actions into basic and nonbasic actions, while outputting the basic actions via a policy network.", "example": "Convert the coordinate to text: [ 7.1332 12.6078]:"}
{"text": "Convert the coordinate to text: [5.4834 2.9824]: The authors introduce a theoretical framework to understand the benefits of Nearest Neighbor (NN) graphs when a graph structure is missing. They propose a formal analysis of Cross-Class Neighborhood Similarity (CCNS) that's used to evaluate the usefulness of the structures in the context of nearest neighbor graphs.", "target": "The authors introduce a theoretical framework to understand the benefits of Nearest Neighbor (NN) graphs when a graph structure is missing. They propose a formal analysis of Cross-Class Neighborhood Similarity (CCNS) that's used to evaluate the usefulness of the structures in the context of nearest neighbor graphs.", "example": "Convert the coordinate to text: [5.4834 2.9824]:"}
{"text": "Convert the coordinate to text: [ 4.6963 -1.4735]: The authors propose Rank-N-Contrast (RNC), a framework that learns continuous representations for regression by contrasting samples against each other based on their rankings in the target space.", "target": "The authors propose Rank-N-Contrast (RNC), a framework that learns continuous representations for regression by contrasting samples against each other based on their rankings in the target space.", "example": "Convert the coordinate to text: [ 4.6963 -1.4735]:"}
{"text": "Convert the coordinate to text: [-0.4902 -8.3253]: The authors propose LayoutDIT, a layout-aware end-to-end DIT method that incorporates layout knowledge into the process. It models visual layout relations with raw OCR results via a layout-aware encoder and a multi-step conductive decoder.", "target": "The authors propose LayoutDIT, a layout-aware end-to-end DIT method that incorporates layout knowledge into the process. It models visual layout relations with raw OCR results via a layout-aware encoder and a multi-step conductive decoder.", "example": "Convert the coordinate to text: [-0.4902 -8.3253]:"}
{"text": "Convert the coordinate to text: [-2.8446  0.4641]: This paper introduces the concept of euphemistic abuse (e.g. \u201cYou inspire me to fall asleep\u201d as a euphemism for \u201cYou are boring\u201d) and creates a novel dataset for identifying such abuse.", "target": "This paper introduces the concept of euphemistic abuse (e.g. \u201cYou inspire me to fall asleep\u201d as a euphemism for \u201cYou are boring\u201d) and creates a novel dataset for identifying such abuse.", "example": "Convert the coordinate to text: [-2.8446  0.4641]:"}
{"text": "Convert the coordinate to text: [-0.0889 -4.9496]: The authors propose a unified bidirectional generative framework that trains a generative model in both text-to-label and label-to-text directions to offer a more general solution for cross-domain ABSA tasks.", "target": "The authors propose a unified bidirectional generative framework that trains a generative model in both text-to-label and label-to-text directions to offer a more general solution for cross-domain ABSA tasks.", "example": "Convert the coordinate to text: [-0.0889 -4.9496]:"}
{"text": "Convert the coordinate to text: [ 3.7203 -3.7503]: The paper conducts a comprehensive evaluation of distillation objectives in both task-specific and task-agnostic settings, showing attention transfer gives the best performance.", "target": "The paper conducts a comprehensive evaluation of distillation objectives in both task-specific and task-agnostic settings, showing attention transfer gives the best performance.", "example": "Convert the coordinate to text: [ 3.7203 -3.7503]:"}
{"text": "Convert the coordinate to text: [-0.6869 -6.5484]: The authors suggest a method of training Longformer-based document encoders using an unsupervised contrastive learning method (SimCSE), complementing it with additional convex neural networks based on functional Bregman divergence to improve the quality of the document representations.", "target": "The authors suggest a method of training Longformer-based document encoders using an unsupervised contrastive learning method (SimCSE), complementing it with additional convex neural networks based on functional Bregman divergence to improve the quality of the document representations.", "example": "Convert the coordinate to text: [-0.6869 -6.5484]:"}
{"text": "Convert the coordinate to text: [-3.7641 -7.0558]: The authors propose to model sequential second language acquisition in language models to understand both positive and negative transfer between first language (L1) and second language (L2). And build a Multilingual Age Ordered CHILDES (MAO-CHILDES) dataset to understand the impact of native Child-Directed Speech (CDS) [L1] on English language acquisition [L2].", "target": "The authors propose to model sequential second language acquisition in language models to understand both positive and negative transfer between first language (L1) and second language (L2). And build a Multilingual Age Ordered CHILDES (MAO-CHILDES) dataset to understand the impact of native Child-Directed Speech (CDS) [L1] on English language acquisition [L2].", "example": "Convert the coordinate to text: [-3.7641 -7.0558]:"}
{"text": "Convert the coordinate to text: [2.8985 2.3521]: The paper proposes Tree based Progressive Regression Model (TPM) for watch time prediction which introduces ordinal ranks of watch time and decomposes the problem into a set of conditional dependent classification tasks in a tree structure. It also incorporates an expectation of watch time by traversing the tree and introduces the variance of watch time predictions as a measurement for uncertainty, while also considering bias amplifications.", "target": "The paper proposes Tree based Progressive Regression Model (TPM) for watch time prediction which introduces ordinal ranks of watch time and decomposes the problem into a set of conditional dependent classification tasks in a tree structure. It also incorporates an expectation of watch time by traversing the tree and introduces the variance of watch time predictions as a measurement for uncertainty, while also considering bias amplifications.", "example": "Convert the coordinate to text: [2.8985 2.3521]:"}
{"text": "Convert the coordinate to text: [14.7922  5.0089]: This study proposes using the family of optimal transport (balanced, partial, and unbalanced OT) as a natural and powerful approach for achieving unbalanced word alignment, which values both alignment and null alignment.", "target": "This study proposes using the family of optimal transport (balanced, partial, and unbalanced OT) as a natural and powerful approach for achieving unbalanced word alignment, which values both alignment and null alignment.", "example": "Convert the coordinate to text: [14.7922  5.0089]:"}
{"text": "Convert the coordinate to text: [ 1.7499 -7.6598]: The authors propose the Focused Transformer (FoT), a technique that uses a contrastive learning-inspired training approach to enhance the structure of the (key, value) space and extend the context length.", "target": "The authors propose the Focused Transformer (FoT), a technique that uses a contrastive learning-inspired training approach to enhance the structure of the (key, value) space and extend the context length.", "example": "Convert the coordinate to text: [ 1.7499 -7.6598]:"}
{"text": "Convert the coordinate to text: [-7.0191  7.0693]: The researchers introduce a new task of identifying fine-grained depressive symptoms from memes. They create the RESTORE dataset, annotated with 8 fine-grained depression symptoms based on the PHQ-9 questionnaire.", "target": "The researchers introduce a new task of identifying fine-grained depressive symptoms from memes. They create the RESTORE dataset, annotated with 8 fine-grained depression symptoms based on the PHQ-9 questionnaire.", "example": "Convert the coordinate to text: [-7.0191  7.0693]:"}
{"text": "Convert the coordinate to text: [-3.3825 -6.6734]: This paper uses various strategies, such as monolingual training, multilingual mixed training, and translation technology, and introduces a weighted voting method that combines these strategies' results for sentiment analysis in low-resource African languages.", "target": "This paper uses various strategies, such as monolingual training, multilingual mixed training, and translation technology, and introduces a weighted voting method that combines these strategies' results for sentiment analysis in low-resource African languages.", "example": "Convert the coordinate to text: [-3.3825 -6.6734]:"}
{"text": "Convert the coordinate to text: [-5.5275 -2.0907]: The authors propose a new method for frame extraction in long clinical reports which is a hybridization between knowledge injection and a learning-based system. They also introduce the concept of scope relations in this context.", "target": "The authors propose a new method for frame extraction in long clinical reports which is a hybridization between knowledge injection and a learning-based system. They also introduce the concept of scope relations in this context.", "example": "Convert the coordinate to text: [-5.5275 -2.0907]:"}
{"text": "Convert the coordinate to text: [7.21   4.3187]: The authors propose two new models for DWSI, one based on Hierarchical Dirichlet Processes (HDP), a nonparametric model, and the other based on the Dynamic Embedded Topic Model (DETM), a dynamic neural model.", "target": "The authors propose two new models for DWSI, one based on Hierarchical Dirichlet Processes (HDP), a nonparametric model, and the other based on the Dynamic Embedded Topic Model (DETM), a dynamic neural model.", "example": "Convert the coordinate to text: [7.21   4.3187]:"}
{"text": "Convert the coordinate to text: [-0.6266  1.4001]: The authors propose a formal verification framework, TextVerifier, that provides certifiable guarantees against word-level alteration attacks on deep neural networks used in natural language processing.", "target": "The authors propose a formal verification framework, TextVerifier, that provides certifiable guarantees against word-level alteration attacks on deep neural networks used in natural language processing.", "example": "Convert the coordinate to text: [-0.6266  1.4001]:"}
{"text": "Convert the coordinate to text: [-8.7539 -5.7332]: In this paper, the authors propose a logic-based indirect supervision approach that exploits declaratively stated structural dependencies between both levels of annotation (session-level and utterance-level) to improve utterance modeling.", "target": "In this paper, the authors propose a logic-based indirect supervision approach that exploits declaratively stated structural dependencies between both levels of annotation (session-level and utterance-level) to improve utterance modeling.", "example": "Convert the coordinate to text: [-8.7539 -5.7332]:"}
{"text": "Convert the coordinate to text: [-3.2207 -5.5615]: The authors summarize and provide a comprehensive survey of 27 existing large language models for NL2Code, and review benchmarks and metrics.", "target": "The authors summarize and provide a comprehensive survey of 27 existing large language models for NL2Code, and review benchmarks and metrics.", "example": "Convert the coordinate to text: [-3.2207 -5.5615]:"}
{"text": "Convert the coordinate to text: [ 6.1689 -0.6752]: The authors propose a variant of the contrastive learning objective named Group Ordering Constraints (GroCo) that leverages sorting of distances of positive and negative pairs and computes the loss based on how many positive pairs have a larger distance than the negative pairs.", "target": "The authors propose a variant of the contrastive learning objective named Group Ordering Constraints (GroCo) that leverages sorting of distances of positive and negative pairs and computes the loss based on how many positive pairs have a larger distance than the negative pairs.", "example": "Convert the coordinate to text: [ 6.1689 -0.6752]:"}
{"text": "Convert the coordinate to text: [-5.6617 11.5386]: An AI-based message generation system is proposed, which utilizes reinforcement learning to optimize message selection policy over time. The system is designed to provide messages tailored according to individual participant's preferences and requirements.", "target": "An AI-based message generation system is proposed, which utilizes reinforcement learning to optimize message selection policy over time. The system is designed to provide messages tailored according to individual participant's preferences and requirements.", "example": "Convert the coordinate to text: [-5.6617 11.5386]:"}
{"text": "Convert the coordinate to text: [ 13.7329 -11.0298]: The authors introduce a new benchmark named FACET (FAirness in Computer Vision EvaluaTion), a publicly available evaluation set of 32k images for common vision tasks. This benchmark includes exhaustive manual annotations for person-related attributes such as perceived skin tone and hair type.", "target": "The authors introduce a new benchmark named FACET (FAirness in Computer Vision EvaluaTion), a publicly available evaluation set of 32k images for common vision tasks. This benchmark includes exhaustive manual annotations for person-related attributes such as perceived skin tone and hair type.", "example": "Convert the coordinate to text: [ 13.7329 -11.0298]:"}
{"text": "Convert the coordinate to text: [9.3238 2.1685]: The authors argue that both a non-linear model and the KF should be optimized similarly, and subsequently propose the Optimized KF (OKF) - an optimized version of the standard KF.", "target": "The authors argue that both a non-linear model and the KF should be optimized similarly, and subsequently propose the Optimized KF (OKF) - an optimized version of the standard KF.", "example": "Convert the coordinate to text: [9.3238 2.1685]:"}
{"text": "Convert the coordinate to text: [ 8.6036 -7.8421]: The authors introduce a novel convolutional neural architecture, XiNet, which is specifically designed for edge devices. It was derived from extensive efficiency analysis of various neural network operators and is able to optimize the number of operations, parameters, and working memory.", "target": "The authors introduce a novel convolutional neural architecture, XiNet, which is specifically designed for edge devices. It was derived from extensive efficiency analysis of various neural network operators and is able to optimize the number of operations, parameters, and working memory.", "example": "Convert the coordinate to text: [ 8.6036 -7.8421]:"}
{"text": "Convert the coordinate to text: [13.7688 -2.4614]: The authors propose a dynamic firing threshold (DFT) mechanism for dealing with over-sparsity and causal set complexities in spiking neurons. Further, they introduce a novel direct training algorithm for TTFS-based deep SNNs called DTA-TTFS, which exploits event-driven processing and spike timing.", "target": "The authors propose a dynamic firing threshold (DFT) mechanism for dealing with over-sparsity and causal set complexities in spiking neurons. Further, they introduce a novel direct training algorithm for TTFS-based deep SNNs called DTA-TTFS, which exploits event-driven processing and spike timing.", "example": "Convert the coordinate to text: [13.7688 -2.4614]:"}
{"text": "Convert the coordinate to text: [ 3.5064 -5.4649]: The authors propose a solution, GRENADE, a Graph-Centric Language model designed to address the issues common in self-supervised representation learning on text-attributed graphs. It leverages the synergy of both pre-trained language model and graph neural networks.", "target": "The authors propose a solution, GRENADE, a Graph-Centric Language model designed to address the issues common in self-supervised representation learning on text-attributed graphs. It leverages the synergy of both pre-trained language model and graph neural networks.", "example": "Convert the coordinate to text: [ 3.5064 -5.4649]:"}
{"text": "Convert the coordinate to text: [ 3.8075 -5.8411]: The authors propose Dynamic EMbedIngs fOr dynamic Tensor dEcomposition (DEMOTE), utilizing a neural diffusion-reaction process to estimate dynamic embeddings for the entities in each tensor mode. They use a graph diffusion process to co-evolve embedding trajectories and a neural network to construct a reaction process for each individual entity.", "target": "The authors propose Dynamic EMbedIngs fOr dynamic Tensor dEcomposition (DEMOTE), utilizing a neural diffusion-reaction process to estimate dynamic embeddings for the entities in each tensor mode. They use a graph diffusion process to co-evolve embedding trajectories and a neural network to construct a reaction process for each individual entity.", "example": "Convert the coordinate to text: [ 3.8075 -5.8411]:"}
{"text": "Convert the coordinate to text: [0.1986 2.6116]: A new uncertainty-aware fairness concept called Equal Opportunity of Coverage (EOC) is proposed that aims to achieve similar coverage rates for different groups with similar outcomes and maintain the population's coverage rate at a predetermined level, while ensuring that the prediction intervals are narrow and informative.", "target": "A new uncertainty-aware fairness concept called Equal Opportunity of Coverage (EOC) is proposed that aims to achieve similar coverage rates for different groups with similar outcomes and maintain the population's coverage rate at a predetermined level, while ensuring that the prediction intervals are narrow and informative.", "example": "Convert the coordinate to text: [0.1986 2.6116]:"}
{"text": "Convert the coordinate to text: [12.6797  2.9529]: The paper presents a novel framework for SMF that reconceptualizes it as a low-rank matrix estimation problem in a combined factor space, and proposes an efficient algorithm that is proven to converge exponentially fast to a global minimizer of the objective with arbitrary initialization.", "target": "The paper presents a novel framework for SMF that reconceptualizes it as a low-rank matrix estimation problem in a combined factor space, and proposes an efficient algorithm that is proven to converge exponentially fast to a global minimizer of the objective with arbitrary initialization.", "example": "Convert the coordinate to text: [12.6797  2.9529]:"}
{"text": "Convert the coordinate to text: [ 2.4865 -8.2391]: The authors propose a method that uses attention and gradient information to automatically locate the positions of key entities in the support images and focus attention during fine-tuning. This approach, applicable to different vision transformers and pre-training ways, helps further generalize the model to the query samples.", "target": "The authors propose a method that uses attention and gradient information to automatically locate the positions of key entities in the support images and focus attention during fine-tuning. This approach, applicable to different vision transformers and pre-training ways, helps further generalize the model to the query samples.", "example": "Convert the coordinate to text: [ 2.4865 -8.2391]:"}
{"text": "Convert the coordinate to text: [ 2.3891 -8.2799]: The authors propose a new transformer block named ConDaFormer which disassembles the cubic window into three orthogonal 2D planes, reducing computational costs and enabling the modeling of local 3D geometric structure.", "target": "The authors propose a new transformer block named ConDaFormer which disassembles the cubic window into three orthogonal 2D planes, reducing computational costs and enabling the modeling of local 3D geometric structure.", "example": "Convert the coordinate to text: [ 2.3891 -8.2799]:"}
{"text": "Convert the coordinate to text: [  3.2113 -11.6225]: The authors propose to incorporate 3D scene features for VSD using an external 3D scene extractor and construct a target object-centered 3D spatial scene graph (Go3D-S2G) for better spatial understanding, and a scene subgraph selecting mechanism for topologically-diverse subgraphs.", "target": "The authors propose to incorporate 3D scene features for VSD using an external 3D scene extractor and construct a target object-centered 3D spatial scene graph (Go3D-S2G) for better spatial understanding, and a scene subgraph selecting mechanism for topologically-diverse subgraphs.", "example": "Convert the coordinate to text: [  3.2113 -11.6225]:"}
{"text": "Convert the coordinate to text: [ 0.7525 -9.7241]: A new model, Cross2StrA, is proposed for unpaired cross-lingual image captioning, incorporating both scene graph structures and syntactic constituency trees for semantic structure-guided image-to-pivot captioning and syntactic structure-guided pivot-to-target translation.", "target": "A new model, Cross2StrA, is proposed for unpaired cross-lingual image captioning, incorporating both scene graph structures and syntactic constituency trees for semantic structure-guided image-to-pivot captioning and syntactic structure-guided pivot-to-target translation.", "example": "Convert the coordinate to text: [ 0.7525 -9.7241]:"}
{"text": "Convert the coordinate to text: [  3.4357 -13.2466]: The authors present a new open-source image-text dataset named 'Annotated 3D Shapes' (A3DS), which comprises over nine million exhaustive natural language annotations and over 12 million variable-granularity captions to enable the evaluation of pragmatic abilities.", "target": "The authors present a new open-source image-text dataset named 'Annotated 3D Shapes' (A3DS), which comprises over nine million exhaustive natural language annotations and over 12 million variable-granularity captions to enable the evaluation of pragmatic abilities.", "example": "Convert the coordinate to text: [  3.4357 -13.2466]:"}
{"text": "Convert the coordinate to text: [-6.7847 -5.861 ]: The authors collect and categorize over 220 popular handcrafted features based on past literature, and devise a systematically expandable, multilingual handcrafted linguistic feature extraction system, LFTK, that is open-source.", "target": "The authors collect and categorize over 220 popular handcrafted features based on past literature, and devise a systematically expandable, multilingual handcrafted linguistic feature extraction system, LFTK, that is open-source.", "example": "Convert the coordinate to text: [-6.7847 -5.861 ]:"}
{"text": "Convert the coordinate to text: [-5.6278 -6.4076]: The authors propose new criteria to evaluate the quality of lexical representation and vocabulary overlap observed in sub-word tokenizers for multilingual language models.", "target": "The authors propose new criteria to evaluate the quality of lexical representation and vocabulary overlap observed in sub-word tokenizers for multilingual language models.", "example": "Convert the coordinate to text: [-5.6278 -6.4076]:"}
{"text": "Convert the coordinate to text: [-8.1885 -8.2936]: The authors introduce an enhanced version of NArabizi Treebank with three main contributions: the addition of two novel annotation layers (named entity recognition and offensive language detection) and a re-annotation of the tokenization, morpho-syntactic and syntactic layers that ensure annotation consistency.", "target": "The authors introduce an enhanced version of NArabizi Treebank with three main contributions: the addition of two novel annotation layers (named entity recognition and offensive language detection) and a re-annotation of the tokenization, morpho-syntactic and syntactic layers that ensure annotation consistency.", "example": "Convert the coordinate to text: [-8.1885 -8.2936]:"}
{"text": "Convert the coordinate to text: [-2.152 -5.81 ]: The paper proposes a suite of techniques for entailment and evidence retrieval tasks in the context of natural language inference for clinical trial reports, using a BERT-based model named Bio+Clinical BERT that is pre-trained on clinical data.", "target": "The paper proposes a suite of techniques for entailment and evidence retrieval tasks in the context of natural language inference for clinical trial reports, using a BERT-based model named Bio+Clinical BERT that is pre-trained on clinical data.", "example": "Convert the coordinate to text: [-2.152 -5.81 ]:"}
{"text": "Convert the coordinate to text: [-3.8134 -6.6654]: The authors propose an approach to augment training data for multilingual named entity recognition through translations. The named entity spans from the original sentences are transferred to translations via word alignment and then filtered with a baseline recognizer.", "target": "The authors propose an approach to augment training data for multilingual named entity recognition through translations. The named entity spans from the original sentences are transferred to translations via word alignment and then filtered with a baseline recognizer.", "example": "Convert the coordinate to text: [-3.8134 -6.6654]:"}
{"text": "Convert the coordinate to text: [18.5119 -3.1887]: The authors have proposed a zero-shot approach of leveraging pre-trained models capable of Question Answering (QA) to extract clickbait spoilers from article texts. This is achieved by rephrasing the clickbait titles as questions to better suit the pretraining task of QA-capable models, and reordering the sentences by their relevance using a semantic similarity model.", "target": "The authors have proposed a zero-shot approach of leveraging pre-trained models capable of Question Answering (QA) to extract clickbait spoilers from article texts. This is achieved by rephrasing the clickbait titles as questions to better suit the pretraining task of QA-capable models, and reordering the sentences by their relevance using a semantic similarity model.", "example": "Convert the coordinate to text: [18.5119 -3.1887]:"}
{"text": "Convert the coordinate to text: [2.2169 0.1645]: The paper presents a predictive deep learning algorithm to infer CSAT on the 1-5 scale on inbound calls in real-time, focusing on maximizing precision for CSAT=1. This is done by reframing the problem as a binary class rather than a five-class problem during model fine-tuning, and then mapping binary outcomes back to five classes using temperature-scaled model probabilities.", "target": "The paper presents a predictive deep learning algorithm to infer CSAT on the 1-5 scale on inbound calls in real-time, focusing on maximizing precision for CSAT=1. This is done by reframing the problem as a binary class rather than a five-class problem during model fine-tuning, and then mapping binary outcomes back to five classes using temperature-scaled model probabilities.", "example": "Convert the coordinate to text: [2.2169 0.1645]:"}
{"text": "Convert the coordinate to text: [ 1.5816 -4.7102]: The paper introduces a new practical setting called Generalized Zero-Shot Class Incremental Learning (CI-GZSL), where unseen classes are incrementally learned without training samples while recognizing previously encountered classes. The proposed solution, MetaZSCIL, is a bi-level meta-learning based method that simulates the incremental learning process during offline training.", "target": "The paper introduces a new practical setting called Generalized Zero-Shot Class Incremental Learning (CI-GZSL), where unseen classes are incrementally learned without training samples while recognizing previously encountered classes. The proposed solution, MetaZSCIL, is a bi-level meta-learning based method that simulates the incremental learning process during offline training.", "example": "Convert the coordinate to text: [ 1.5816 -4.7102]:"}
{"text": "Convert the coordinate to text: [ 6.0688 -4.1386]: The paper defines a more realistic task termed as distribution-agnostic generalized category discovery (DA-GCD) which is about generating fine-grained predictions for both close and open-set classes in a long-tailed open-world setting. And introduces a new Self-Balanced Co-Advice contrastive framework (BaCon) which provides solutions to DA-GCD task.", "target": "The paper defines a more realistic task termed as distribution-agnostic generalized category discovery (DA-GCD) which is about generating fine-grained predictions for both close and open-set classes in a long-tailed open-world setting. And introduces a new Self-Balanced Co-Advice contrastive framework (BaCon) which provides solutions to DA-GCD task.", "example": "Convert the coordinate to text: [ 6.0688 -4.1386]:"}
{"text": "Convert the coordinate to text: [  9.4341 -12.6452]: This study introduces a novel image matching method, named Occ^2Net, that models occlusion relations using 3D occupancy and infers matching points in occluded regions.", "target": "This study introduces a novel image matching method, named Occ^2Net, that models occlusion relations using 3D occupancy and infers matching points in occluded regions.", "example": "Convert the coordinate to text: [  9.4341 -12.6452]:"}
{"text": "Convert the coordinate to text: [  8.6404 -11.9521]: The authors collaborated CLIP and GPT to create a unified 3D open-world learner named Point-CLIP V2, which is capable of zero-shot 3D classification, segmentation, and detection.", "target": "The authors collaborated CLIP and GPT to create a unified 3D open-world learner named Point-CLIP V2, which is capable of zero-shot 3D classification, segmentation, and detection.", "example": "Convert the coordinate to text: [  8.6404 -11.9521]:"}
{"text": "Convert the coordinate to text: [ 2.8013 -7.9321]: This study introduces the K-nearest neighbor attention with relative pose encoding (KNARPE), a novel attention mechanism, and the Heterogeneous Polyline Transformer with Relative pose encoding (HPTR), a hierarchical framework enabling asynchronous token update during the online inference.", "target": "This study introduces the K-nearest neighbor attention with relative pose encoding (KNARPE), a novel attention mechanism, and the Heterogeneous Polyline Transformer with Relative pose encoding (HPTR), a hierarchical framework enabling asynchronous token update during the online inference.", "example": "Convert the coordinate to text: [ 2.8013 -7.9321]:"}
{"text": "Convert the coordinate to text: [  9.9844 -19.3446]: In this paper, an unified optimization target called normalized depth is proposed to unify 3D detection problems, taking into account different pitch angles and focal lengths. The authors also develop a 3D normalized cube depth of obstacle to enhance the accuracy of monocular 3D detection.", "target": "In this paper, an unified optimization target called normalized depth is proposed to unify 3D detection problems, taking into account different pitch angles and focal lengths. The authors also develop a 3D normalized cube depth of obstacle to enhance the accuracy of monocular 3D detection.", "example": "Convert the coordinate to text: [  9.9844 -19.3446]:"}
{"text": "Convert the coordinate to text: [13.287  -2.9042]: The authors propose a novel approach for modeling and preventing errors in NAND flash memory, using the capabilities of generative and unsupervised machine learning methods. Specifically, they construct and train a neural modulator that translates information bits into programming operations on each memory cell in NAND devices, reducing programming errors and compensating for data degradation over time.", "target": "The authors propose a novel approach for modeling and preventing errors in NAND flash memory, using the capabilities of generative and unsupervised machine learning methods. Specifically, they construct and train a neural modulator that translates information bits into programming operations on each memory cell in NAND devices, reducing programming errors and compensating for data degradation over time.", "example": "Convert the coordinate to text: [13.287  -2.9042]:"}
{"text": "Convert the coordinate to text: [-4.7566 10.2412]: The tutorial focuses on the emerging area of open-domain creative generation, touching on aspects at both the sentence level and longer forms of text, demonstrating the importance of content planning, domain knowledge and creativity-specific heuristics.", "target": "The tutorial focuses on the emerging area of open-domain creative generation, touching on aspects at both the sentence level and longer forms of text, demonstrating the importance of content planning, domain knowledge and creativity-specific heuristics.", "example": "Convert the coordinate to text: [-4.7566 10.2412]:"}
{"text": "Convert the coordinate to text: [ 2.4168 -6.0538]: The authors propose the Mixture-Of-Memory Augmentation (MoMA) method, which retrieves augmentation documents from multiple information corpora, with a feature to include new memory at inference time, thereby enhancing the zero-shot generalization ability of language models.", "target": "The authors propose the Mixture-Of-Memory Augmentation (MoMA) method, which retrieves augmentation documents from multiple information corpora, with a feature to include new memory at inference time, thereby enhancing the zero-shot generalization ability of language models.", "example": "Convert the coordinate to text: [ 2.4168 -6.0538]:"}
{"text": "Convert the coordinate to text: [  8.5339 -21.6942]: The authors propose a new method that bridges the gap in recent trends by combining a parametric light model with 360-degree panoramas, resulting in an HDRI capable of being used in rendering engines. This method integrates advances in GAN-based LDR panorama extrapolation from regular images extended to HDR through parametric spherical gaussians.", "target": "The authors propose a new method that bridges the gap in recent trends by combining a parametric light model with 360-degree panoramas, resulting in an HDRI capable of being used in rendering engines. This method integrates advances in GAN-based LDR panorama extrapolation from regular images extended to HDR through parametric spherical gaussians.", "example": "Convert the coordinate to text: [  8.5339 -21.6942]:"}
{"text": "Convert the coordinate to text: [-12.5663  11.6935]: The authors present a longitudinal analysis that uses building energy data from a period covering the COVID-19 lockdown measures. The pandemic is viewed as a unique, grand-scale 'energy intervention' to help identify the energy associated with these buildings and their users.", "target": "The authors present a longitudinal analysis that uses building energy data from a period covering the COVID-19 lockdown measures. The pandemic is viewed as a unique, grand-scale 'energy intervention' to help identify the energy associated with these buildings and their users.", "example": "Convert the coordinate to text: [-12.5663  11.6935]:"}
{"text": "Convert the coordinate to text: [-1.2676  8.0859]: The authors propose DSR-LM, a Differentiable Symbolic Reasoning framework where pre-trained language models govern the perception of factual knowledge while a symbolic module performs deductive reasoning.", "target": "The authors propose DSR-LM, a Differentiable Symbolic Reasoning framework where pre-trained language models govern the perception of factual knowledge while a symbolic module performs deductive reasoning.", "example": "Convert the coordinate to text: [-1.2676  8.0859]:"}
{"text": "Convert the coordinate to text: [6.9239 0.2902]: The authors introduce a two-stage framework, RSMI, which combines randomized smoothing (RS) and masked inference (MI) to improve the adversarial robustness of NLP systems. RS is used to transform a classifier into a smoothed classifier to obtain robust representations, whereas MI forces a model to make use of the surrounding context of a masked token in an input sequence.", "target": "The authors introduce a two-stage framework, RSMI, which combines randomized smoothing (RS) and masked inference (MI) to improve the adversarial robustness of NLP systems. RS is used to transform a classifier into a smoothed classifier to obtain robust representations, whereas MI forces a model to make use of the surrounding context of a masked token in an input sequence.", "example": "Convert the coordinate to text: [6.9239 0.2902]:"}
{"text": "Convert the coordinate to text: [ 3.7348 -3.9408]: The paper proposes a novel attribution-driven knowledge distillation approach which uses the token-level rationale of the teacher model based on Integrated Gradients (IG) and transfers this attribution knowledge to the student model.", "target": "The paper proposes a novel attribution-driven knowledge distillation approach which uses the token-level rationale of the teacher model based on Integrated Gradients (IG) and transfers this attribution knowledge to the student model.", "example": "Convert the coordinate to text: [ 3.7348 -3.9408]:"}
{"text": "Convert the coordinate to text: [ 1.9525 -7.0497]: The authors propose a novel framework for MRE that simultaneously implements the idea of internal-information screening and external-information exploiting, which is characterized by the creation of a unified cross-modal graph (CMG) from visual and textual scene graphs, and the incorporation of latent multimodal topic features.", "target": "The authors propose a novel framework for MRE that simultaneously implements the idea of internal-information screening and external-information exploiting, which is characterized by the creation of a unified cross-modal graph (CMG) from visual and textual scene graphs, and the incorporation of latent multimodal topic features.", "example": "Convert the coordinate to text: [ 1.9525 -7.0497]:"}
{"text": "Convert the coordinate to text: [-1.2032 -5.0382]: This paper explores the potential of utilizing pseudo-code prompts, which are less ambiguous than natural language instructions, to improve the performance of pre-trained language models.", "target": "This paper explores the potential of utilizing pseudo-code prompts, which are less ambiguous than natural language instructions, to improve the performance of pre-trained language models.", "example": "Convert the coordinate to text: [-1.2032 -5.0382]:"}
{"text": "Convert the coordinate to text: [-5.9129 -0.6467]: The paper proposes a lightweight Domain Aligned Prefix Averaging (DAPA) approach for domain generalization in abstractive summarization, which computes weights for averaging source prefixes based on the similarity of generated summaries to their corresponding documents.", "target": "The paper proposes a lightweight Domain Aligned Prefix Averaging (DAPA) approach for domain generalization in abstractive summarization, which computes weights for averaging source prefixes based on the similarity of generated summaries to their corresponding documents.", "example": "Convert the coordinate to text: [-5.9129 -0.6467]:"}
{"text": "Convert the coordinate to text: [ 4.7479 -5.6884]: This paper proposes a Diffusion Event Graph Model (DEGM), a novel approach for event skeleton generation. This model has features such as embedding and rounding techniques with edge-based loss and a denoising training process to offer robustness and error correction capabilities, refining the latent representation during the schema generation process.", "target": "This paper proposes a Diffusion Event Graph Model (DEGM), a novel approach for event skeleton generation. This model has features such as embedding and rounding techniques with edge-based loss and a denoising training process to offer robustness and error correction capabilities, refining the latent representation during the schema generation process.", "example": "Convert the coordinate to text: [ 4.7479 -5.6884]:"}
{"text": "Convert the coordinate to text: [ -0.2655 -10.5603]: The study introduces HaVQA, the first multimodal dataset for VQA tasks in the Hausa language, created by manually translating English question-answer pairs associated with unique images from the Visual Genome dataset.", "target": "The study introduces HaVQA, the first multimodal dataset for VQA tasks in the Hausa language, created by manually translating English question-answer pairs associated with unique images from the Visual Genome dataset.", "example": "Convert the coordinate to text: [ -0.2655 -10.5603]:"}
{"text": "Convert the coordinate to text: [-2.5878 -8.5091]: This work reformulates EAE as a link prediction problem on AMR graphs, with a novel graph structure termed Tailored AMR Graph (TAG) introduced to modify and enhance AMR for the task. Alongside TAG, a new method using graph neural networks as a link prediction model to find event arguments is proposed.", "target": "This work reformulates EAE as a link prediction problem on AMR graphs, with a novel graph structure termed Tailored AMR Graph (TAG) introduced to modify and enhance AMR for the task. Alongside TAG, a new method using graph neural networks as a link prediction model to find event arguments is proposed.", "example": "Convert the coordinate to text: [-2.5878 -8.5091]:"}
{"text": "Convert the coordinate to text: [-5.1791 -6.3789]: The study introduces an unsupervised approach for paraphrasing multiword expressions using only monolingual corpus data and pre-trained language models, without any external resources or fine-tuning.", "target": "The study introduces an unsupervised approach for paraphrasing multiword expressions using only monolingual corpus data and pre-trained language models, without any external resources or fine-tuning.", "example": "Convert the coordinate to text: [-5.1791 -6.3789]:"}
{"text": "Convert the coordinate to text: [ 6.8952 11.615 ]: The authors propose an algorithm based on Thompson sampling with dynamically-sized episodes to optimally control unknown Markov Decision Processes (MDPs) with a countably infinite state-space and an unbounded cost function. This unknown MDP is governed by a random unknown parameter, which is generated via a given fixed prior distribution.", "target": "The authors propose an algorithm based on Thompson sampling with dynamically-sized episodes to optimally control unknown Markov Decision Processes (MDPs) with a countably infinite state-space and an unbounded cost function. This unknown MDP is governed by a random unknown parameter, which is generated via a given fixed prior distribution.", "example": "Convert the coordinate to text: [ 6.8952 11.615 ]:"}
{"text": "Convert the coordinate to text: [-3.7949 -7.0286]: This work explores the second language (L2) acquisition of neural language models by training bilingual language models in a scenario similar to human L2 acquisition.", "target": "This work explores the second language (L2) acquisition of neural language models by training bilingual language models in a scenario similar to human L2 acquisition.", "example": "Convert the coordinate to text: [-3.7949 -7.0286]:"}
{"text": "Convert the coordinate to text: [5.5161 1.9379]: FIRE, an optimization-based framework, is introduced for fast and interpretable rule extraction, that provides a sparse, usable collection of decision rules by fusing shared common antecedents, and using a non-convex sparsity-inducing penalty for rule selection.", "target": "FIRE, an optimization-based framework, is introduced for fast and interpretable rule extraction, that provides a sparse, usable collection of decision rules by fusing shared common antecedents, and using a non-convex sparsity-inducing penalty for rule selection.", "example": "Convert the coordinate to text: [5.5161 1.9379]:"}
{"text": "Convert the coordinate to text: [-3.1113 -6.6112]: The study investigates the effect of English monolingual and multilingual pre-trained models on the sentiment classification task for Nigerian Pidgin, employing both zero-shot models and a fine-tuned Nigerian Pidgin model.", "target": "The study investigates the effect of English monolingual and multilingual pre-trained models on the sentiment classification task for Nigerian Pidgin, employing both zero-shot models and a fine-tuned Nigerian Pidgin model.", "example": "Convert the coordinate to text: [-3.1113 -6.6112]:"}
{"text": "Convert the coordinate to text: [-5.9923 -0.907 ]: The BioLaySumm 2023 Shared Task aims at developing abstractive summarisation models for generating lay summaries of biomedical research articles in controllable and non-controllable settings.", "target": "The BioLaySumm 2023 Shared Task aims at developing abstractive summarisation models for generating lay summaries of biomedical research articles in controllable and non-controllable settings.", "example": "Convert the coordinate to text: [-5.9923 -0.907 ]:"}
{"text": "Convert the coordinate to text: [ 6.6457 -3.7688]: The authors propose a new approach to federated domain adaptation that uses distillation and instance weighting to facilitate knowledge transfer across platforms dealing with heterogeneous tag sets under the multi-domain setting.", "target": "The authors propose a new approach to federated domain adaptation that uses distillation and instance weighting to facilitate knowledge transfer across platforms dealing with heterogeneous tag sets under the multi-domain setting.", "example": "Convert the coordinate to text: [ 6.6457 -3.7688]:"}
{"text": "Convert the coordinate to text: [-1.0851 -5.0858]: This work proposes the Multi-View Knowledge Retrieval with Prompt Tuning (MVP-Tuning) method, which uses similar question-answer pairs in the training set to improve knowledge retrieval and employs a single prompt-tuned PLM to jointly model knowledge and input text.", "target": "This work proposes the Multi-View Knowledge Retrieval with Prompt Tuning (MVP-Tuning) method, which uses similar question-answer pairs in the training set to improve knowledge retrieval and employs a single prompt-tuned PLM to jointly model knowledge and input text.", "example": "Convert the coordinate to text: [-1.0851 -5.0858]:"}
{"text": "Convert the coordinate to text: [-8.9494 -6.9228]: The authors propose a unified approach for continuous and discontinuous constituency parsing via autoregressive span selection, where they sort gold spans in a predefined order and use a pointer network for selection, dealing with discontinuous spans by consecutively selecting their subspans from left to right.", "target": "The authors propose a unified approach for continuous and discontinuous constituency parsing via autoregressive span selection, where they sort gold spans in a predefined order and use a pointer network for selection, dealing with discontinuous spans by consecutively selecting their subspans from left to right.", "example": "Convert the coordinate to text: [-8.9494 -6.9228]:"}
{"text": "Convert the coordinate to text: [-5.516  1.133]: The authors propose a multilingual, multifacet dataset of news articles that is annotated for genre, framing, and persuasion techniques.", "target": "The authors propose a multilingual, multifacet dataset of news articles that is annotated for genre, framing, and persuasion techniques.", "example": "Convert the coordinate to text: [-5.516  1.133]:"}
{"text": "Convert the coordinate to text: [ 1.735  -7.8357]: This paper introduces an Asymmetric-Sensitive Transformer (AsT) to capture the uneven development of the bilateral femoral head and improve the detection of ONFH. This is achieved using a self-attention mechanism focused on femoral head regions, allowing for sensitivity to uneven development with the help of attention-shared transformers.", "target": "This paper introduces an Asymmetric-Sensitive Transformer (AsT) to capture the uneven development of the bilateral femoral head and improve the detection of ONFH. This is achieved using a self-attention mechanism focused on femoral head regions, allowing for sensitivity to uneven development with the help of attention-shared transformers.", "example": "Convert the coordinate to text: [ 1.735  -7.8357]:"}
{"text": "Convert the coordinate to text: [-14.3017   9.0834]: The paper highlights the need for an holistic approach to customer journey optimization that encapsulates all aspects of the customer experience.", "target": "The paper highlights the need for an holistic approach to customer journey optimization that encapsulates all aspects of the customer experience.", "example": "Convert the coordinate to text: [-14.3017   9.0834]:"}
{"text": "Convert the coordinate to text: [ 13.1827 -16.5042]: The authors propose a novel synthetic data framework, Retinal Optic Flow Learning (ROFL), and a new hierarchical VAE. They test these against alternative models on two tasks, predicting ground truth causes of retinal optic flow (e.g., self-motion) and predicting the responses of neurons in the motion processing pathway of primates.", "target": "The authors propose a novel synthetic data framework, Retinal Optic Flow Learning (ROFL), and a new hierarchical VAE. They test these against alternative models on two tasks, predicting ground truth causes of retinal optic flow (e.g., self-motion) and predicting the responses of neurons in the motion processing pathway of primates.", "example": "Convert the coordinate to text: [ 13.1827 -16.5042]:"}
{"text": "Convert the coordinate to text: [ 6.0409 -2.2927]: The authors present a new unsupervised Test-Time Training (TTT) technique based on the maximization of Mutual Information between multi-scale feature maps and a discrete latent representation, integrated into the standard training as an auxiliary clustering task.", "target": "The authors present a new unsupervised Test-Time Training (TTT) technique based on the maximization of Mutual Information between multi-scale feature maps and a discrete latent representation, integrated into the standard training as an auxiliary clustering task.", "example": "Convert the coordinate to text: [ 6.0409 -2.2927]:"}
{"text": "Convert the coordinate to text: [ 1.1629 -3.9262]: To overcome these challenges, a Multi-annotated explanation-guided learning (MAGI) framework is proposed. This framework uses a novel generative model to create comprehensive, high-quality annotations.", "target": "To overcome these challenges, a Multi-annotated explanation-guided learning (MAGI) framework is proposed. This framework uses a novel generative model to create comprehensive, high-quality annotations.", "example": "Convert the coordinate to text: [ 1.1629 -3.9262]:"}
{"text": "Convert the coordinate to text: [  6.3932 -12.0397]: The authors propose a novel method, RichSem, which effectively learns rich semantics from coarse locations without the need for accurate bounding boxes. The method utilizes rich semantics from the images as additional soft supervision for training object detectors which allows for more robust long-tailed object detection.", "target": "The authors propose a novel method, RichSem, which effectively learns rich semantics from coarse locations without the need for accurate bounding boxes. The method utilizes rich semantics from the images as additional soft supervision for training object detectors which allows for more robust long-tailed object detection.", "example": "Convert the coordinate to text: [  6.3932 -12.0397]:"}
{"text": "Convert the coordinate to text: [ 3.7304 -2.9204]: The authors propose an efficient meta neural heuristic (EMNH) that first trains a meta-model and then fine-tunes it with a few steps to solve corresponding single-objective subproblems. The EMNH leverages a (partial) architecture-shared multi-task model for parallel learning and applies a scaled symmetric sampling method to stabilize training.", "target": "The authors propose an efficient meta neural heuristic (EMNH) that first trains a meta-model and then fine-tunes it with a few steps to solve corresponding single-objective subproblems. The EMNH leverages a (partial) architecture-shared multi-task model for parallel learning and applies a scaled symmetric sampling method to stabilize training.", "example": "Convert the coordinate to text: [ 3.7304 -2.9204]:"}
{"text": "Convert the coordinate to text: [8.747  0.7889]: In this work, the authors introduce a hybrid-grained feature interaction selection approach that targets both feature field and feature value for deep sparse networks. They propose a decomposed space, calculated on the fly, to explore these spaces.", "target": "In this work, the authors introduce a hybrid-grained feature interaction selection approach that targets both feature field and feature value for deep sparse networks. They propose a decomposed space, calculated on the fly, to explore these spaces.", "example": "Convert the coordinate to text: [8.747  0.7889]:"}
{"text": "Convert the coordinate to text: [ 9.7055 12.2402]: This study introduces a new problem setting, referred to as bandit task assignment, that incorporates the processing time of each task in the bandit setting where the reward and processing time for each task follow unknown distributions that are only revealed after the task has been completed.", "target": "This study introduces a new problem setting, referred to as bandit task assignment, that incorporates the processing time of each task in the bandit setting where the reward and processing time for each task follow unknown distributions that are only revealed after the task has been completed.", "example": "Convert the coordinate to text: [ 9.7055 12.2402]:"}
{"text": "Convert the coordinate to text: [ 1.0315 -5.1151]: The paper proposes EZ-STANCE, a large English ZSSD dataset with 30,606 annotated text-target pairs. It goes beyond the VAST dataset by including varied domains and both noun-phrase and claim targets. They also introduce two new subtasks for ZSSD, named target-based and domain-based ZSSD.", "target": "The paper proposes EZ-STANCE, a large English ZSSD dataset with 30,606 annotated text-target pairs. It goes beyond the VAST dataset by including varied domains and both noun-phrase and claim targets. They also introduce two new subtasks for ZSSD, named target-based and domain-based ZSSD.", "example": "Convert the coordinate to text: [ 1.0315 -5.1151]:"}
{"text": "Convert the coordinate to text: [-8.0136  7.3963]: This study challenges the common 'echo chamber' narrative and proposes that individuals actually prefer to engage with the opposite ideological side in online discussions. Instead, the segregation observed is more demographic (based on aspects like age and income).", "target": "This study challenges the common 'echo chamber' narrative and proposes that individuals actually prefer to engage with the opposite ideological side in online discussions. Instead, the segregation observed is more demographic (based on aspects like age and income).", "example": "Convert the coordinate to text: [-8.0136  7.3963]:"}
{"text": "Convert the coordinate to text: [-2.457  -5.5627]: The study aims to explore the potential privacy threats posed by Large Language Models (LLMs), particularly those enhanced by OpenAI's ChatGPT, and contemplates that application-integrated LLMs might pose even more serious privacy dangers than previously anticipated.", "target": "The study aims to explore the potential privacy threats posed by Large Language Models (LLMs), particularly those enhanced by OpenAI's ChatGPT, and contemplates that application-integrated LLMs might pose even more serious privacy dangers than previously anticipated.", "example": "Convert the coordinate to text: [-2.457  -5.5627]:"}
{"text": "Convert the coordinate to text: [-6.1841 -1.1515]: A new framework, the metric preference checklist, is proposed. It assesses the discriminative power of automatic metrics in three NLG tasks: Text Summarization, Dialogue Response Generation, and Controlled Generation.", "target": "A new framework, the metric preference checklist, is proposed. It assesses the discriminative power of automatic metrics in three NLG tasks: Text Summarization, Dialogue Response Generation, and Controlled Generation.", "example": "Convert the coordinate to text: [-6.1841 -1.1515]:"}
{"text": "Convert the coordinate to text: [-1.3135 -7.9738]: The authors propose a novel image-to-text based TSR method that relieves error accumulation problems with a cascaded two-step decoder architecture. The first decoder predicts HTML table row tags non-autoregressively and the second predicts HTML table cell tags of each row in a semi-autoregressive manner.", "target": "The authors propose a novel image-to-text based TSR method that relieves error accumulation problems with a cascaded two-step decoder architecture. The first decoder predicts HTML table row tags non-autoregressively and the second predicts HTML table cell tags of each row in a semi-autoregressive manner.", "example": "Convert the coordinate to text: [-1.3135 -7.9738]:"}
{"text": "Convert the coordinate to text: [-0.73    0.5787]: The authors introduce CHBias, a new Chinese dataset for bias evaluation and mitigation in Chinese conversational language models, extending previous research by adding less-studied biases such as ageism and appearance biases.", "target": "The authors introduce CHBias, a new Chinese dataset for bias evaluation and mitigation in Chinese conversational language models, extending previous research by adding less-studied biases such as ageism and appearance biases.", "example": "Convert the coordinate to text: [-0.73    0.5787]:"}
{"text": "Convert the coordinate to text: [-1.1469  1.9698]: A new approach, Historical Data Reuse (HDR), is proposed to address this problem. HDR leverages historical data from previous promotions to better adapt the CVR prediction model during current and future sales promotions.", "target": "A new approach, Historical Data Reuse (HDR), is proposed to address this problem. HDR leverages historical data from previous promotions to better adapt the CVR prediction model during current and future sales promotions.", "example": "Convert the coordinate to text: [-1.1469  1.9698]:"}
{"text": "Convert the coordinate to text: [ 4.2316 -1.7474]: To address the limitations of current semi-supervised learning techniques, the authors introduce Jointprop, a Heterogeneous Graph-based Propagation framework that allows for simultaneous semi-supervised extraction of entities and relations. This captures the global structure information between the two tasks and leverages interactions within unlabeled data.", "target": "To address the limitations of current semi-supervised learning techniques, the authors introduce Jointprop, a Heterogeneous Graph-based Propagation framework that allows for simultaneous semi-supervised extraction of entities and relations. This captures the global structure information between the two tasks and leverages interactions within unlabeled data.", "example": "Convert the coordinate to text: [ 4.2316 -1.7474]:"}
{"text": "Convert the coordinate to text: [ 4.9953 -8.3108]: The authors propose Warpformer, a new approach that fully considers both intra-series irregularity and inter-series discrepancy through specific input representation, a warping module that unifies irregular time series on a certain scale, and a customized attention module for representation learning. Additionally, they stack multiple warping and attention modules to learn at different scales.", "target": "The authors propose Warpformer, a new approach that fully considers both intra-series irregularity and inter-series discrepancy through specific input representation, a warping module that unifies irregular time series on a certain scale, and a customized attention module for representation learning. Additionally, they stack multiple warping and attention modules to learn at different scales.", "example": "Convert the coordinate to text: [ 4.9953 -8.3108]:"}
{"text": "Convert the coordinate to text: [10.2059 -8.0322]: The authors propose Rapid Diffusion, a novel framework for training and deploying super-resolution, text-to-image latent diffusion models with rich entity knowledge injected and optimized networks.", "target": "The authors propose Rapid Diffusion, a novel framework for training and deploying super-resolution, text-to-image latent diffusion models with rich entity knowledge injected and optimized networks.", "example": "Convert the coordinate to text: [10.2059 -8.0322]:"}
{"text": "Convert the coordinate to text: [-3.4012 -1.9104]: The paper introduces a new approach for Structure-Aware Event Causality Generation (SEAG) which generates the event causality graph structure using a text2text generation method based on a pre-trained language model, aiming to address the limitations of traditional pipelined approaches.", "target": "The paper introduces a new approach for Structure-Aware Event Causality Generation (SEAG) which generates the event causality graph structure using a text2text generation method based on a pre-trained language model, aiming to address the limitations of traditional pipelined approaches.", "example": "Convert the coordinate to text: [-3.4012 -1.9104]:"}
{"text": "Convert the coordinate to text: [-0.5111 -6.901 ]: The authors propose a model that uses tree-transformers to generate sentence representations and a continuous update mechanism to fine-tune word embeddings, thereby enriching the sentence representations while maintaining syntactical information and enhancing semantic information.", "target": "The authors propose a model that uses tree-transformers to generate sentence representations and a continuous update mechanism to fine-tune word embeddings, thereby enriching the sentence representations while maintaining syntactical information and enhancing semantic information.", "example": "Convert the coordinate to text: [-0.5111 -6.901 ]:"}
{"text": "Convert the coordinate to text: [-7.297  -8.2625]: The authors create a new manually annotated dataset called the Korean-Learner-Morpheme (KLM) corpus, that features morpheme tokenization and part-of-speech (POS) tagging, specifically dealing with L2-Korean corpora.", "target": "The authors create a new manually annotated dataset called the Korean-Learner-Morpheme (KLM) corpus, that features morpheme tokenization and part-of-speech (POS) tagging, specifically dealing with L2-Korean corpora.", "example": "Convert the coordinate to text: [-7.297  -8.2625]:"}
{"text": "Convert the coordinate to text: [-11.7259   0.6375]: The authors propose a novel task, Comparison-Based database search Ambiguity handling (CBA), to handle database search result ambiguity in TOD systems. This task deals with ambiguity by comparing the properties of multiple entities, enabling users to choose based on their preferences.", "target": "The authors propose a novel task, Comparison-Based database search Ambiguity handling (CBA), to handle database search result ambiguity in TOD systems. This task deals with ambiguity by comparing the properties of multiple entities, enabling users to choose based on their preferences.", "example": "Convert the coordinate to text: [-11.7259   0.6375]:"}
{"text": "Convert the coordinate to text: [15.5643 -0.0267]: The authors propose a compression scheme named GPUSQ-TLM which utilizes the GPU-friendly 2:4 fine-grained structured sparsity and quantization characters, priming a dense TLM model to meet the GPU's acceleration constraint of sparse patterns with FP16 type before further quantizing it into a fixed-point one using quantization-aware training.", "target": "The authors propose a compression scheme named GPUSQ-TLM which utilizes the GPU-friendly 2:4 fine-grained structured sparsity and quantization characters, priming a dense TLM model to meet the GPU's acceleration constraint of sparse patterns with FP16 type before further quantizing it into a fixed-point one using quantization-aware training.", "example": "Convert the coordinate to text: [15.5643 -0.0267]:"}
{"text": "Convert the coordinate to text: [-3.2597 -3.424 ]: The authors introduce S2ynRE, a two-stage self-training framework that uses synthetic data for relation extraction. The framework first leverages large language models to adapt to the target domain and automatically generate large volumes of coherent, realistic training data.", "target": "The authors introduce S2ynRE, a two-stage self-training framework that uses synthetic data for relation extraction. The framework first leverages large language models to adapt to the target domain and automatically generate large volumes of coherent, realistic training data.", "example": "Convert the coordinate to text: [-3.2597 -3.424 ]:"}
{"text": "Convert the coordinate to text: [-0.6779  6.9967]: The study proposes Neural Probabilistic Soft Logic Dialogue Structure Induction (NEUPSL DSI), a neural-symbolic strategy that injects symbolic knowledge into the latent space of a generative neural model for improving DSI.", "target": "The study proposes Neural Probabilistic Soft Logic Dialogue Structure Induction (NEUPSL DSI), a neural-symbolic strategy that injects symbolic knowledge into the latent space of a generative neural model for improving DSI.", "example": "Convert the coordinate to text: [-0.6779  6.9967]:"}
{"text": "Convert the coordinate to text: [ 0.4169 -9.0208]: This paper proposes using language tied self-supervised learning combined with a modified backbone for temporal modeling in order to adapt an image CLIP model to the video domain, using a training approach that makes use of feature vectors of diverse action concepts formed from a language encoder.", "target": "This paper proposes using language tied self-supervised learning combined with a modified backbone for temporal modeling in order to adapt an image CLIP model to the video domain, using a training approach that makes use of feature vectors of diverse action concepts formed from a language encoder.", "example": "Convert the coordinate to text: [ 0.4169 -9.0208]:"}
{"text": "Convert the coordinate to text: [ 4.346  -2.8909]: The authors propose TaskExpert, a multi-task mixture-of-experts model that dynamically learns multiple representative task-generic feature spaces and decodes task-specific features by decomposing the backbone feature and using dynamic task-specific gating networks.", "target": "The authors propose TaskExpert, a multi-task mixture-of-experts model that dynamically learns multiple representative task-generic feature spaces and decodes task-specific features by decomposing the backbone feature and using dynamic task-specific gating networks.", "example": "Convert the coordinate to text: [ 4.346  -2.8909]:"}
{"text": "Convert the coordinate to text: [-4.278   3.7317]: The significant update of RecBole is presented in this paper, aimed to make the library more user-friendly and easy to use. The focus is on improving its data processing, training, and evaluation aspects, and releasing reproducible configurations for benchmarking recommendation models.", "target": "The significant update of RecBole is presented in this paper, aimed to make the library more user-friendly and easy to use. The focus is on improving its data processing, training, and evaluation aspects, and releasing reproducible configurations for benchmarking recommendation models.", "example": "Convert the coordinate to text: [-4.278   3.7317]:"}
{"text": "Convert the coordinate to text: [  7.8218 -11.8639]: In this study, a new Gather-and-Distribute (GD) mechanism is proposed, realized with convolution and self-attention operations, resulting in the Gold-YOLO model. This enhances multi-scale feature fusion capabilities and strikes a balance between latency and accuracy across all model scales. Unsupervised pretraining is also implemented in the YOLO-series for the first time.", "target": "In this study, a new Gather-and-Distribute (GD) mechanism is proposed, realized with convolution and self-attention operations, resulting in the Gold-YOLO model. This enhances multi-scale feature fusion capabilities and strikes a balance between latency and accuracy across all model scales. Unsupervised pretraining is also implemented in the YOLO-series for the first time.", "example": "Convert the coordinate to text: [  7.8218 -11.8639]:"}
{"text": "Convert the coordinate to text: [  9.4025 -18.3944]: The authors present a novel problem setting -- multi-task view synthesis (MTVS), which reinterprets multi-task prediction as a set of novel-view synthesis tasks for multiple scene properties, including RGB.", "target": "The authors present a novel problem setting -- multi-task view synthesis (MTVS), which reinterprets multi-task prediction as a set of novel-view synthesis tasks for multiple scene properties, including RGB.", "example": "Convert the coordinate to text: [  9.4025 -18.3944]:"}
{"text": "Convert the coordinate to text: [11.9119 -8.7782]: The authors present 'Diffusion in Style', a method that highlights the role of the initial latent tensor in determining the style of images generated by Stable Diffusion, proposing its adaptation to make fine-tuning more efficient.", "target": "The authors present 'Diffusion in Style', a method that highlights the role of the initial latent tensor in determining the style of images generated by Stable Diffusion, proposing its adaptation to make fine-tuning more efficient.", "example": "Convert the coordinate to text: [11.9119 -8.7782]:"}
{"text": "Convert the coordinate to text: [-5.8995  2.2546]: The authors introduce HeTrue, a publicly available dataset for evaluating the credibility of statements made by Israeli public figures and politicians. The dataset consists of 1021 statements manually annotated for their credibility status by Israeli professional journalists.", "target": "The authors introduce HeTrue, a publicly available dataset for evaluating the credibility of statements made by Israeli public figures and politicians. The dataset consists of 1021 statements manually annotated for their credibility status by Israeli professional journalists.", "example": "Convert the coordinate to text: [-5.8995  2.2546]:"}
{"text": "Convert the coordinate to text: [12.2832 -1.8629]: The authors propose careful design of deep RNNs using standard signal propagation strategies. This design includes linearizing and diagonalizing the recurrence, using better parameterizations and initializations, and ensuring proper normalization of the forward pass, leading to the new RNN block called the Linear Recurrent Unit.", "target": "The authors propose careful design of deep RNNs using standard signal propagation strategies. This design includes linearizing and diagonalizing the recurrence, using better parameterizations and initializations, and ensuring proper normalization of the forward pass, leading to the new RNN block called the Linear Recurrent Unit.", "example": "Convert the coordinate to text: [12.2832 -1.8629]:"}
{"text": "Convert the coordinate to text: [-6.4764 -4.9388]: The authors propose an approach that uses automatically generated natural language definitions of contextualized word usages as interpretable word and word sense representations. Using a dataset of usage examples for a target word and corresponding data-driven usage clusters as input, the authors use a Flan-T5 language model to generate a definition for each usage, then select the most prototypical definition in a usage cluster as the sense label.", "target": "The authors propose an approach that uses automatically generated natural language definitions of contextualized word usages as interpretable word and word sense representations. Using a dataset of usage examples for a target word and corresponding data-driven usage clusters as input, the authors use a Flan-T5 language model to generate a definition for each usage, then select the most prototypical definition in a usage cluster as the sense label.", "example": "Convert the coordinate to text: [-6.4764 -4.9388]:"}
{"text": "Convert the coordinate to text: [ 0.0649 -7.2629]: The authors present a Slow-Fast two-stream learning model, TranSFormer, which uses a 'slow' branch for subword sequences and a 'fast' branch for longer character sequences, with the fast branch being lighter by reducing the model width and enhancing the slow branch with fine-grained features.", "target": "The authors present a Slow-Fast two-stream learning model, TranSFormer, which uses a 'slow' branch for subword sequences and a 'fast' branch for longer character sequences, with the fast branch being lighter by reducing the model width and enhancing the slow branch with fine-grained features.", "example": "Convert the coordinate to text: [ 0.0649 -7.2629]:"}
{"text": "Convert the coordinate to text: [ 1.3137 -9.9321]: The authors tackle the problem of image-caption pretraining by introducing a curriculum learning framework inspired by studies in cognitive science dealing with children's language learning.", "target": "The authors tackle the problem of image-caption pretraining by introducing a curriculum learning framework inspired by studies in cognitive science dealing with children's language learning.", "example": "Convert the coordinate to text: [ 1.3137 -9.9321]:"}
{"text": "Convert the coordinate to text: [-3.2256 -5.6383]: The authors propose bgGLUE (Bulgarian General Language Understanding Evaluation), a benchmark for evaluating language models on NLU tasks in Bulgarian, covering a variety of NLP and machine learning tasks.", "target": "The authors propose bgGLUE (Bulgarian General Language Understanding Evaluation), a benchmark for evaluating language models on NLU tasks in Bulgarian, covering a variety of NLP and machine learning tasks.", "example": "Convert the coordinate to text: [-3.2256 -5.6383]:"}
{"text": "Convert the coordinate to text: [-1.3959  0.0443]: The authors propose an approach that uses a combination of sentence transformer models, including ALBERT, BERT, RoBERTa, DistilBERT, and XLNet, to detect and classify instances of online sexism more accurately.", "target": "The authors propose an approach that uses a combination of sentence transformer models, including ALBERT, BERT, RoBERTa, DistilBERT, and XLNet, to detect and classify instances of online sexism more accurately.", "example": "Convert the coordinate to text: [-1.3959  0.0443]:"}
{"text": "Convert the coordinate to text: [-1.724  -6.3126]: This paper presents a new approach to human value argument mining that uses contrastive learning to leverage the isotropy of language models. The authors fine-tune the DeBERTa-Large model in a multi-label classification format.", "target": "This paper presents a new approach to human value argument mining that uses contrastive learning to leverage the isotropy of language models. The authors fine-tune the DeBERTa-Large model in a multi-label classification format.", "example": "Convert the coordinate to text: [-1.724  -6.3126]:"}
{"text": "Convert the coordinate to text: [ 5.8984 -4.5137]: The authors propose HyperMixer, a simple variant of MLP-based architectures which forms the token mixing MLP dynamically using hypernetworks.", "target": "The authors propose HyperMixer, a simple variant of MLP-based architectures which forms the token mixing MLP dynamically using hypernetworks.", "example": "Convert the coordinate to text: [ 5.8984 -4.5137]:"}
{"text": "Convert the coordinate to text: [-5.5361 -0.66  ]: The authors propose UniSumm, a unified few-shot summarization model pre-trained with multiple summarization tasks that can be fine-tuned for any specific few-shot summarization task.", "target": "The authors propose UniSumm, a unified few-shot summarization model pre-trained with multiple summarization tasks that can be fine-tuned for any specific few-shot summarization task.", "example": "Convert the coordinate to text: [-5.5361 -0.66  ]:"}
{"text": "Convert the coordinate to text: [12.577  -4.8725]: The authors propose a defense framework that mitigates adversarial attacks by confusing attackers and correcting adversarial contexts caused by malicious perturbations. The framework includes a synonym-based transformation, a BERT-based defender, and a simple detection method.", "target": "The authors propose a defense framework that mitigates adversarial attacks by confusing attackers and correcting adversarial contexts caused by malicious perturbations. The framework includes a synonym-based transformation, a BERT-based defender, and a simple detection method.", "example": "Convert the coordinate to text: [12.577  -4.8725]:"}
{"text": "Convert the coordinate to text: [ 2.3118 -5.545 ]: The authors propose two new methods, TER and AER, which generate high-quality edge representation vectors based on graph structure and edge attributes respectively. TER captures high-order proximities of edges in an efficient and theoretically sound way, while AER augments edge attributes via a feature aggregation scheme.", "target": "The authors propose two new methods, TER and AER, which generate high-quality edge representation vectors based on graph structure and edge attributes respectively. TER captures high-order proximities of edges in an efficient and theoretically sound way, while AER augments edge attributes via a feature aggregation scheme.", "example": "Convert the coordinate to text: [ 2.3118 -5.545 ]:"}
{"text": "Convert the coordinate to text: [ 3.0217 -1.225 ]: The paper introduces a novel concept of pre-learning for future knowledge, where the feature space and output space are optimized for unlabeled data, thus allowing models to acquire knowledge for future classes and as a result, making the learning process for new classes as smooth as for old classes.", "target": "The paper introduces a novel concept of pre-learning for future knowledge, where the feature space and output space are optimized for unlabeled data, thus allowing models to acquire knowledge for future classes and as a result, making the learning process for new classes as smooth as for old classes.", "example": "Convert the coordinate to text: [ 3.0217 -1.225 ]:"}
{"text": "Convert the coordinate to text: [  9.7859 -11.6736]: The authors present ShapeScaffolder, a structure-based neural network for generating colored 3D shapes from a text description. The unique feature of the approach is the construction of structured shape implicit fields and alignment of two modalities via a part-level attention mechanism between shape parts and textual graph nodes.", "target": "The authors present ShapeScaffolder, a structure-based neural network for generating colored 3D shapes from a text description. The unique feature of the approach is the construction of structured shape implicit fields and alignment of two modalities via a part-level attention mechanism between shape parts and textual graph nodes.", "example": "Convert the coordinate to text: [  9.7859 -11.6736]:"}
{"text": "Convert the coordinate to text: [  9.0764 -12.9422]: To address the safety issue of weak illumination, the authors developed a thermal infrared blind road segmentation neural network (TINN) that preserves the inherent radiation characteristics within the thermal imaging process. This is opposed to conventional segmentation techniques that focus mainly on enhancing feature extraction and perception.", "target": "To address the safety issue of weak illumination, the authors developed a thermal infrared blind road segmentation neural network (TINN) that preserves the inherent radiation characteristics within the thermal imaging process. This is opposed to conventional segmentation techniques that focus mainly on enhancing feature extraction and perception.", "example": "Convert the coordinate to text: [  9.0764 -12.9422]:"}
{"text": "Convert the coordinate to text: [ 9.5267 -7.6891]: This paper presents a novel strategy that integrates global and local operators by employing image-adaptive 3D LUTs and local Laplacian filters. These new strategies involve the use of a closed-form Laplacian pyramid decomposition and reconstruction to manipulate the tone in the low-frequency image, and the refinement of edge details in an adaptive manner.", "target": "This paper presents a novel strategy that integrates global and local operators by employing image-adaptive 3D LUTs and local Laplacian filters. These new strategies involve the use of a closed-form Laplacian pyramid decomposition and reconstruction to manipulate the tone in the low-frequency image, and the refinement of edge details in an adaptive manner.", "example": "Convert the coordinate to text: [ 9.5267 -7.6891]:"}
{"text": "Convert the coordinate to text: [ 1.8689 -5.1714]: This paper investigates the adapter routing mechanism and proposes two variants: Multi-Head Routing (MHR) which combines subsets of adapter parameters, and MHR-z which tunes the routing function but not the adapters for improved parameter efficiency. Furthermore, the authors propose MHR-\u03bc which disregards routing and fine-tunes the average of the pre-trained adapters on each downstream task as a method for single-adapter fine-tuning.", "target": "This paper investigates the adapter routing mechanism and proposes two variants: Multi-Head Routing (MHR) which combines subsets of adapter parameters, and MHR-z which tunes the routing function but not the adapters for improved parameter efficiency. Furthermore, the authors propose MHR-\u03bc which disregards routing and fine-tunes the average of the pre-trained adapters on each downstream task as a method for single-adapter fine-tuning.", "example": "Convert the coordinate to text: [ 1.8689 -5.1714]:"}
{"text": "Convert the coordinate to text: [-0.8751  6.366 ]: The authors introduce a new MWP dataset, DMath (Diverse Math Word Problems), which offers a greater range in problem types, lexical usage patterns, languages, and intermediate solutions.", "target": "The authors introduce a new MWP dataset, DMath (Diverse Math Word Problems), which offers a greater range in problem types, lexical usage patterns, languages, and intermediate solutions.", "example": "Convert the coordinate to text: [-0.8751  6.366 ]:"}
{"text": "Convert the coordinate to text: [-0.7512 -6.7157]: The authors introduce MIReAD, a method that fine-tunes a transformer model to learn high-quality representations of scientific papers by predicting the target journal class based on the abstract.", "target": "The authors introduce MIReAD, a method that fine-tunes a transformer model to learn high-quality representations of scientific papers by predicting the target journal class based on the abstract.", "example": "Convert the coordinate to text: [-0.7512 -6.7157]:"}
{"text": "Convert the coordinate to text: [-4.3745  8.0006]: The paper presents Diana, a dynamic architecture-based lifelong learning model that learns a sequence of tasks with a prompt-enhanced language model using four types of hierarchically organized prompts to capture knowledge at different granularities, including task-specific knowledge and knowledge shared across input samples.", "target": "The paper presents Diana, a dynamic architecture-based lifelong learning model that learns a sequence of tasks with a prompt-enhanced language model using four types of hierarchically organized prompts to capture knowledge at different granularities, including task-specific knowledge and knowledge shared across input samples.", "example": "Convert the coordinate to text: [-4.3745  8.0006]:"}
{"text": "Convert the coordinate to text: [-3.1988 -6.8379]: This review paper surveys the literature investigating various factors contributing to the capacity of MLLMs to perform zero-shot cross-lingual transfer, aiming to provide a structured understanding and to resolve discrepancies among previous findings.", "target": "This review paper surveys the literature investigating various factors contributing to the capacity of MLLMs to perform zero-shot cross-lingual transfer, aiming to provide a structured understanding and to resolve discrepancies among previous findings.", "example": "Convert the coordinate to text: [-3.1988 -6.8379]:"}
{"text": "Convert the coordinate to text: [-3.2368 -6.1208]: This paper investigates the capacity of monolingual English language models to capture moral norms from various countries, and assesses their ability to understand both fine-grained moral variation over topics like 'homosexuality' and 'divorce', and shared or divergent global moral tendencies.", "target": "This paper investigates the capacity of monolingual English language models to capture moral norms from various countries, and assesses their ability to understand both fine-grained moral variation over topics like 'homosexuality' and 'divorce', and shared or divergent global moral tendencies.", "example": "Convert the coordinate to text: [-3.2368 -6.1208]:"}
{"text": "Convert the coordinate to text: [-5.3166 -0.9444]: The authors introduce the Hierarchical Ensemble of Summarization Models (HESM), a token-level ensemble of diverse fine-tuned Clinical-T5 models combined with Minimum Bayes Risk (MBR) decoding.", "target": "The authors introduce the Hierarchical Ensemble of Summarization Models (HESM), a token-level ensemble of diverse fine-tuned Clinical-T5 models combined with Minimum Bayes Risk (MBR) decoding.", "example": "Convert the coordinate to text: [-5.3166 -0.9444]:"}
{"text": "Convert the coordinate to text: [-5.9816 -7.429 ]: The authors propose WSPAlign, an approach to word alignment that relies on a large-scale, weakly-supervised dataset made up of noisy, partially aligned and non-parallel paragraphs, which is then used for pre-training via span prediction.", "target": "The authors propose WSPAlign, an approach to word alignment that relies on a large-scale, weakly-supervised dataset made up of noisy, partially aligned and non-parallel paragraphs, which is then used for pre-training via span prediction.", "example": "Convert the coordinate to text: [-5.9816 -7.429 ]:"}
{"text": "Convert the coordinate to text: [ 14.7904 -15.1647]: The authors propose Binary Radiance Fields (BiRF), a more storage-efficient radiance field representation that uses binary feature encoding and a 2D-3D hybrid feature grid design to maintain quality while dramatically reducing required storage size.", "target": "The authors propose Binary Radiance Fields (BiRF), a more storage-efficient radiance field representation that uses binary feature encoding and a 2D-3D hybrid feature grid design to maintain quality while dramatically reducing required storage size.", "example": "Convert the coordinate to text: [ 14.7904 -15.1647]:"}
{"text": "Convert the coordinate to text: [-10.5822  -2.0584]: The authors introduce a new problem of automatic question generation (QG) from multi-modal sources containing images and texts, and propose a simple solution called MultiQG-TI, which enables a text-only question generator to process both visual and textual inputs.", "target": "The authors introduce a new problem of automatic question generation (QG) from multi-modal sources containing images and texts, and propose a simple solution called MultiQG-TI, which enables a text-only question generator to process both visual and textual inputs.", "example": "Convert the coordinate to text: [-10.5822  -2.0584]:"}
{"text": "Convert the coordinate to text: [-8.1518 -3.7293]: The authors introduce ANALOGICAL, a new benchmark for intrinsic evaluation of LLMs across a taxonomy of analogies of long texts with six levels of complexity.", "target": "The authors introduce ANALOGICAL, a new benchmark for intrinsic evaluation of LLMs across a taxonomy of analogies of long texts with six levels of complexity.", "example": "Convert the coordinate to text: [-8.1518 -3.7293]:"}
{"text": "Convert the coordinate to text: [ 0.2516 -8.6897]: This paper investigates and compared three types of fusion strategies for MHD detection from textual data - (i) feature-level fusion, (ii) model fusion, and (iii) task fusion. The authors also propose the inclusion of personality information, along with emotion, as a new parameter.", "target": "This paper investigates and compared three types of fusion strategies for MHD detection from textual data - (i) feature-level fusion, (ii) model fusion, and (iii) task fusion. The authors also propose the inclusion of personality information, along with emotion, as a new parameter.", "example": "Convert the coordinate to text: [ 0.2516 -8.6897]:"}
{"text": "Convert the coordinate to text: [0.7703 1.5584]: The proposed CounterComp uses counterfactual scenarios to generate samples with compositional contrast, providing an approach based on metric learning rather than data augmentation.", "target": "The proposed CounterComp uses counterfactual scenarios to generate samples with compositional contrast, providing an approach based on metric learning rather than data augmentation.", "example": "Convert the coordinate to text: [0.7703 1.5584]:"}
{"text": "Convert the coordinate to text: [-0.5596 -9.0177]: The paper proposes MultiEMO, an attention-based correlation-aware multimodal fusion framework that integrates multimodal cues across textual, audio, and visual modalities using bidirectional multi-head cross-attention layers, and mitigates difficulty in recognizing minority and hard-to-distinguish emotions with a Sample-Weighted Focal Contrastive (SWFC) loss.", "target": "The paper proposes MultiEMO, an attention-based correlation-aware multimodal fusion framework that integrates multimodal cues across textual, audio, and visual modalities using bidirectional multi-head cross-attention layers, and mitigates difficulty in recognizing minority and hard-to-distinguish emotions with a Sample-Weighted Focal Contrastive (SWFC) loss.", "example": "Convert the coordinate to text: [-0.5596 -9.0177]:"}
{"text": "Convert the coordinate to text: [-10.5304  -1.3067]: The authors address the challenge of NFQA by introducing WikiHowQA, a new multi-document NFQA benchmark built on WikiHow, a website dedicated to answering \u201chow-to\u201d questions.", "target": "The authors address the challenge of NFQA by introducing WikiHowQA, a new multi-document NFQA benchmark built on WikiHow, a website dedicated to answering \u201chow-to\u201d questions.", "example": "Convert the coordinate to text: [-10.5304  -1.3067]:"}
{"text": "Convert the coordinate to text: [-4.3819  4.3814]: The authors propose a new approach to design efficient online recommendation algorithms that optimize for relevance and cross-team information flow in a temporal communication network in the workplace.", "target": "The authors propose a new approach to design efficient online recommendation algorithms that optimize for relevance and cross-team information flow in a temporal communication network in the workplace.", "example": "Convert the coordinate to text: [-4.3819  4.3814]:"}
{"text": "Convert the coordinate to text: [10.2643 -6.0582]: The authors propose a framework for end-to-end training of a sampling importance network, a latent space encoder network, and a denoiser network. The method uses reinforcement learning to optimize the sampling importance network, avoids the need for explicit numerically approximated gradients, and uses a latent space encoder instead of handcrafted spatiotemporal heuristics.", "target": "The authors propose a framework for end-to-end training of a sampling importance network, a latent space encoder network, and a denoiser network. The method uses reinforcement learning to optimize the sampling importance network, avoids the need for explicit numerically approximated gradients, and uses a latent space encoder instead of handcrafted spatiotemporal heuristics.", "example": "Convert the coordinate to text: [10.2643 -6.0582]:"}
{"text": "Convert the coordinate to text: [-0.752  -5.1883]: The authors propose a novel generative model, Order-Prompted Tag Sequence Generation (OP-TSG), which treats video tagging as a tag sequence generation problem guided by sample-dependent order prompts.", "target": "The authors propose a novel generative model, Order-Prompted Tag Sequence Generation (OP-TSG), which treats video tagging as a tag sequence generation problem guided by sample-dependent order prompts.", "example": "Convert the coordinate to text: [-0.752  -5.1883]:"}
{"text": "Convert the coordinate to text: [ 3.9814 -3.989 ]: The authors propose a simple but effective one-for-all KD framework called OFA-KD that enhances the distillation performance between heterogeneous architectures. They discard architecture-specific information by projecting intermediate features into an aligned latent space, and introduce an adaptive target enhancement scheme to minimize disturbance from irrelevant information to the student model.", "target": "The authors propose a simple but effective one-for-all KD framework called OFA-KD that enhances the distillation performance between heterogeneous architectures. They discard architecture-specific information by projecting intermediate features into an aligned latent space, and introduce an adaptive target enhancement scheme to minimize disturbance from irrelevant information to the student model.", "example": "Convert the coordinate to text: [ 3.9814 -3.989 ]:"}
{"text": "Convert the coordinate to text: [-1.0803 -5.0843]: The paper proposes a prompt-enhanced framework for GCL-based recommender systems, named CPTPP, which leverages the original GCL protocol through prompt tuning. In this approach, personalized user prompts are generated from summarized user profiles and combined with pre-trained user embeddings to conduct prompt-tuning in downstream tasks.", "target": "The paper proposes a prompt-enhanced framework for GCL-based recommender systems, named CPTPP, which leverages the original GCL protocol through prompt tuning. In this approach, personalized user prompts are generated from summarized user profiles and combined with pre-trained user embeddings to conduct prompt-tuning in downstream tasks.", "example": "Convert the coordinate to text: [-1.0803 -5.0843]:"}
{"text": "Convert the coordinate to text: [4.274  2.9574]: The authors propose a new encryption scheme to preserve the Gini impurity in the dataset, which is crucial for the construction of random forests. They modify the structure of the binary search tree to store multiple examples in each node and encrypt data features by incorporating label and order information.", "target": "The authors propose a new encryption scheme to preserve the Gini impurity in the dataset, which is crucial for the construction of random forests. They modify the structure of the binary search tree to store multiple examples in each node and encrypt data features by incorporating label and order information.", "example": "Convert the coordinate to text: [4.274  2.9574]:"}
{"text": "Convert the coordinate to text: [ 9.0024 10.4428]: The authors introduce several methods to approximate the infimum KL in a way that drastically reduces computational and memory costs of existing optimal algorithms, while maintaining their regret guarantees.", "target": "The authors introduce several methods to approximate the infimum KL in a way that drastically reduces computational and memory costs of existing optimal algorithms, while maintaining their regret guarantees.", "example": "Convert the coordinate to text: [ 9.0024 10.4428]:"}
{"text": "Convert the coordinate to text: [-4.2157  0.4968]: The authors propose a scope-assisted multi-view graph contrastive learning framework for aspect-based sentiment analysis, which mitigates noisy interference for better locating aspect and its corresponding sentiment opinion with aspect-specific scope, while also capturing the correlation and difference between sentiment polarities and syntactic/semantic information.", "target": "The authors propose a scope-assisted multi-view graph contrastive learning framework for aspect-based sentiment analysis, which mitigates noisy interference for better locating aspect and its corresponding sentiment opinion with aspect-specific scope, while also capturing the correlation and difference between sentiment polarities and syntactic/semantic information.", "example": "Convert the coordinate to text: [-4.2157  0.4968]:"}
{"text": "Convert the coordinate to text: [11.7343 -1.6165]: The authors find an analytical expression for the global minima of a deep linear network with weight decay and stochastic neurons and infer that the origin is a special point in the neural network loss landscape where highly nonlinear phenomenon emerge.", "target": "The authors find an analytical expression for the global minima of a deep linear network with weight decay and stochastic neurons and infer that the origin is a special point in the neural network loss landscape where highly nonlinear phenomenon emerge.", "example": "Convert the coordinate to text: [11.7343 -1.6165]:"}
{"text": "Convert the coordinate to text: [-9.145   8.6689]: This doctoral research project intends to explore how social media platforms could better empower users, especially the more vulnerable ones, and ensure a safer user experience.", "target": "This doctoral research project intends to explore how social media platforms could better empower users, especially the more vulnerable ones, and ensure a safer user experience.", "example": "Convert the coordinate to text: [-9.145   8.6689]:"}
{"text": "Convert the coordinate to text: [-0.3816  1.6802]: The authors propose a taxonomy of attributes drawing on a measurement modelling framework. This taxonomy captures the intended measure of bias tests and the manner in which the measurement is carried out.", "target": "The authors propose a taxonomy of attributes drawing on a measurement modelling framework. This taxonomy captures the intended measure of bias tests and the manner in which the measurement is carried out.", "example": "Convert the coordinate to text: [-0.3816  1.6802]:"}
{"text": "Convert the coordinate to text: [15.4647 -4.9742]: The authors propose an efficient neural architecture search (NAS) method for learning PET architectures through structured and unstructured pruning.", "target": "The authors propose an efficient neural architecture search (NAS) method for learning PET architectures through structured and unstructured pruning.", "example": "Convert the coordinate to text: [15.4647 -4.9742]:"}
{"text": "Convert the coordinate to text: [-8.1063  1.3327]: The authors propose EAR (Expansion And Reranking), a method that applies a query expansion model to generate a diverse set of queries, and then uses a query reranker to select the ones that could improve retrieval results.", "target": "The authors propose EAR (Expansion And Reranking), a method that applies a query expansion model to generate a diverse set of queries, and then uses a query reranker to select the ones that could improve retrieval results.", "example": "Convert the coordinate to text: [-8.1063  1.3327]:"}
{"text": "Convert the coordinate to text: [-2.6293 -2.4542]: The authors introduce a new dataset called DMASTE, which is manually annotated to fit real-world scenarios by providing more diverse and realistic reviews, including various lengths, diverse expressions, more aspect types, and more domains.", "target": "The authors introduce a new dataset called DMASTE, which is manually annotated to fit real-world scenarios by providing more diverse and realistic reviews, including various lengths, diverse expressions, more aspect types, and more domains.", "example": "Convert the coordinate to text: [-2.6293 -2.4542]:"}
{"text": "Convert the coordinate to text: [-12.2337   4.3641]: The authors introduce a Visual Knowledge oriented Programming platform (VisKoP) that allows humans to edit and debug KB queries. In addition to converting natural language questions into KoPL, VisKoP maps KoPL programs into graphical elements for simplified editing.", "target": "The authors introduce a Visual Knowledge oriented Programming platform (VisKoP) that allows humans to edit and debug KB queries. In addition to converting natural language questions into KoPL, VisKoP maps KoPL programs into graphical elements for simplified editing.", "example": "Convert the coordinate to text: [-12.2337   4.3641]:"}
{"text": "Convert the coordinate to text: [-1.1975 -6.6051]: The paper presents a variant of Transformer models that are fine-tuned and leverage external resources for Named Entity Recognition, including a Wikipedia-based reclassification system and an annotation campaign in Farsi.", "target": "The paper presents a variant of Transformer models that are fine-tuned and leverage external resources for Named Entity Recognition, including a Wikipedia-based reclassification system and an annotation campaign in Farsi.", "example": "Convert the coordinate to text: [-1.1975 -6.6051]:"}
{"text": "Convert the coordinate to text: [-2.6277 -6.7526]: The authors developed a classification system based on the RoBERTa-base model trained mostly on English to label the persuasion techniques across 9 different languages.", "target": "The authors developed a classification system based on the RoBERTa-base model trained mostly on English to label the persuasion techniques across 9 different languages.", "example": "Convert the coordinate to text: [-2.6277 -6.7526]:"}
{"text": "Convert the coordinate to text: [-5.218  -7.8634]: This paper proposes a new method for document-level translation repair (DocRepair) which is underpinned by a model to explicitly assess translation inconsistency. It detects inconsistencies in automatic translations and proposes translation candidates to rectify these inconsistencies.", "target": "This paper proposes a new method for document-level translation repair (DocRepair) which is underpinned by a model to explicitly assess translation inconsistency. It detects inconsistencies in automatic translations and proposes translation candidates to rectify these inconsistencies.", "example": "Convert the coordinate to text: [-5.218  -7.8634]:"}
{"text": "Convert the coordinate to text: [5.8846 8.4539]: The paper investigates the plausibility of applying multiple efficiency methods on models sequentially in a pipeline of operators and studies their commutativity and cumulativeness.", "target": "The paper investigates the plausibility of applying multiple efficiency methods on models sequentially in a pipeline of operators and studies their commutativity and cumulativeness.", "example": "Convert the coordinate to text: [5.8846 8.4539]:"}
{"text": "Convert the coordinate to text: [-5.7227 -2.8751]: The authors investigate the impact of incorporating contradiction as well as entailment in NLI for question answering.", "target": "The authors investigate the impact of incorporating contradiction as well as entailment in NLI for question answering.", "example": "Convert the coordinate to text: [-5.7227 -2.8751]:"}
{"text": "Convert the coordinate to text: [14.7388  4.9843]: The authors propose a dynamic many-to-one label assignment strategy named IOT, which transforms the label assignment process in OIE into an Optimal Transport problem. They also introduce an Assignment-guided Multi-granularity loss (AM) to make use of the knowledge from the assignment process.", "target": "The authors propose a dynamic many-to-one label assignment strategy named IOT, which transforms the label assignment process in OIE into an Optimal Transport problem. They also introduce an Assignment-guided Multi-granularity loss (AM) to make use of the knowledge from the assignment process.", "example": "Convert the coordinate to text: [14.7388  4.9843]:"}
{"text": "Convert the coordinate to text: [-3.8549 -1.9793]: This study introduces a retrieval strategy specifically designed for document-level EAE that augments it with pseudo demonstrations sampled from event semantic regions to cover alternatives in the same context and event schema.", "target": "This study introduces a retrieval strategy specifically designed for document-level EAE that augments it with pseudo demonstrations sampled from event semantic regions to cover alternatives in the same context and event schema.", "example": "Convert the coordinate to text: [-3.8549 -1.9793]:"}
{"text": "Convert the coordinate to text: [  4.6857 -10.8056]: The authors develop 'Ego-Only', the first approach that enables state-of-the-art action detection on egocentric videos, without any form of exocentric transferring. The authors propose a strategy that involves training of the video representation with a masked autoencoder that is finetuned for temporal segmentation.", "target": "The authors develop 'Ego-Only', the first approach that enables state-of-the-art action detection on egocentric videos, without any form of exocentric transferring. The authors propose a strategy that involves training of the video representation with a masked autoencoder that is finetuned for temporal segmentation.", "example": "Convert the coordinate to text: [  4.6857 -10.8056]:"}
{"text": "Convert the coordinate to text: [9.2105 4.3207]: The authors propose using the natural parametrization of the Gaussian for heteroscedastic regression, which is more stable. In addition, an efficient Laplace approximation for heteroscedastic neural networks is proposed that allows automatic regularization through empirical Bayes and provides epistemic uncertainties.", "target": "The authors propose using the natural parametrization of the Gaussian for heteroscedastic regression, which is more stable. In addition, an efficient Laplace approximation for heteroscedastic neural networks is proposed that allows automatic regularization through empirical Bayes and provides epistemic uncertainties.", "example": "Convert the coordinate to text: [9.2105 4.3207]:"}
{"text": "Convert the coordinate to text: [9.2892 4.3263]: This paper provides an alternative approach to scalability issues in variational GPs by making training and test conditionals flexible. More specifically, the authors propose decoupling the parametric form of the predictive mean and covariance in the conditionals, and learning independent parameters for predictive mean and covariance.", "target": "This paper provides an alternative approach to scalability issues in variational GPs by making training and test conditionals flexible. More specifically, the authors propose decoupling the parametric form of the predictive mean and covariance in the conditionals, and learning independent parameters for predictive mean and covariance.", "example": "Convert the coordinate to text: [9.2892 4.3263]:"}
{"text": "Convert the coordinate to text: [-0.9606 -7.2281]: The authors propose Big Little Decoder (BiLD), a framework containing two differently sized models that collaboratively generate text. The smaller model generates text autoregressively at low inference cost, and the larger model is invoked only occasionally to refine inaccuracies in a non-autoregressive manner. The BiLD also introduces two policies: a fallback policy to determine when to invoke the larger model, and a rollback policy to ascertain when the larger model needs to correct the smaller model's inaccuracies.", "target": "The authors propose Big Little Decoder (BiLD), a framework containing two differently sized models that collaboratively generate text. The smaller model generates text autoregressively at low inference cost, and the larger model is invoked only occasionally to refine inaccuracies in a non-autoregressive manner. The BiLD also introduces two policies: a fallback policy to determine when to invoke the larger model, and a rollback policy to ascertain when the larger model needs to correct the smaller model's inaccuracies.", "example": "Convert the coordinate to text: [-0.9606 -7.2281]:"}
{"text": "Convert the coordinate to text: [ 2.4387 -9.9943]: This paper introduces a novel model named CORE-3DVG specifically designed to overcome the challenges of 3D visual grounding by explicitly learning about contextual objects and their relations through three sequential modular networks.", "target": "This paper introduces a novel model named CORE-3DVG specifically designed to overcome the challenges of 3D visual grounding by explicitly learning about contextual objects and their relations through three sequential modular networks.", "example": "Convert the coordinate to text: [ 2.4387 -9.9943]:"}
{"text": "Convert the coordinate to text: [-5.4779 -0.5249]: The authors propose a new task, Multi-modal Perspective based Dialogue Summarization (MM-PerSumm) for educational environments, and propose an Image and Perspective-guided Dialogue Summarization (IP-Summ) model which uses a Seq2Seq language model that incorporates images and a perspective-based encoder that constructs a dialogue graph.", "target": "The authors propose a new task, Multi-modal Perspective based Dialogue Summarization (MM-PerSumm) for educational environments, and propose an Image and Perspective-guided Dialogue Summarization (IP-Summ) model which uses a Seq2Seq language model that incorporates images and a perspective-based encoder that constructs a dialogue graph.", "example": "Convert the coordinate to text: [-5.4779 -0.5249]:"}
{"text": "Convert the coordinate to text: [11.801  -1.7838]: The authors propose a new mean-field analysis of a two-layer neural network in an infinite-dimensional parameter space.", "target": "The authors propose a new mean-field analysis of a two-layer neural network in an infinite-dimensional parameter space.", "example": "Convert the coordinate to text: [11.801  -1.7838]:"}
{"text": "Convert the coordinate to text: [-2.1222 -5.4053]: The authors proposed the use of OpenAI's GPT-3 model to generate synthetic questionnaire responses about the experience of video games as art, a topic that is not easily addressed with traditional computational user models.", "target": "The authors proposed the use of OpenAI's GPT-3 model to generate synthetic questionnaire responses about the experience of video games as art, a topic that is not easily addressed with traditional computational user models.", "example": "Convert the coordinate to text: [-2.1222 -5.4053]:"}
{"text": "Convert the coordinate to text: [-1.6113 -2.6234]: This paper proposes a new task to detect commonsense causation between two events in an event sequence (i.e., context), called contextualized commonsense causal reasoning. It also proposes a new zero-shot framework: COLA (Contextualized Commonsense Causality Reasoner) to solve the task from the causal inference perspective.", "target": "This paper proposes a new task to detect commonsense causation between two events in an event sequence (i.e., context), called contextualized commonsense causal reasoning. It also proposes a new zero-shot framework: COLA (Contextualized Commonsense Causality Reasoner) to solve the task from the causal inference perspective.", "example": "Convert the coordinate to text: [-1.6113 -2.6234]:"}
{"text": "Convert the coordinate to text: [8.8842 1.263 ]: The authors propose a general framework for accommodating learnwares from heterogeneous feature spaces without requiring additional auxiliary data by utilizing the submitted RKME specifications to establish the relationship between different feature spaces.", "target": "The authors propose a general framework for accommodating learnwares from heterogeneous feature spaces without requiring additional auxiliary data by utilizing the submitted RKME specifications to establish the relationship between different feature spaces.", "example": "Convert the coordinate to text: [8.8842 1.263 ]:"}
{"text": "Convert the coordinate to text: [-9.9248 -8.2738]: The authors propose a novel speed-up of Jelinek and Lafferty's (1991) algorithm to improve algorithmic runtime with respect to the number of non-terminals in the grammar.", "target": "The authors propose a novel speed-up of Jelinek and Lafferty's (1991) algorithm to improve algorithmic runtime with respect to the number of non-terminals in the grammar.", "example": "Convert the coordinate to text: [-9.9248 -8.2738]:"}
{"text": "Convert the coordinate to text: [13.8486 -0.0178]: The paper proposes a machine learning framework, GG-ODE (Generalized Graph Ordinary Differential Equations), for learning continuous multi-agent system dynamics across different environments. It generalizes the system dynamics learning by capturing continuous interaction among agents through neural ordinary differential equations (ODE) parameterized by Graph Neural Networks (GNNs).", "target": "The paper proposes a machine learning framework, GG-ODE (Generalized Graph Ordinary Differential Equations), for learning continuous multi-agent system dynamics across different environments. It generalizes the system dynamics learning by capturing continuous interaction among agents through neural ordinary differential equations (ODE) parameterized by Graph Neural Networks (GNNs).", "example": "Convert the coordinate to text: [13.8486 -0.0178]:"}
{"text": "Convert the coordinate to text: [-3.1825 -2.9143]: The paper proposes a novel distantly supervised document-level biomedical relation extraction model that incorporates partial knowledge graphs which include the graph neighborhood of the entities appearing in each input document.", "target": "The paper proposes a novel distantly supervised document-level biomedical relation extraction model that incorporates partial knowledge graphs which include the graph neighborhood of the entities appearing in each input document.", "example": "Convert the coordinate to text: [-3.1825 -2.9143]:"}
{"text": "Convert the coordinate to text: [-0.8221 -6.9699]: The authors propose an approach that assembles sentence chunks to feed into the Transformer models in a manner that prevents the insertion of padding tokens and the truncation of sentences, hoping to achieve better sentence embeddings.", "target": "The authors propose an approach that assembles sentence chunks to feed into the Transformer models in a manner that prevents the insertion of padding tokens and the truncation of sentences, hoping to achieve better sentence embeddings.", "example": "Convert the coordinate to text: [-0.8221 -6.9699]:"}
{"text": "Convert the coordinate to text: [-4.8475 -7.8698]: The study presents a focused examination of translations about King Charles III as produced both by publicly-available MT systems and by a neural machine translation system trained specifically on Canadian parliamentary text, providing insights into the inadequacies of machine translation in handling new real-world context.", "target": "The study presents a focused examination of translations about King Charles III as produced both by publicly-available MT systems and by a neural machine translation system trained specifically on Canadian parliamentary text, providing insights into the inadequacies of machine translation in handling new real-world context.", "example": "Convert the coordinate to text: [-4.8475 -7.8698]:"}
{"text": "Convert the coordinate to text: [-0.7538 -6.9206]: The authors propose a modified transformer model architecture that distinguishes grocery brand names from general words in a query and correctly translates only the non-brand Hinglish words.", "target": "The authors propose a modified transformer model architecture that distinguishes grocery brand names from general words in a query and correctly translates only the non-brand Hinglish words.", "example": "Convert the coordinate to text: [-0.7538 -6.9206]:"}
{"text": "Convert the coordinate to text: [ 3.0714 -4.6544]: The authors propose to introduce attention labels into the dataset distillation process, as these can efficiently distill knowledge from the original dataset and transfer it to transformer models via attention probabilities.", "target": "The authors propose to introduce attention labels into the dataset distillation process, as these can efficiently distill knowledge from the original dataset and transfer it to transformer models via attention probabilities.", "example": "Convert the coordinate to text: [ 3.0714 -4.6544]:"}
{"text": "Convert the coordinate to text: [ 0.5894 -4.0779]: The paper presents Structure-based Pseudo Label generation (SPL), a novel method that tackles the above problems by generating free-form, interpretable pseudo-queries before creating query-dependent event proposals by modeling the event's temporal structure.", "target": "The paper presents Structure-based Pseudo Label generation (SPL), a novel method that tackles the above problems by generating free-form, interpretable pseudo-queries before creating query-dependent event proposals by modeling the event's temporal structure.", "example": "Convert the coordinate to text: [ 0.5894 -4.0779]:"}
{"text": "Convert the coordinate to text: [-3.8702  0.8672]: The authors introduce the X-CI, an Explainable Complaint dataset, and propose a commonsense-aware unified generative framework that reframes the multitask problem of complaint detection as a text-to-text generation task.", "target": "The authors introduce the X-CI, an Explainable Complaint dataset, and propose a commonsense-aware unified generative framework that reframes the multitask problem of complaint detection as a text-to-text generation task.", "example": "Convert the coordinate to text: [-3.8702  0.8672]:"}
{"text": "Convert the coordinate to text: [ 4.531  -1.2139]: In this study, the authors relax the previous assumption and propose that a small subset of the training data is clean, which can provide substantial gains in noisy label detection. They introduce a novel framework that uses clean data to frame noisy label detection as a multiple hypothesis testing problem.", "target": "In this study, the authors relax the previous assumption and propose that a small subset of the training data is clean, which can provide substantial gains in noisy label detection. They introduce a novel framework that uses clean data to frame noisy label detection as a multiple hypothesis testing problem.", "example": "Convert the coordinate to text: [ 4.531  -1.2139]:"}
{"text": "Convert the coordinate to text: [ 2.9174 13.7939]: The authors suggest adopting stochastic differential games to utilize interacting collective intelligence in time series analysis, and propose a gradient descent-based algorithm called deep neural fictitious play to approximate the Nash equilibrium.", "target": "The authors suggest adopting stochastic differential games to utilize interacting collective intelligence in time series analysis, and propose a gradient descent-based algorithm called deep neural fictitious play to approximate the Nash equilibrium.", "example": "Convert the coordinate to text: [ 2.9174 13.7939]:"}
{"text": "Convert the coordinate to text: [  8.4712 -12.542 ]: The authors propose Uni3DETR, a unified 3D detector that can handle both indoor and outdoor 3D detections using the same framework. It utilizes a detection transformer with point-voxel interaction and a proposed mixture of query points, which optimally exploits global information for dense indoor scenes and local information for sparse outdoor scenes.", "target": "The authors propose Uni3DETR, a unified 3D detector that can handle both indoor and outdoor 3D detections using the same framework. It utilizes a detection transformer with point-voxel interaction and a proposed mixture of query points, which optimally exploits global information for dense indoor scenes and local information for sparse outdoor scenes.", "example": "Convert the coordinate to text: [  8.4712 -12.542 ]:"}
{"text": "Convert the coordinate to text: [13.2289 -8.2518]: The paper introduces 3DHumanGAN, a 3D-aware GAN that generates high-quality images of humans with consistent appearances under different view-angles and body-poses. It proposes a new generator architecture that employs a 2D convolutional backbone modulated by a 3D pose mapping network.", "target": "The paper introduces 3DHumanGAN, a 3D-aware GAN that generates high-quality images of humans with consistent appearances under different view-angles and body-poses. It proposes a new generator architecture that employs a 2D convolutional backbone modulated by a 3D pose mapping network.", "example": "Convert the coordinate to text: [13.2289 -8.2518]:"}
{"text": "Convert the coordinate to text: [13.5185 -4.7981]: A certified backdoor detector (CBD) is introduced, based on a novel, adjustable conformal prediction scheme using a metric called local dominant probability. This detector provides detection inference, detectable attack conditions, and a probabilistic upper bound for the false positive rate.", "target": "A certified backdoor detector (CBD) is introduced, based on a novel, adjustable conformal prediction scheme using a metric called local dominant probability. This detector provides detection inference, detectable attack conditions, and a probabilistic upper bound for the false positive rate.", "example": "Convert the coordinate to text: [13.5185 -4.7981]:"}
{"text": "Convert the coordinate to text: [ -0.2384 -10.6445]: This study introduces the task of 3D-aware VQA which involves reasoning over the 3D structure of visual scenes and proposes a 3D-aware VQA model called PO3D-VQA that combines probabilistic neural symbolic program execution for reasoning and deep neural networks with 3D generative representations of objects for robust visual recognition.", "target": "This study introduces the task of 3D-aware VQA which involves reasoning over the 3D structure of visual scenes and proposes a 3D-aware VQA model called PO3D-VQA that combines probabilistic neural symbolic program execution for reasoning and deep neural networks with 3D generative representations of objects for robust visual recognition.", "example": "Convert the coordinate to text: [ -0.2384 -10.6445]:"}
{"text": "Convert the coordinate to text: [  6.7658 -11.8597]: A novel approach named Hierarchical Adaptive Self-Supervised Object Detection (HASSOD) is proposed. HASSOD learns to detect objects and understand their compositions without human supervision through a hierarchical adaptive clustering strategy for grouping regions into object masks and identifying hierarchical levels of objects in terms of composition.", "target": "A novel approach named Hierarchical Adaptive Self-Supervised Object Detection (HASSOD) is proposed. HASSOD learns to detect objects and understand their compositions without human supervision through a hierarchical adaptive clustering strategy for grouping regions into object masks and identifying hierarchical levels of objects in terms of composition.", "example": "Convert the coordinate to text: [  6.7658 -11.8597]:"}
{"text": "Convert the coordinate to text: [-2.7704 -6.2435]: Based on the observation that the performance of pre-trained language models is significantly tied to syntactically changed tokens, the authors propose SG-TLM, a method which learns inherent language changes by capturing the intrinsic relationship between the time prefix and the tokens with marked syntactic change.", "target": "Based on the observation that the performance of pre-trained language models is significantly tied to syntactically changed tokens, the authors propose SG-TLM, a method which learns inherent language changes by capturing the intrinsic relationship between the time prefix and the tokens with marked syntactic change.", "example": "Convert the coordinate to text: [-2.7704 -6.2435]:"}
{"text": "Convert the coordinate to text: [ 1.0852 -5.1963]: This study introduces a new perspective on stance detection where the background knowledge of the targets is considered for better stance detection. The authors propose a novel Knowledge-Augmented Stance Detection (KASD) framework where the background knowledge is categorized into two types: episodic knowledge and discourse knowledge.", "target": "This study introduces a new perspective on stance detection where the background knowledge of the targets is considered for better stance detection. The authors propose a novel Knowledge-Augmented Stance Detection (KASD) framework where the background knowledge is categorized into two types: episodic knowledge and discourse knowledge.", "example": "Convert the coordinate to text: [ 1.0852 -5.1963]:"}
{"text": "Convert the coordinate to text: [10.7976 -6.4366]: The paper presents a more comprehensive perspective on denoising diffusion models by introducing novel condition- and training-free strategies, namely 'blur guidance', which benefits intermediate samples with its fine-scale information and structures, and 'Self-Attention Guidance (SAG)', which uses the intermediate self-attention maps of diffusion models to enhance their stability and efficacy.", "target": "The paper presents a more comprehensive perspective on denoising diffusion models by introducing novel condition- and training-free strategies, namely 'blur guidance', which benefits intermediate samples with its fine-scale information and structures, and 'Self-Attention Guidance (SAG)', which uses the intermediate self-attention maps of diffusion models to enhance their stability and efficacy.", "example": "Convert the coordinate to text: [10.7976 -6.4366]:"}
{"text": "Convert the coordinate to text: [3.343  6.8948]: Atrapos is presented as a new approach for the real-time evaluation of metapath query workloads that leverages efficient sparse matrix multiplication and intermediate result caching.", "target": "Atrapos is presented as a new approach for the real-time evaluation of metapath query workloads that leverages efficient sparse matrix multiplication and intermediate result caching.", "example": "Convert the coordinate to text: [3.343  6.8948]:"}
{"text": "Convert the coordinate to text: [-3.1396 -6.508 ]: The authors propose a strategy for horizontally scaling LLMs to cover 511 languages, including many low-resource ones, by creating an LLM, Glot500-m, continued pretraining. Additionally, they compile a new multi-language corpus, Glot500-c, to facilitate this scaling.", "target": "The authors propose a strategy for horizontally scaling LLMs to cover 511 languages, including many low-resource ones, by creating an LLM, Glot500-m, continued pretraining. Additionally, they compile a new multi-language corpus, Glot500-c, to facilitate this scaling.", "example": "Convert the coordinate to text: [-3.1396 -6.508 ]:"}
{"text": "Convert the coordinate to text: [ 2.3788 -2.9764]: The key idea in this paper is the study of catastrophic forgetting and methods to minimize this within a massively multilingual continual learning framework. The authors present LR ADJUST, a learning rate scheduling method that helps to preserve new information without strongly overwriting past knowledge.", "target": "The key idea in this paper is the study of catastrophic forgetting and methods to minimize this within a massively multilingual continual learning framework. The authors present LR ADJUST, a learning rate scheduling method that helps to preserve new information without strongly overwriting past knowledge.", "example": "Convert the coordinate to text: [ 2.3788 -2.9764]:"}
{"text": "Convert the coordinate to text: [-9.6491 -7.0751]: The authors propose a Semi-Autoregressive Dependency Parser. This model generates dependency graphs by adding node and edge groups autoregressively, then outputting all group elements in parallel. It is designed to strike a balance between non-autoregression and autoregression.", "target": "The authors propose a Semi-Autoregressive Dependency Parser. This model generates dependency graphs by adding node and edge groups autoregressively, then outputting all group elements in parallel. It is designed to strike a balance between non-autoregression and autoregression.", "example": "Convert the coordinate to text: [-9.6491 -7.0751]:"}
{"text": "Convert the coordinate to text: [-2.9999 -7.7147]: The authors propose a monolingual PLM-sponsored NMT model to allow both the encoder and decoder to benefit from the PLM enhancement. This is achieved by incorporating a novel frequency-weighted embedding transformation algorithm.", "target": "The authors propose a monolingual PLM-sponsored NMT model to allow both the encoder and decoder to benefit from the PLM enhancement. This is achieved by incorporating a novel frequency-weighted embedding transformation algorithm.", "example": "Convert the coordinate to text: [-2.9999 -7.7147]:"}
{"text": "Convert the coordinate to text: [-7.4482 -4.1695]: The authors probe the performance of three black-box TLMs and two intrinsically transparent white-box models on figurative language classification of sarcasm, similes, idioms, and metaphors. They conduct two studies on the classification results to provide insights into the inner workings of such models.", "target": "The authors probe the performance of three black-box TLMs and two intrinsically transparent white-box models on figurative language classification of sarcasm, similes, idioms, and metaphors. They conduct two studies on the classification results to provide insights into the inner workings of such models.", "example": "Convert the coordinate to text: [-7.4482 -4.1695]:"}
{"text": "Convert the coordinate to text: [18.5017 -3.2015]: They employed transformer models in ensemble configuration for Clickbait classification and proposed a two-level ensemble strategy trained for extractive QA for Spoiler Generation task.", "target": "They employed transformer models in ensemble configuration for Clickbait classification and proposed a two-level ensemble strategy trained for extractive QA for Spoiler Generation task.", "example": "Convert the coordinate to text: [18.5017 -3.2015]:"}
{"text": "Convert the coordinate to text: [ 3.4075 -5.5317]: The authors present the Graph Neural Network-based model with a pre-trained Language Model (GNNLM), which uniquely incorporates the relationship between users and products.", "target": "The authors present the Graph Neural Network-based model with a pre-trained Language Model (GNNLM), which uniquely incorporates the relationship between users and products.", "example": "Convert the coordinate to text: [ 3.4075 -5.5317]:"}
{"text": "Convert the coordinate to text: [-1.0826 -5.2226]: The authors formally define Fixed Input Parameterization (FIP) problem that focuses on injecting the fixed prompt into the parameters of an LM as an efficient alternative to attaching fixed prompts to the input.", "target": "The authors formally define Fixed Input Parameterization (FIP) problem that focuses on injecting the fixed prompt into the parameters of an LM as an efficient alternative to attaching fixed prompts to the input.", "example": "Convert the coordinate to text: [-1.0826 -5.2226]:"}
{"text": "Convert the coordinate to text: [ 3.3246 -7.8114]: The authors propose a Frequency Attention (FA) model to capture global temporal dependencies between a relation and the entire timestamp using Discrete Cosine Transform (DCT). Additionally, the authors introduce Orthogonal Regularization (OR) variants for the core tensor, limiting non-superdiagonal elements of the 3-rd core tensor.", "target": "The authors propose a Frequency Attention (FA) model to capture global temporal dependencies between a relation and the entire timestamp using Discrete Cosine Transform (DCT). Additionally, the authors introduce Orthogonal Regularization (OR) variants for the core tensor, limiting non-superdiagonal elements of the 3-rd core tensor.", "example": "Convert the coordinate to text: [ 3.3246 -7.8114]:"}
{"text": "Convert the coordinate to text: [-3.663  -6.7858]: The authors present the Cross-lingual Continual Learning (CCL) evaluation paradigm that can continually adapt to emerging data from different languages sequentially, which goes beyond traditional transfer learning.", "target": "The authors present the Cross-lingual Continual Learning (CCL) evaluation paradigm that can continually adapt to emerging data from different languages sequentially, which goes beyond traditional transfer learning.", "example": "Convert the coordinate to text: [-3.663  -6.7858]:"}
{"text": "Convert the coordinate to text: [-4.3265 -7.9331]: The paper proposes a novel approach that leverages traditional translation models as teachers and employs a two-stage beam search algorithm to generate monotonic yet accurate reference translations for sequence-level knowledge distillation.", "target": "The paper proposes a novel approach that leverages traditional translation models as teachers and employs a two-stage beam search algorithm to generate monotonic yet accurate reference translations for sequence-level knowledge distillation.", "example": "Convert the coordinate to text: [-4.3265 -7.9331]:"}
{"text": "Convert the coordinate to text: [ 6.6454 -4.1056]: The authors propose a new cross-domain Data Augmentation approach called DA 2 LM that is based on Domain-Adaptive Language Modeling. The approach has three steps: assigning pseudo labels to unlabeled target-domain data; unifying token generation and labeling with a Domain-Adaptive Language Model (DALM); using the trained DALM to generate labeled target-domain data.", "target": "The authors propose a new cross-domain Data Augmentation approach called DA 2 LM that is based on Domain-Adaptive Language Modeling. The approach has three steps: assigning pseudo labels to unlabeled target-domain data; unifying token generation and labeling with a Domain-Adaptive Language Model (DALM); using the trained DALM to generate labeled target-domain data.", "example": "Convert the coordinate to text: [ 6.6454 -4.1056]:"}
{"text": "Convert the coordinate to text: [  5.9324 -12.2609]: A novel weakly-supervised tissue segmentation framework, PistoSeg, is proposed. This framework is implemented in a fully-supervised manner by transferring tissue category labels to pixel-level masks.", "target": "A novel weakly-supervised tissue segmentation framework, PistoSeg, is proposed. This framework is implemented in a fully-supervised manner by transferring tissue category labels to pixel-level masks.", "example": "Convert the coordinate to text: [  5.9324 -12.2609]:"}
{"text": "Convert the coordinate to text: [  6.4973 -11.6865]: The authors propose ALWOD, a new framework that fuses active learning with weakly and semi-supervised object detection paradigms. It includes an auxiliary image generator strategy for model initialization and a new AL acquisition function for proposing the most informative images to annotate.", "target": "The authors propose ALWOD, a new framework that fuses active learning with weakly and semi-supervised object detection paradigms. It includes an auxiliary image generator strategy for model initialization and a new AL acquisition function for proposing the most informative images to annotate.", "example": "Convert the coordinate to text: [  6.4973 -11.6865]:"}
{"text": "Convert the coordinate to text: [ 4.9862 14.2011]: The authors propose to use reinforcement learning to modify the output of the video captioning model to be more class-level discriminative. They present ReGen, a reinforcement learning based framework with three-fold objective reward functions.", "target": "The authors propose to use reinforcement learning to modify the output of the video captioning model to be more class-level discriminative. They present ReGen, a reinforcement learning based framework with three-fold objective reward functions.", "example": "Convert the coordinate to text: [ 4.9862 14.2011]:"}
{"text": "Convert the coordinate to text: [ 2.9978 -8.7555]: This paper proposes a new design scheme called spatially decoupled DETR (SD-DETR). It decouples localization and classification tasks in DETR by introducing a task-aware query generation module and a disentangled feature learning process.", "target": "This paper proposes a new design scheme called spatially decoupled DETR (SD-DETR). It decouples localization and classification tasks in DETR by introducing a task-aware query generation module and a disentangled feature learning process.", "example": "Convert the coordinate to text: [ 2.9978 -8.7555]:"}
{"text": "Convert the coordinate to text: [10.6232 -3.3259]: The authors observed that directly averaging the weights of the adjacent learned subnetworks significantly improves the performance of LTs. Based on this, they propose a method called 'Lottery Pools', an alternative way to perform an 'ensemble' over the subnetworks identified by iterative magnitude pruning, using a simple interpolating strategy.", "target": "The authors observed that directly averaging the weights of the adjacent learned subnetworks significantly improves the performance of LTs. Based on this, they propose a method called 'Lottery Pools', an alternative way to perform an 'ensemble' over the subnetworks identified by iterative magnitude pruning, using a simple interpolating strategy.", "example": "Convert the coordinate to text: [10.6232 -3.3259]:"}
{"text": "Convert the coordinate to text: [ 1.9883 -6.3086]: FormNetV2 introduces a centralized multimodal graph contrastive learning strategy to unify self-supervised pre-training for all modalities in one loss. Image features are extracted within the bounding box that joins a pair of tokens connected by a graph edge, capturing more targeted visual cues without a separately pre-trained image embedder.", "target": "FormNetV2 introduces a centralized multimodal graph contrastive learning strategy to unify self-supervised pre-training for all modalities in one loss. Image features are extracted within the bounding box that joins a pair of tokens connected by a graph edge, capturing more targeted visual cues without a separately pre-trained image embedder.", "example": "Convert the coordinate to text: [ 1.9883 -6.3086]:"}
{"text": "Convert the coordinate to text: [-0.7847  0.4366]: The authors propose Finspector, a human-centered visual inspection tool designed to detect biases in different categories using log-likelihood scores generated by language models.", "target": "The authors propose Finspector, a human-centered visual inspection tool designed to detect biases in different categories using log-likelihood scores generated by language models.", "example": "Convert the coordinate to text: [-0.7847  0.4366]:"}
{"text": "Convert the coordinate to text: [-4.7533 -8.1936]: The authors introduce HistRED, a dataset constructed from Yeonhaengnok, a collection of records originally written in Hanja and translated into Korean. HistRED provides bilingual annotations to support RE tasks on Korean and Hanja texts, covering various self-contained subtexts with different lengths, from sentence level to document level.", "target": "The authors introduce HistRED, a dataset constructed from Yeonhaengnok, a collection of records originally written in Hanja and translated into Korean. HistRED provides bilingual annotations to support RE tasks on Korean and Hanja texts, covering various self-contained subtexts with different lengths, from sentence level to document level.", "example": "Convert the coordinate to text: [-4.7533 -8.1936]:"}
{"text": "Convert the coordinate to text: [ 3.1776 -6.5121]: Team RGAT uses a unique approach where the dependency tree of the input query is used as an additional feature in a Graph Attention Network, along with token and part-of-speech features. The team also experiments with adding BiLSTM and Transformer layers in addition to a CRF layer.", "target": "Team RGAT uses a unique approach where the dependency tree of the input query is used as an additional feature in a Graph Attention Network, along with token and part-of-speech features. The team also experiments with adding BiLSTM and Transformer layers in addition to a CRF layer.", "example": "Convert the coordinate to text: [ 3.1776 -6.5121]:"}
{"text": "Convert the coordinate to text: [-2.7996 -6.0277]: The authors propose the use of recently proposed large language model fine-tuned on the provided datasets as a solution to the unique challenges of the task.", "target": "The authors propose the use of recently proposed large language model fine-tuned on the provided datasets as a solution to the unique challenges of the task.", "example": "Convert the coordinate to text: [-2.7996 -6.0277]:"}
{"text": "Convert the coordinate to text: [-1.8886 -6.3342]: The authors propose a system to automatically generate rhetorical roles of sentences in a legal case document using a Hierarchical Bi-LSTM CRF model and RoBERTa transformer.", "target": "The authors propose a system to automatically generate rhetorical roles of sentences in a legal case document using a Hierarchical Bi-LSTM CRF model and RoBERTa transformer.", "example": "Convert the coordinate to text: [-1.8886 -6.3342]:"}
{"text": "Convert the coordinate to text: [-1.713   9.3221]: The authors introduce a new dataset named MTR, which is composed of two parts: one combines deductive and inductive reasoning, while the other combines inductive and defeasible reasoning, to mimic the complex reasoning humans use in everyday life.", "target": "The authors introduce a new dataset named MTR, which is composed of two parts: one combines deductive and inductive reasoning, while the other combines inductive and defeasible reasoning, to mimic the complex reasoning humans use in everyday life.", "example": "Convert the coordinate to text: [-1.713   9.3221]:"}
{"text": "Convert the coordinate to text: [-2.2035 -5.2843]: The authors explore multiple pipeline methods for using GPT-3.5 to summarize a large collection of user reviews in a prompted manner, including recursive summarization and selecting salient content to summarize through supervised clustering or extraction.", "target": "The authors explore multiple pipeline methods for using GPT-3.5 to summarize a large collection of user reviews in a prompted manner, including recursive summarization and selecting salient content to summarize through supervised clustering or extraction.", "example": "Convert the coordinate to text: [-2.2035 -5.2843]:"}
{"text": "Convert the coordinate to text: [ 0.7697 -2.7152]: A weakly supervised Hierarchical Multi-task Classification Framework (HMCF) is proposed to identify topics from customer questions at various granularity levels. A Taxonomy Creation and Data Labeling (TCDL) module is introduced for creating taxonomy and labeled data with minimal supervision.", "target": "A weakly supervised Hierarchical Multi-task Classification Framework (HMCF) is proposed to identify topics from customer questions at various granularity levels. A Taxonomy Creation and Data Labeling (TCDL) module is introduced for creating taxonomy and labeled data with minimal supervision.", "example": "Convert the coordinate to text: [ 0.7697 -2.7152]:"}
{"text": "Convert the coordinate to text: [-2.7701 -3.5634]: The authors propose a new method where they initially train an entity typing model with a broad type coverage using ultra-fine entity typing data. When a model needs to be produced for a new fine-grained entity type schema, they fine-tune the previously trained model with a small number of examples annotated under this schema.", "target": "The authors propose a new method where they initially train an entity typing model with a broad type coverage using ultra-fine entity typing data. When a model needs to be produced for a new fine-grained entity type schema, they fine-tune the previously trained model with a small number of examples annotated under this schema.", "example": "Convert the coordinate to text: [-2.7701 -3.5634]:"}
{"text": "Convert the coordinate to text: [ 14.717  -15.2349]: The authors propose a new formulation of the sample-based rendering equation so it corresponds to the exact integral under piecewise linear volume density in order to overcome the quadrature instability witnessed in current NeRF methods.", "target": "The authors propose a new formulation of the sample-based rendering equation so it corresponds to the exact integral under piecewise linear volume density in order to overcome the quadrature instability witnessed in current NeRF methods.", "example": "Convert the coordinate to text: [ 14.717  -15.2349]:"}
{"text": "Convert the coordinate to text: [0.0119 1.95  ]: The authors differentiate sources of discrimination in ML into two types: aleatoric discrimination, which occurs due to the data distribution, and epistemic discrimination, which is a result of decisions made during model development. They propose ways to quantify both these types of discrimination.", "target": "The authors differentiate sources of discrimination in ML into two types: aleatoric discrimination, which occurs due to the data distribution, and epistemic discrimination, which is a result of decisions made during model development. They propose ways to quantify both these types of discrimination.", "example": "Convert the coordinate to text: [0.0119 1.95  ]:"}
{"text": "Convert the coordinate to text: [-2.3908 10.3484]: The authors propose a new physics-guided learning method that not only incorporates observation knowledge such as initial and boundary conditions, but also includes basic physical principles and laws to guide the model optimization.", "target": "The authors propose a new physics-guided learning method that not only incorporates observation knowledge such as initial and boundary conditions, but also includes basic physical principles and laws to guide the model optimization.", "example": "Convert the coordinate to text: [-2.3908 10.3484]:"}
{"text": "Convert the coordinate to text: [-1.7731 -6.8058]: The authors developed a solution that employs a pre-training procedure based on multilingual transformers using a label-aware contrastive loss function.", "target": "The authors developed a solution that employs a pre-training procedure based on multilingual transformers using a label-aware contrastive loss function.", "example": "Convert the coordinate to text: [-1.7731 -6.8058]:"}
{"text": "Convert the coordinate to text: [ 0.9894 -8.8802]: To address this gap, the authors propose a Multi-modal Context Reasoning approach called ModCR, which uses given textual abstract semantics and image information as pre-context information and embeds them into a language model to perform context reasoning. In contrast to recent models, ModCR introduces learnable alignment between image and text in the pretrained language model.", "target": "To address this gap, the authors propose a Multi-modal Context Reasoning approach called ModCR, which uses given textual abstract semantics and image information as pre-context information and embeds them into a language model to perform context reasoning. In contrast to recent models, ModCR introduces learnable alignment between image and text in the pretrained language model.", "example": "Convert the coordinate to text: [ 0.9894 -8.8802]:"}
{"text": "Convert the coordinate to text: [  0.1044 -17.6177]: The authors propose an Embedding Watermark method, EmbMarker, to protect the copyright of LLMs for EaaS. This method implants backdoors on embeddings, using a group of moderate-frequency words as a trigger set and a target embedding as the watermark.", "target": "The authors propose an Embedding Watermark method, EmbMarker, to protect the copyright of LLMs for EaaS. This method implants backdoors on embeddings, using a group of moderate-frequency words as a trigger set and a target embedding as the watermark.", "example": "Convert the coordinate to text: [  0.1044 -17.6177]:"}
{"text": "Convert the coordinate to text: [-4.8461 -1.5938]: The authors propose an evaluation paradigm to disentangle factual and contextual errors in entity description generation tasks, setting them apart from each other and assessing the ability of models to handle these error types separately.", "target": "The authors propose an evaluation paradigm to disentangle factual and contextual errors in entity description generation tasks, setting them apart from each other and assessing the ability of models to handle these error types separately.", "example": "Convert the coordinate to text: [-4.8461 -1.5938]:"}
{"text": "Convert the coordinate to text: [-5.7731 -7.2041]: In this study, the authors propose the use of word alignments computed over large scale bilingual corpora to predict lexical translation difficulty.", "target": "In this study, the authors propose the use of word alignments computed over large scale bilingual corpora to predict lexical translation difficulty.", "example": "Convert the coordinate to text: [-5.7731 -7.2041]:"}
{"text": "Convert the coordinate to text: [-7.8504 -5.2387]: The authors introduced Riveter, a tool for analyzing verb connotations associated with entities in text corpora, with the aim of improving the accessibility of verb lexica. Riveter comes prepopulated with connotation frames of sentiment, power, and agency.", "target": "The authors introduced Riveter, a tool for analyzing verb connotations associated with entities in text corpora, with the aim of improving the accessibility of verb lexica. Riveter comes prepopulated with connotation frames of sentiment, power, and agency.", "example": "Convert the coordinate to text: [-7.8504 -5.2387]:"}
{"text": "Convert the coordinate to text: [-0.3006 -0.5356]: The authors propose HyperHawkes, a hypernetwork based temporal point process framework that is capable of modeling time of event occurrence for unseen sequences and zero-shot learning for time-to-event modeling and also continuously modelling time-to-event sequences with minimal forgetting.", "target": "The authors propose HyperHawkes, a hypernetwork based temporal point process framework that is capable of modeling time of event occurrence for unseen sequences and zero-shot learning for time-to-event modeling and also continuously modelling time-to-event sequences with minimal forgetting.", "example": "Convert the coordinate to text: [-0.3006 -0.5356]:"}
{"text": "Convert the coordinate to text: [10.0247 -8.3901]: The authors propose a two-stage framework for efficient high-resolution image generation, emphasizing multi-grained feature interaction through a combination of local and global attention mechanisms. They also propose a new generation pipeline including autoencoding training and autoregressive generation strategy.", "target": "The authors propose a two-stage framework for efficient high-resolution image generation, emphasizing multi-grained feature interaction through a combination of local and global attention mechanisms. They also propose a new generation pipeline including autoencoding training and autoregressive generation strategy.", "example": "Convert the coordinate to text: [10.0247 -8.3901]:"}
{"text": "Convert the coordinate to text: [  4.8063 -10.7851]: The authors propose to improve the detection of positive segments in a video by modeling the number of positive segments as a latent variable, which they show can be modeled as a Poisson binomial distribution. They propose an Expectation-Maximization approach to maximize the evidence lower bound (ELBO) and iteratively estimate and refine the minimum positive segments in a video.", "target": "The authors propose to improve the detection of positive segments in a video by modeling the number of positive segments as a latent variable, which they show can be modeled as a Poisson binomial distribution. They propose an Expectation-Maximization approach to maximize the evidence lower bound (ELBO) and iteratively estimate and refine the minimum positive segments in a video.", "example": "Convert the coordinate to text: [  4.8063 -10.7851]:"}
{"text": "Convert the coordinate to text: [ 1.572  -5.1654]: This paper proposes a feature synthesis approach for zero-shot semantic segmentation that uses class-level semantic information for unseen objects to create a correspondence, alignment and consistency between the visual and semantic spaces.", "target": "This paper proposes a feature synthesis approach for zero-shot semantic segmentation that uses class-level semantic information for unseen objects to create a correspondence, alignment and consistency between the visual and semantic spaces.", "example": "Convert the coordinate to text: [ 1.572  -5.1654]:"}
{"text": "Convert the coordinate to text: [-0.9298 -5.293 ]: This paper extends the recent constant modality gap phenomenon to learnable prompts and justifies the superiority of vision-language transfer with multi-prompt augmentation. The authors propose an Energy-based Multi-prompt Learning (EMPL) to generate multiple prompt embeddings by drawing instances from an energy-based distribution, which is implicitly defined by VLMs.", "target": "This paper extends the recent constant modality gap phenomenon to learnable prompts and justifies the superiority of vision-language transfer with multi-prompt augmentation. The authors propose an Energy-based Multi-prompt Learning (EMPL) to generate multiple prompt embeddings by drawing instances from an energy-based distribution, which is implicitly defined by VLMs.", "example": "Convert the coordinate to text: [-0.9298 -5.293 ]:"}
{"text": "Convert the coordinate to text: [ 4.2149 -4.852 ]: The paper proposes a Multi-view Hierarchical Clustering Network (MHCN) that performs simultaneous multi-view learning and hierarchy modeling, with multiple hyperbolic autoencoders mapping the latent space onto the Poincar\u00e9 ball to uncover efficient tree-like structures among all views.", "target": "The paper proposes a Multi-view Hierarchical Clustering Network (MHCN) that performs simultaneous multi-view learning and hierarchy modeling, with multiple hyperbolic autoencoders mapping the latent space onto the Poincar\u00e9 ball to uncover efficient tree-like structures among all views.", "example": "Convert the coordinate to text: [ 4.2149 -4.852 ]:"}
{"text": "Convert the coordinate to text: [ 0.7247 -7.3702]: The authors introduce the Blockwise Parallel Transformer (BPT), a new approach that uses blockwise computation of self-attention and feedforward network fusion to reduce memory costs.", "target": "The authors introduce the Blockwise Parallel Transformer (BPT), a new approach that uses blockwise computation of self-attention and feedforward network fusion to reduce memory costs.", "example": "Convert the coordinate to text: [ 0.7247 -7.3702]:"}
{"text": "Convert the coordinate to text: [9.651  1.1874]: The authors develop a dimensionality reduction framework that determines the subset of populations described by each latent dimension, the direction of signal flow among those populations, and how those signals evolve over time within and across experimental trials.", "target": "The authors develop a dimensionality reduction framework that determines the subset of populations described by each latent dimension, the direction of signal flow among those populations, and how those signals evolve over time within and across experimental trials.", "example": "Convert the coordinate to text: [9.651  1.1874]:"}
{"text": "Convert the coordinate to text: [11.7076  6.7631]: The authors propose the novel Hessian/Jacobian-free bilevel optimizer FdeHBO, which features a fully single-loop structure, a projection-aided finite-difference Hessian/Jacobian-vector approximation, and momentum-based updates.", "target": "The authors propose the novel Hessian/Jacobian-free bilevel optimizer FdeHBO, which features a fully single-loop structure, a projection-aided finite-difference Hessian/Jacobian-vector approximation, and momentum-based updates.", "example": "Convert the coordinate to text: [11.7076  6.7631]:"}
{"text": "Convert the coordinate to text: [ 5.3133 -7.9878]: The authors propose the Query-based Temporal Fusion Network (QTNet) that uses object queries from previous frames to enhance the representation of current object queries. Also, they introduce the Motion-guided Temporal Modeling (MTM) module that uses spatial position information of object queries to construct their relevance between adjacent frames.", "target": "The authors propose the Query-based Temporal Fusion Network (QTNet) that uses object queries from previous frames to enhance the representation of current object queries. Also, they introduce the Motion-guided Temporal Modeling (MTM) module that uses spatial position information of object queries to construct their relevance between adjacent frames.", "example": "Convert the coordinate to text: [ 5.3133 -7.9878]:"}
{"text": "Convert the coordinate to text: [12.3464 -1.5014]: The authors present a self-consistent dynamical field theory for understanding feature learning in wide neural networks. They construct deterministic dynamical order parameters, representing the inner-product kernels for hidden unit activations and gradients in each layer, to describe the network activity through training.", "target": "The authors present a self-consistent dynamical field theory for understanding feature learning in wide neural networks. They construct deterministic dynamical order parameters, representing the inner-product kernels for hidden unit activations and gradients in each layer, to describe the network activity through training.", "example": "Convert the coordinate to text: [12.3464 -1.5014]:"}
{"text": "Convert the coordinate to text: [-8.4907 -0.6912]: The authors question the suitability of template filling as a method for evaluating IE systems, arguing that it requires definitive answers to the problem of event individuation, an area with significant expert disagreement.", "target": "The authors question the suitability of template filling as a method for evaluating IE systems, arguing that it requires definitive answers to the problem of event individuation, an area with significant expert disagreement.", "example": "Convert the coordinate to text: [-8.4907 -0.6912]:"}
{"text": "Convert the coordinate to text: [ 1.328 -0.107]: The authors contradict the model capacity hypothesis, arguing that a generalizable DR can be trained for high accuracy in both supervised and zero-shot retrieval without increasing model size. They systematically examine the contrastive learning of DRs under the frame of data augmentation (DA), and propose a new DA approach with diverse queries and sources of supervision to train a generalizable DR.", "target": "The authors contradict the model capacity hypothesis, arguing that a generalizable DR can be trained for high accuracy in both supervised and zero-shot retrieval without increasing model size. They systematically examine the contrastive learning of DRs under the frame of data augmentation (DA), and propose a new DA approach with diverse queries and sources of supervision to train a generalizable DR.", "example": "Convert the coordinate to text: [ 1.328 -0.107]:"}
{"text": "Convert the coordinate to text: [-9.4148 16.321 ]: The authors propose Ocularone, a platform that uses drones to enhance the lifestyle of Visually-Impaired People through navigational assistance and situational awareness. It achieves this through visual analytics of drone video streams and includes features like using gestures and audio prompts for communication.", "target": "The authors propose Ocularone, a platform that uses drones to enhance the lifestyle of Visually-Impaired People through navigational assistance and situational awareness. It achieves this through visual analytics of drone video streams and includes features like using gestures and audio prompts for communication.", "example": "Convert the coordinate to text: [-9.4148 16.321 ]:"}
{"text": "Convert the coordinate to text: [-9.1471 -3.0086]: The authors suggest that recent advancements in deep learning have created a convergence between speech processing and mainstream NLP that may potentially allow for a unification of these two fields in order to start taking spoken language seriously as the primary mode of human communication.", "target": "The authors suggest that recent advancements in deep learning have created a convergence between speech processing and mainstream NLP that may potentially allow for a unification of these two fields in order to start taking spoken language seriously as the primary mode of human communication.", "example": "Convert the coordinate to text: [-9.1471 -3.0086]:"}
{"text": "Convert the coordinate to text: [-0.1637 -7.5393]: This study explores four methods for multi-label classification, two based on an encoder only, and two based on an encoder-decoder, starting from the same pre-trained model, T5.", "target": "This study explores four methods for multi-label classification, two based on an encoder only, and two based on an encoder-decoder, starting from the same pre-trained model, T5.", "example": "Convert the coordinate to text: [-0.1637 -7.5393]:"}
{"text": "Convert the coordinate to text: [-0.3647 -6.6752]: The authors propose a system comprising of transformer-based pre-trained models with task-adaptive pretraining and ensemble learning, while using large amounts of unlabeled data for model adaptive pretraining and exploring several strategies.", "target": "The authors propose a system comprising of transformer-based pre-trained models with task-adaptive pretraining and ensemble learning, while using large amounts of unlabeled data for model adaptive pretraining and exploring several strategies.", "example": "Convert the coordinate to text: [-0.3647 -6.6752]:"}
{"text": "Convert the coordinate to text: [-9.2847 -4.3471]: The authors propose a new task of simulating NL feedback for interactive semantic parsing, along with a novel feedback evaluator to assess the quality of the simulated feedback.", "target": "The authors propose a new task of simulating NL feedback for interactive semantic parsing, along with a novel feedback evaluator to assess the quality of the simulated feedback.", "example": "Convert the coordinate to text: [-9.2847 -4.3471]:"}
{"text": "Convert the coordinate to text: [-11.956    5.5399]: The authors propose a novel class of insight-based visualization recommendation systems that automatically rank and recommend groups of related insights along with the most important insights within each group.", "target": "The authors propose a novel class of insight-based visualization recommendation systems that automatically rank and recommend groups of related insights along with the most important insights within each group.", "example": "Convert the coordinate to text: [-11.956    5.5399]:"}
{"text": "Convert the coordinate to text: [-2.6019 -6.1767]: The authors propose architecture- and data-driven language modeling approaches to build application-agnostic models. They introduce two novel feed-forward architectures to balance the trade-offs related to on-device constraints.", "target": "The authors propose architecture- and data-driven language modeling approaches to build application-agnostic models. They introduce two novel feed-forward architectures to balance the trade-offs related to on-device constraints.", "example": "Convert the coordinate to text: [-2.6019 -6.1767]:"}
{"text": "Convert the coordinate to text: [5.8462 6.7155]: The authors investigate how different candidate generation strategies, such as ancestral, nucleus, and top-k sampling, influence the performance of MBR decoding in MT. They also propose using the relatively new epsilon-sampling approach which prunes all tokens with a probability lower than epsilon, providing each token in a sample a fair probability mass.", "target": "The authors investigate how different candidate generation strategies, such as ancestral, nucleus, and top-k sampling, influence the performance of MBR decoding in MT. They also propose using the relatively new epsilon-sampling approach which prunes all tokens with a probability lower than epsilon, providing each token in a sample a fair probability mass.", "example": "Convert the coordinate to text: [5.8462 6.7155]:"}
{"text": "Convert the coordinate to text: [-3.0627 -7.1911]: The authors present multilingual Pre-trained Machine Reader (mPMR), a new method for multilingual machine reading comprehension (MRC) style pre-training that aims to guide mPLMs to perform both sequence classification and span extraction in multiple languages.", "target": "The authors present multilingual Pre-trained Machine Reader (mPMR), a new method for multilingual machine reading comprehension (MRC) style pre-training that aims to guide mPLMs to perform both sequence classification and span extraction in multiple languages.", "example": "Convert the coordinate to text: [-3.0627 -7.1911]:"}
{"text": "Convert the coordinate to text: [-10.4055  -1.8869]: The authors propose to use paraphrased reference questions for a more robust QG evaluation. These semantically and syntactically diverse questions are created using large language models such as GPT-3.", "target": "The authors propose to use paraphrased reference questions for a more robust QG evaluation. These semantically and syntactically diverse questions are created using large language models such as GPT-3.", "example": "Convert the coordinate to text: [-10.4055  -1.8869]:"}
{"text": "Convert the coordinate to text: [-7.7203 -4.4434]: In contrast, this paper introduces a novel metaphor detection method that models the basic meaning of a word using literal annotation from the training set. This basic meaning is then compared with the contextual meaning in a target sentence to identify metaphors.", "target": "In contrast, this paper introduces a novel metaphor detection method that models the basic meaning of a word using literal annotation from the training set. This basic meaning is then compared with the contextual meaning in a target sentence to identify metaphors.", "example": "Convert the coordinate to text: [-7.7203 -4.4434]:"}
{"text": "Convert the coordinate to text: [9.6128 4.1515]: The authors propose a method using the recently proposed dual sparse variational GP. The method enables accurate inference for generic likelihoods and improves learning by actively building and updating a memory of past data.", "target": "The authors propose a method using the recently proposed dual sparse variational GP. The method enables accurate inference for generic likelihoods and improves learning by actively building and updating a memory of past data.", "example": "Convert the coordinate to text: [9.6128 4.1515]:"}
{"text": "Convert the coordinate to text: [12.4136 -5.0186]: This study aims to conduct an extensive assessment of the adversarial robustness of several FSL methods.", "target": "This study aims to conduct an extensive assessment of the adversarial robustness of several FSL methods.", "example": "Convert the coordinate to text: [12.4136 -5.0186]:"}
{"text": "Convert the coordinate to text: [-1.2405 -6.7   ]: The authors suggest that domain-specific models, particularly smaller Transformer-based models fine-tuned on relevant data, are necessary and can actually outperform larger foundational models like GPT-3.5 in Natural Language Inference tasks.", "target": "The authors suggest that domain-specific models, particularly smaller Transformer-based models fine-tuned on relevant data, are necessary and can actually outperform larger foundational models like GPT-3.5 in Natural Language Inference tasks.", "example": "Convert the coordinate to text: [-1.2405 -6.7   ]:"}
{"text": "Convert the coordinate to text: [ 2.9517 -6.0889]: The paper proposes the Label Graph Transformer (LG-Transformer), a two-stage pipeline architecture for multi-label classification of human values in argument mining, with the stages comprising of a Transformer that jointly encodes arguments and labels, and a graph module encoding and obtaining further interactions between labels.", "target": "The paper proposes the Label Graph Transformer (LG-Transformer), a two-stage pipeline architecture for multi-label classification of human values in argument mining, with the stages comprising of a Transformer that jointly encodes arguments and labels, and a graph module encoding and obtaining further interactions between labels.", "example": "Convert the coordinate to text: [ 2.9517 -6.0889]:"}
{"text": "Convert the coordinate to text: [  2.8527 -12.3584]: This work proposes the use of commonsense knowledge about the prototypical functions of objects, as used in previous NLP research, to be beneficial for visual situation recognition task.", "target": "This work proposes the use of commonsense knowledge about the prototypical functions of objects, as used in previous NLP research, to be beneficial for visual situation recognition task.", "example": "Convert the coordinate to text: [  2.8527 -12.3584]:"}
{"text": "Convert the coordinate to text: [-2.4142 -4.5654]: The authors introduce ChartT5, a visual and language model that learns to interpret table information from chart images via cross-modal pre-training on plot table pairs. Two novel pre-training objectives, namely Masked Header Prediction (MHP) and Masked Value Prediction (MVP), are proposed to enhance the ability of this model to interpret table data.", "target": "The authors introduce ChartT5, a visual and language model that learns to interpret table information from chart images via cross-modal pre-training on plot table pairs. Two novel pre-training objectives, namely Masked Header Prediction (MHP) and Masked Value Prediction (MVP), are proposed to enhance the ability of this model to interpret table data.", "example": "Convert the coordinate to text: [-2.4142 -4.5654]:"}
{"text": "Convert the coordinate to text: [-8.7445  5.8869]: This paper presents a use case for suspect data identification in a maritime setting, introducing a system named UMBAR. This system ingests sensor and text data, processes them through an information extraction step to feed a Knowledge Base, and performs coherence checks between the extracted facts.", "target": "This paper presents a use case for suspect data identification in a maritime setting, introducing a system named UMBAR. This system ingests sensor and text data, processes them through an information extraction step to feed a Knowledge Base, and performs coherence checks between the extracted facts.", "example": "Convert the coordinate to text: [-8.7445  5.8869]:"}
{"text": "Convert the coordinate to text: [-3.3475  1.1015]: The authors propose a novel architecture for generating sarcastic sentences coupled with emojis from non-sarcastic input sentences, encompassing two sub-tasks: one for generating textual sarcasm invoked by valence reversal and semantic incongruity, and another for identifying suitable emojis corresponding to the generated sarcastic sentences.", "target": "The authors propose a novel architecture for generating sarcastic sentences coupled with emojis from non-sarcastic input sentences, encompassing two sub-tasks: one for generating textual sarcasm invoked by valence reversal and semantic incongruity, and another for identifying suitable emojis corresponding to the generated sarcastic sentences.", "example": "Convert the coordinate to text: [-3.3475  1.1015]:"}
{"text": "Convert the coordinate to text: [-4.8668 -7.3946]: The authors propose a reference-free evaluation method, ReFreeEval, that characterizes translation based on fluency and faithfulness at both word-level and sentence-level.", "target": "The authors propose a reference-free evaluation method, ReFreeEval, that characterizes translation based on fluency and faithfulness at both word-level and sentence-level.", "example": "Convert the coordinate to text: [-4.8668 -7.3946]:"}
{"text": "Convert the coordinate to text: [  8.3245 -13.1244]: The authors propose ImGeoNet, a multi-view image-based 3D object detection framework that models a 3D space by an image-induced geometry-aware voxel representation. Unlike previous methods, this approach considers geometry during induction from multi-view images.", "target": "The authors propose ImGeoNet, a multi-view image-based 3D object detection framework that models a 3D space by an image-induced geometry-aware voxel representation. Unlike previous methods, this approach considers geometry during induction from multi-view images.", "example": "Convert the coordinate to text: [  8.3245 -13.1244]:"}
{"text": "Convert the coordinate to text: [  8.264 -20.917]: The authors propose image formation model and optimization procedure that combines the advantages of neural radiance fields and structured light imaging, which explicitly models the raw structured light images themselves, without relying on the fidelity of processed depth maps.", "target": "The authors propose image formation model and optimization procedure that combines the advantages of neural radiance fields and structured light imaging, which explicitly models the raw structured light images themselves, without relying on the fidelity of processed depth maps.", "example": "Convert the coordinate to text: [  8.264 -20.917]:"}
{"text": "Convert the coordinate to text: [  6.5009 -15.7105]: The authors propose a Template-guided Hierarchical Feature Restoration method, introducing two techniques, bottleneck compression and template-guided compensation, for restoring anomaly-free features in an image.", "target": "The authors propose a Template-guided Hierarchical Feature Restoration method, introducing two techniques, bottleneck compression and template-guided compensation, for restoring anomaly-free features in an image.", "example": "Convert the coordinate to text: [  6.5009 -15.7105]:"}
{"text": "Convert the coordinate to text: [11.9978 -2.5441]: This paper presents novel exact conditions and algorithms for verifying safety of feedforward NCBFs with ReLU activation functions. The authors propose a method to leverage a generalization of Nagumo's theorem for proving invariance of sets with nonsmooth boundaries to derive necessary and sufficient conditions for safety.", "target": "This paper presents novel exact conditions and algorithms for verifying safety of feedforward NCBFs with ReLU activation functions. The authors propose a method to leverage a generalization of Nagumo's theorem for proving invariance of sets with nonsmooth boundaries to derive necessary and sufficient conditions for safety.", "example": "Convert the coordinate to text: [11.9978 -2.5441]:"}
{"text": "Convert the coordinate to text: [11.7748 -2.1044]: The authors aim to establish a global convergence theory of shallow, encoder-only Transformers. This involves special considerations for the softmax input/output and proves that quadratic overparameterization is enough to ensure their convergence, under commonly-used He/LeCun initialization in practice.", "target": "The authors aim to establish a global convergence theory of shallow, encoder-only Transformers. This involves special considerations for the softmax input/output and proves that quadratic overparameterization is enough to ensure their convergence, under commonly-used He/LeCun initialization in practice.", "example": "Convert the coordinate to text: [11.7748 -2.1044]:"}
{"text": "Convert the coordinate to text: [ 4.7431 14.0294]: The study proposes SUGARL (Sensorimotor Understanding Guided Active Reinforcement Learning), a framework that models motor and sensory policies separately but jointly learns them using an intrinsic sensorimotor reward, which is given by a sensorimotor reward module and incentivizes the sensory policy to choose optimal observations to infer its own motor action, inspired by the sensorimotor stage of humans.", "target": "The study proposes SUGARL (Sensorimotor Understanding Guided Active Reinforcement Learning), a framework that models motor and sensory policies separately but jointly learns them using an intrinsic sensorimotor reward, which is given by a sensorimotor reward module and incentivizes the sensory policy to choose optimal observations to infer its own motor action, inspired by the sensorimotor stage of humans.", "example": "Convert the coordinate to text: [ 4.7431 14.0294]:"}
{"text": "Convert the coordinate to text: [ 6.6525 11.5029]: This paper proposes a computationally efficient solution framework for solving distributionally robust MDPs with Wasserstein ambiguity sets, which decomposes the optimization problems associated with distributionally robust Bellman updates into smaller subproblems.", "target": "This paper proposes a computationally efficient solution framework for solving distributionally robust MDPs with Wasserstein ambiguity sets, which decomposes the optimization problems associated with distributionally robust Bellman updates into smaller subproblems.", "example": "Convert the coordinate to text: [ 6.6525 11.5029]:"}
{"text": "Convert the coordinate to text: [8.0812 5.6825]: The authors propose a scalable Bayesian causal discovery framework that uses a combination of stochastic gradient Markov Chain Monte Carlo (SG-MCMC) and Variational Inference (VI), and directly samples DAGs from the posterior without requiring DAG regularization and is applicable to both linear and nonlinear causal models.", "target": "The authors propose a scalable Bayesian causal discovery framework that uses a combination of stochastic gradient Markov Chain Monte Carlo (SG-MCMC) and Variational Inference (VI), and directly samples DAGs from the posterior without requiring DAG regularization and is applicable to both linear and nonlinear causal models.", "example": "Convert the coordinate to text: [8.0812 5.6825]:"}
{"text": "Convert the coordinate to text: [ 0.6749 -5.464 ]: The researchers propose a new method to identify shortcut reasoning. Their method quantifies the severity of shortcut reasoning using out-of-distribution data and refrains from any assumptions about the token types triggering the shortcut reasoning.", "target": "The researchers propose a new method to identify shortcut reasoning. Their method quantifies the severity of shortcut reasoning using out-of-distribution data and refrains from any assumptions about the token types triggering the shortcut reasoning.", "example": "Convert the coordinate to text: [ 0.6749 -5.464 ]:"}
{"text": "Convert the coordinate to text: [ 1.1592 14.6579]: The authors propose a framework and algorithms for learning stable market outcomes under uncertainty. The primary setting is matching with transferable utilities where the platform matches agents and sets monetary transfers between them.", "target": "The authors propose a framework and algorithms for learning stable market outcomes under uncertainty. The primary setting is matching with transferable utilities where the platform matches agents and sets monetary transfers between them.", "example": "Convert the coordinate to text: [ 1.1592 14.6579]:"}
{"text": "Convert the coordinate to text: [11.097  -2.1605]: This paper overcomes the limitation of the Gaussian i.i.d. weight assumption and establishes the state evolution of ML-AMP for random convolutional layers and proves that random convolutional layers belong to the same universality class as Gaussian matrices.", "target": "This paper overcomes the limitation of the Gaussian i.i.d. weight assumption and establishes the state evolution of ML-AMP for random convolutional layers and proves that random convolutional layers belong to the same universality class as Gaussian matrices.", "example": "Convert the coordinate to text: [11.097  -2.1605]:"}
{"text": "Convert the coordinate to text: [14.3258  1.5269]: The paper introduces HALOC, a hardware-aware automatic low-rank compression framework designed to address the challenges of existing methods by providing layer-wise rank in a differentiable and hardware-aware approach.", "target": "The paper introduces HALOC, a hardware-aware automatic low-rank compression framework designed to address the challenges of existing methods by providing layer-wise rank in a differentiable and hardware-aware approach.", "example": "Convert the coordinate to text: [14.3258  1.5269]:"}
{"text": "Convert the coordinate to text: [ 3.6791 -3.8183]: This paper introduces 'Distilling step-by-step', a new method that aims to train smaller models, which can outperform LLMs, while leveraging less training data needed by finetuning or distillation. The key innovation is to extract LLM rationales as additional supervision for small models within a multi-task training framework.", "target": "This paper introduces 'Distilling step-by-step', a new method that aims to train smaller models, which can outperform LLMs, while leveraging less training data needed by finetuning or distillation. The key innovation is to extract LLM rationales as additional supervision for small models within a multi-task training framework.", "example": "Convert the coordinate to text: [ 3.6791 -3.8183]:"}
{"text": "Convert the coordinate to text: [-0.7019 -3.2857]: The authors propose Verify-and-Edit, a framework for CoT prompting, which aims to improve prediction factuality by post-editing reasoning chains based on external knowledge.", "target": "The authors propose Verify-and-Edit, a framework for CoT prompting, which aims to improve prediction factuality by post-editing reasoning chains based on external knowledge.", "example": "Convert the coordinate to text: [-0.7019 -3.2857]:"}
{"text": "Convert the coordinate to text: [-5.7275 -2.3327]: This study explores when aggregating diverse skills from multiple datasets can provide successful outcomes within the Financial NLP domain, particularly in the case of tasks like numeric reasoning and sentiment analysis which are relevant to this domain.", "target": "This study explores when aggregating diverse skills from multiple datasets can provide successful outcomes within the Financial NLP domain, particularly in the case of tasks like numeric reasoning and sentiment analysis which are relevant to this domain.", "example": "Convert the coordinate to text: [-5.7275 -2.3327]:"}
{"text": "Convert the coordinate to text: [-3.2634 -9.4955]: The authors propose the first audio-visual speech-to-speech (AV-S2ST) translation model, AV-TranSpeech, that complements the audio stream with visual information, increasing the system's robustness without relying on intermediate text.", "target": "The authors propose the first audio-visual speech-to-speech (AV-S2ST) translation model, AV-TranSpeech, that complements the audio stream with visual information, increasing the system's robustness without relying on intermediate text.", "example": "Convert the coordinate to text: [-3.2634 -9.4955]:"}
{"text": "Convert the coordinate to text: [-10.0822  -3.6406]: The authors introduce Alfred, a novel system for PWS that prompts users to encode their subject matter expertise via natural language prompts for language and vision-language models, instead of requiring expert coding.", "target": "The authors introduce Alfred, a novel system for PWS that prompts users to encode their subject matter expertise via natural language prompts for language and vision-language models, instead of requiring expert coding.", "example": "Convert the coordinate to text: [-10.0822  -3.6406]:"}
{"text": "Convert the coordinate to text: [-2.8527 -3.7359]: The paper introduces the Structure Aware Dense Retrieval (SANTA) model, which encodes user queries and structured data in one universal embedding space for retrieval. SANTA proposes two pretraining methods - Structured Data Alignment and Masked Entity Prediction to make language models structure-aware.", "target": "The paper introduces the Structure Aware Dense Retrieval (SANTA) model, which encodes user queries and structured data in one universal embedding space for retrieval. SANTA proposes two pretraining methods - Structured Data Alignment and Masked Entity Prediction to make language models structure-aware.", "example": "Convert the coordinate to text: [-2.8527 -3.7359]:"}
{"text": "Convert the coordinate to text: [  0.778  -10.0967]: The study proposes computational methods that use text-to-image generation models, such as DALLE mini, to measure the imageability of not only single English words but also connected text.", "target": "The study proposes computational methods that use text-to-image generation models, such as DALLE mini, to measure the imageability of not only single English words but also connected text.", "example": "Convert the coordinate to text: [  0.778  -10.0967]:"}
{"text": "Convert the coordinate to text: [ 0.3951 -9.3911]: Based on the observation that fine-grained information, like keywords in sentences and objects in images, can be informative for understanding semantics, the authors propose a unified framework, UniFine, to leverage this fine-grained information for zero-shot vision-language learning across tasks like VQA, SNLI-VE, and VCR.", "target": "Based on the observation that fine-grained information, like keywords in sentences and objects in images, can be informative for understanding semantics, the authors propose a unified framework, UniFine, to leverage this fine-grained information for zero-shot vision-language learning across tasks like VQA, SNLI-VE, and VCR.", "example": "Convert the coordinate to text: [ 0.3951 -9.3911]:"}
{"text": "Convert the coordinate to text: [-1.2942 -3.0017]: This paper introduces a novel method called SToKE that uses pre-trained language models to learn joint Structural and Temporal Contextualized Knowledge Embeddings. It includes the construction of an event evolution tree (EET) for each query to enable language models to handle TKGs and a novel temporal embedding and structural matrix to learn the time information and structural dependencies of facts.", "target": "This paper introduces a novel method called SToKE that uses pre-trained language models to learn joint Structural and Temporal Contextualized Knowledge Embeddings. It includes the construction of an event evolution tree (EET) for each query to enable language models to handle TKGs and a novel temporal embedding and structural matrix to learn the time information and structural dependencies of facts.", "example": "Convert the coordinate to text: [-1.2942 -3.0017]:"}
{"text": "Convert the coordinate to text: [-4.2739 -2.2615]: The authors develop a new model for within-document event coreference resolution, which learns and integrates multiple representations from event pairs, as well as introducing multiple linguistics-motivated features for individual events. It captures the distinction of event pair through multiple similarity measures.", "target": "The authors develop a new model for within-document event coreference resolution, which learns and integrates multiple representations from event pairs, as well as introducing multiple linguistics-motivated features for individual events. It captures the distinction of event pair through multiple similarity measures.", "example": "Convert the coordinate to text: [-4.2739 -2.2615]:"}
{"text": "Convert the coordinate to text: [-2.0638 -5.5201]: The authors propose AutoConv, a method for synthetic conversation generation that capitalizes on large language models (LLM)'s few-shot learning ability and generation capacity.", "target": "The authors propose AutoConv, a method for synthetic conversation generation that capitalizes on large language models (LLM)'s few-shot learning ability and generation capacity.", "example": "Convert the coordinate to text: [-2.0638 -5.5201]:"}
{"text": "Convert the coordinate to text: [ 0.0667 -6.1889]: The authors propose a novel method, TemplateGEC, which combines the strengths of Seq2Edit and Seq2Seq frameworks, using detection labels from a Seq2Edit model to construct the input template, and a Seq2Seq model for consistency learning.", "target": "The authors propose a novel method, TemplateGEC, which combines the strengths of Seq2Edit and Seq2Seq frameworks, using detection labels from a Seq2Edit model to construct the input template, and a Seq2Seq model for consistency learning.", "example": "Convert the coordinate to text: [ 0.0667 -6.1889]:"}
{"text": "Convert the coordinate to text: [ 0.9448 14.4956]: This study proposes a reward scheme for CCI, leveraging statistical properties essential for causal inference, ensuring fairness and benefit for parties based on their contribution.", "target": "This study proposes a reward scheme for CCI, leveraging statistical properties essential for causal inference, ensuring fairness and benefit for parties based on their contribution.", "example": "Convert the coordinate to text: [ 0.9448 14.4956]:"}
{"text": "Convert the coordinate to text: [ 5.5082 13.4438]: The paper introduces the concept of Incremental Reinforcement Learning where the Markov Decision Process search space continually expands, and proposes Dual-Adaptive e-greedy Exploration (DAE), a new exploration framework that uses a Meta Policy and an Explorer to reduce redundant computation.", "target": "The paper introduces the concept of Incremental Reinforcement Learning where the Markov Decision Process search space continually expands, and proposes Dual-Adaptive e-greedy Exploration (DAE), a new exploration framework that uses a Meta Policy and an Explorer to reduce redundant computation.", "example": "Convert the coordinate to text: [ 5.5082 13.4438]:"}
{"text": "Convert the coordinate to text: [  7.2613 -12.0898]: The paper introduces a method for weakly semi-supervised 3D object detection (WSS3D) with point annotations, called ViT-WSS3D, that uses a plain, non-hierarchical vision transformer. This is achieved by transforming point annotations to form a point-to-box converter to fully utilize the information the point annotations provide, which ordinarily get overlooked.", "target": "The paper introduces a method for weakly semi-supervised 3D object detection (WSS3D) with point annotations, called ViT-WSS3D, that uses a plain, non-hierarchical vision transformer. This is achieved by transforming point annotations to form a point-to-box converter to fully utilize the information the point annotations provide, which ordinarily get overlooked.", "example": "Convert the coordinate to text: [  7.2613 -12.0898]:"}
{"text": "Convert the coordinate to text: [  2.0404 -15.8012]: The authors developed a dual-stream vision model that mimics the human eyes and brain, separating retinal inputs using magnocellular and parvocellular retinal ganglion cells and processing these inputs through two branches of convolutional neural networks that mimic the dorsal and ventral cortical pathways of the human brain for parallel visual processing.", "target": "The authors developed a dual-stream vision model that mimics the human eyes and brain, separating retinal inputs using magnocellular and parvocellular retinal ganglion cells and processing these inputs through two branches of convolutional neural networks that mimic the dorsal and ventral cortical pathways of the human brain for parallel visual processing.", "example": "Convert the coordinate to text: [  2.0404 -15.8012]:"}
{"text": "Convert the coordinate to text: [12.5598  6.9155]: This paper makes a contribution by demonstrating that the stationary distribution of offline (or multi-pass) SGD exhibits 'approximate' power-law tails. The extent of this approximation error is controlled by how quickly the empirical distribution of the training data converges to the true data distribution in the Wasserstein metric.", "target": "This paper makes a contribution by demonstrating that the stationary distribution of offline (or multi-pass) SGD exhibits 'approximate' power-law tails. The extent of this approximation error is controlled by how quickly the empirical distribution of the training data converges to the true data distribution in the Wasserstein metric.", "example": "Convert the coordinate to text: [12.5598  6.9155]:"}
{"text": "Convert the coordinate to text: [ 6.8536 -3.3363]: This work addresses the domain-varying dependence between content and style variables in counterfactual generation. To identify these latent-variable models, the authors leverage the relative sparsity of influences from different variables and developed a model called MATTE (doMain AdapTive counTerfactual gEneration).", "target": "This work addresses the domain-varying dependence between content and style variables in counterfactual generation. To identify these latent-variable models, the authors leverage the relative sparsity of influences from different variables and developed a model called MATTE (doMain AdapTive counTerfactual gEneration).", "example": "Convert the coordinate to text: [ 6.8536 -3.3363]:"}
{"text": "Convert the coordinate to text: [-1.4482  2.2952]: The authors propose to meta-evaluate metrics with a version of pairwise accuracy that credits metrics for correctly predicting ties, in combination with a tie calibration procedure that introduces ties into metric scores, enabling comparison between metrics that predict ties and those that do not.", "target": "The authors propose to meta-evaluate metrics with a version of pairwise accuracy that credits metrics for correctly predicting ties, in combination with a tie calibration procedure that introduces ties into metric scores, enabling comparison between metrics that predict ties and those that do not.", "example": "Convert the coordinate to text: [-1.4482  2.2952]:"}
{"text": "Convert the coordinate to text: [ 3.8941 -3.9763]: The authors proposed an Inter-class Distance Distillation (IDD) method for transferring the inter-class distance in the feature space from a teacher network to a student network, and a position information distillation module to help the student network encode more position information.", "target": "The authors proposed an Inter-class Distance Distillation (IDD) method for transferring the inter-class distance in the feature space from a teacher network to a student network, and a position information distillation module to help the student network encode more position information.", "example": "Convert the coordinate to text: [ 3.8941 -3.9763]:"}
{"text": "Convert the coordinate to text: [-7.1735 -1.3135]: As part of the challenge, the authors developed a language-model-based automatic extraction system for extracting patient experiences and medical conditions information from online discussions.", "target": "As part of the challenge, the authors developed a language-model-based automatic extraction system for extracting patient experiences and medical conditions information from online discussions.", "example": "Convert the coordinate to text: [-7.1735 -1.3135]:"}
{"text": "Convert the coordinate to text: [-1.4417 -5.3385]: The authors propose prompting large language models as a replacement to fine-tuning on conditional generation for controlling mixed-initiative dialogues. ", "target": "The authors propose prompting large language models as a replacement to fine-tuning on conditional generation for controlling mixed-initiative dialogues. ", "example": "Convert the coordinate to text: [-1.4417 -5.3385]:"}
{"text": "Convert the coordinate to text: [-5.3997 -6.0141]: The authors propose that by replacing the query vocabulary with a vocabulary that is more aligned with the LM tokenizer, the performance of models may improve.", "target": "The authors propose that by replacing the query vocabulary with a vocabulary that is more aligned with the LM tokenizer, the performance of models may improve.", "example": "Convert the coordinate to text: [-5.3997 -6.0141]:"}
{"text": "Convert the coordinate to text: [-2.2584 -4.6975]: The authors propose refactoring conventional tasks on hierarchical datasets into a long-tail prediction task, and address observed limitations of LLMs in these tasks by using entailment-contradiction prediction in conjunction with LLMs.", "target": "The authors propose refactoring conventional tasks on hierarchical datasets into a long-tail prediction task, and address observed limitations of LLMs in these tasks by using entailment-contradiction prediction in conjunction with LLMs.", "example": "Convert the coordinate to text: [-2.2584 -4.6975]:"}
{"text": "Convert the coordinate to text: [-2.5028 -5.0368]: The authors examine the performance of LLMs in generating correct Python code when default function names are swapped, showcasing a possible shortcoming of LLMs related to the understanding of identifier semantics within programming languages.", "target": "The authors examine the performance of LLMs in generating correct Python code when default function names are swapped, showcasing a possible shortcoming of LLMs related to the understanding of identifier semantics within programming languages.", "example": "Convert the coordinate to text: [-2.5028 -5.0368]:"}
{"text": "Convert the coordinate to text: [13.3131  6.1277]: In this paper, the authors revisit the loss of SAM and propose a more general method, WSAM (Weighted Sharpness-Aware Minimization), which incorporates sharpness as a regularization term.", "target": "In this paper, the authors revisit the loss of SAM and propose a more general method, WSAM (Weighted Sharpness-Aware Minimization), which incorporates sharpness as a regularization term.", "example": "Convert the coordinate to text: [13.3131  6.1277]:"}
{"text": "Convert the coordinate to text: [-2.0237 -7.1105]: The authors propose Sequential Integrated Gradients (SIG) which calculates the importance of each word in a sentence without modifying other words, producing interpolations between the baseline and the word of interest only, thereby close to the original sentences' essence. They further suggest replacing the baseline token 'pad' with the trained token 'mask'.", "target": "The authors propose Sequential Integrated Gradients (SIG) which calculates the importance of each word in a sentence without modifying other words, producing interpolations between the baseline and the word of interest only, thereby close to the original sentences' essence. They further suggest replacing the baseline token 'pad' with the trained token 'mask'.", "example": "Convert the coordinate to text: [-2.0237 -7.1105]:"}
{"text": "Convert the coordinate to text: [12.4251  1.4577]: The authors propose an intermediate problem termed Causal Component Analysis (CauCA), generalizing ICA by modeling causal dependence among the latent components and presenting as a special case of CRL. This offers a focus on learning the unmixing function and the causal mechanisms.", "target": "The authors propose an intermediate problem termed Causal Component Analysis (CauCA), generalizing ICA by modeling causal dependence among the latent components and presenting as a special case of CRL. This offers a focus on learning the unmixing function and the causal mechanisms.", "example": "Convert the coordinate to text: [12.4251  1.4577]:"}
{"text": "Convert the coordinate to text: [-5.4545 -0.444 ]: The authors propose to use reinforcement learning with reference-free, textual entailment rewards, to deal with the problem of factual inconsistency in abstractive summarization systems.", "target": "The authors propose to use reinforcement learning with reference-free, textual entailment rewards, to deal with the problem of factual inconsistency in abstractive summarization systems.", "example": "Convert the coordinate to text: [-5.4545 -0.444 ]:"}
{"text": "Convert the coordinate to text: [ 2.4761 -2.6044]: The authors introduce a new template-agnostic method that controls token-level generation to optimize learning and reduce mistakes. This is achieved by considering negative samples in the training process.", "target": "The authors introduce a new template-agnostic method that controls token-level generation to optimize learning and reduce mistakes. This is achieved by considering negative samples in the training process.", "example": "Convert the coordinate to text: [ 2.4761 -2.6044]:"}
{"text": "Convert the coordinate to text: [0.463  1.0716]: The study investigates recent parameter-efficient methods in combination with counterfactual data augmentation (CDA) for mitigating biases inherited from training corpora in pretrained language models.", "target": "The study investigates recent parameter-efficient methods in combination with counterfactual data augmentation (CDA) for mitigating biases inherited from training corpora in pretrained language models.", "example": "Convert the coordinate to text: [0.463  1.0716]:"}
{"text": "Convert the coordinate to text: [ 1.742  -4.1351]: The authors propose a novel contrastive learning framework, CKCL, which distinguishes between utterances that are context- and knowledge-independent and those that aren't. This distinction aims to obtain latent features reflecting the influence degree of context and external knowledge on predicted results.", "target": "The authors propose a novel contrastive learning framework, CKCL, which distinguishes between utterances that are context- and knowledge-independent and those that aren't. This distinction aims to obtain latent features reflecting the influence degree of context and external knowledge on predicted results.", "example": "Convert the coordinate to text: [ 1.742  -4.1351]:"}
{"text": "Convert the coordinate to text: [ 2.12   -4.0497]: In this study, the authors approach the problem from a different angle by proposing five novel contrastive losses for multi-label text classification tasks; these include Strict Contrastive Loss (SCL), Intra-label Contrastive Loss (ICL), Jaccard Similarity Contrastive Loss (JSCL), Jaccard Similarity Probability Contrastive Loss (JSPCL), and Stepwise Label Contrastive Loss (SLCL).", "target": "In this study, the authors approach the problem from a different angle by proposing five novel contrastive losses for multi-label text classification tasks; these include Strict Contrastive Loss (SCL), Intra-label Contrastive Loss (ICL), Jaccard Similarity Contrastive Loss (JSCL), Jaccard Similarity Probability Contrastive Loss (JSPCL), and Stepwise Label Contrastive Loss (SLCL).", "example": "Convert the coordinate to text: [ 2.12   -4.0497]:"}
{"text": "Convert the coordinate to text: [ 4.0122 -3.665 ]: The authors introduce a novel framework 'BADGE', comprising of block-wise bypasses and divergence-based early exiting (DGE) mechanism. The block-wise bypasses address issues with training a multi-exit PLM and improve the overall performances whilst adding negligible extra computing power (flops). The DGE obtains early exit signals by comparing the predicted distributions of two proximate layers' exits.", "target": "The authors introduce a novel framework 'BADGE', comprising of block-wise bypasses and divergence-based early exiting (DGE) mechanism. The block-wise bypasses address issues with training a multi-exit PLM and improve the overall performances whilst adding negligible extra computing power (flops). The DGE obtains early exit signals by comparing the predicted distributions of two proximate layers' exits.", "example": "Convert the coordinate to text: [ 4.0122 -3.665 ]:"}
{"text": "Convert the coordinate to text: [-10.1784  -1.4364]: This paper introduces two types of buzzer-quiz answering systems. The first one directly generates an answer from part of a question using an autoregressive language model, while the second reconstructs the entire question using an autoregressive language model and then determines the answer according to the reconstructed question.", "target": "This paper introduces two types of buzzer-quiz answering systems. The first one directly generates an answer from part of a question using an autoregressive language model, while the second reconstructs the entire question using an autoregressive language model and then determines the answer according to the reconstructed question.", "example": "Convert the coordinate to text: [-10.1784  -1.4364]:"}
{"text": "Convert the coordinate to text: [ 1.0649 -5.1107]: The authors present C-STANCE, which is, to their knowledge, the first Chinese dataset for zero-shot stance detection. They introduce two new challenging subtasks within ZSSD: target-based and domain-based ZSSD.", "target": "The authors present C-STANCE, which is, to their knowledge, the first Chinese dataset for zero-shot stance detection. They introduce two new challenging subtasks within ZSSD: target-based and domain-based ZSSD.", "example": "Convert the coordinate to text: [ 1.0649 -5.1107]:"}
{"text": "Convert the coordinate to text: [  1.756  -12.7895]: A system named Sniffer is proposed to make model-type-sensitive attacks more effective against real-world applications as it is capable of determining the type of models hidden behind the black-box MLaaS interfaces.", "target": "A system named Sniffer is proposed to make model-type-sensitive attacks more effective against real-world applications as it is capable of determining the type of models hidden behind the black-box MLaaS interfaces.", "example": "Convert the coordinate to text: [  1.756  -12.7895]:"}
{"text": "Convert the coordinate to text: [11.9203 -2.1806]: This study seeks to fill the aforementioned gap by demonstrating why SAM generalizes better than Stochastic Gradient Descent (SGD) for a certain data model and two-layer convolutional ReLU networks.", "target": "This study seeks to fill the aforementioned gap by demonstrating why SAM generalizes better than Stochastic Gradient Descent (SGD) for a certain data model and two-layer convolutional ReLU networks.", "example": "Convert the coordinate to text: [11.9203 -2.1806]:"}
{"text": "Convert the coordinate to text: [10.2982 -2.4649]: The authors propose a different approach to dropout mask construction that relies on the gradient-signal-to-noise ratio (GSNR) of a network's parameters, wherein parameters with a high GSNR are discarded at each training step.", "target": "The authors propose a different approach to dropout mask construction that relies on the gradient-signal-to-noise ratio (GSNR) of a network's parameters, wherein parameters with a high GSNR are discarded at each training step.", "example": "Convert the coordinate to text: [10.2982 -2.4649]:"}
{"text": "Convert the coordinate to text: [ 11.9996 -11.2475]: The authors introduce DeepChange, a large and realistic long-term person re-identification benchmark that captures rich personal appearance variations, camera setups, and conditions.", "target": "The authors introduce DeepChange, a large and realistic long-term person re-identification benchmark that captures rich personal appearance variations, camera setups, and conditions.", "example": "Convert the coordinate to text: [ 11.9996 -11.2475]:"}
{"text": "Convert the coordinate to text: [13.4524 -4.7051]: The authors propose a defense framework that injects non-adversarial backdoors targeted at the poisoned samples, which once triggered, suppresses the attacker's backdoor on the poisoned data and minimally affects clean data.", "target": "The authors propose a defense framework that injects non-adversarial backdoors targeted at the poisoned samples, which once triggered, suppresses the attacker's backdoor on the poisoned data and minimally affects clean data.", "example": "Convert the coordinate to text: [13.4524 -4.7051]:"}
{"text": "Convert the coordinate to text: [  7.9606 -12.6847]: The authors propose to adapt RL-based methods to unsupervised object discovery, i.e., learning to detect objects from LiDAR points without training labels, using simple heuristics to mimic human feedback and combining these heuristics into a reward function that correlates its score with bounding box accuracy.", "target": "The authors propose to adapt RL-based methods to unsupervised object discovery, i.e., learning to detect objects from LiDAR points without training labels, using simple heuristics to mimic human feedback and combining these heuristics into a reward function that correlates its score with bounding box accuracy.", "example": "Convert the coordinate to text: [  7.9606 -12.6847]:"}
{"text": "Convert the coordinate to text: [-2.1847 -4.7411]: The authors propose a student-teacher framework between two LLM agents, with the objective of evaluating if and how a teacher LLM can improve the performance of a weaker student LLM through the use of natural language explanations.", "target": "The authors propose a student-teacher framework between two LLM agents, with the objective of evaluating if and how a teacher LLM can improve the performance of a weaker student LLM through the use of natural language explanations.", "example": "Convert the coordinate to text: [-2.1847 -4.7411]:"}
{"text": "Convert the coordinate to text: [13.8598 -0.0789]: The authors propose ContiFormer, an extension of the relation modeling of vanilla Transformer to the continuous-time domain. It incorporates the modeling abilities of Neural ODE's continuous dynamics with Transformers' attention mechanism.", "target": "The authors propose ContiFormer, an extension of the relation modeling of vanilla Transformer to the continuous-time domain. It incorporates the modeling abilities of Neural ODE's continuous dynamics with Transformers' attention mechanism.", "example": "Convert the coordinate to text: [13.8598 -0.0789]:"}
{"text": "Convert the coordinate to text: [-2.6638 -3.6486]: The authors propose the KVZEL framework for zero-shot entity linking, which selects key views from descriptions to remove irrelevant noise and focus on mention-related information.", "target": "The authors propose the KVZEL framework for zero-shot entity linking, which selects key views from descriptions to remove irrelevant noise and focus on mention-related information.", "example": "Convert the coordinate to text: [-2.6638 -3.6486]:"}
{"text": "Convert the coordinate to text: [-5.9388 -5.2405]: The authors propose to estimate and compare the lexical-semantic structure in both humans and large language models, highlighting differences in how these estimates are influenced by factors such as culture, language, and estimation method.", "target": "The authors propose to estimate and compare the lexical-semantic structure in both humans and large language models, highlighting differences in how these estimates are influenced by factors such as culture, language, and estimation method.", "example": "Convert the coordinate to text: [-5.9388 -5.2405]:"}
{"text": "Convert the coordinate to text: [ 3.446  -8.5269]: The proposal is a tuning-free method, MasaCtrl, which is developed to simultaneously achieve consistent image generation and complex non-rigid image editing. MasaCtrl transforms existing self-attention in diffusion models into mutual self-attention, allowing correlated local content and textures from source images to be queried for consistency.", "target": "The proposal is a tuning-free method, MasaCtrl, which is developed to simultaneously achieve consistent image generation and complex non-rigid image editing. MasaCtrl transforms existing self-attention in diffusion models into mutual self-attention, allowing correlated local content and textures from source images to be queried for consistency.", "example": "Convert the coordinate to text: [ 3.446  -8.5269]:"}
{"text": "Convert the coordinate to text: [-7.8231 14.0296]: This study investigates the effect of facial animation method (static, synthesized, or tracked expressions) and the synchronization of these animations to speaker audio (in sync or delayed by the method\u2019s inherent latency) on an avatar\u2019s perceived naturalness and plausibility.", "target": "This study investigates the effect of facial animation method (static, synthesized, or tracked expressions) and the synchronization of these animations to speaker audio (in sync or delayed by the method\u2019s inherent latency) on an avatar\u2019s perceived naturalness and plausibility.", "example": "Convert the coordinate to text: [-7.8231 14.0296]:"}
{"text": "Convert the coordinate to text: [-1.846  -5.4315]: This study investigates the use of large-scale language models such as GPT-k, renowned for their text generation capabilities, to enhance the prompt editing process in T2I generation.", "target": "This study investigates the use of large-scale language models such as GPT-k, renowned for their text generation capabilities, to enhance the prompt editing process in T2I generation.", "example": "Convert the coordinate to text: [-1.846  -5.4315]:"}
{"text": "Convert the coordinate to text: [-3.5158 -7.5511]: The authors propose GLOSS, a model built on a pre-trained multilingual machine translation model (PMMTM) with an added code-switching module. The code-switching module utilizes patterns from code-switched data during training to synthesize code-switched texts for language pairs that weren't in the training data.", "target": "The authors propose GLOSS, a model built on a pre-trained multilingual machine translation model (PMMTM) with an added code-switching module. The code-switching module utilizes patterns from code-switched data during training to synthesize code-switched texts for language pairs that weren't in the training data.", "example": "Convert the coordinate to text: [-3.5158 -7.5511]:"}
{"text": "Convert the coordinate to text: [-3.7042 -1.2101]: The authors propose a unified framework for ETRE that transforms temporal relations into logical expressions of time points and predicts the relationships between specific pairs of time points.", "target": "The authors propose a unified framework for ETRE that transforms temporal relations into logical expressions of time points and predicts the relationships between specific pairs of time points.", "example": "Convert the coordinate to text: [-3.7042 -1.2101]:"}
{"text": "Convert the coordinate to text: [-0.9579 -2.1313]: A two-stage decoding mechanism is proposed for predicting ICD codes, which takes inspiration from the process human coders employ. This methodology leverages the hierarchical properties of ICD codes where the parent code is first forecasted, followed by the prediction of the child code.", "target": "A two-stage decoding mechanism is proposed for predicting ICD codes, which takes inspiration from the process human coders employ. This methodology leverages the hierarchical properties of ICD codes where the parent code is first forecasted, followed by the prediction of the child code.", "example": "Convert the coordinate to text: [-0.9579 -2.1313]:"}
{"text": "Convert the coordinate to text: [-2.0634 -7.4678]: The authors present ACLM (Attention-map aware keyword selection for Conditional Language Model fine-tuning), a data augmentation approach based on conditional generation which addresses data scarcity in low-resource complex NER and alleviates context-entity mismatch issues. ACLM is built on BART and is optimized on a novel denoising task using selective masking to retain contextually relevant keywords and named entities.", "target": "The authors present ACLM (Attention-map aware keyword selection for Conditional Language Model fine-tuning), a data augmentation approach based on conditional generation which addresses data scarcity in low-resource complex NER and alleviates context-entity mismatch issues. ACLM is built on BART and is optimized on a novel denoising task using selective masking to retain contextually relevant keywords and named entities.", "example": "Convert the coordinate to text: [-2.0634 -7.4678]:"}
{"text": "Convert the coordinate to text: [-1.3755 -6.0951]: The authors propose framing fine-tuning into a causal graph to identify the missing causal effects from the pre-trained data, and they introduce a unified objective for fine-tuning to bring back the causality, which they claim can mitigate negative transfer while preserving knowledge from pre-trained language models (PLMs).", "target": "The authors propose framing fine-tuning into a causal graph to identify the missing causal effects from the pre-trained data, and they introduce a unified objective for fine-tuning to bring back the causality, which they claim can mitigate negative transfer while preserving knowledge from pre-trained language models (PLMs).", "example": "Convert the coordinate to text: [-1.3755 -6.0951]:"}
{"text": "Convert the coordinate to text: [-9.9861 -8.2153]: The authors describe a refined version of Earley's parsing algorithm that includes a worst-case runtime improvement to match the runtime of CKY on a binarized version of the grammar, as well as a version that achieves a further reduced runtime using a single finite-state automaton.", "target": "The authors describe a refined version of Earley's parsing algorithm that includes a worst-case runtime improvement to match the runtime of CKY on a binarized version of the grammar, as well as a version that achieves a further reduced runtime using a single finite-state automaton.", "example": "Convert the coordinate to text: [-9.9861 -8.2153]:"}
{"text": "Convert the coordinate to text: [-1.1058 -6.7258]: The authors experiment with many state-of-the-art transformer-based language models and use a transformer model called \u201cLongformer\u201d to categorize news articles into different categories.", "target": "The authors experiment with many state-of-the-art transformer-based language models and use a transformer model called \u201cLongformer\u201d to categorize news articles into different categories.", "example": "Convert the coordinate to text: [-1.1058 -6.7258]:"}
{"text": "Convert the coordinate to text: [ 7.5715 -1.9936]: The authors propose the concept of parameter-efficient tuning (PETuning) of PLMs in a federated context, creating a benchmark known as FedPETuning. It investigates privacy attacks, performance comparisons, and resource-constrained analysis.", "target": "The authors propose the concept of parameter-efficient tuning (PETuning) of PLMs in a federated context, creating a benchmark known as FedPETuning. It investigates privacy attacks, performance comparisons, and resource-constrained analysis.", "example": "Convert the coordinate to text: [ 7.5715 -1.9936]:"}
{"text": "Convert the coordinate to text: [-2.8029 -0.738 ]: The authors present a dynamic structured neural topic model that can handle the time-series development of topics while capturing their dependencies. This is achieved through the introduction of a self-attention mechanism and a novel citation regularization to represent citation relations by modeling text and citations jointly.", "target": "The authors present a dynamic structured neural topic model that can handle the time-series development of topics while capturing their dependencies. This is achieved through the introduction of a self-attention mechanism and a novel citation regularization to represent citation relations by modeling text and citations jointly.", "example": "Convert the coordinate to text: [-2.8029 -0.738 ]:"}
{"text": "Convert the coordinate to text: [-4.3238 -3.1531]: To address the named entity recognition and relationship extraction problems in recipe translation, a new framework is proposed, consisting of two modules that construct a flow graph from the input recipe.", "target": "To address the named entity recognition and relationship extraction problems in recipe translation, a new framework is proposed, consisting of two modules that construct a flow graph from the input recipe.", "example": "Convert the coordinate to text: [-4.3238 -3.1531]:"}
{"text": "Convert the coordinate to text: [-0.6102 -3.5771]: The authors propose a dynamic heterogeneous-graph reasoning method with Language Models and Knowledge Representation Learning (DHLK), which optimizes the structure and knowledge representation of a Heterogeneous Knowledge Graph (HKG) using a two-stage pruning strategy and knowledge representation learning (KRL).", "target": "The authors propose a dynamic heterogeneous-graph reasoning method with Language Models and Knowledge Representation Learning (DHLK), which optimizes the structure and knowledge representation of a Heterogeneous Knowledge Graph (HKG) using a two-stage pruning strategy and knowledge representation learning (KRL).", "example": "Convert the coordinate to text: [-0.6102 -3.5771]:"}
{"text": "Convert the coordinate to text: [16.1311  1.8285]: This work is the first attempt to give a well-trained graph neural network (GNN) the ability to detect OODs without modifying its parameters. For this, an Adaptive Amplifier for Graph OOD Detection (AAGOD) framework is proposed, which emphasizes key patterns helpful for graph OOD detection, thereby increasing the gap between OOD and in-distribution graphs.", "target": "This work is the first attempt to give a well-trained graph neural network (GNN) the ability to detect OODs without modifying its parameters. For this, an Adaptive Amplifier for Graph OOD Detection (AAGOD) framework is proposed, which emphasizes key patterns helpful for graph OOD detection, thereby increasing the gap between OOD and in-distribution graphs.", "example": "Convert the coordinate to text: [16.1311  1.8285]:"}
{"text": "Convert the coordinate to text: [11.8834  7.5293]: The authors propose a new first-order optimization algorithm, AcceleratedGradient-OptimisticGradient (AG-OG) Descent Ascent, that leverages the structure of the minimax problem to perform Nesterov acceleration on the individual component and optimistic gradient on the coupling component to achieve optimal convergence rate.", "target": "The authors propose a new first-order optimization algorithm, AcceleratedGradient-OptimisticGradient (AG-OG) Descent Ascent, that leverages the structure of the minimax problem to perform Nesterov acceleration on the individual component and optimistic gradient on the coupling component to achieve optimal convergence rate.", "example": "Convert the coordinate to text: [11.8834  7.5293]:"}
{"text": "Convert the coordinate to text: [ 2.6183 -9.934 ]: The authors propose a method called Length-Insensitive Scene TExt Recognizer (LISTER), featuring a Neighbor Decoder and a Feature Enhancement Module designed to handle text of any length and model long-range dependencies with low computation cost.", "target": "The authors propose a method called Length-Insensitive Scene TExt Recognizer (LISTER), featuring a Neighbor Decoder and a Feature Enhancement Module designed to handle text of any length and model long-range dependencies with low computation cost.", "example": "Convert the coordinate to text: [ 2.6183 -9.934 ]:"}
{"text": "Convert the coordinate to text: [ 9.505  12.1249]: The authors propose a Whittle index based Q-learning algorithm for restless multi-armed bandits (RMAB) with neural network function approximation, called Neural-Q-Whittle. Because it updates Q-function values at a faster timescale and Whittle indices at a slower timescale, it acts as an example of nonlinear two-timescale stochastic approximation.", "target": "The authors propose a Whittle index based Q-learning algorithm for restless multi-armed bandits (RMAB) with neural network function approximation, called Neural-Q-Whittle. Because it updates Q-function values at a faster timescale and Whittle indices at a slower timescale, it acts as an example of nonlinear two-timescale stochastic approximation.", "example": "Convert the coordinate to text: [ 9.505  12.1249]:"}
{"text": "Convert the coordinate to text: [ 2.7053 11.1105]: The authors proposed a principled approach to determine when efficient replanning should occur in diffusion models based on the model's estimated likelihood of existing generated plans. Along with this, they also present an approach to replan existing trajectories to ensure new plans follow the same goal state as the original trajectory, by leveraging already generated plans.", "target": "The authors proposed a principled approach to determine when efficient replanning should occur in diffusion models based on the model's estimated likelihood of existing generated plans. Along with this, they also present an approach to replan existing trajectories to ensure new plans follow the same goal state as the original trajectory, by leveraging already generated plans.", "example": "Convert the coordinate to text: [ 2.7053 11.1105]:"}
{"text": "Convert the coordinate to text: [4.6301 0.2586]: The paper aims to address the imbalanced FER problem by proposing a novel approach that extracts extra knowledge related to the minor classes from both major and minor class samples, assuming a sample may contain information about multiple classes.", "target": "The paper aims to address the imbalanced FER problem by proposing a novel approach that extracts extra knowledge related to the minor classes from both major and minor class samples, assuming a sample may contain information about multiple classes.", "example": "Convert the coordinate to text: [4.6301 0.2586]:"}
{"text": "Convert the coordinate to text: [  9.1936 -12.4638]: The authors propose LEPARD, a learning-based framework to discover semantically meaningful 3D parts and reconstruct 3D shapes in a part-based manner, which is more robust to pose variations due to articulations.", "target": "The authors propose LEPARD, a learning-based framework to discover semantically meaningful 3D parts and reconstruct 3D shapes in a part-based manner, which is more robust to pose variations due to articulations.", "example": "Convert the coordinate to text: [  9.1936 -12.4638]:"}
{"text": "Convert the coordinate to text: [ 8.6801 10.4849]: The authors propose a new model called the failure-aware Gaussian process upper confidence bound (F-GP-UCB) that assumes an optimal solution lies in the interior of a feasible region, in order to handle the scenario of observation failure in black-box optimization.", "target": "The authors propose a new model called the failure-aware Gaussian process upper confidence bound (F-GP-UCB) that assumes an optimal solution lies in the interior of a feasible region, in order to handle the scenario of observation failure in black-box optimization.", "example": "Convert the coordinate to text: [ 8.6801 10.4849]:"}
{"text": "Convert the coordinate to text: [ 8.7004 -5.1109]: The authors developed a theoretical foundation for SE(3) invariant diffusion models on multiple frames and proposed a framework, FrameDiff, for learning the SE(3) equivariant score over multiple frames.", "target": "The authors developed a theoretical foundation for SE(3) invariant diffusion models on multiple frames and proposed a framework, FrameDiff, for learning the SE(3) equivariant score over multiple frames.", "example": "Convert the coordinate to text: [ 8.7004 -5.1109]:"}
{"text": "Convert the coordinate to text: [-1.2354 -6.5601]: The authors propose using BERT-based preprocessors and encoders with varied activation functions in the output layer for predicting soft labels in the learning with disagreement task. They also introduced a sinusoidal activation function for the first time.", "target": "The authors propose using BERT-based preprocessors and encoders with varied activation functions in the output layer for predicting soft labels in the learning with disagreement task. They also introduced a sinusoidal activation function for the first time.", "example": "Convert the coordinate to text: [-1.2354 -6.5601]:"}
{"text": "Convert the coordinate to text: [-3.2793 -3.8389]: The authors propose a trustworthy NER framework E-NER by introducing two uncertainty-guided loss terms to the conventional EDL, along with a series of uncertainty-guided training strategies.", "target": "The authors propose a trustworthy NER framework E-NER by introducing two uncertainty-guided loss terms to the conventional EDL, along with a series of uncertainty-guided training strategies.", "example": "Convert the coordinate to text: [-3.2793 -3.8389]:"}
{"text": "Convert the coordinate to text: [ 1.1508 -7.4171]: The authors investigate the uniform design choice in Transformers and propose a more complex block, named Brainformer, which consists of a diverse set of layers like sparsely gated feed-forward layers, dense feed-forward layers, attention layers, and various forms of layer normalization and activation functions.", "target": "The authors investigate the uniform design choice in Transformers and propose a more complex block, named Brainformer, which consists of a diverse set of layers like sparsely gated feed-forward layers, dense feed-forward layers, attention layers, and various forms of layer normalization and activation functions.", "example": "Convert the coordinate to text: [ 1.1508 -7.4171]:"}
{"text": "Convert the coordinate to text: [-1.3647 -5.3658]: This paper proposes a novel sequence-to-sequence&set text-to-table generation model. Instead of serializing each table into a token sequence, the proposed model uses a table header generator to first output a table header, then a table body generator with learnable row embeddings and column embeddings to generate a set of table body rows in parallel.", "target": "This paper proposes a novel sequence-to-sequence&set text-to-table generation model. Instead of serializing each table into a token sequence, the proposed model uses a table header generator to first output a table header, then a table body generator with learnable row embeddings and column embeddings to generate a set of table body rows in parallel.", "example": "Convert the coordinate to text: [-1.3647 -5.3658]:"}
{"text": "Convert the coordinate to text: [-5.0202  8.505 ]: The authors introduce a novel task of automatically rewriting GBV descriptions to alter the perceived level of responsibility on the perpetrator. The idea is to facilitate access to alternative perspectives and raise awareness on perspective-based writing.", "target": "The authors introduce a novel task of automatically rewriting GBV descriptions to alter the perceived level of responsibility on the perpetrator. The idea is to facilitate access to alternative perspectives and raise awareness on perspective-based writing.", "example": "Convert the coordinate to text: [-5.0202  8.505 ]:"}
{"text": "Convert the coordinate to text: [-2.139  -5.0342]: In this study, the authors explore the Spoken Language Understanding (SLU) pipeline within a task-oriented dialogue system developed for Kid Space, using a multi-task architecture for Natural Language Understanding (NLU) and an array of pretrained language representations for Intent Recognition and Entity Extraction tasks in the math learning domain.", "target": "In this study, the authors explore the Spoken Language Understanding (SLU) pipeline within a task-oriented dialogue system developed for Kid Space, using a multi-task architecture for Natural Language Understanding (NLU) and an array of pretrained language representations for Intent Recognition and Entity Extraction tasks in the math learning domain.", "example": "Convert the coordinate to text: [-2.139  -5.0342]:"}
{"text": "Convert the coordinate to text: [ 2.5645 -3.7564]: The authors propose a novel continual user representation learning method, the TERACON, which is not limited in its learning capability as the number of learned tasks increases and can capture the relationship between the tasks. In this method, a task embedding is used to generate task-specific soft masks aiding the entire model's parameters to be updated until the end of training sequence and helping capture the relationships between tasks.", "target": "The authors propose a novel continual user representation learning method, the TERACON, which is not limited in its learning capability as the number of learned tasks increases and can capture the relationship between the tasks. In this method, a task embedding is used to generate task-specific soft masks aiding the entire model's parameters to be updated until the end of training sequence and helping capture the relationships between tasks.", "example": "Convert the coordinate to text: [ 2.5645 -3.7564]:"}
{"text": "Convert the coordinate to text: [-10.3664  -1.9597]: Proposes a data augmentation method for enriching the training dataset with diverse questions given the same context and answer, and an overgenerate-and-rank method for selecting the best question from a pool of candidates.", "target": "Proposes a data augmentation method for enriching the training dataset with diverse questions given the same context and answer, and an overgenerate-and-rank method for selecting the best question from a pool of candidates.", "example": "Convert the coordinate to text: [-10.3664  -1.9597]:"}
{"text": "Convert the coordinate to text: [-1.9453 -4.0972]: The paper proposes a new approach for dealing with misspelled queries in dense retrieval. Rather than just minimizing the representation discrepancy between misspelled queries and their correct counterparts, the method also improves the contrast between each misspelled query and its surrounding queries.", "target": "The paper proposes a new approach for dealing with misspelled queries in dense retrieval. Rather than just minimizing the representation discrepancy between misspelled queries and their correct counterparts, the method also improves the contrast between each misspelled query and its surrounding queries.", "example": "Convert the coordinate to text: [-1.9453 -4.0972]:"}
{"text": "Convert the coordinate to text: [-4.8449 -1.6179]: The authors propose an evaluation scheme to model human judgements across 7 NLP tasks, based on fine-grained mismatches between two texts. They also introduce 13 specific error types related to the mismatches, and design a neural framework that utilises these error types as aids for evaluating the quality of machine-generated texts.", "target": "The authors propose an evaluation scheme to model human judgements across 7 NLP tasks, based on fine-grained mismatches between two texts. They also introduce 13 specific error types related to the mismatches, and design a neural framework that utilises these error types as aids for evaluating the quality of machine-generated texts.", "example": "Convert the coordinate to text: [-4.8449 -1.6179]:"}
{"text": "Convert the coordinate to text: [-2.994   1.6248]: This paper introduces a novel signal-highlighting task based on the year-to-year structure of financial reports, and proposes a compare-and-contrast multistage pipeline that recognizes different relationships between the reports and locates relevant rationales for these relationships.", "target": "This paper introduces a novel signal-highlighting task based on the year-to-year structure of financial reports, and proposes a compare-and-contrast multistage pipeline that recognizes different relationships between the reports and locates relevant rationales for these relationships.", "example": "Convert the coordinate to text: [-2.994   1.6248]:"}
{"text": "Convert the coordinate to text: [-1.7174 -6.4318]: The authors' best-performing approach to Human Value Detection used BERT Large, modelled with four classification heads implementing two different classification approaches with different activation and loss functions, alongside two different partitioning schemes to address the class imbalance issue.", "target": "The authors' best-performing approach to Human Value Detection used BERT Large, modelled with four classification heads implementing two different classification approaches with different activation and loss functions, alongside two different partitioning schemes to address the class imbalance issue.", "example": "Convert the coordinate to text: [-1.7174 -6.4318]:"}
{"text": "Convert the coordinate to text: [-6.414   6.6731]: This research proposes using the framework of relationality to model social relations and socio-ethical styles for a deeper understanding and better modeling of offensive language, particularly in minoritized languages.", "target": "This research proposes using the framework of relationality to model social relations and socio-ethical styles for a deeper understanding and better modeling of offensive language, particularly in minoritized languages.", "example": "Convert the coordinate to text: [-6.414   6.6731]:"}
{"text": "Convert the coordinate to text: [-5.6261 -1.9991]: The authors propose a sequential sentence classification process to categorize legal documents into 13 segments, referred to as Rhetorical Roles. The approach allows for the extraction of valuable insights from various categories within the structured document.", "target": "The authors propose a sequential sentence classification process to categorize legal documents into 13 segments, referred to as Rhetorical Roles. The approach allows for the extraction of valuable insights from various categories within the structured document.", "example": "Convert the coordinate to text: [-5.6261 -1.9991]:"}
{"text": "Convert the coordinate to text: [ 6.7045 -4.205 ]: The authors propose InterDAPT, a novel framework which utilizes Intermediate Domain Fine-tuning to aid language models in adapting to specific domains using smaller, noisy data sets by leveraging peripherally-related, unlabeled data sets.", "target": "The authors propose InterDAPT, a novel framework which utilizes Intermediate Domain Fine-tuning to aid language models in adapting to specific domains using smaller, noisy data sets by leveraging peripherally-related, unlabeled data sets.", "example": "Convert the coordinate to text: [ 6.7045 -4.205 ]:"}
{"text": "Convert the coordinate to text: [-8.0572 -1.1867]: The authors propose an explainable automatic short answer grading framework that combines a fine-tuned Transformer-based classifier with either SHAP or Integrated Gradients based explainability module to generate interpretable language explanations for each prediction.", "target": "The authors propose an explainable automatic short answer grading framework that combines a fine-tuned Transformer-based classifier with either SHAP or Integrated Gradients based explainability module to generate interpretable language explanations for each prediction.", "example": "Convert the coordinate to text: [-8.0572 -1.1867]:"}
{"text": "Convert the coordinate to text: [-0.8366  0.5186]: This paper presents the first multi-dimensional analysis of bias in English VL models, with a focus on gender, ethnicity, and age dimensions.", "target": "This paper presents the first multi-dimensional analysis of bias in English VL models, with a focus on gender, ethnicity, and age dimensions.", "example": "Convert the coordinate to text: [-0.8366  0.5186]:"}
{"text": "Convert the coordinate to text: [ 0.0679 -7.3306]: The authors propose a new paradigm called Uni-Encoder, which encodes all the candidates with context in a single forward pass using the same positional embedding, and introduces a new attention mechanism to avoid confusion.", "target": "The authors propose a new paradigm called Uni-Encoder, which encodes all the candidates with context in a single forward pass using the same positional embedding, and introduces a new attention mechanism to avoid confusion.", "example": "Convert the coordinate to text: [ 0.0679 -7.3306]:"}
{"text": "Convert the coordinate to text: [-0.4815  0.1645]: The authors introduce Gender-tuning, a method of debiasing the PLMs by fine-tuning them on downstream tasks' datasets, integrating Masked Language Modeling (MLM) training objectives into the fine-tuning process.", "target": "The authors introduce Gender-tuning, a method of debiasing the PLMs by fine-tuning them on downstream tasks' datasets, integrating Masked Language Modeling (MLM) training objectives into the fine-tuning process.", "example": "Convert the coordinate to text: [-0.4815  0.1645]:"}
{"text": "Convert the coordinate to text: [ 0.7843 -8.9336]: The authors propose PEIT, an end-to-end image translation framework that bridges this modality gap using pre-trained models. PEIT consists of four components: a visual encoder, a shared encoder-decoder backbone network, a vision-text representation aligner, and a cross-modal regularizer, all aimed at reducing the modality gap.", "target": "The authors propose PEIT, an end-to-end image translation framework that bridges this modality gap using pre-trained models. PEIT consists of four components: a visual encoder, a shared encoder-decoder backbone network, a vision-text representation aligner, and a cross-modal regularizer, all aimed at reducing the modality gap.", "example": "Convert the coordinate to text: [ 0.7843 -8.9336]:"}
{"text": "Convert the coordinate to text: [13.4746 -4.7371]: The authors designed and evaluated a simple yet effective self-supervised backdoor attack, Ctrl, which demonstrates that both SSL and supervised learning are comparably vulnerable to backdoor attacks.", "target": "The authors designed and evaluated a simple yet effective self-supervised backdoor attack, Ctrl, which demonstrates that both SSL and supervised learning are comparably vulnerable to backdoor attacks.", "example": "Convert the coordinate to text: [13.4746 -4.7371]:"}
{"text": "Convert the coordinate to text: [ 5.8152 -3.7894]: The paper proposes TransIFF, an instance-level feature fusion framework with transformers. It focuses on reducing bandwidth usage, aligning domain gaps between vehicle and infrastructure features, and improving robustness of feature fusion, all aiming for high cooperative perception accuracy.", "target": "The paper proposes TransIFF, an instance-level feature fusion framework with transformers. It focuses on reducing bandwidth usage, aligning domain gaps between vehicle and infrastructure features, and improving robustness of feature fusion, all aiming for high cooperative perception accuracy.", "example": "Convert the coordinate to text: [ 5.8152 -3.7894]:"}
{"text": "Convert the coordinate to text: [ 9.185  -8.3501]: The authors propose PUCA, a novel J-invariant U-Net architecture for self-supervised denoising, which utilizes patch-unshuffle/shuffle for expanding receptive fields while maintaining J-invariance, and dilated attention blocks (DABs) for global context incorporation.", "target": "The authors propose PUCA, a novel J-invariant U-Net architecture for self-supervised denoising, which utilizes patch-unshuffle/shuffle for expanding receptive fields while maintaining J-invariance, and dilated attention blocks (DABs) for global context incorporation.", "example": "Convert the coordinate to text: [ 9.185  -8.3501]:"}
{"text": "Convert the coordinate to text: [ 6.8849 -0.0949]: The authors revisit the logistic-softmax likelihood, and redesign it to allow control of the prior confidence level through the use of a temperature parameter. The authors also establish that the softmax can be seen as a special case of logistic-softmax, and that logistic-softmax induces a larger family of data distribution than softmax.", "target": "The authors revisit the logistic-softmax likelihood, and redesign it to allow control of the prior confidence level through the use of a temperature parameter. The authors also establish that the softmax can be seen as a special case of logistic-softmax, and that logistic-softmax induces a larger family of data distribution than softmax.", "example": "Convert the coordinate to text: [ 6.8849 -0.0949]:"}
{"text": "Convert the coordinate to text: [ 1.8829 -7.5403]: The authors reinterpret self-attention mechanism as a non-parametric kernel density estimator, and create new classes of transformers that are resistant to adversarial attacks and data contamination by adapting robust kernel density estimation methods.", "target": "The authors reinterpret self-attention mechanism as a non-parametric kernel density estimator, and create new classes of transformers that are resistant to adversarial attacks and data contamination by adapting robust kernel density estimation methods.", "example": "Convert the coordinate to text: [ 1.8829 -7.5403]:"}
{"text": "Convert the coordinate to text: [ 4.1704 -4.0952]: The authors propose a new method called 'fair graph distillation', an approach for generating small, distilled, fair, and informative graphs based on the graph distillation method.", "target": "The authors propose a new method called 'fair graph distillation', an approach for generating small, distilled, fair, and informative graphs based on the graph distillation method.", "example": "Convert the coordinate to text: [ 4.1704 -4.0952]:"}
{"text": "Convert the coordinate to text: [-5.9025 -0.5623]: The authors propose TempoSum, a benchmark containing data samples from 2010 to 2022, to examine the temporal generalization ability of abstractive summarization models.", "target": "The authors propose TempoSum, a benchmark containing data samples from 2010 to 2022, to examine the temporal generalization ability of abstractive summarization models.", "example": "Convert the coordinate to text: [-5.9025 -0.5623]:"}
{"text": "Convert the coordinate to text: [-3.7662 -5.0673]: Influenced by the global-local contextualization from current methods, the authors propose UnifieR, a learning framework that integrates dense-vector and lexicon-based retrieval into one model with a dual-representing capability.", "target": "Influenced by the global-local contextualization from current methods, the authors propose UnifieR, a learning framework that integrates dense-vector and lexicon-based retrieval into one model with a dual-representing capability.", "example": "Convert the coordinate to text: [-3.7662 -5.0673]:"}
{"text": "Convert the coordinate to text: [ -1.4736 -13.0895]: The authors propose an approach called Language-Quantized AutoEncoder (LQAE), a version of VQ-VAE. It aligns text-image data in an unsupervised way by encoding image as sequences of text tokens, leveraging pretrained language models like BERT, RoBERTa. Thereby, it represents and aligns these two modalities without using specific image-text pairs.", "target": "The authors propose an approach called Language-Quantized AutoEncoder (LQAE), a version of VQ-VAE. It aligns text-image data in an unsupervised way by encoding image as sequences of text tokens, leveraging pretrained language models like BERT, RoBERTa. Thereby, it represents and aligns these two modalities without using specific image-text pairs.", "example": "Convert the coordinate to text: [ -1.4736 -13.0895]:"}
{"text": "Convert the coordinate to text: [-10.3507   8.8676]: The authors aim to enhance the effectiveness of IIMC by using historical personal data. They study ways in which this data-driven approach can improve work-nonwork balance.", "target": "The authors aim to enhance the effectiveness of IIMC by using historical personal data. They study ways in which this data-driven approach can improve work-nonwork balance.", "example": "Convert the coordinate to text: [-10.3507   8.8676]:"}
{"text": "Convert the coordinate to text: [-10.2251   7.6916]: Several challenges with ODRL usage in the AURORAL project's context have been identified, and certain areas for action have been proposed - one of which is considering dynamic values from external data sources into privacy policies.", "target": "Several challenges with ODRL usage in the AURORAL project's context have been identified, and certain areas for action have been proposed - one of which is considering dynamic values from external data sources into privacy policies.", "example": "Convert the coordinate to text: [-10.2251   7.6916]:"}
{"text": "Convert the coordinate to text: [-2.468  -1.1104]: HyHTM, a Hyperbolic geometry based Hierarchical Topic Models, is proposed to address these issues, incorporating hierarchical information from hyperbolic geometry to explicitly model hierarchies within topic models.", "target": "HyHTM, a Hyperbolic geometry based Hierarchical Topic Models, is proposed to address these issues, incorporating hierarchical information from hyperbolic geometry to explicitly model hierarchies within topic models.", "example": "Convert the coordinate to text: [-2.468  -1.1104]:"}
{"text": "Convert the coordinate to text: [-5.006  -1.3946]: The authors propose a novel diversity-aware coherence loss for neural topic models, which encourages the model to learn corpus-level coherence scores while maintaining a high diversity between topics.", "target": "The authors propose a novel diversity-aware coherence loss for neural topic models, which encourages the model to learn corpus-level coherence scores while maintaining a high diversity between topics.", "example": "Convert the coordinate to text: [-5.006  -1.3946]:"}
{"text": "Convert the coordinate to text: [-6.1709 -5.0737]: The authors propose a novel multi-task learning framework that leverages linguistic rules and techniques from basic sense discrimination (BSD) and word sense disambiguation (WSD) to address the limited data problem in metaphor detection. The authors utilize adversarial training to align the data distributions of MD and BSD in the same feature space and seamlessly transition knowledge from BSD to MD.", "target": "The authors propose a novel multi-task learning framework that leverages linguistic rules and techniques from basic sense discrimination (BSD) and word sense disambiguation (WSD) to address the limited data problem in metaphor detection. The authors utilize adversarial training to align the data distributions of MD and BSD in the same feature space and seamlessly transition knowledge from BSD to MD.", "example": "Convert the coordinate to text: [-6.1709 -5.0737]:"}
{"text": "Convert the coordinate to text: [-0.558  -3.3363]: The authors propose a new inference framework, called Recursion of Thought (RoT), which introduces special tokens that the models can output to trigger context-related operations, dividing a problem into multiple contexts.", "target": "The authors propose a new inference framework, called Recursion of Thought (RoT), which introduces special tokens that the models can output to trigger context-related operations, dividing a problem into multiple contexts.", "example": "Convert the coordinate to text: [-0.558  -3.3363]:"}
{"text": "Convert the coordinate to text: [4.4218 8.282 ]: The paper formalizes BPE as a combinatorial optimization problem and proposes a faster implementation of BPE that improves its runtime complexity.", "target": "The paper formalizes BPE as a combinatorial optimization problem and proposes a faster implementation of BPE that improves its runtime complexity.", "example": "Convert the coordinate to text: [4.4218 8.282 ]:"}
{"text": "Convert the coordinate to text: [-3.7819 -9.3658]: The authors describe their subtitling pipeline, comprising of speech segmentation, speech recognition, punctuation prediction and inverse text normalization, text machine translation and direct speech-to-text translation, and intelligent line segmentation. For the formality track, formality control was supported via prefix tokens in their En-Ru and En-Pt production models.", "target": "The authors describe their subtitling pipeline, comprising of speech segmentation, speech recognition, punctuation prediction and inverse text normalization, text machine translation and direct speech-to-text translation, and intelligent line segmentation. For the formality track, formality control was supported via prefix tokens in their En-Ru and En-Pt production models.", "example": "Convert the coordinate to text: [-3.7819 -9.3658]:"}
{"text": "Convert the coordinate to text: [-6.2382 -0.1928]: This study proposes an investigation into the feasibility of summarizing hospital discharge summaries by determining the origin, or data provenance, of the discharge summary's source text.", "target": "This study proposes an investigation into the feasibility of summarizing hospital discharge summaries by determining the origin, or data provenance, of the discharge summary's source text.", "example": "Convert the coordinate to text: [-6.2382 -0.1928]:"}
{"text": "Convert the coordinate to text: [-5.839   0.9219]: The authors propose ClaimDiff, a dataset focussing on comparing the nuance between claim pairs rather than strictly verifying them, given the assumption that among trusted sources, one's argument is not necessarily more true than the other.", "target": "The authors propose ClaimDiff, a dataset focussing on comparing the nuance between claim pairs rather than strictly verifying them, given the assumption that among trusted sources, one's argument is not necessarily more true than the other.", "example": "Convert the coordinate to text: [-5.839   0.9219]:"}
{"text": "Convert the coordinate to text: [ 4.5994 -2.3912]: The paper proposes a simple yet competent Semi-Supervised Learning (SSL) approach for label-efficient intent classification using a small labeled corpus and relatively larger unlabeled query data to train a transformer model.", "target": "The paper proposes a simple yet competent Semi-Supervised Learning (SSL) approach for label-efficient intent classification using a small labeled corpus and relatively larger unlabeled query data to train a transformer model.", "example": "Convert the coordinate to text: [ 4.5994 -2.3912]:"}
{"text": "Convert the coordinate to text: [-2.1315 -7.4462]: This paper aims to investigate the true impact of anisotropy on the performance of text representations by assessing the impact of different transformations on both the isotropy and the performance.", "target": "This paper aims to investigate the true impact of anisotropy on the performance of text representations by assessing the impact of different transformations on both the isotropy and the performance.", "example": "Convert the coordinate to text: [-2.1315 -7.4462]:"}
{"text": "Convert the coordinate to text: [-2.3226 -3.7366]: A novel data-to-text generation approach is proposed, which provides a unified representation that can accommodate a variety of structured data forms, such as tables, knowledge graph triples, and meaning representations, improving potential performance in multi-task, zero-shot and few-shot scenarios.", "target": "A novel data-to-text generation approach is proposed, which provides a unified representation that can accommodate a variety of structured data forms, such as tables, knowledge graph triples, and meaning representations, improving potential performance in multi-task, zero-shot and few-shot scenarios.", "example": "Convert the coordinate to text: [-2.3226 -3.7366]:"}
{"text": "Convert the coordinate to text: [-2.2715 -5.5086]: This paper proposes to probe the ability of GPT-3 to detect metaphoric language and predict the metaphor\u2019s source domain without any pre-set domains, enhancing our understanding of the AI model's interpretation of metaphors.", "target": "This paper proposes to probe the ability of GPT-3 to detect metaphoric language and predict the metaphor\u2019s source domain without any pre-set domains, enhancing our understanding of the AI model's interpretation of metaphors.", "example": "Convert the coordinate to text: [-2.2715 -5.5086]:"}
{"text": "Convert the coordinate to text: [ 4.831 -6.225]: The authors introduce SSAGCN (Self-Supervised Adaptive Graph Convolutional Network), a method which fuses topology information and attribute information automatically through an adaptive graph convolutional network and uses a dual decoder for simultaneous reconstruction of network topology and attributes.", "target": "The authors introduce SSAGCN (Self-Supervised Adaptive Graph Convolutional Network), a method which fuses topology information and attribute information automatically through an adaptive graph convolutional network and uses a dual decoder for simultaneous reconstruction of network topology and attributes.", "example": "Convert the coordinate to text: [ 4.831 -6.225]:"}
{"text": "Convert the coordinate to text: [12.7939 -4.7691]: This research proposes Fraud's Bargain Attack (FBA), a new strategy which employs a novel randomization mechanism to enlarge the searching space for adversarial examples, and applies the Metropolis-Hasting algorithm to enhance the selection of such examples. The paper also introduces a contextual-aware Word Manipulation Process (WMP) for perturbing words one at a time.", "target": "This research proposes Fraud's Bargain Attack (FBA), a new strategy which employs a novel randomization mechanism to enlarge the searching space for adversarial examples, and applies the Metropolis-Hasting algorithm to enhance the selection of such examples. The paper also introduces a contextual-aware Word Manipulation Process (WMP) for perturbing words one at a time.", "example": "Convert the coordinate to text: [12.7939 -4.7691]:"}
{"text": "Convert the coordinate to text: [ 3.6745 -0.9205]: This paper introduces the concept of positive distribution pollution, referring to inaccuracies in estimating the positive data distribution when labeled data is limited. It proposes that various issues inherent to PU learning are linked to this problem.", "target": "This paper introduces the concept of positive distribution pollution, referring to inaccuracies in estimating the positive data distribution when labeled data is limited. It proposes that various issues inherent to PU learning are linked to this problem.", "example": "Convert the coordinate to text: [ 3.6745 -0.9205]:"}
{"text": "Convert the coordinate to text: [ 8.8778 -4.8119]: The goal of the paper is to enable flexible symmetry constraints that can be automatically learned from data using gradients. The authors aim to improve parameterizations of soft equivariance and learn the amount of equivariance in layers by optimizing the marginal likelihood using differentiable Laplace approximations.", "target": "The goal of the paper is to enable flexible symmetry constraints that can be automatically learned from data using gradients. The authors aim to improve parameterizations of soft equivariance and learn the amount of equivariance in layers by optimizing the marginal likelihood using differentiable Laplace approximations.", "example": "Convert the coordinate to text: [ 8.8778 -4.8119]:"}
{"text": "Convert the coordinate to text: [16.1929  1.6723]: The authors propose Deep Feature Deblurring Diffusion (DFDD), a new approach consisting of forward blurring and reverse deblurring processes, to improve the performance of detecting OOD objects. The forward process synthesizes virtual OOD features, close to the classification boundary between ID and OOD objects, while the reverse process recovers the lost details in the forward process using a dedicated deblurring model.", "target": "The authors propose Deep Feature Deblurring Diffusion (DFDD), a new approach consisting of forward blurring and reverse deblurring processes, to improve the performance of detecting OOD objects. The forward process synthesizes virtual OOD features, close to the classification boundary between ID and OOD objects, while the reverse process recovers the lost details in the forward process using a dedicated deblurring model.", "example": "Convert the coordinate to text: [16.1929  1.6723]:"}
{"text": "Convert the coordinate to text: [-2.6893 14.5394]: The authors propose a comprehensive framework to learn physically plausible human dynamics from real driving scenarios, integrating physics with a reinforcement learning-based motion controller to address the shortcomings of the existing methods.", "target": "The authors propose a comprehensive framework to learn physically plausible human dynamics from real driving scenarios, integrating physics with a reinforcement learning-based motion controller to address the shortcomings of the existing methods.", "example": "Convert the coordinate to text: [-2.6893 14.5394]:"}
{"text": "Convert the coordinate to text: [ 5.4987 12.609 ]: The authors propose to incorporate state-space distance information into the diversity measure to capture the behavioral difference more accurately. They also propose a novel diversity-driven RL algorithm, State-based Intrinsic-reward Policy Optimization (SIPO), that combines iterative learning with state-distance-based diversity measures.", "target": "The authors propose to incorporate state-space distance information into the diversity measure to capture the behavioral difference more accurately. They also propose a novel diversity-driven RL algorithm, State-based Intrinsic-reward Policy Optimization (SIPO), that combines iterative learning with state-distance-based diversity measures.", "example": "Convert the coordinate to text: [ 5.4987 12.609 ]:"}
{"text": "Convert the coordinate to text: [-1.2858 14.0691]: Rather than optimizing environments, this paper proposes to optimize Neural Cellular Automata (NCA) environment generators using QD algorithms. This approach trains a set of NCA generators in small environments, then uses them to create arbitrarily large environments at test time.", "target": "Rather than optimizing environments, this paper proposes to optimize Neural Cellular Automata (NCA) environment generators using QD algorithms. This approach trains a set of NCA generators in small environments, then uses them to create arbitrarily large environments at test time.", "example": "Convert the coordinate to text: [-1.2858 14.0691]:"}
{"text": "Convert the coordinate to text: [-5.3965  1.8524]: The paper presents a latent variable-based framework to predict the ideology of news articles by comparing multiple articles on the same story and identifying partisan events whose inclusion or omission reveals the ideology.", "target": "The paper presents a latent variable-based framework to predict the ideology of news articles by comparing multiple articles on the same story and identifying partisan events whose inclusion or omission reveals the ideology.", "example": "Convert the coordinate to text: [-5.3965  1.8524]:"}
{"text": "Convert the coordinate to text: [3.1757 1.8501]: The authors propose a novel risk-averse active sensing approach (RAS) that decides when to conduct the acquisition of patient covariates and which measurements to make. This approach decomposes the policy into two sub-policies: acquisition scheduler and feature selector.", "target": "The authors propose a novel risk-averse active sensing approach (RAS) that decides when to conduct the acquisition of patient covariates and which measurements to make. This approach decomposes the policy into two sub-policies: acquisition scheduler and feature selector.", "example": "Convert the coordinate to text: [3.1757 1.8501]:"}
{"text": "Convert the coordinate to text: [11.6877 -2.1149]: The key idea of the study is an account of how the optimization process in two-layer fully connected networks with linear activations carries an implicit bias on the parameters depending on the scale of initialization. The linear neural network's hidden layer has a bias toward a low-rank structure in the small scale initialization regime.", "target": "The key idea of the study is an account of how the optimization process in two-layer fully connected networks with linear activations carries an implicit bias on the parameters depending on the scale of initialization. The linear neural network's hidden layer has a bias toward a low-rank structure in the small scale initialization regime.", "example": "Convert the coordinate to text: [11.6877 -2.1149]:"}
{"text": "Convert the coordinate to text: [-1.2851 -4.8987]: The study introduces 'Synthetic prompting', a method that uses a few handcrafted examples to prompt the model to generate additional examples by itself, and selects effective demonstrations to elicit improved reasoning.", "target": "The study introduces 'Synthetic prompting', a method that uses a few handcrafted examples to prompt the model to generate additional examples by itself, and selects effective demonstrations to elicit improved reasoning.", "example": "Convert the coordinate to text: [-1.2851 -4.8987]:"}
{"text": "Convert the coordinate to text: [ 6.1447 -1.4979]: This paper conducts local-global feature alignment by leveraging global semantic knowledge for learning a better representation. The authors also quantify the benefit of classifier combination for each client as a function of the combining weights and derive an optimization problem for estimating optimal weights.", "target": "This paper conducts local-global feature alignment by leveraging global semantic knowledge for learning a better representation. The authors also quantify the benefit of classifier combination for each client as a function of the combining weights and derive an optimization problem for estimating optimal weights.", "example": "Convert the coordinate to text: [ 6.1447 -1.4979]:"}
{"text": "Convert the coordinate to text: [-1.4928  0.1588]: The authors introduce SemEval Task 10, the Explainable Detection of Online Sexism (EDOS), which consists of a new hierarchical taxonomy of sexist content for improved explainability, a new dataset of 20,000 fine-grained labelled social media comments, and unlabelled datasets for model adaptation.", "target": "The authors introduce SemEval Task 10, the Explainable Detection of Online Sexism (EDOS), which consists of a new hierarchical taxonomy of sexist content for improved explainability, a new dataset of 20,000 fine-grained labelled social media comments, and unlabelled datasets for model adaptation.", "example": "Convert the coordinate to text: [-1.4928  0.1588]:"}
{"text": "Convert the coordinate to text: [-2.7872 -5.3126]: The authors propose the use of large language models (LLMs) as an alternative to human evaluation, calling this method 'LLM evaluation'. The LLM is presented with the same instructions, samples, and questions used in human evaluation and is then asked to answer these questions.", "target": "The authors propose the use of large language models (LLMs) as an alternative to human evaluation, calling this method 'LLM evaluation'. The LLM is presented with the same instructions, samples, and questions used in human evaluation and is then asked to answer these questions.", "example": "Convert the coordinate to text: [-2.7872 -5.3126]:"}
{"text": "Convert the coordinate to text: [-2.6839 -7.5125]: A new method called BOLT is proposed, which incorporates tunable biases to directly adjust the language model's output logits, while keeping the generator's autoregressive nature to gain strong control over token-wise conditional dependencies and overall fluency, which leads to faster convergence.", "target": "A new method called BOLT is proposed, which incorporates tunable biases to directly adjust the language model's output logits, while keeping the generator's autoregressive nature to gain strong control over token-wise conditional dependencies and overall fluency, which leads to faster convergence.", "example": "Convert the coordinate to text: [-2.6839 -7.5125]:"}
{"text": "Convert the coordinate to text: [-4.8965 12.7498]: The authors introduce Maestro, a game-based platform designed to advance robust AI education by offering computer science students challenging, practical assignments inspired by real life.", "target": "The authors introduce Maestro, a game-based platform designed to advance robust AI education by offering computer science students challenging, practical assignments inspired by real life.", "example": "Convert the coordinate to text: [-4.8965 12.7498]:"}
{"text": "Convert the coordinate to text: [-4.0775 11.1251]: This paper provides a formal definition of equity in text generation and proves a formal connection between learning human-likeness and learning equity, suggesting that algorithms for improving equity ultimately reduce to algorithms for improving human-likeness on augmented data.", "target": "This paper provides a formal definition of equity in text generation and proves a formal connection between learning human-likeness and learning equity, suggesting that algorithms for improving equity ultimately reduce to algorithms for improving human-likeness on augmented data.", "example": "Convert the coordinate to text: [-4.0775 11.1251]:"}
{"text": "Convert the coordinate to text: [-0.4368 -6.988 ]: The authors propose a novel Transformer-TabNet based multimodal architecture that leverages both text data and statistical features from the text for improved intimacy prediction in Tweets.", "target": "The authors propose a novel Transformer-TabNet based multimodal architecture that leverages both text data and statistical features from the text for improved intimacy prediction in Tweets.", "example": "Convert the coordinate to text: [-0.4368 -6.988 ]:"}
{"text": "Convert the coordinate to text: [-0.331   2.6364]: This paper is a tutorial on the latest research in MMLMs, covering issues such as data collection, training and fine-tuning of models, Responsible AI issues like fairness, bias, and toxicity, linguistic diversity and evaluation, and real-world deployment challenges.", "target": "This paper is a tutorial on the latest research in MMLMs, covering issues such as data collection, training and fine-tuning of models, Responsible AI issues like fairness, bias, and toxicity, linguistic diversity and evaluation, and real-world deployment challenges.", "example": "Convert the coordinate to text: [-0.331   2.6364]:"}
{"text": "Convert the coordinate to text: [ 8.0063 -2.8179]: The paper investigates behavior of popular learning-based deep registration models under 'sanity-checking' and finds issues like low inverse consistency and non-discrimination of identical pairs. The authors then propose a novel, regularization-based 'sanity-enforcer' method, designed to rectify these behaviours by implementing two sanity checks on deep models.", "target": "The paper investigates behavior of popular learning-based deep registration models under 'sanity-checking' and finds issues like low inverse consistency and non-discrimination of identical pairs. The authors then propose a novel, regularization-based 'sanity-enforcer' method, designed to rectify these behaviours by implementing two sanity checks on deep models.", "example": "Convert the coordinate to text: [ 8.0063 -2.8179]:"}
{"text": "Convert the coordinate to text: [-16.6138   1.8332]: This paper introduces the TPC Express Benchmark for Artificial Intelligence (TPCx-AI), the first industry standard benchmark for end-to-end machine learning deployments, representing the pipelines typically found in common ML and AI workloads.", "target": "This paper introduces the TPC Express Benchmark for Artificial Intelligence (TPCx-AI), the first industry standard benchmark for end-to-end machine learning deployments, representing the pipelines typically found in common ML and AI workloads.", "example": "Convert the coordinate to text: [-16.6138   1.8332]:"}
{"text": "Convert the coordinate to text: [-15.3288   0.9838]: The authors propose in-situ cross-database query processing without a mediating engine, aiming to optimize runtime performance and reduce data movement by leveraging existing systems and eliminating the need for an additional federated query engine.", "target": "The authors propose in-situ cross-database query processing without a mediating engine, aiming to optimize runtime performance and reduce data movement by leveraging existing systems and eliminating the need for an additional federated query engine.", "example": "Convert the coordinate to text: [-15.3288   0.9838]:"}
{"text": "Convert the coordinate to text: [1.6405 2.6154]: The authors propose a novel method of implementing front-door adjustment (FA), which effectively deals with hidden confounders. This method uses the semantic information of images as a mediator, which provides access to the causal mechanism without needing to observe the confounders.", "target": "The authors propose a novel method of implementing front-door adjustment (FA), which effectively deals with hidden confounders. This method uses the semantic information of images as a mediator, which provides access to the causal mechanism without needing to observe the confounders.", "example": "Convert the coordinate to text: [1.6405 2.6154]:"}
{"text": "Convert the coordinate to text: [-1.2448 -1.4604]: The authors propose the use of topological data analysis (TDA), a new set of mathematical techniques used in data analysis and machine learning, to detect and classify solar surface and coronal activity.", "target": "The authors propose the use of topological data analysis (TDA), a new set of mathematical techniques used in data analysis and machine learning, to detect and classify solar surface and coronal activity.", "example": "Convert the coordinate to text: [-1.2448 -1.4604]:"}
{"text": "Convert the coordinate to text: [ 7.2564 -4.1676]: The authors propose an Invariance-acquired Domain AdaptivE HAshing (IDEA) model that decomposes each image into a causal feature representing label information and a non-causal feature indicating domain information, thereby addressing the issues related to domain adaptation and image retrieval.", "target": "The authors propose an Invariance-acquired Domain AdaptivE HAshing (IDEA) model that decomposes each image into a causal feature representing label information and a non-causal feature indicating domain information, thereby addressing the issues related to domain adaptation and image retrieval.", "example": "Convert the coordinate to text: [ 7.2564 -4.1676]:"}
{"text": "Convert the coordinate to text: [ 9.3854 11.9214]: The authors propose a novel distributed learning algorithm based on the upper confidence bound (UCB) algorithm, named H-LINUCB, where agents cooperatively minimize the group regret under the coordination of a central server, in the context of linear contextual bandits.", "target": "The authors propose a novel distributed learning algorithm based on the upper confidence bound (UCB) algorithm, named H-LINUCB, where agents cooperatively minimize the group regret under the coordination of a central server, in the context of linear contextual bandits.", "example": "Convert the coordinate to text: [ 9.3854 11.9214]:"}
{"text": "Convert the coordinate to text: [-3.1598 -2.5106]: The authors propose the task of multi-defendant LJP, intended to predict the judgment results for each defendant of multi-defendant cases. To tackle this, they introduce a multi-defendant LJP method, Hierarchical Reasoning Network (HRN), which follows hierarchical reasoning chains.", "target": "The authors propose the task of multi-defendant LJP, intended to predict the judgment results for each defendant of multi-defendant cases. To tackle this, they introduce a multi-defendant LJP method, Hierarchical Reasoning Network (HRN), which follows hierarchical reasoning chains.", "example": "Convert the coordinate to text: [-3.1598 -2.5106]:"}
{"text": "Convert the coordinate to text: [-7.5008  0.0996]: The authors propose a novel approach, DiffusionRet, which uses document generation from a query as an intermediate step before retrieval. The approach consists of two steps, a diffusion-based document generation and an N-gram-base generative retrieval.", "target": "The authors propose a novel approach, DiffusionRet, which uses document generation from a query as an intermediate step before retrieval. The approach consists of two steps, a diffusion-based document generation and an N-gram-base generative retrieval.", "example": "Convert the coordinate to text: [-7.5008  0.0996]:"}
{"text": "Convert the coordinate to text: [-10.47   -2.032]: The paper introduces a real-world implementation of a question answering system for Vietnamese, called ViGPTQA. The authors also propose, evaluate, and open-source an instruction-tuned LLM for Vietnamese, named ViGPT.", "target": "The paper introduces a real-world implementation of a question answering system for Vietnamese, called ViGPTQA. The authors also propose, evaluate, and open-source an instruction-tuned LLM for Vietnamese, named ViGPT.", "example": "Convert the coordinate to text: [-10.47   -2.032]:"}
{"text": "Convert the coordinate to text: [  5.7724 -11.7756]: In order to address the challenge of VOS in complex scenes, the authors introduce a new dataset called coMplex video Object SEgmentation (MOSE). MOSE is characterized by complex scenes with crowded and occluded objects.", "target": "In order to address the challenge of VOS in complex scenes, the authors introduce a new dataset called coMplex video Object SEgmentation (MOSE). MOSE is characterized by complex scenes with crowded and occluded objects.", "example": "Convert the coordinate to text: [  5.7724 -11.7756]:"}
{"text": "Convert the coordinate to text: [11.8147 -1.9609]: The authors present a novel algorithm, based on mathematical representation theory, for examining how small neural networks learn to implement group composition, providing a means to study the universality hypothesis.", "target": "The authors present a novel algorithm, based on mathematical representation theory, for examining how small neural networks learn to implement group composition, providing a means to study the universality hypothesis.", "example": "Convert the coordinate to text: [11.8147 -1.9609]:"}
{"text": "Convert the coordinate to text: [-2.122  11.0613]: This paper proposes a Knowledge Enhanced Reasoning Model (KERM) that leverages knowledge, crucial information complementary to visible content, to improve an agent's navigation ability.", "target": "This paper proposes a Knowledge Enhanced Reasoning Model (KERM) that leverages knowledge, crucial information complementary to visible content, to improve an agent's navigation ability.", "example": "Convert the coordinate to text: [-2.122  11.0613]:"}
{"text": "Convert the coordinate to text: [-10.684    8.2439]: The authors propose a preliminary three-level ontology of dark patterns to harmonize regulatory and academic taxonomies and create a shared language across fields.", "target": "The authors propose a preliminary three-level ontology of dark patterns to harmonize regulatory and academic taxonomies and create a shared language across fields.", "example": "Convert the coordinate to text: [-10.684    8.2439]:"}
{"text": "Convert the coordinate to text: [-4.1607 11.8235]: The authors are working towards the development of a maturity model for HCAI (HCAI-MM) that aims to support AI development practices in companies, ultimately leading to AI solutions that are efficient, trustworthy, and safe. This paper presents the first phase of the model's development.", "target": "The authors are working towards the development of a maturity model for HCAI (HCAI-MM) that aims to support AI development practices in companies, ultimately leading to AI solutions that are efficient, trustworthy, and safe. This paper presents the first phase of the model's development.", "example": "Convert the coordinate to text: [-4.1607 11.8235]:"}
{"text": "Convert the coordinate to text: [-1.2225 -3.902 ]: The authors propose combining the advantages of sparse and dense persona descriptions and dialogue histories to obtain a richer and more accurate persona. They introduce a model, Contrastive Latent Variable-based model (CLV), that clusters the dense persona descriptions into sparse categories, which, combined with the history query, generate personalized responses.", "target": "The authors propose combining the advantages of sparse and dense persona descriptions and dialogue histories to obtain a richer and more accurate persona. They introduce a model, Contrastive Latent Variable-based model (CLV), that clusters the dense persona descriptions into sparse categories, which, combined with the history query, generate personalized responses.", "example": "Convert the coordinate to text: [-1.2225 -3.902 ]:"}
{"text": "Convert the coordinate to text: [12.7178 -4.9702]: The authors propose to assess the robustness of NLP models by surveying human participants about the perceptibility of text adversarial examples produced by state-of-the-art methods.", "target": "The authors propose to assess the robustness of NLP models by surveying human participants about the perceptibility of text adversarial examples produced by state-of-the-art methods.", "example": "Convert the coordinate to text: [12.7178 -4.9702]:"}
{"text": "Convert the coordinate to text: [-3.3789 -7.4847]: The authors propose to extract compressed, language-specific models from MMTs that still hold the capacity for cross-lingual transfer, achieved by distilling the MMT bilingually using only the source and target language of interest. This is done using a two-phase distillation approach called BiStil, which involves creating a general bilingual model and task-specific models.", "target": "The authors propose to extract compressed, language-specific models from MMTs that still hold the capacity for cross-lingual transfer, achieved by distilling the MMT bilingually using only the source and target language of interest. This is done using a two-phase distillation approach called BiStil, which involves creating a general bilingual model and task-specific models.", "example": "Convert the coordinate to text: [-3.3789 -7.4847]:"}
{"text": "Convert the coordinate to text: [12.1192 -2.665 ]: The authors link degeneration problem with the predictor's Lipschitz continuity, and propose a method named DR that can naturally restrict the Lipschitz constant of the predictor to mitigate this problem.", "target": "The authors link degeneration problem with the predictor's Lipschitz continuity, and propose a method named DR that can naturally restrict the Lipschitz constant of the predictor to mitigate this problem.", "example": "Convert the coordinate to text: [12.1192 -2.665 ]:"}
{"text": "Convert the coordinate to text: [-4.999  -6.9056]: This study introduces a new dataset, InfoSyncC, and a two-step method for tabular synchronization consisting of 1) Information Alignment to map rows and 2) Information Update for updating missing/outdated information for aligned tables across multilingual tables.", "target": "This study introduces a new dataset, InfoSyncC, and a two-step method for tabular synchronization consisting of 1) Information Alignment to map rows and 2) Information Update for updating missing/outdated information for aligned tables across multilingual tables.", "example": "Convert the coordinate to text: [-4.999  -6.9056]:"}
{"text": "Convert the coordinate to text: [13.1036  3.1441]: A new approach for multi-task learning is proposed which is based on stacking the weights of Neural Networks as a tensor. Low-rank updates in the canonical polyadic tensor decomposition of this tensor of weights are shown to lead to an efficient algorithm which reduces the model parameters without losing performance.", "target": "A new approach for multi-task learning is proposed which is based on stacking the weights of Neural Networks as a tensor. Low-rank updates in the canonical polyadic tensor decomposition of this tensor of weights are shown to lead to an efficient algorithm which reduces the model parameters without losing performance.", "example": "Convert the coordinate to text: [13.1036  3.1441]:"}
{"text": "Convert the coordinate to text: [ 0.4302 -9.6258]: The authors propose a solution for Visual Word Sense Disambiguation that blends text augmentation and multi-modal models. The solution leverages the fine-grained semantic annotation from WordNet to get a better representation of the textual component.", "target": "The authors propose a solution for Visual Word Sense Disambiguation that blends text augmentation and multi-modal models. The solution leverages the fine-grained semantic annotation from WordNet to get a better representation of the textual component.", "example": "Convert the coordinate to text: [ 0.4302 -9.6258]:"}
{"text": "Convert the coordinate to text: [-3.2548 -6.5649]: The paper proposes the use of an ensemble of multilingual models together with a language-specific monolingual model to predict the level of intimacy in a given text.", "target": "The paper proposes the use of an ensemble of multilingual models together with a language-specific monolingual model to predict the level of intimacy in a given text.", "example": "Convert the coordinate to text: [-3.2548 -6.5649]:"}
{"text": "Convert the coordinate to text: [-7.2015 -5.5998]: The study proposes a Common European Framework of Reference (CEFR) based classifier for single-word and multi-word lexical complexities in English and French, constructed specifically to serve as an analytical tool for the Mauril language learning application. The model uses rich contextual representations to accurately label and disambiguate polysemous occurrences.", "target": "The study proposes a Common European Framework of Reference (CEFR) based classifier for single-word and multi-word lexical complexities in English and French, constructed specifically to serve as an analytical tool for the Mauril language learning application. The model uses rich contextual representations to accurately label and disambiguate polysemous occurrences.", "example": "Convert the coordinate to text: [-7.2015 -5.5998]:"}
{"text": "Convert the coordinate to text: [12.5301  8.3889]: This paper introduces the Accelerated Iterative Diffusion Inversion (AIDI) method that looks to enhance reconstruction accuracy with minimal additional overhead in space and time complexity.", "target": "This paper introduces the Accelerated Iterative Diffusion Inversion (AIDI) method that looks to enhance reconstruction accuracy with minimal additional overhead in space and time complexity.", "example": "Convert the coordinate to text: [12.5301  8.3889]:"}
{"text": "Convert the coordinate to text: [  9.0907 -11.5041]: The authors propose an adaptive transformation framework called AdaptPoint, based on the structure of the 3D point cloud sample to handle potential corruption. This includes a Deformation Controller and a Mask Controller for predicting deformation parameters and producing a point mask based on the intrinsic structural information of the input point cloud.", "target": "The authors propose an adaptive transformation framework called AdaptPoint, based on the structure of the 3D point cloud sample to handle potential corruption. This includes a Deformation Controller and a Mask Controller for predicting deformation parameters and producing a point mask based on the intrinsic structural information of the input point cloud.", "example": "Convert the coordinate to text: [  9.0907 -11.5041]:"}
{"text": "Convert the coordinate to text: [  5.042  -12.5648]: The paper introduces Object Style Compensation, and constructs the Object-Level Discrepancy Memory with sets of discrepancy features. These features capture the style changes of the same category's object instances when they are adapted from target to source domains.", "target": "The paper introduces Object Style Compensation, and constructs the Object-Level Discrepancy Memory with sets of discrepancy features. These features capture the style changes of the same category's object instances when they are adapted from target to source domains.", "example": "Convert the coordinate to text: [  5.042  -12.5648]:"}
{"text": "Convert the coordinate to text: [ 5.8783 10.4169]: The authors propose to overcome the limitations of existing algorithms by deriving a deterministic relationship between a simplified solution that is easier to obtain and the theoretically optimal one. They aim to achieve this by defining bounds for selecting a subset of observations to branch from while computing a complete belief at each posterior node and extending these bounds to support the reduction of both the state and observation spaces.", "target": "The authors propose to overcome the limitations of existing algorithms by deriving a deterministic relationship between a simplified solution that is easier to obtain and the theoretically optimal one. They aim to achieve this by defining bounds for selecting a subset of observations to branch from while computing a complete belief at each posterior node and extending these bounds to support the reduction of both the state and observation spaces.", "example": "Convert the coordinate to text: [ 5.8783 10.4169]:"}
{"text": "Convert the coordinate to text: [ 8.5384 -3.1364]: The authors introduce a novel language representation model that is capable of learning to compress to different levels of abstraction at different layers of the same model by applying the Nonparametric Variational Information Bottleneck (NVIB) to stacked Transformer self-attention layers in the encoder.", "target": "The authors introduce a novel language representation model that is capable of learning to compress to different levels of abstraction at different layers of the same model by applying the Nonparametric Variational Information Bottleneck (NVIB) to stacked Transformer self-attention layers in the encoder.", "example": "Convert the coordinate to text: [ 8.5384 -3.1364]:"}
{"text": "Convert the coordinate to text: [ 0.5435 -9.7809]: The authors propose an approach where large language models make initial hypotheses based on their underlying knowledge, then actively gather the visual evidence to confirm these hypotheses. It provides a task-oriented approach that focuses on relevant visual information.", "target": "The authors propose an approach where large language models make initial hypotheses based on their underlying knowledge, then actively gather the visual evidence to confirm these hypotheses. It provides a task-oriented approach that focuses on relevant visual information.", "example": "Convert the coordinate to text: [ 0.5435 -9.7809]:"}
{"text": "Convert the coordinate to text: [16.0414 -0.5507]: This paper proposes TexQ, a novel zero-shot quantization method that uses synthetic samples. The process involves synthesizing a calibration image and extracting its calibration center for each category with a texture feature energy distribution calibration method. This information guides the generator to synthesize samples.", "target": "This paper proposes TexQ, a novel zero-shot quantization method that uses synthetic samples. The process involves synthesizing a calibration image and extracting its calibration center for each category with a texture feature energy distribution calibration method. This information guides the generator to synthesize samples.", "example": "Convert the coordinate to text: [16.0414 -0.5507]:"}
{"text": "Convert the coordinate to text: [ 4.3716 13.0415]: The study proposes imitation learning with vague feedback, where the data annotator can only distinguish the paired demonstrations correctly when their quality differs significantly. The authors model the underlying demonstration pool as a mixture of expert and non-expert data and integrate this with generative adversarial imitation learning to form an end-to-end algorithm.", "target": "The study proposes imitation learning with vague feedback, where the data annotator can only distinguish the paired demonstrations correctly when their quality differs significantly. The authors model the underlying demonstration pool as a mixture of expert and non-expert data and integrate this with generative adversarial imitation learning to form an end-to-end algorithm.", "example": "Convert the coordinate to text: [ 4.3716 13.0415]:"}
{"text": "Convert the coordinate to text: [  7.589  -17.3457]: The authors have introduced a novel Riemannian framework for human body scan representation, interpolation, and extrapolation named Basis Restricted Elastic Shape Analysis (BaRe-ESA). It operates directly on unregistered meshes without the need for prior point-to-point correspondences or consistent mesh structure.", "target": "The authors have introduced a novel Riemannian framework for human body scan representation, interpolation, and extrapolation named Basis Restricted Elastic Shape Analysis (BaRe-ESA). It operates directly on unregistered meshes without the need for prior point-to-point correspondences or consistent mesh structure.", "example": "Convert the coordinate to text: [  7.589  -17.3457]:"}
{"text": "Convert the coordinate to text: [8.5002 8.715 ]: The authors propose a method for discovering optimization algorithms through program search, resulting in a memory-efficient algorithm named Lion (Evolved Sign Momentum) that only keeps track of the momentum and uses the sign operation to calculate parameter updates, differing from adaptive optimizers.", "target": "The authors propose a method for discovering optimization algorithms through program search, resulting in a memory-efficient algorithm named Lion (Evolved Sign Momentum) that only keeps track of the momentum and uses the sign operation to calculate parameter updates, differing from adaptive optimizers.", "example": "Convert the coordinate to text: [8.5002 8.715 ]:"}
{"text": "Convert the coordinate to text: [ 7.3787 -6.8252]: In this work, Hyena is proposed, which is a subquadratic drop-in replacement for attention constructed by interleaving implicitly parametrized long convolutions and data-controlled gating.", "target": "In this work, Hyena is proposed, which is a subquadratic drop-in replacement for attention constructed by interleaving implicitly parametrized long convolutions and data-controlled gating.", "example": "Convert the coordinate to text: [ 7.3787 -6.8252]:"}
{"text": "Convert the coordinate to text: [-11.7258  16.2214]: The authors propose Stiff-switch, a thermo-mechanical stiffness control method. They present new thermo-mechanical structures that can control the stiffness by heating the minimum portion of the structure where stress is concentrated, using phase change materials in an H-beam structure and mechanical linkage joint.", "target": "The authors propose Stiff-switch, a thermo-mechanical stiffness control method. They present new thermo-mechanical structures that can control the stiffness by heating the minimum portion of the structure where stress is concentrated, using phase change materials in an H-beam structure and mechanical linkage joint.", "example": "Convert the coordinate to text: [-11.7258  16.2214]:"}
{"text": "Convert the coordinate to text: [ 4.6332 14.0981]: The paper introduces RL4F (Reinforcement Learning for Feedback), a multi-agent collaborative framework where the critique generator is trained to maximize the end-task performance of GPT-3, a black-box model, by providing critiques to revise its outputs.", "target": "The paper introduces RL4F (Reinforcement Learning for Feedback), a multi-agent collaborative framework where the critique generator is trained to maximize the end-task performance of GPT-3, a black-box model, by providing critiques to revise its outputs.", "example": "Convert the coordinate to text: [ 4.6332 14.0981]:"}
{"text": "Convert the coordinate to text: [-1.288 -5.35 ]: The authors propose a new Soft prompt learning framework with the Multilingual Verbalizer (SoftMV) for XNLI. SoftMV constructs cloze-style questions with soft prompts and generates an augmented multilingual question using bilingual dictionaries.", "target": "The authors propose a new Soft prompt learning framework with the Multilingual Verbalizer (SoftMV) for XNLI. SoftMV constructs cloze-style questions with soft prompts and generates an augmented multilingual question using bilingual dictionaries.", "example": "Convert the coordinate to text: [-1.288 -5.35 ]:"}
{"text": "Convert the coordinate to text: [-1.8278 -3.3568]: The authors propose PGRA, a two-stage framework for non-knowledge-intensive tasks that uses a task-agnostic retriever to build a shared static index and select candidate evidence, and a prompt-guided reranker to rerank the nearest evidence based on task-specific relevance.", "target": "The authors propose PGRA, a two-stage framework for non-knowledge-intensive tasks that uses a task-agnostic retriever to build a shared static index and select candidate evidence, and a prompt-guided reranker to rerank the nearest evidence based on task-specific relevance.", "example": "Convert the coordinate to text: [-1.8278 -3.3568]:"}
{"text": "Convert the coordinate to text: [ 0.4081 -9.8612]: The authors investigate knowledge retrieval with multi-modal queries by introducing a dataset, ReMuQ, that requires systems to retrieve knowledge by integrating content from both text and image queries, and a retriever model 'ReViz' that can process input text and images directly to retrieve relevant knowledge, without dependence on intermediate modules.", "target": "The authors investigate knowledge retrieval with multi-modal queries by introducing a dataset, ReMuQ, that requires systems to retrieve knowledge by integrating content from both text and image queries, and a retriever model 'ReViz' that can process input text and images directly to retrieve relevant knowledge, without dependence on intermediate modules.", "example": "Convert the coordinate to text: [ 0.4081 -9.8612]:"}
{"text": "Convert the coordinate to text: [-2.2249 -4.6033]: Two solutions are proposed: Span Substitution (SpanSub), a multi-grained compositional augmentation strategy, and the Learning to Substitute Span (L2S2) framework, which empowers the learning of span substitution probabilities in an end-to-end manner.", "target": "Two solutions are proposed: Span Substitution (SpanSub), a multi-grained compositional augmentation strategy, and the Learning to Substitute Span (L2S2) framework, which empowers the learning of span substitution probabilities in an end-to-end manner.", "example": "Convert the coordinate to text: [-2.2249 -4.6033]:"}
{"text": "Convert the coordinate to text: [2.0741 1.7008]: The authors introduce a new type of anomaly detection, referred to as 'Precursor-of-Anomaly' (PoA) detection. This approach aims to detect future anomalies before they happen, unlike traditional anomaly detection methods that only determine whether a given time series observation is an anomaly.", "target": "The authors introduce a new type of anomaly detection, referred to as 'Precursor-of-Anomaly' (PoA) detection. This approach aims to detect future anomalies before they happen, unlike traditional anomaly detection methods that only determine whether a given time series observation is an anomaly.", "example": "Convert the coordinate to text: [2.0741 1.7008]:"}
{"text": "Convert the coordinate to text: [ 0.2702 -7.073 ]: The authors propose to update the RNN-based encoder-decoder with attention model with a state-of-the-art seq2seq model: the Transformer.", "target": "The authors propose to update the RNN-based encoder-decoder with attention model with a state-of-the-art seq2seq model: the Transformer.", "example": "Convert the coordinate to text: [ 0.2702 -7.073 ]:"}
{"text": "Convert the coordinate to text: [-2.8007 -6.755 ]: The authors propose an approach based on data augmentation and the use of three multilingual Large Language Models (multilingual BERT, XLM and mDeBERTA) by ensemble learning to predict tweet intimacy across multiple languages.", "target": "The authors propose an approach based on data augmentation and the use of three multilingual Large Language Models (multilingual BERT, XLM and mDeBERTA) by ensemble learning to predict tweet intimacy across multiple languages.", "example": "Convert the coordinate to text: [-2.8007 -6.755 ]:"}
{"text": "Convert the coordinate to text: [-3.8701 -6.8779]: The authors propose the Aligned CROSs-lingual Summarization (ACROSS) model to tackle these issues. The ACROSS model aligns low-resource cross-lingual data with high-resource monolingual data using contrastive and consistency loss, and a data augmentation method is introduced to select informative monolingual sentences.", "target": "The authors propose the Aligned CROSs-lingual Summarization (ACROSS) model to tackle these issues. The ACROSS model aligns low-resource cross-lingual data with high-resource monolingual data using contrastive and consistency loss, and a data augmentation method is introduced to select informative monolingual sentences.", "example": "Convert the coordinate to text: [-3.8701 -6.8779]:"}
{"text": "Convert the coordinate to text: [5.7811 0.6775]: The authors propose a method to handle the false negative issue in the KCL by re-weighting the positive pairs in the KCL loss while ensuring that the sum of the weights is as close as possible to K+1.", "target": "The authors propose a method to handle the false negative issue in the KCL by re-weighting the positive pairs in the KCL loss while ensuring that the sum of the weights is as close as possible to K+1.", "example": "Convert the coordinate to text: [5.7811 0.6775]:"}
{"text": "Convert the coordinate to text: [-3.8994 -6.417 ]: In this work, the authors introduce XL-LEXEME, a Lexical Semantic Change Detection model that extends SBERT by highlighting the target word in the sentence.", "target": "In this work, the authors introduce XL-LEXEME, a Lexical Semantic Change Detection model that extends SBERT by highlighting the target word in the sentence.", "example": "Convert the coordinate to text: [-3.8994 -6.417 ]:"}
{"text": "Convert the coordinate to text: [11.6213  9.8008]: This paper introduces a new doubly robust dAUC optimization (DRAUC) algorithm which addresses the problem of AUC optimization in the presence of noisy and adversarial samples simultaneously. This algorithm is the result of a deep integration of self-paced learning and adversarial training within the framework of AUC optimization.", "target": "This paper introduces a new doubly robust dAUC optimization (DRAUC) algorithm which addresses the problem of AUC optimization in the presence of noisy and adversarial samples simultaneously. This algorithm is the result of a deep integration of self-paced learning and adversarial training within the framework of AUC optimization.", "example": "Convert the coordinate to text: [11.6213  9.8008]:"}
{"text": "Convert the coordinate to text: [8.517  2.8253]: The paper proposes a novel divergence measure for distributions over biological sequences, the KSD-B, which is based on the kernelized Stein discrepancy (KSD). It allows for variable length sequences and can consider biological sequence distances, even when the normalizing constant of the model is unknown.", "target": "The paper proposes a novel divergence measure for distributions over biological sequences, the KSD-B, which is based on the kernelized Stein discrepancy (KSD). It allows for variable length sequences and can consider biological sequence distances, even when the normalizing constant of the model is unknown.", "example": "Convert the coordinate to text: [8.517  2.8253]:"}
{"text": "Convert the coordinate to text: [2.3715 4.7804]: The authors present DAGSTER, a system that takes disjunctive clauses and a labelled directed acyclic graph (DAG) as inputs, then decomposes them into a set of interrelated problems which are solved using systematic backtracking search, local search, and clause-strengthening processes.", "target": "The authors present DAGSTER, a system that takes disjunctive clauses and a labelled directed acyclic graph (DAG) as inputs, then decomposes them into a set of interrelated problems which are solved using systematic backtracking search, local search, and clause-strengthening processes.", "example": "Convert the coordinate to text: [2.3715 4.7804]:"}
{"text": "Convert the coordinate to text: [ 8.7831 -2.8829]: The authors present an unsupervised Deep Functional Maps that enforces harmony of learned maps under the spectral and point-wise representation.", "target": "The authors present an unsupervised Deep Functional Maps that enforces harmony of learned maps under the spectral and point-wise representation.", "example": "Convert the coordinate to text: [ 8.7831 -2.8829]:"}
{"text": "Convert the coordinate to text: [12.3039 -0.65  ]: This paper introduces a new type of neural fields, NeuRBF, which uses general radial bases with flexible kernel position and shape for signal representation. It combines this approach with multi-frequency sinusoid functions to extend the capacity of radial basis functions and represent more details.", "target": "This paper introduces a new type of neural fields, NeuRBF, which uses general radial bases with flexible kernel position and shape for signal representation. It combines this approach with multi-frequency sinusoid functions to extend the capacity of radial basis functions and represent more details.", "example": "Convert the coordinate to text: [12.3039 -0.65  ]:"}
{"text": "Convert the coordinate to text: [ 6.7761 12.6759]: This paper introduces a novel method to encourage exploration called $f$-Policy Gradients, or $f$-PG. $f$-PG minimizes the f-divergence between the agent's state visitation distribution and the goal, which can lead to an optimal policy. It also introduces an entropy-regularized policy optimization objective, $state$-MaxEnt RL (or $s$-MaxEnt RL).", "target": "This paper introduces a novel method to encourage exploration called $f$-Policy Gradients, or $f$-PG. $f$-PG minimizes the f-divergence between the agent's state visitation distribution and the goal, which can lead to an optimal policy. It also introduces an entropy-regularized policy optimization objective, $state$-MaxEnt RL (or $s$-MaxEnt RL).", "example": "Convert the coordinate to text: [ 6.7761 12.6759]:"}
{"text": "Convert the coordinate to text: [12.3987 -5.678 ]: The authors propose a novel mechanism known as the False negative and False positive (F&F) attack, that perturbs input images to erase original detections and inject false alarms around the originals, effectively causing identity switches in multi-object trackers with only a few fooled detector frames.", "target": "The authors propose a novel mechanism known as the False negative and False positive (F&F) attack, that perturbs input images to erase original detections and inject false alarms around the originals, effectively causing identity switches in multi-object trackers with only a few fooled detector frames.", "example": "Convert the coordinate to text: [12.3987 -5.678 ]:"}
{"text": "Convert the coordinate to text: [-5.6302 10.7234]: The paper proposes HiBug, an automated framework for interpretable model debugging that employs large pre-trained models, such as chatGPT, to propose human-understandable attributes related to targeted computer vision tasks.", "target": "The paper proposes HiBug, an automated framework for interpretable model debugging that employs large pre-trained models, such as chatGPT, to propose human-understandable attributes related to targeted computer vision tasks.", "example": "Convert the coordinate to text: [-5.6302 10.7234]:"}
{"text": "Convert the coordinate to text: [ 9.3649 -5.5223]: The authors introduce a new class of shift invariant neural networks, called Functional Neural Networks (FNNs), that preserve smoothness of data by extending multi-layer perceptrons and convolutional neural networks to functional data.", "target": "The authors introduce a new class of shift invariant neural networks, called Functional Neural Networks (FNNs), that preserve smoothness of data by extending multi-layer perceptrons and convolutional neural networks to functional data.", "example": "Convert the coordinate to text: [ 9.3649 -5.5223]:"}
{"text": "Convert the coordinate to text: [9.0686 6.244 ]: This paper proposes a new methodology for deriving information-theoretic generalization bounds for learning algorithms using a probabilistic decorrelation lemma based on a change of measure and a relaxation of Young's inequality in $L_{\\psi_p}$ Orlicz spaces.", "target": "This paper proposes a new methodology for deriving information-theoretic generalization bounds for learning algorithms using a probabilistic decorrelation lemma based on a change of measure and a relaxation of Young's inequality in $L_{\\psi_p}$ Orlicz spaces.", "example": "Convert the coordinate to text: [9.0686 6.244 ]:"}
{"text": "Convert the coordinate to text: [-0.8319 -6.943 ]: The authors present a new procedure to analyze Transformer models for language generation, specifically to understand how prior words influence the model's decisions.", "target": "The authors present a new procedure to analyze Transformer models for language generation, specifically to understand how prior words influence the model's decisions.", "example": "Convert the coordinate to text: [-0.8319 -6.943 ]:"}
{"text": "Convert the coordinate to text: [-1.1999  6.5248]: The authors propose to incorporate the relationship between inputs and possible outputs/behaviors into learning, aiming to achieve a deeper semantic understanding of programs. They introduce fuzz tuning to boost the performance of program understanding and code representation learning, given a pre-trained large language model.", "target": "The authors propose to incorporate the relationship between inputs and possible outputs/behaviors into learning, aiming to achieve a deeper semantic understanding of programs. They introduce fuzz tuning to boost the performance of program understanding and code representation learning, given a pre-trained large language model.", "example": "Convert the coordinate to text: [-1.1999  6.5248]:"}
{"text": "Convert the coordinate to text: [-0.5409 -3.5813]: The authors propose a novel augmentation technique for relational texts, called GDA, which utilizes two complementary modules to maintain both semantic consistency and syntax structures. Also, GDA incorporates entity hints as prior knowledge of the generative model to augment sentences diversely.", "target": "The authors propose a novel augmentation technique for relational texts, called GDA, which utilizes two complementary modules to maintain both semantic consistency and syntax structures. Also, GDA incorporates entity hints as prior knowledge of the generative model to augment sentences diversely.", "example": "Convert the coordinate to text: [-0.5409 -3.5813]:"}
{"text": "Convert the coordinate to text: [-2.1196 -0.5967]: The authors propose to create a collection of human rationale annotations augmented with the annotators' demographic information, covering three datasets spanning sentiment analysis and common-sense reasoning, and six demographic groups.", "target": "The authors propose to create a collection of human rationale annotations augmented with the annotators' demographic information, covering three datasets spanning sentiment analysis and common-sense reasoning, and six demographic groups.", "example": "Convert the coordinate to text: [-2.1196 -0.5967]:"}
{"text": "Convert the coordinate to text: [ 6.2    13.1922]: This study proposes a method known as 'rewarded soup', which makes use of a multi-policy strategy by specializing multiple networks independently (one for each proxy reward) and then interpolating their weights linearly. The idea is to aim for Pareto-optimal generalization across the entire space of preferences rather than focusing on a single a priori reward.", "target": "This study proposes a method known as 'rewarded soup', which makes use of a multi-policy strategy by specializing multiple networks independently (one for each proxy reward) and then interpolating their weights linearly. The idea is to aim for Pareto-optimal generalization across the entire space of preferences rather than focusing on a single a priori reward.", "example": "Convert the coordinate to text: [ 6.2    13.1922]:"}
{"text": "Convert the coordinate to text: [18.5083 -3.202 ]: The authors propose a Zero-Shot approach using two different Transformer architectures, BLOOM and RoBERTa, to generate three different types of spoilers: phrase, passage and multi.", "target": "The authors propose a Zero-Shot approach using two different Transformer architectures, BLOOM and RoBERTa, to generate three different types of spoilers: phrase, passage and multi.", "example": "Convert the coordinate to text: [18.5083 -3.202 ]:"}
{"text": "Convert the coordinate to text: [-6.799  -3.1958]: The authors propose three original methods for semantic annotation of the decompositional marker \u201cagain\u201d. These methods are exhaustive expert annotation, extension of expert annotation with prediction of presuppositions using a classifier, and quality-controlled crowdsourcing.", "target": "The authors propose three original methods for semantic annotation of the decompositional marker \u201cagain\u201d. These methods are exhaustive expert annotation, extension of expert annotation with prediction of presuppositions using a classifier, and quality-controlled crowdsourcing.", "example": "Convert the coordinate to text: [-6.799  -3.1958]:"}
{"text": "Convert the coordinate to text: [  2.6214 -10.0263]: The authors propose augmenting the training text of these models with labels of detected objects in the corresponding video segments, providing a new method of enhancing the context of video translation.", "target": "The authors propose augmenting the training text of these models with labels of detected objects in the corresponding video segments, providing a new method of enhancing the context of video translation.", "example": "Convert the coordinate to text: [  2.6214 -10.0263]:"}
{"text": "Convert the coordinate to text: [-1.4731 -5.6612]: The authors introduce a new task called word-level prefix/suffix sense detection and propose a novel few-shot learning approach that addresses the ambiguity by applying an input-augmentation prompt to a token-replaced detection pre-training model.", "target": "The authors introduce a new task called word-level prefix/suffix sense detection and propose a novel few-shot learning approach that addresses the ambiguity by applying an input-augmentation prompt to a token-replaced detection pre-training model.", "example": "Convert the coordinate to text: [-1.4731 -5.6612]:"}
{"text": "Convert the coordinate to text: [-0.4236 -7.0493]: The authors propose an approach to transfer knowledge from transformer models to smaller neural models for token- and post-level predictions.", "target": "The authors propose an approach to transfer knowledge from transformer models to smaller neural models for token- and post-level predictions.", "example": "Convert the coordinate to text: [-0.4236 -7.0493]:"}
{"text": "Convert the coordinate to text: [-0.6285 -7.1134]: The authors propose a new approach using a byte-level encoder-only Transformer model for whitespace correction, arguing that it can perform faster and achieve better quality than the existing models.", "target": "The authors propose a new approach using a byte-level encoder-only Transformer model for whitespace correction, arguing that it can perform faster and achieve better quality than the existing models.", "example": "Convert the coordinate to text: [-0.6285 -7.1134]:"}
{"text": "Convert the coordinate to text: [-2.4307 -4.521 ]: The authors propose OpenRT, an open-source framework for reasoning over tabular data designed to reproduce existing table pre-training models for performance comparison and quickly develop new models. They also introduce TaRAT, an annotation tool to assist the community in constructing new table reasoning datasets.", "target": "The authors propose OpenRT, an open-source framework for reasoning over tabular data designed to reproduce existing table pre-training models for performance comparison and quickly develop new models. They also introduce TaRAT, an annotation tool to assist the community in constructing new table reasoning datasets.", "example": "Convert the coordinate to text: [-2.4307 -4.521 ]:"}
{"text": "Convert the coordinate to text: [ 7.4954 -2.2075]: The authors propose a privacy-preserved interpretable skill learning framework called FedSkill, which enables global policy learning to incorporate data from different sources with interpretable interpretations to each local user.", "target": "The authors propose a privacy-preserved interpretable skill learning framework called FedSkill, which enables global policy learning to incorporate data from different sources with interpretable interpretations to each local user.", "example": "Convert the coordinate to text: [ 7.4954 -2.2075]:"}
{"text": "Convert the coordinate to text: [3.8932 5.4062]: The authors introduced a new optimization-based framework for graph coarsening that considers both the graph matrix and the node features, and jointly learns the coarsened graph matrix and the coarsened feature matrix while ensuring desired properties.", "target": "The authors introduced a new optimization-based framework for graph coarsening that considers both the graph matrix and the node features, and jointly learns the coarsened graph matrix and the coarsened feature matrix while ensuring desired properties.", "example": "Convert the coordinate to text: [3.8932 5.4062]:"}
{"text": "Convert the coordinate to text: [  3.4048 -13.0985]: The authors introduce a novel synthetic vision dataset, FunnyBirds, and corresponding automated evaluation protocols. This dataset facilitates semantically meaningful image interventions, such as the removal of individual object parts.", "target": "The authors introduce a novel synthetic vision dataset, FunnyBirds, and corresponding automated evaluation protocols. This dataset facilitates semantically meaningful image interventions, such as the removal of individual object parts.", "example": "Convert the coordinate to text: [  3.4048 -13.0985]:"}
{"text": "Convert the coordinate to text: [ 1.1368 -7.4455]: The authors propose a new Transformer variant, named Multi-branch Transformer expanded by Taylor formula (MB-TaylorFormer), which applies the Taylor expansion to approximate the softmax-attention, and introduces a multi-scale attention refinement module to correct the error of the Taylor expansion. Furthermore, the model uses a multi-branch architecture with multi-scale patch embedding, which embeds features by overlapping deformable convolution of different scales.", "target": "The authors propose a new Transformer variant, named Multi-branch Transformer expanded by Taylor formula (MB-TaylorFormer), which applies the Taylor expansion to approximate the softmax-attention, and introduces a multi-scale attention refinement module to correct the error of the Taylor expansion. Furthermore, the model uses a multi-branch architecture with multi-scale patch embedding, which embeds features by overlapping deformable convolution of different scales.", "example": "Convert the coordinate to text: [ 1.1368 -7.4455]:"}
{"text": "Convert the coordinate to text: [16.114  1.815]: To deal with overconfidence issues in OOD detection, a method called Nearest Neighbor Guidance (NNGuide) is proposed. This method guides the classifier-based score to respect the boundary geometry of the data manifold, thus reducing the overconfidence of OOD samples.", "target": "To deal with overconfidence issues in OOD detection, a method called Nearest Neighbor Guidance (NNGuide) is proposed. This method guides the classifier-based score to respect the boundary geometry of the data manifold, thus reducing the overconfidence of OOD samples.", "example": "Convert the coordinate to text: [16.114  1.815]:"}
{"text": "Convert the coordinate to text: [10.6584 -6.9571]: Steered Diffusion is proposed as a generalized framework for zero-shot conditional image generation. It leverages a diffusion model trained for unconditional generation, and steers this with a loss function determined by a pretrained inverse model that characterizes the specific conditional task.", "target": "Steered Diffusion is proposed as a generalized framework for zero-shot conditional image generation. It leverages a diffusion model trained for unconditional generation, and steers this with a loss function determined by a pretrained inverse model that characterizes the specific conditional task.", "example": "Convert the coordinate to text: [10.6584 -6.9571]:"}
{"text": "Convert the coordinate to text: [ 7.4459 -2.218 ]: The authors propose a method called Federated Feature distillation (FedFed) to address data heterogeneity in federated learning. They partition data into performance-sensitive features (contributing greatly to model performance) and performance-robust features (contributing limitedly to model performance).", "target": "The authors propose a method called Federated Feature distillation (FedFed) to address data heterogeneity in federated learning. They partition data into performance-sensitive features (contributing greatly to model performance) and performance-robust features (contributing limitedly to model performance).", "example": "Convert the coordinate to text: [ 7.4459 -2.218 ]:"}
{"text": "Convert the coordinate to text: [ 5.3438 -8.5737]: The authors propose a Scene Complexity Aware Network (SCANet), a system that measures the 'scene complexity' of multiple scenes in each video and generates adaptive proposals responding to various complexities of scenes.", "target": "The authors propose a Scene Complexity Aware Network (SCANet), a system that measures the 'scene complexity' of multiple scenes in each video and generates adaptive proposals responding to various complexities of scenes.", "example": "Convert the coordinate to text: [ 5.3438 -8.5737]:"}
{"text": "Convert the coordinate to text: [ 4.6482 -1.5828]: This paper introduces a novel hierarchical visual category modeling scheme for separating out-of-distribution data from in-distribution data through joint representation learning and statistical modeling, without using auxiliary outlier data.", "target": "This paper introduces a novel hierarchical visual category modeling scheme for separating out-of-distribution data from in-distribution data through joint representation learning and statistical modeling, without using auxiliary outlier data.", "example": "Convert the coordinate to text: [ 4.6482 -1.5828]:"}
{"text": "Convert the coordinate to text: [ 9.941  -3.5194]: The authors propose a fundamental explanation for neural text degeneration, attributing it to the presence of repetitions in the training data and suggesting that selectively ignoring these repetitions during training can significantly reduce the issue.", "target": "The authors propose a fundamental explanation for neural text degeneration, attributing it to the presence of repetitions in the training data and suggesting that selectively ignoring these repetitions during training can significantly reduce the issue.", "example": "Convert the coordinate to text: [ 9.941  -3.5194]:"}
{"text": "Convert the coordinate to text: [-6.6564 -2.0525]: To address the inconsistency issue in product categorization, the authors propose a new framework for consistent text categorization that aims to retain production-level performance.", "target": "To address the inconsistency issue in product categorization, the authors propose a new framework for consistent text categorization that aims to retain production-level performance.", "example": "Convert the coordinate to text: [-6.6564 -2.0525]:"}
{"text": "Convert the coordinate to text: [-1.7629 -7.4043]: The authors proposed a linguistically motivated method of regularization designed to improve the APE models' comprehension of the target language, which is a loss function that encourages symmetric self-attention on the given MT.", "target": "The authors proposed a linguistically motivated method of regularization designed to improve the APE models' comprehension of the target language, which is a loss function that encourages symmetric self-attention on the given MT.", "example": "Convert the coordinate to text: [-1.7629 -7.4043]:"}
{"text": "Convert the coordinate to text: [-2.5202 -5.812 ]: This work investigates an unsupervised approach to improve the faithfulness of output text by using cycle training, which uses two models that are inverses of each other -- one generates text from structured data, and the other generates the structured data from natural language text.", "target": "This work investigates an unsupervised approach to improve the faithfulness of output text by using cycle training, which uses two models that are inverses of each other -- one generates text from structured data, and the other generates the structured data from natural language text.", "example": "Convert the coordinate to text: [-2.5202 -5.812 ]:"}
{"text": "Convert the coordinate to text: [-0.4744 -4.4298]: The authors study the role of task definitions in instruction learning. They conduct an ablation analysis to understand which parts of a task definition are vital and propose an automatic algorithm to compress task definitions to a minimal supporting set of tokens. They also propose two strategies to help models better understand task instructions - providing only key information for tasks in a common structured format and adding a meta-tuning stage.", "target": "The authors study the role of task definitions in instruction learning. They conduct an ablation analysis to understand which parts of a task definition are vital and propose an automatic algorithm to compress task definitions to a minimal supporting set of tokens. They also propose two strategies to help models better understand task instructions - providing only key information for tasks in a common structured format and adding a meta-tuning stage.", "example": "Convert the coordinate to text: [-0.4744 -4.4298]:"}
{"text": "Convert the coordinate to text: [-9.3326 -6.94  ]: The authors introduce construction grammar (CxG), which pairs form and meaning, to enhance language representation in PLMs. They propose a three-stage framework called HyCxG to achieve this.", "target": "The authors introduce construction grammar (CxG), which pairs form and meaning, to enhance language representation in PLMs. They propose a three-stage framework called HyCxG to achieve this.", "example": "Convert the coordinate to text: [-9.3326 -6.94  ]:"}
{"text": "Convert the coordinate to text: [ 3.4952 11.1762]: The authors cast the problem of multi-source test-time adaptation as a stochastic decision-making process, aiming to determine the best adapted model after adaptation.", "target": "The authors cast the problem of multi-source test-time adaptation as a stochastic decision-making process, aiming to determine the best adapted model after adaptation.", "example": "Convert the coordinate to text: [ 3.4952 11.1762]:"}
{"text": "Convert the coordinate to text: [ 3.8705 -3.8284]: In this work, the authors focus on decision-based KD for PLMs, where only teacher decisions (i.e., top-1 labels) are accessible, and propose a method to estimate logits from the decision distributions.", "target": "In this work, the authors focus on decision-based KD for PLMs, where only teacher decisions (i.e., top-1 labels) are accessible, and propose a method to estimate logits from the decision distributions.", "example": "Convert the coordinate to text: [ 3.8705 -3.8284]:"}
{"text": "Convert the coordinate to text: [8.9184 8.5136]: This work introduces a confidence-guided strategy to reduce the instability associated with current memory-efficient optimizers, and based on this strategy, presents CAME - an optimizer that aims to achieve the dual objectives of fast convergence typically seen in conventional adaptive methods, and the low memory usage characteristic of memory efficient methods.", "target": "This work introduces a confidence-guided strategy to reduce the instability associated with current memory-efficient optimizers, and based on this strategy, presents CAME - an optimizer that aims to achieve the dual objectives of fast convergence typically seen in conventional adaptive methods, and the low memory usage characteristic of memory efficient methods.", "example": "Convert the coordinate to text: [8.9184 8.5136]:"}
{"text": "Convert the coordinate to text: [ 13.5212 -11.0839]: Two-stage framework, Facial expression-aware Multimodal Multi-Task learning (FacialMMT), was proposed. FacialMMT first identifies the real speaker's face sequence using a pipeline incorporating multimodal face recognition, unsupervised face clustering, and face matching. Then it uses this sequence in a multi-task learning emotion recognition model.", "target": "Two-stage framework, Facial expression-aware Multimodal Multi-Task learning (FacialMMT), was proposed. FacialMMT first identifies the real speaker's face sequence using a pipeline incorporating multimodal face recognition, unsupervised face clustering, and face matching. Then it uses this sequence in a multi-task learning emotion recognition model.", "example": "Convert the coordinate to text: [ 13.5212 -11.0839]:"}
{"text": "Convert the coordinate to text: [-4.9884 -6.2877]: This study aims to investigate how NLMs can be used to distinguish between coherent and incoherent text, with a particular focus on extending the investigation to multiple languages.", "target": "This study aims to investigate how NLMs can be used to distinguish between coherent and incoherent text, with a particular focus on extending the investigation to multiple languages.", "example": "Convert the coordinate to text: [-4.9884 -6.2877]:"}
{"text": "Convert the coordinate to text: [-3.4612 -6.531 ]: Paper introduces three novel contributions to improve cross-lingual transfer by exploiting nearest neighbours at the token level during training: (i) Sharing representations between neighboring tokens, (ii) extracting latent features from shared embeddings through an attentional semantic layer, and (iii) enforcing an agreement loss to harmonize predictions across different sentence representations.", "target": "Paper introduces three novel contributions to improve cross-lingual transfer by exploiting nearest neighbours at the token level during training: (i) Sharing representations between neighboring tokens, (ii) extracting latent features from shared embeddings through an attentional semantic layer, and (iii) enforcing an agreement loss to harmonize predictions across different sentence representations.", "example": "Convert the coordinate to text: [-3.4612 -6.531 ]:"}
{"text": "Convert the coordinate to text: [-10.1437  -7.8464]: The authors propose a novel evaluation metric, 'decomposed scoring', leveraging the compositional nature of CCG lexical categories and utilizing subcategorial labels to improve the evaluation of dependencies.", "target": "The authors propose a novel evaluation metric, 'decomposed scoring', leveraging the compositional nature of CCG lexical categories and utilizing subcategorial labels to improve the evaluation of dependencies.", "example": "Convert the coordinate to text: [-10.1437  -7.8464]:"}
{"text": "Convert the coordinate to text: [ 6.727  -4.0712]: The authors propose the use of domain adaptation (DA) techniques on heterogeneous spoken language data to test the hypothesis of generalizability across diverse datasets for the common task of dementia detection.", "target": "The authors propose the use of domain adaptation (DA) techniques on heterogeneous spoken language data to test the hypothesis of generalizability across diverse datasets for the common task of dementia detection.", "example": "Convert the coordinate to text: [ 6.727  -4.0712]:"}
{"text": "Convert the coordinate to text: [3.2655 2.4469]: A new probabilistic hierarchical forecasting model called PROFHiT is proposed, which uses a probabilistic Bayesian approach and a novel Distributional Coherency regularization to learn from hierarchical relations across the entire forecast distribution. This allows the model to provide robust and calibrated forecasts, even when datasets exhibit varying degrees of hierarchical consistency.", "target": "A new probabilistic hierarchical forecasting model called PROFHiT is proposed, which uses a probabilistic Bayesian approach and a novel Distributional Coherency regularization to learn from hierarchical relations across the entire forecast distribution. This allows the model to provide robust and calibrated forecasts, even when datasets exhibit varying degrees of hierarchical consistency.", "example": "Convert the coordinate to text: [3.2655 2.4469]:"}
{"text": "Convert the coordinate to text: [4.82   4.6724]: This paper presents a new family of algorithms for online hierarchical clustering that ensures both high-quality trees and fast per-point insertion time by utilizing a small amount of parallel non-greedy tree re-arrangements.", "target": "This paper presents a new family of algorithms for online hierarchical clustering that ensures both high-quality trees and fast per-point insertion time by utilizing a small amount of parallel non-greedy tree re-arrangements.", "example": "Convert the coordinate to text: [4.82   4.6724]:"}
{"text": "Convert the coordinate to text: [8.1372 3.8197]: The core idea of the study is to propose a novel spatially clustered coefficients regression model for count value data, based on a Bayesian mixture of finite mixtures model, which detects the spatial homogeneity of the Poisson regression coefficients.", "target": "The core idea of the study is to propose a novel spatially clustered coefficients regression model for count value data, based on a Bayesian mixture of finite mixtures model, which detects the spatial homogeneity of the Poisson regression coefficients.", "example": "Convert the coordinate to text: [8.1372 3.8197]:"}
{"text": "Convert the coordinate to text: [ 5.566  13.5858]: The authors suggest a new, deep, partially observable RL algorithm that models belief states, a technique that has traditionally been challenging to apply in more complex environments.", "target": "The authors suggest a new, deep, partially observable RL algorithm that models belief states, a technique that has traditionally been challenging to apply in more complex environments.", "example": "Convert the coordinate to text: [ 5.566  13.5858]:"}
{"text": "Convert the coordinate to text: [ 11.3155 -13.5358]: The key idea is the proposal of a depth and camera pose estimation system to alleviate the scale ambiguity in multi-body scenes. The system includes a novel multi-view scale estimator for ironing out camera pose ambiguity and a multi-body plane sweep network for generalizing depth estimation to dynamic scenes.", "target": "The key idea is the proposal of a depth and camera pose estimation system to alleviate the scale ambiguity in multi-body scenes. The system includes a novel multi-view scale estimator for ironing out camera pose ambiguity and a multi-body plane sweep network for generalizing depth estimation to dynamic scenes.", "example": "Convert the coordinate to text: [ 11.3155 -13.5358]:"}
{"text": "Convert the coordinate to text: [1.6608 2.4517]: The authors propose a novel data characterization framework called TRIAGE, which is tailored specifically to regression tasks and compatible with a variety of regressors. This works by using conformal predictive distributions to provide a model-agnostic scoring method, the TRIAGE score.", "target": "The authors propose a novel data characterization framework called TRIAGE, which is tailored specifically to regression tasks and compatible with a variety of regressors. This works by using conformal predictive distributions to provide a model-agnostic scoring method, the TRIAGE score.", "example": "Convert the coordinate to text: [1.6608 2.4517]:"}
{"text": "Convert the coordinate to text: [-12.2851  -0.487 ]: To better capture the structural characteristics of SQL and bridge the gaps in knowledge, a retrieval-augmentation framework, namely ReFSQL, is proposed that includes a structure-enhanced retriever to identify comparable specific knowledge and a generator to incorporate this knowledge into the input, improving the accuracy and robustness of Text-to-SQL generation.", "target": "To better capture the structural characteristics of SQL and bridge the gaps in knowledge, a retrieval-augmentation framework, namely ReFSQL, is proposed that includes a structure-enhanced retriever to identify comparable specific knowledge and a generator to incorporate this knowledge into the input, improving the accuracy and robustness of Text-to-SQL generation.", "example": "Convert the coordinate to text: [-12.2851  -0.487 ]:"}
{"text": "Convert the coordinate to text: [-4.8778 -6.565 ]: To eliminate the need for translation data and encourage more surface structure variations, the authors suggest a self-supervised pseudo-data construction method for generating diverse pseudo-paraphrases in varying surface structures. A new unsupervised paraphrasing model is also proposed to regulate similarity and generate precise entities by encoding sentence meaning and entities using discrete and continuous variables, respectively.", "target": "To eliminate the need for translation data and encourage more surface structure variations, the authors suggest a self-supervised pseudo-data construction method for generating diverse pseudo-paraphrases in varying surface structures. A new unsupervised paraphrasing model is also proposed to regulate similarity and generate precise entities by encoding sentence meaning and entities using discrete and continuous variables, respectively.", "example": "Convert the coordinate to text: [-4.8778 -6.565 ]:"}
{"text": "Convert the coordinate to text: [12.4053  5.4031]: The authors propose a new approach that leverages total variation distance (TVD) with its robustness to outliers, and develops practical bounds to apply it to language generation. An objective, termed TaiLr, is introduced that balances the tradeoff of estimating TVD by downweighting real data samples with low model probabilities, providing a tunable penalization intensity.", "target": "The authors propose a new approach that leverages total variation distance (TVD) with its robustness to outliers, and develops practical bounds to apply it to language generation. An objective, termed TaiLr, is introduced that balances the tradeoff of estimating TVD by downweighting real data samples with low model probabilities, providing a tunable penalization intensity.", "example": "Convert the coordinate to text: [12.4053  5.4031]:"}
{"text": "Convert the coordinate to text: [-1.4501 -6.4614]: The authors propose BERT4ETH, a universal pre-trained Transformer encoder that can be used as an account representation extractor for detecting a variety of fraudulent behaviors on Ethereum. It leverages the Transformer's superior modeling capacity to capture the dynamic sequential patterns in Ethereum transactions and tackles challenges of pre-training a BERT model for Ethereum with strategies such as repetitiveness reduction, skew alleviation, and heterogeneity modeling.", "target": "The authors propose BERT4ETH, a universal pre-trained Transformer encoder that can be used as an account representation extractor for detecting a variety of fraudulent behaviors on Ethereum. It leverages the Transformer's superior modeling capacity to capture the dynamic sequential patterns in Ethereum transactions and tackles challenges of pre-training a BERT model for Ethereum with strategies such as repetitiveness reduction, skew alleviation, and heterogeneity modeling.", "example": "Convert the coordinate to text: [-1.4501 -6.4614]:"}
{"text": "Convert the coordinate to text: [-3.6279 -9.2378]: ESPnet-ST-v2 is a revamped version of the toolkit supporting 1) offline speech-to-text translation (ST), 2) simultaneous speech-to-text translation (SST), and 3) offline speech-to-speech translation (S2ST), with a larger variety of approaches, differentiating from other similar toolkits.", "target": "ESPnet-ST-v2 is a revamped version of the toolkit supporting 1) offline speech-to-text translation (ST), 2) simultaneous speech-to-text translation (SST), and 3) offline speech-to-speech translation (S2ST), with a larger variety of approaches, differentiating from other similar toolkits.", "example": "Convert the coordinate to text: [-3.6279 -9.2378]:"}
{"text": "Convert the coordinate to text: [-10.7257  -1.9532]: The authors present the concept of Open Long-Tailed QA (OLTQA), which learns from long-tailed distributed data and optimizes performance over both seen and unseen QA tasks. They introduce an OLTQA model that emphasizes knowledge sharing among seen, rare, and unseen tasks and proactively extracts knowledge from a large, pre-trained language model.", "target": "The authors present the concept of Open Long-Tailed QA (OLTQA), which learns from long-tailed distributed data and optimizes performance over both seen and unseen QA tasks. They introduce an OLTQA model that emphasizes knowledge sharing among seen, rare, and unseen tasks and proactively extracts knowledge from a large, pre-trained language model.", "example": "Convert the coordinate to text: [-10.7257  -1.9532]:"}
{"text": "Convert the coordinate to text: [11.063   7.7017]: The authors propose a second-order method for distributed optimization that requires only $\\mathcal{O}(d)$ communication complexity, where $d$ is the problem dimension.", "target": "The authors propose a second-order method for distributed optimization that requires only $\\mathcal{O}(d)$ communication complexity, where $d$ is the problem dimension.", "example": "Convert the coordinate to text: [11.063   7.7017]:"}
{"text": "Convert the coordinate to text: [1.3355 0.6377]: The authors posit that changes in online learning environments can be attributed to partial changes in parameters. They propose an algorithm that assumes data at each instance can be disentangled into an environment-invariant semantic factor and an environment-specific variation factor, with the semantic factor used for fair prediction under a group fairness constraint.", "target": "The authors posit that changes in online learning environments can be attributed to partial changes in parameters. They propose an algorithm that assumes data at each instance can be disentangled into an environment-invariant semantic factor and an environment-specific variation factor, with the semantic factor used for fair prediction under a group fairness constraint.", "example": "Convert the coordinate to text: [1.3355 0.6377]:"}
{"text": "Convert the coordinate to text: [11.7605 -7.4709]: The authors propose an unsupervised method for discovering generative concepts from a collection of images, a task which addresses the inverse problem of text-to-image generation.", "target": "The authors propose an unsupervised method for discovering generative concepts from a collection of images, a task which addresses the inverse problem of text-to-image generation.", "example": "Convert the coordinate to text: [11.7605 -7.4709]:"}
{"text": "Convert the coordinate to text: [-10.5683  -1.7623]: The authors propose a QAG framework aimed at enhancing the diversity of question-and-answer types by generating different interrogative sentences and both implicit and explicit answers. This framework includes a QFS-based answer generator, an iterative question-and-answer generator, and a relevancy-aware ranking module.", "target": "The authors propose a QAG framework aimed at enhancing the diversity of question-and-answer types by generating different interrogative sentences and both implicit and explicit answers. This framework includes a QFS-based answer generator, an iterative question-and-answer generator, and a relevancy-aware ranking module.", "example": "Convert the coordinate to text: [-10.5683  -1.7623]:"}
{"text": "Convert the coordinate to text: [12.6628  2.2374]: The authors present a new dynamic network embedding paradigm, Dynamic Adjacency Matrix Factorization (DAMF), that rotates and scales the axes of the embedding space, instead of updating each node individually.", "target": "The authors present a new dynamic network embedding paradigm, Dynamic Adjacency Matrix Factorization (DAMF), that rotates and scales the axes of the embedding space, instead of updating each node individually.", "example": "Convert the coordinate to text: [12.6628  2.2374]:"}
{"text": "Convert the coordinate to text: [-6.7108 10.1137]: The authors develop a model for generating hedges in conversation, which involves fine-tuning language models trained on tutoring data, and then reranking to select the candidate that best matches the expected hedging strategy using a hedge classifier.", "target": "The authors develop a model for generating hedges in conversation, which involves fine-tuning language models trained on tutoring data, and then reranking to select the candidate that best matches the expected hedging strategy using a hedge classifier.", "example": "Convert the coordinate to text: [-6.7108 10.1137]:"}
{"text": "Convert the coordinate to text: [12.336  -6.4196]: The authors propose a neural topic modeling framework based on cycle adversarial training and contrastive learning, which applies contrastive learning to the generator directly. To balance the generation and discrimination, the authors propose a self-supervised contrastive loss and a discriminative contrastsive loss.", "target": "The authors propose a neural topic modeling framework based on cycle adversarial training and contrastive learning, which applies contrastive learning to the generator directly. To balance the generation and discrimination, the authors propose a self-supervised contrastive loss and a discriminative contrastsive loss.", "example": "Convert the coordinate to text: [12.336  -6.4196]:"}
{"text": "Convert the coordinate to text: [-3.8681 -3.5704]: This paper presents a NER system that leverages a Frustratingly Easy Domain Adaptation (FEDA) method over multiple legal corpora, with the aim of detecting 14 types of legal entities within Indian judgments. It also explores an approach based on overlapping context and averaging tensors to handle long input texts, which are common in legal documents.", "target": "This paper presents a NER system that leverages a Frustratingly Easy Domain Adaptation (FEDA) method over multiple legal corpora, with the aim of detecting 14 types of legal entities within Indian judgments. It also explores an approach based on overlapping context and averaging tensors to handle long input texts, which are common in legal documents.", "example": "Convert the coordinate to text: [-3.8681 -3.5704]:"}
{"text": "Convert the coordinate to text: [-3.411  -9.2993]: The authors use offline speech-to-text models, incorporating WavLM front-end features and mBART decoder initialization, and adapt these models for simultaneous speech-to-text translation by incrementally encoding and decoding chunks of input. The authors also construct text-to-speech models using the VITS framework, achieving simultaneous speech-to-speech translation by cascading the SST and TTS models.", "target": "The authors use offline speech-to-text models, incorporating WavLM front-end features and mBART decoder initialization, and adapt these models for simultaneous speech-to-text translation by incrementally encoding and decoding chunks of input. The authors also construct text-to-speech models using the VITS framework, achieving simultaneous speech-to-speech translation by cascading the SST and TTS models.", "example": "Convert the coordinate to text: [-3.411  -9.2993]:"}
{"text": "Convert the coordinate to text: [ 7.151  -4.0216]: A new method for unsupervised domain adaptation in a non-parametric manner is proposed, utilizing in-domain monolingual data and performing nearest neighbour inference on both forward and backward translation directions, in an iterative strengthening style.", "target": "A new method for unsupervised domain adaptation in a non-parametric manner is proposed, utilizing in-domain monolingual data and performing nearest neighbour inference on both forward and backward translation directions, in an iterative strengthening style.", "example": "Convert the coordinate to text: [ 7.151  -4.0216]:"}
{"text": "Convert the coordinate to text: [-4.5709 -6.9345]: The authors propose the use of machine-translated corpora for pre-training language models as an alternative or a supplement to real data.", "target": "The authors propose the use of machine-translated corpora for pre-training language models as an alternative or a supplement to real data.", "example": "Convert the coordinate to text: [-4.5709 -6.9345]:"}
{"text": "Convert the coordinate to text: [-3.4389 -5.9177]: The paper proposes INFINITY, a fully unsupervised method for graph-text mutual conversion that just uses a unified pretrained language model, without the need for external annotation tools or additional parallel information. It also introduces a structure-aware fine-tuning strategy to retain structural information in graph sequences.", "target": "The paper proposes INFINITY, a fully unsupervised method for graph-text mutual conversion that just uses a unified pretrained language model, without the need for external annotation tools or additional parallel information. It also introduces a structure-aware fine-tuning strategy to retain structural information in graph sequences.", "example": "Convert the coordinate to text: [-3.4389 -5.9177]:"}
{"text": "Convert the coordinate to text: [-15.7329  16.7346]: This paper proposes UniLG, a unified, structure-aware lyrics generation framework that uses compound templates to integrate textual and musical information, enhancing the modelling of song structure across various generation conditions.", "target": "This paper proposes UniLG, a unified, structure-aware lyrics generation framework that uses compound templates to integrate textual and musical information, enhancing the modelling of song structure across various generation conditions.", "example": "Convert the coordinate to text: [-15.7329  16.7346]:"}
{"text": "Convert the coordinate to text: [10.7527  6.2256]: The authors propose a convex OT program with a sum-of-norms regularization term that is theoretically designed to respect and recover the underlying class structure in accordance with certain geometric assumptions.", "target": "The authors propose a convex OT program with a sum-of-norms regularization term that is theoretically designed to respect and recover the underlying class structure in accordance with certain geometric assumptions.", "example": "Convert the coordinate to text: [10.7527  6.2256]:"}
{"text": "Convert the coordinate to text: [-4.9156 -4.5894]: The authors propose MaxSimE, an explanation method for language models applied to measure semantic similarity, which generates explanations by matching contextualized query tokens to the most similar tokens from the retrieved document according to the cosine similarity of their embeddings.", "target": "The authors propose MaxSimE, an explanation method for language models applied to measure semantic similarity, which generates explanations by matching contextualized query tokens to the most similar tokens from the retrieved document according to the cosine similarity of their embeddings.", "example": "Convert the coordinate to text: [-4.9156 -4.5894]:"}
{"text": "Convert the coordinate to text: [-5.0776 11.8828]: The authors call for a holistic approach to customer service using both virtual agents and human operators working in harmony, an approach which demands the integration of diverse AI technologies across numerous disciplines beyond computer science.", "target": "The authors call for a holistic approach to customer service using both virtual agents and human operators working in harmony, an approach which demands the integration of diverse AI technologies across numerous disciplines beyond computer science.", "example": "Convert the coordinate to text: [-5.0776 11.8828]:"}
{"text": "Convert the coordinate to text: [0.5116 1.1162]: The paper proposes a fast model debiasing framework (FMD) which identifies biases in trained models through an explicit counterfactual concept, quantifies the influence of samples with influence functions, and uses a machine unlearning-based strategy to remove bias from the model using a small counterfactual dataset.", "target": "The paper proposes a fast model debiasing framework (FMD) which identifies biases in trained models through an explicit counterfactual concept, quantifies the influence of samples with influence functions, and uses a machine unlearning-based strategy to remove bias from the model using a small counterfactual dataset.", "example": "Convert the coordinate to text: [0.5116 1.1162]:"}
{"text": "Convert the coordinate to text: [-0.0922 -9.2433]: The key idea is to investigate whether vision-and-language models, specifically CLIP and Stable Diffusion, exhibit sound symbolism, which correlates specific sounds with certain meanings across different languages and demographics.", "target": "The key idea is to investigate whether vision-and-language models, specifically CLIP and Stable Diffusion, exhibit sound symbolism, which correlates specific sounds with certain meanings across different languages and demographics.", "example": "Convert the coordinate to text: [-0.0922 -9.2433]:"}
{"text": "Convert the coordinate to text: [ 6.8974 12.7804]: The authors explore the generality of DreamerV3's tricks by applying them to the Proximal Policy Optimization (PPO) reinforcement learning algorithm.", "target": "The authors explore the generality of DreamerV3's tricks by applying them to the Proximal Policy Optimization (PPO) reinforcement learning algorithm.", "example": "Convert the coordinate to text: [ 6.8974 12.7804]:"}
{"text": "Convert the coordinate to text: [12.849  -4.9839]: This paper presents a new adversarial attack, WAFFLE, designed to test the robustness of multi-exit language models by gradually generating adversarial text and bypassing early-exit points.", "target": "This paper presents a new adversarial attack, WAFFLE, designed to test the robustness of multi-exit language models by gradually generating adversarial text and bypassing early-exit points.", "example": "Convert the coordinate to text: [12.849  -4.9839]:"}
{"text": "Convert the coordinate to text: [10.4917 -8.3985]: The authors propose a test-time adaptation framework for SR, SRTTA, capable of quickly adapting SR models to different or unknown degradation types in the test domains. A second-order degradation scheme is designed to construct paired data based on the degradation type of the test image, which is predicted by a pre-trained degradation classifier.", "target": "The authors propose a test-time adaptation framework for SR, SRTTA, capable of quickly adapting SR models to different or unknown degradation types in the test domains. A second-order degradation scheme is designed to construct paired data based on the degradation type of the test image, which is predicted by a pre-trained degradation classifier.", "example": "Convert the coordinate to text: [10.4917 -8.3985]:"}
{"text": "Convert the coordinate to text: [-3.8156  1.121 ]: The authors propose a multitasking model called TWISTED which focuses on stance detection by exploiting toxicity, morality, and speech act as auxiliary tasks. The model extracts valence, arousal, and dominance aspects hidden in the tweets and injects emotional sense into the embedded text followed by an efficient attention framework.", "target": "The authors propose a multitasking model called TWISTED which focuses on stance detection by exploiting toxicity, morality, and speech act as auxiliary tasks. The model extracts valence, arousal, and dominance aspects hidden in the tweets and injects emotional sense into the embedded text followed by an efficient attention framework.", "example": "Convert the coordinate to text: [-3.8156  1.121 ]:"}
{"text": "Convert the coordinate to text: [ 2.4045 15.7833]: The authors refine previously established findings by improving results of Betzler et al. (JAIR 47:475\u2013519, 2013) regarding the Chamberlin\u2013Courant rule, and expanding the research to cover the parameterized complexity of the Pessimist voting rule, and introducing two new rules of egalitarian median and egalitarian mean.", "target": "The authors refine previously established findings by improving results of Betzler et al. (JAIR 47:475\u2013519, 2013) regarding the Chamberlin\u2013Courant rule, and expanding the research to cover the parameterized complexity of the Pessimist voting rule, and introducing two new rules of egalitarian median and egalitarian mean.", "example": "Convert the coordinate to text: [ 2.4045 15.7833]:"}
{"text": "Convert the coordinate to text: [-7.9186 -1.7076]: The paper proposes a holistic approach for building a natural language classification system for real-world content moderation. The approach includes careful design of content taxonomies and labeling instructions, data quality control, an active learning pipeline for rare events, and methods for maintaining model robustness and avoiding overfitting.", "target": "The paper proposes a holistic approach for building a natural language classification system for real-world content moderation. The approach includes careful design of content taxonomies and labeling instructions, data quality control, an active learning pipeline for rare events, and methods for maintaining model robustness and avoiding overfitting.", "example": "Convert the coordinate to text: [-7.9186 -1.7076]:"}
{"text": "Convert the coordinate to text: [13.4406 -4.6814]: The study introduces the novel problem of unnoticeable graph backdoor attacks with a limited attack budget. It proposes a strategy to selectively choose nodes to inject triggers and target class labels in the poisoning phase.", "target": "The study introduces the novel problem of unnoticeable graph backdoor attacks with a limited attack budget. It proposes a strategy to selectively choose nodes to inject triggers and target class labels in the poisoning phase.", "example": "Convert the coordinate to text: [13.4406 -4.6814]:"}
{"text": "Convert the coordinate to text: [  9.3405 -14.1422]: The paper presents MixCycle, the first semi-supervised approach for 3D Single Object Tracking (SOT), that utilizes two cycle-consistency strategies: self tracking cycles and forward-backward cycles. It also introduces a data augmentation strategy, SOTMixup, to improve the robustness of the tracker to point cloud diversity.", "target": "The paper presents MixCycle, the first semi-supervised approach for 3D Single Object Tracking (SOT), that utilizes two cycle-consistency strategies: self tracking cycles and forward-backward cycles. It also introduces a data augmentation strategy, SOTMixup, to improve the robustness of the tracker to point cloud diversity.", "example": "Convert the coordinate to text: [  9.3405 -14.1422]:"}
{"text": "Convert the coordinate to text: [-1.1881 -5.2329]: The paper proposes an unsupervised approach, called PromptRank, which uses the PLM with an encoder-decoder architecture. It feeds the document into the encoder and calculates the probability of generating the candidate with a designed prompt by the decoder.", "target": "The paper proposes an unsupervised approach, called PromptRank, which uses the PLM with an encoder-decoder architecture. It feeds the document into the encoder and calculates the probability of generating the candidate with a designed prompt by the decoder.", "example": "Convert the coordinate to text: [-1.1881 -5.2329]:"}
{"text": "Convert the coordinate to text: [-5.3073  0.7558]: The authors propose a novel task of hawkish-dovish classification and to support this, they construct the largest tokenized and annotated dataset of FOMC speeches, meeting minutes, and press conference transcripts.", "target": "The authors propose a novel task of hawkish-dovish classification and to support this, they construct the largest tokenized and annotated dataset of FOMC speeches, meeting minutes, and press conference transcripts.", "example": "Convert the coordinate to text: [-5.3073  0.7558]:"}
{"text": "Convert the coordinate to text: [-2.1839 -7.5052]: The authors propose NAIL (Non-Autoregressive Indexing with Language models), a model architecture that can capture up to 86% of transformer cross-attention model's performance with significantly less computational resources. NAIL employs a lexicalized scoring function and can be used on the commodity CPUs.", "target": "The authors propose NAIL (Non-Autoregressive Indexing with Language models), a model architecture that can capture up to 86% of transformer cross-attention model's performance with significantly less computational resources. NAIL employs a lexicalized scoring function and can be used on the commodity CPUs.", "example": "Convert the coordinate to text: [-2.1839 -7.5052]:"}
{"text": "Convert the coordinate to text: [3.6244 5.8708]: The paper proposes two novel algorithms, TGT and TGT+, to compute approximations of spanning centrality of all edges (AESC). TGT works by conducting deterministic graph traversals with carefully set truncated lengths. TGT+ is an enhanced version that combines TGT with random walks and additional heuristic optimizations for better efficiency and performance.", "target": "The paper proposes two novel algorithms, TGT and TGT+, to compute approximations of spanning centrality of all edges (AESC). TGT works by conducting deterministic graph traversals with carefully set truncated lengths. TGT+ is an enhanced version that combines TGT with random walks and additional heuristic optimizations for better efficiency and performance.", "example": "Convert the coordinate to text: [3.6244 5.8708]:"}
{"text": "Convert the coordinate to text: [ 2.3971 -3.5213]: To enhance contrastive learning, the authors propose BatchSampler, a method that samples mini-batches of hard-to-distinguish instances from the input data and creates a proximity graph to reduce false negatives.", "target": "To enhance contrastive learning, the authors propose BatchSampler, a method that samples mini-batches of hard-to-distinguish instances from the input data and creates a proximity graph to reduce false negatives.", "example": "Convert the coordinate to text: [ 2.3971 -3.5213]:"}
{"text": "Convert the coordinate to text: [-1.3112 -5.9541]: This paper suggests an approach to trace the origin of a fine-tuned LLM back to its corresponding pre-trained base model, as a way to tackle these issues.", "target": "This paper suggests an approach to trace the origin of a fine-tuned LLM back to its corresponding pre-trained base model, as a way to tackle these issues.", "example": "Convert the coordinate to text: [-1.3112 -5.9541]:"}
{"text": "Convert the coordinate to text: [-0.2573  2.2982]: This study explores the fairness of two automatic quality rating systems for medical research, with a focus on sensitive attributes such as participant sex and medical area. The authors also apply various debiasing methods to these systems.", "target": "This study explores the fairness of two automatic quality rating systems for medical research, with a focus on sensitive attributes such as participant sex and medical area. The authors also apply various debiasing methods to these systems.", "example": "Convert the coordinate to text: [-0.2573  2.2982]:"}
{"text": "Convert the coordinate to text: [6.626  1.2454]: The authors utilized Support Vector Machine (SVM) + One vs Rest, SVM + One vs Rest with SMOTE, and AfriBERTa-large models to address these tracks.", "target": "The authors utilized Support Vector Machine (SVM) + One vs Rest, SVM + One vs Rest with SMOTE, and AfriBERTa-large models to address these tracks.", "example": "Convert the coordinate to text: [6.626  1.2454]:"}
{"text": "Convert the coordinate to text: [-2.4088  0.8527]: This paper presents a novel SM listening approach for analyzing online patient conversations related to drug switching, drug effectiveness, side effects, and adverse drug reactions. A deep learning-based approach is used for identifying instances of drug switching in SM posts and a method for extracting the reasons behind these switches.", "target": "This paper presents a novel SM listening approach for analyzing online patient conversations related to drug switching, drug effectiveness, side effects, and adverse drug reactions. A deep learning-based approach is used for identifying instances of drug switching in SM posts and a method for extracting the reasons behind these switches.", "example": "Convert the coordinate to text: [-2.4088  0.8527]:"}
{"text": "Convert the coordinate to text: [-4.6996 -3.375 ]: This paper proposes that coreference resolution in procedural texts can be significantly improved by performing transformation-based entity linking before identifying coreference relations. The authors argue that all transformation predicates, not just creation verbs, introduce a new entity into the discourse as a generalized Result Role, which is typically not mentioned in the text.", "target": "This paper proposes that coreference resolution in procedural texts can be significantly improved by performing transformation-based entity linking before identifying coreference relations. The authors argue that all transformation predicates, not just creation verbs, introduce a new entity into the discourse as a generalized Result Role, which is typically not mentioned in the text.", "example": "Convert the coordinate to text: [-4.6996 -3.375 ]:"}
{"text": "Convert the coordinate to text: [-11.5172  18.9017]: The paper investigates whether gesture representations can improve the language model\u2019s performance and if spontaneous gestures demonstrate entropy rate constancy (ERC), a pattern found in most verbal language data that supports the rational communication assumption.", "target": "The paper investigates whether gesture representations can improve the language model\u2019s performance and if spontaneous gestures demonstrate entropy rate constancy (ERC), a pattern found in most verbal language data that supports the rational communication assumption.", "example": "Convert the coordinate to text: [-11.5172  18.9017]:"}
{"text": "Convert the coordinate to text: [-5.5281 -0.2237]: The authors propose a new benchmark, FIB (Factual Inconsistency Benchmark), which is focused on the task of summarization. The benchmark involves comparing the scores an LLM assigns to factually consistent and factually inconsistent summaries for an input news article.", "target": "The authors propose a new benchmark, FIB (Factual Inconsistency Benchmark), which is focused on the task of summarization. The benchmark involves comparing the scores an LLM assigns to factually consistent and factually inconsistent summaries for an input news article.", "example": "Convert the coordinate to text: [-5.5281 -0.2237]:"}
{"text": "Convert the coordinate to text: [-10.1397  -1.7502]: The authors propose to model content moderation as a binary question answering problem where the questions validate the loosely coupled themes constituting a policy. A decision logic is applied on top to aggregate the theme-specific validations. The questions pass theme information to a transformer network as explicit policy prompts, enabling explainability and allowing faster adaptation to policy updates.", "target": "The authors propose to model content moderation as a binary question answering problem where the questions validate the loosely coupled themes constituting a policy. A decision logic is applied on top to aggregate the theme-specific validations. The questions pass theme information to a transformer network as explicit policy prompts, enabling explainability and allowing faster adaptation to policy updates.", "example": "Convert the coordinate to text: [-10.1397  -1.7502]:"}
{"text": "Convert the coordinate to text: [-1.0039 -3.8233]: This paper proposes a retrieval-free approach, KiDG, that turns knowledge documents into simulated multi-turn dialogues through a Multi-Document Traversal algorithm.", "target": "This paper proposes a retrieval-free approach, KiDG, that turns knowledge documents into simulated multi-turn dialogues through a Multi-Document Traversal algorithm.", "example": "Convert the coordinate to text: [-1.0039 -3.8233]:"}
{"text": "Convert the coordinate to text: [-1.0076 -4.956 ]: The authors propose a Parameter-Efficient Multi-level IDRR (PEMI) framework that utilizes prompt-based parameter-efficient tuning to match input arguments with the pre-trained space and introduce a hierarchical label refining (HLR) method to integrate hierarchical guidance into the prompt tuning.", "target": "The authors propose a Parameter-Efficient Multi-level IDRR (PEMI) framework that utilizes prompt-based parameter-efficient tuning to match input arguments with the pre-trained space and introduce a hierarchical label refining (HLR) method to integrate hierarchical guidance into the prompt tuning.", "example": "Convert the coordinate to text: [-1.0076 -4.956 ]:"}
{"text": "Convert the coordinate to text: [-6.3894 -4.0627]: The authors explore the idea of using minimal or no textual context for lexical relation classification (LRC) and graded Lexical Entailment (LE) tasks by fine-tuning PTLMs with different verbalizations.", "target": "The authors explore the idea of using minimal or no textual context for lexical relation classification (LRC) and graded Lexical Entailment (LE) tasks by fine-tuning PTLMs with different verbalizations.", "example": "Convert the coordinate to text: [-6.3894 -4.0627]:"}
{"text": "Convert the coordinate to text: [0.8534 0.3804]: The authors introduce DISCO (DIStilled COunterfactual Data), a new method for automatically generating high-quality counterfactual data at scale. DISCO uses prompts to generate phrasal perturbations with a large general language model, then a task-specific teacher model is used to filter these generations to distill high-quality counterfactual data.", "target": "The authors introduce DISCO (DIStilled COunterfactual Data), a new method for automatically generating high-quality counterfactual data at scale. DISCO uses prompts to generate phrasal perturbations with a large general language model, then a task-specific teacher model is used to filter these generations to distill high-quality counterfactual data.", "example": "Convert the coordinate to text: [0.8534 0.3804]:"}
{"text": "Convert the coordinate to text: [4.6749 0.1213]: The study proposes a method for online learning, where a predictor attempts to predict the actual (label) distribution given only the features and noisy labels from previous steps. The performance of this predictor is measured by the expected KL-risk that compares the predicted distributions to the actual underlying ones.", "target": "The study proposes a method for online learning, where a predictor attempts to predict the actual (label) distribution given only the features and noisy labels from previous steps. The performance of this predictor is measured by the expected KL-risk that compares the predicted distributions to the actual underlying ones.", "example": "Convert the coordinate to text: [4.6749 0.1213]:"}
{"text": "Convert the coordinate to text: [11.076  -3.9338]: FLOOD (Flexible invariant Learning framework for Out-Of-Distribution generalization on graphs) is proposed to address the aforementioned challenges. It comprises two key components: invariant learning and bootstrapped learning, with a graph encoder that can be flexibly refined during the test phase.", "target": "FLOOD (Flexible invariant Learning framework for Out-Of-Distribution generalization on graphs) is proposed to address the aforementioned challenges. It comprises two key components: invariant learning and bootstrapped learning, with a graph encoder that can be flexibly refined during the test phase.", "example": "Convert the coordinate to text: [11.076  -3.9338]:"}
{"text": "Convert the coordinate to text: [-2.072  14.5169]: The paper proposes DREAMWALKER, a world model-based VLN-CE agent that summarises properties of the environment into a discrete, structured, compact representation, allowing the agent to simulate possible plans before executing actions.", "target": "The paper proposes DREAMWALKER, a world model-based VLN-CE agent that summarises properties of the environment into a discrete, structured, compact representation, allowing the agent to simulate possible plans before executing actions.", "example": "Convert the coordinate to text: [-2.072  14.5169]:"}
{"text": "Convert the coordinate to text: [  6.3071 -12.3404]: The authors propose an unsupervised method for segmenting multiple objects in real-world sequences. This object-centric learning framework binds objects to slots on each frame and then correlates these slots across frames. The aim of this temporally-aware slots training is to reconstruct the middle frame within a high-level semantic feature space.", "target": "The authors propose an unsupervised method for segmenting multiple objects in real-world sequences. This object-centric learning framework binds objects to slots on each frame and then correlates these slots across frames. The aim of this temporally-aware slots training is to reconstruct the middle frame within a high-level semantic feature space.", "example": "Convert the coordinate to text: [  6.3071 -12.3404]:"}
{"text": "Convert the coordinate to text: [-3.2945 -4.1778]: The authors propose BioT5, a pre-training framework that enhances cross-modal integration in biology through the augmentation of chemical knowledge and natural language associations. BioT5 utilizes SELFIES for robust molecular representation and extracts knowledge from the surrounding context of bio-entities in unstructured biological literature, effectively discriminating between structured and unstructured knowledge.", "target": "The authors propose BioT5, a pre-training framework that enhances cross-modal integration in biology through the augmentation of chemical knowledge and natural language associations. BioT5 utilizes SELFIES for robust molecular representation and extracts knowledge from the surrounding context of bio-entities in unstructured biological literature, effectively discriminating between structured and unstructured knowledge.", "example": "Convert the coordinate to text: [-3.2945 -4.1778]:"}
{"text": "Convert the coordinate to text: [ 0.3131 -9.0006]: The authors propose a novel sparse retrieval paradigm for ITR that exploits sparse representations in the vocabulary space for images and texts. Further, to leverage the proposed sparse retrieval, the authors introduced Lexicon-Bottlenecked Language-Image Pre-Training (LexLIP), a novel pre-training framework.", "target": "The authors propose a novel sparse retrieval paradigm for ITR that exploits sparse representations in the vocabulary space for images and texts. Further, to leverage the proposed sparse retrieval, the authors introduced Lexicon-Bottlenecked Language-Image Pre-Training (LexLIP), a novel pre-training framework.", "example": "Convert the coordinate to text: [ 0.3131 -9.0006]:"}
{"text": "Convert the coordinate to text: [ 9.4284 -4.6274]: The authors propose an Extensible proxy (Eproxy) that leverages self-supervised, few-shot training for near-zero costs. A jey component in the Eproxy's efficiency is a barrier layer with randomly initialized frozen convolution parameters, adding non-linearities to the optimization spaces and allowing Eproxy to discriminate architecture performance early on.", "target": "The authors propose an Extensible proxy (Eproxy) that leverages self-supervised, few-shot training for near-zero costs. A jey component in the Eproxy's efficiency is a barrier layer with randomly initialized frozen convolution parameters, adding non-linearities to the optimization spaces and allowing Eproxy to discriminate architecture performance early on.", "example": "Convert the coordinate to text: [ 9.4284 -4.6274]:"}
{"text": "Convert the coordinate to text: [ 11.8681 -10.9211]: The authors propose a system, GarmentTwin, which can track garment poses in dynamic environments such as manipulation, and an optimization-based method to align the pose with real-world observations.", "target": "The authors propose a system, GarmentTwin, which can track garment poses in dynamic environments such as manipulation, and an optimization-based method to align the pose with real-world observations.", "example": "Convert the coordinate to text: [ 11.8681 -10.9211]:"}
{"text": "Convert the coordinate to text: [ 6.2294 -7.413 ]: The authors introduce a multi-contrast variational network (MC-VarNet) that explicitly models the relationship of multi-contrast images. The model is constructed assuming that multi-contrast images have both consistent and inconsistent information, and decomposes the reference image into a common component and a unique component, only transferring the common component to the target image.", "target": "The authors introduce a multi-contrast variational network (MC-VarNet) that explicitly models the relationship of multi-contrast images. The model is constructed assuming that multi-contrast images have both consistent and inconsistent information, and decomposes the reference image into a common component and a unique component, only transferring the common component to the target image.", "example": "Convert the coordinate to text: [ 6.2294 -7.413 ]:"}
{"text": "Convert the coordinate to text: [-10.839   -1.6693]: The authors introduce a novel task called Interactive Sketch Question Answering (ISQA), where two collaborative players interact through sketches to answer a question about an image in a multi-round manner. They also propose an efficient interactive emergent communication system designed to balance question-answering accuracy, drawing complexity, and human interpretability.", "target": "The authors introduce a novel task called Interactive Sketch Question Answering (ISQA), where two collaborative players interact through sketches to answer a question about an image in a multi-round manner. They also propose an efficient interactive emergent communication system designed to balance question-answering accuracy, drawing complexity, and human interpretability.", "example": "Convert the coordinate to text: [-10.839   -1.6693]:"}
{"text": "Convert the coordinate to text: [8.4504 6.9791]: This paper distinguishes two families of stability definitions - distribution-dependent and distribution-independent Bayesian stability, proposing equivalences between various definitions like approximate differential privacy, pure differential privacy, replicability, global stability, perfect generalization, TV stability, mutual information stability, KL-divergence stability, and R\u00e9nyi-divergence stability.", "target": "This paper distinguishes two families of stability definitions - distribution-dependent and distribution-independent Bayesian stability, proposing equivalences between various definitions like approximate differential privacy, pure differential privacy, replicability, global stability, perfect generalization, TV stability, mutual information stability, KL-divergence stability, and R\u00e9nyi-divergence stability.", "example": "Convert the coordinate to text: [8.4504 6.9791]:"}
{"text": "Convert the coordinate to text: [  2.1055 -10.3816]: The authors propose a method, called UniHOI, that utilizes Vision-Language (VL) foundation models and large language models (LLMs) to recognize universal interactions in an open-world setting. The approach introduces novel strategies: a method for high-level relation extraction (HO prompt-based learning) and an HO Prompt-guided Decoder (HOPD) for better association between relation representations and HO pairs within the image. They also use a large language model (GPT) for generating a rich linguistic understanding for complex HOIs.", "target": "The authors propose a method, called UniHOI, that utilizes Vision-Language (VL) foundation models and large language models (LLMs) to recognize universal interactions in an open-world setting. The approach introduces novel strategies: a method for high-level relation extraction (HO prompt-based learning) and an HO Prompt-guided Decoder (HOPD) for better association between relation representations and HO pairs within the image. They also use a large language model (GPT) for generating a rich linguistic understanding for complex HOIs.", "example": "Convert the coordinate to text: [  2.1055 -10.3816]:"}
{"text": "Convert the coordinate to text: [ 2.6763 -8.3916]: The paper proposes Divide-And-Conquer DETR (DAC-DETR) which separates the cross-attention from the self-attention by employing an auxiliary decoder during training. This auxiliary decoder focuses on learning the cross-attention layers, has no self-attention layers and utilizes a one-to-many label assignment to enhance the gathering effect.", "target": "The paper proposes Divide-And-Conquer DETR (DAC-DETR) which separates the cross-attention from the self-attention by employing an auxiliary decoder during training. This auxiliary decoder focuses on learning the cross-attention layers, has no self-attention layers and utilizes a one-to-many label assignment to enhance the gathering effect.", "example": "Convert the coordinate to text: [ 2.6763 -8.3916]:"}
{"text": "Convert the coordinate to text: [10.2881 -1.9552]: The authors propose the Interactive Neural Process (INP), a deep Bayesian active learning framework for learning deep surrogate models to accelerate stochastic simulations. INP combines a spatiotemporal surrogate model built upon the Neural Process (NP) family with an acquisition function for active learning.", "target": "The authors propose the Interactive Neural Process (INP), a deep Bayesian active learning framework for learning deep surrogate models to accelerate stochastic simulations. INP combines a spatiotemporal surrogate model built upon the Neural Process (NP) family with an acquisition function for active learning.", "example": "Convert the coordinate to text: [10.2881 -1.9552]:"}
{"text": "Convert the coordinate to text: [-10.7336  14.8506]: The authors propose a course that teaches the principles of rapid prototyping for XR, incorporating techniques such as low-fidelity prototyping with paper and other physical materials, as well as digital prototyping including immersive authoring.", "target": "The authors propose a course that teaches the principles of rapid prototyping for XR, incorporating techniques such as low-fidelity prototyping with paper and other physical materials, as well as digital prototyping including immersive authoring.", "example": "Convert the coordinate to text: [-10.7336  14.8506]:"}
{"text": "Convert the coordinate to text: [  9.5098 -17.9908]: The authors present a new approach that adopts a volumetric image-based rendering framework, DynIBaR, that synthesizes new viewpoints by aggregating features from nearby views in a scene motion-aware manner.", "target": "The authors present a new approach that adopts a volumetric image-based rendering framework, DynIBaR, that synthesizes new viewpoints by aggregating features from nearby views in a scene motion-aware manner.", "example": "Convert the coordinate to text: [  9.5098 -17.9908]:"}
{"text": "Convert the coordinate to text: [ 3.7976 -8.6816]: The authors propose the Gaze Attention Supervise Network which employs fixation information to assist in generating the attention of the network feature layer using an attention supervised module.", "target": "The authors propose the Gaze Attention Supervise Network which employs fixation information to assist in generating the attention of the network feature layer using an attention supervised module.", "example": "Convert the coordinate to text: [ 3.7976 -8.6816]:"}
{"text": "Convert the coordinate to text: [ 11.4602 -13.1065]: The paper proposes a scene-aware egocentric pose estimation method using an egocentric depth estimation network and a scene-aware pose estimation network. The method guides the egocentric pose prediction with scene constraints and uses depth-inpainting network to mitigate the occlusion of the human body.", "target": "The paper proposes a scene-aware egocentric pose estimation method using an egocentric depth estimation network and a scene-aware pose estimation network. The method guides the egocentric pose prediction with scene constraints and uses depth-inpainting network to mitigate the occlusion of the human body.", "example": "Convert the coordinate to text: [ 11.4602 -13.1065]:"}
{"text": "Convert the coordinate to text: [11.9949  6.6336]: The authors propose a new technique, Stein Variational Goal Generation (SVGG), which relies on recent developments in automatic curriculum learning for goal-conditioned policies. SVGG seeks to preferentially sample new goals in the agent's zone of proximal development, adjusting to the agent's current capabilities by using a learned model of those capabilities and a goal distribution modeled as particles in the exploration space.", "target": "The authors propose a new technique, Stein Variational Goal Generation (SVGG), which relies on recent developments in automatic curriculum learning for goal-conditioned policies. SVGG seeks to preferentially sample new goals in the agent's zone of proximal development, adjusting to the agent's current capabilities by using a learned model of those capabilities and a goal distribution modeled as particles in the exploration space.", "example": "Convert the coordinate to text: [11.9949  6.6336]:"}
{"text": "Convert the coordinate to text: [-11.85     0.6301]: The paper presents a novel conceptual model and analysis that understands data-cleaning workflows through process abstraction and workflow recipes, refining operations to the column level. This model provides detailed provenance information for data cleaning workflow, facilitating auditing and improvement of these processes.", "target": "The paper presents a novel conceptual model and analysis that understands data-cleaning workflows through process abstraction and workflow recipes, refining operations to the column level. This model provides detailed provenance information for data cleaning workflow, facilitating auditing and improvement of these processes.", "example": "Convert the coordinate to text: [-11.85     0.6301]:"}
{"text": "Convert the coordinate to text: [-4.0162  0.5583]: The authors propose a new dataset, NollySenti, for sentiment classification that is based on Nollywood movie reviews for five languages widely spoken in Nigeria. They use both classical machine learning methods and pre-trained language models, leveraging transfer learning and machine translation in the cross domain and cross-lingual adaptation tasks.", "target": "The authors propose a new dataset, NollySenti, for sentiment classification that is based on Nollywood movie reviews for five languages widely spoken in Nigeria. They use both classical machine learning methods and pre-trained language models, leveraging transfer learning and machine translation in the cross domain and cross-lingual adaptation tasks.", "example": "Convert the coordinate to text: [-4.0162  0.5583]:"}
{"text": "Convert the coordinate to text: [ 0.1595 -9.4397]: The authors suggest using language-only models, through the use of separate verbalisation models, to handle tasks that require visual input, arguing that many of these tasks also require a strong reasoning component.", "target": "The authors suggest using language-only models, through the use of separate verbalisation models, to handle tasks that require visual input, arguing that many of these tasks also require a strong reasoning component.", "example": "Convert the coordinate to text: [ 0.1595 -9.4397]:"}
{"text": "Convert the coordinate to text: [-2.3081 -5.4297]: The authors propose the hypothesis that model ensemble based on the perplexity computed by pre-trained language models (PLMs) should benefit the GEC system and explore several ensemble strategies using strong PLMs with four sophisticated single models.", "target": "The authors propose the hypothesis that model ensemble based on the perplexity computed by pre-trained language models (PLMs) should benefit the GEC system and explore several ensemble strategies using strong PLMs with four sophisticated single models.", "example": "Convert the coordinate to text: [-2.3081 -5.4297]:"}
{"text": "Convert the coordinate to text: [-6.5767 -9.8059]: To enhance grammatical error correction systems with explanations, the authors introduce a large dataset, EXPECT, which is annotated with evidence words and grammatical error types.", "target": "To enhance grammatical error correction systems with explanations, the authors introduce a large dataset, EXPECT, which is annotated with evidence words and grammatical error types.", "example": "Convert the coordinate to text: [-6.5767 -9.8059]:"}
{"text": "Convert the coordinate to text: [ 4.7901 -3.1015]: The study aims to investigate three key factors to optimize DWT for NLP pre-training, differing from the factors used in the vision domain or traditional knowledge distillation. These factors include the quality of the teacher model, guidelines for adjusting the weighting value for DWT loss, and the impact of parameter remapping for DWT.", "target": "The study aims to investigate three key factors to optimize DWT for NLP pre-training, differing from the factors used in the vision domain or traditional knowledge distillation. These factors include the quality of the teacher model, guidelines for adjusting the weighting value for DWT loss, and the impact of parameter remapping for DWT.", "example": "Convert the coordinate to text: [ 4.7901 -3.1015]:"}
{"text": "Convert the coordinate to text: [-2.8281 -5.1364]: The authors propose a system that leverages large-scale medical text data for domain-adaptive pre-training of instruction-tuned LLMs to enhance its medical knowledge and performance on specific medical tasks.", "target": "The authors propose a system that leverages large-scale medical text data for domain-adaptive pre-training of instruction-tuned LLMs to enhance its medical knowledge and performance on specific medical tasks.", "example": "Convert the coordinate to text: [-2.8281 -5.1364]:"}
{"text": "Convert the coordinate to text: [-3.3495 -7.7887]: The authors provide an explanation for this contradictory phenomenon by observing that TM-augmented NMT exhibits lower bias but higher variance, making it more sensitive to fluctuations in the training data. They also propose a new TM-augmented NMT model to promote the variance and address the problem.", "target": "The authors provide an explanation for this contradictory phenomenon by observing that TM-augmented NMT exhibits lower bias but higher variance, making it more sensitive to fluctuations in the training data. They also propose a new TM-augmented NMT model to promote the variance and address the problem.", "example": "Convert the coordinate to text: [-3.3495 -7.7887]:"}
{"text": "Convert the coordinate to text: [-3.5625 -6.5983]: The paper proposes DiffuDetox, a mixed conditional and unconditional diffusion model for text detoxification. The conditional model takes toxic text and reduces its toxicity, while the unconditional model is trained to recover the input text, introducing additional fluent text for training to ensure fluency.", "target": "The paper proposes DiffuDetox, a mixed conditional and unconditional diffusion model for text detoxification. The conditional model takes toxic text and reduces its toxicity, while the unconditional model is trained to recover the input text, introducing additional fluent text for training to ensure fluency.", "example": "Convert the coordinate to text: [-3.5625 -6.5983]:"}
{"text": "Convert the coordinate to text: [15.4918 -0.3169]: The purpose of this study is to provide a comprehensive comparison between neural network pruning and quantization, in order to inform design decisions for future neural network hardware.", "target": "The purpose of this study is to provide a comprehensive comparison between neural network pruning and quantization, in order to inform design decisions for future neural network hardware.", "example": "Convert the coordinate to text: [15.4918 -0.3169]:"}
{"text": "Convert the coordinate to text: [-7.2697 -1.1984]: To assure the validity of knowledge tuples, this paper proposes a new task, constrained tuple extraction (CTE), that aims to extract tuples with added constraints from unstructured text. An interaction-aware network is put forward to handle this task, specifically exploiting combinatorial interactions among context-specific external features and distinct-granularity internal features to uncover potential constraints.", "target": "To assure the validity of knowledge tuples, this paper proposes a new task, constrained tuple extraction (CTE), that aims to extract tuples with added constraints from unstructured text. An interaction-aware network is put forward to handle this task, specifically exploiting combinatorial interactions among context-specific external features and distinct-granularity internal features to uncover potential constraints.", "example": "Convert the coordinate to text: [-7.2697 -1.1984]:"}
{"text": "Convert the coordinate to text: [-0.7576 -7.0743]: The authors propose a two-stage model using transformer-based pretrained models with high cross-lingual transferability. In the first stage, the model learns from all tracks; in the second, it fine-tunes for individual tracks.", "target": "The authors propose a two-stage model using transformer-based pretrained models with high cross-lingual transferability. In the first stage, the model learns from all tracks; in the second, it fine-tunes for individual tracks.", "example": "Convert the coordinate to text: [-0.7576 -7.0743]:"}
{"text": "Convert the coordinate to text: [-6.6564 -2.039 ]: The authors aim to perform a quantitative evaluation of the PubMed Similar Articles based on three existing biomedical text similarity datasets (RELISH, TREC-COVID, and SMAFIRA-c) using various text similarity methods.", "target": "The authors aim to perform a quantitative evaluation of the PubMed Similar Articles based on three existing biomedical text similarity datasets (RELISH, TREC-COVID, and SMAFIRA-c) using various text similarity methods.", "example": "Convert the coordinate to text: [-6.6564 -2.039 ]:"}
{"text": "Convert the coordinate to text: [-5.6736 10.1663]: The authors propose GrounDialog, an annotated dataset of spoken conversations where they elicit a rich set of R&G patterns, specifically for language learning with SDS.", "target": "The authors propose GrounDialog, an annotated dataset of spoken conversations where they elicit a rich set of R&G patterns, specifically for language learning with SDS.", "example": "Convert the coordinate to text: [-5.6736 10.1663]:"}
{"text": "Convert the coordinate to text: [ 5.4495 -0.3723]: The authors propose a method for weighed importance of the examples in a dataset using their Example Training dynamics (ETD), offering a new viewpoint for improving in-distribution and out-of-distribution testing performance.", "target": "The authors propose a method for weighed importance of the examples in a dataset using their Example Training dynamics (ETD), offering a new viewpoint for improving in-distribution and out-of-distribution testing performance.", "example": "Convert the coordinate to text: [ 5.4495 -0.3723]:"}
{"text": "Convert the coordinate to text: [-3.5747 10.7184]: The authors formulated task-oriented cognitive capabilities (search capability and pragmatic capability) that language models can use to perform tasks, and have identified a need to align cognitive capabilities of language models with task requirements.", "target": "The authors formulated task-oriented cognitive capabilities (search capability and pragmatic capability) that language models can use to perform tasks, and have identified a need to align cognitive capabilities of language models with task requirements.", "example": "Convert the coordinate to text: [-3.5747 10.7184]:"}
{"text": "Convert the coordinate to text: [-2.3057  0.6954]: The authors propose a prescription digitization system for online medicine ordering built with minimal supervision, utilizing a modular pipeline comprising a mix of machine learning and rule-based components.", "target": "The authors propose a prescription digitization system for online medicine ordering built with minimal supervision, utilizing a modular pipeline comprising a mix of machine learning and rule-based components.", "example": "Convert the coordinate to text: [-2.3057  0.6954]:"}
{"text": "Convert the coordinate to text: [-1.0005 -8.4883]: The authors present a method for automatic radiology report generation from radiologists\u2019 dictation using knowledge graphs (KGs) of ten abdominal organs constructed by extracting entity1-relation-entity2 triplets from a large collection of free-text radiology reports.", "target": "The authors present a method for automatic radiology report generation from radiologists\u2019 dictation using knowledge graphs (KGs) of ten abdominal organs constructed by extracting entity1-relation-entity2 triplets from a large collection of free-text radiology reports.", "example": "Convert the coordinate to text: [-1.0005 -8.4883]:"}
{"text": "Convert the coordinate to text: [-4.3393 -2.3813]: The study examines ambiguities and issues in current evaluation practice including coreferent argument mentions, conflicting argument head conventions, and ignorance of modality and event class details, and how these problems may understate the actual performance of zero-shot and other low-supervision event extraction.", "target": "The study examines ambiguities and issues in current evaluation practice including coreferent argument mentions, conflicting argument head conventions, and ignorance of modality and event class details, and how these problems may understate the actual performance of zero-shot and other low-supervision event extraction.", "example": "Convert the coordinate to text: [-4.3393 -2.3813]:"}
{"text": "Convert the coordinate to text: [ 0.6473 -3.3386]: The authors propose to improve HTC by exploring the latent relevancy of peer labels. To this end, they develop the PeerHTC method, which measures the latent relevancy through several metrics and encodes the relevancy using a Graph Convolutional Neural Network.", "target": "The authors propose to improve HTC by exploring the latent relevancy of peer labels. To this end, they develop the PeerHTC method, which measures the latent relevancy through several metrics and encodes the relevancy using a Graph Convolutional Neural Network.", "example": "Convert the coordinate to text: [ 0.6473 -3.3386]:"}
{"text": "Convert the coordinate to text: [2.0006 3.1035]: This paper presents a more general setting allowing for post-treatment and post-outcome variables in the observed covariates, aiming to separate treatment-only variables from the adjustment features. The authors propose an Optimal Adjustment Features (OAF) metric that empirically measures the asymptotic variance of the estimation, assuming no mediator variables exist.", "target": "This paper presents a more general setting allowing for post-treatment and post-outcome variables in the observed covariates, aiming to separate treatment-only variables from the adjustment features. The authors propose an Optimal Adjustment Features (OAF) metric that empirically measures the asymptotic variance of the estimation, assuming no mediator variables exist.", "example": "Convert the coordinate to text: [2.0006 3.1035]:"}
{"text": "Convert the coordinate to text: [-0.8614 -5.285 ]: This study introduces a novel method - a Generative Prompt Model (GenPromp), which is the first generative pipeline dedicated to localizing less discriminative object parts by formulating WSOL as a conditional image denoising procedure.", "target": "This study introduces a novel method - a Generative Prompt Model (GenPromp), which is the first generative pipeline dedicated to localizing less discriminative object parts by formulating WSOL as a conditional image denoising procedure.", "example": "Convert the coordinate to text: [-0.8614 -5.285 ]:"}
{"text": "Convert the coordinate to text: [-13.9692   4.1868]: This paper presents Microsoft Purview, a service that allows for the centralized governance of an organization's data estate. It consists of a Data Map populated by automated scanning of data sources, a system to manage sensitivity classification, and a policy system for creating and implementing organization-wide data policies.", "target": "This paper presents Microsoft Purview, a service that allows for the centralized governance of an organization's data estate. It consists of a Data Map populated by automated scanning of data sources, a system to manage sensitivity classification, and a policy system for creating and implementing organization-wide data policies.", "example": "Convert the coordinate to text: [-13.9692   4.1868]:"}
{"text": "Convert the coordinate to text: [-2.9519 14.9218]: The paper proposes an approach for navigational-specific visual representation learning by contrasting the agent's egocentric views and semantic maps, termed Ego$^2$-Map. The model uses the visual transformer as the backbone encoder, which facilitates transferring compact and rich information from a map to the agent's egocentric representations for navigation.", "target": "The paper proposes an approach for navigational-specific visual representation learning by contrasting the agent's egocentric views and semantic maps, termed Ego$^2$-Map. The model uses the visual transformer as the backbone encoder, which facilitates transferring compact and rich information from a map to the agent's egocentric representations for navigation.", "example": "Convert the coordinate to text: [-2.9519 14.9218]:"}
{"text": "Convert the coordinate to text: [ 9.8508 12.3054]: This paper introduces an online learning problem, LOCUD, to learn and utilize unknown user relations from disrupted behaviours to enhance learning speed and identify corrupted users. They propose a new bandit algorithm, RCLUB-WCU, to robustly learn and leverage unknown relations among potentially corrupted users, and devise an online detection algorithm (OCCUD) based on user relations inferred from RCLUB-WCU.", "target": "This paper introduces an online learning problem, LOCUD, to learn and utilize unknown user relations from disrupted behaviours to enhance learning speed and identify corrupted users. They propose a new bandit algorithm, RCLUB-WCU, to robustly learn and leverage unknown relations among potentially corrupted users, and devise an online detection algorithm (OCCUD) based on user relations inferred from RCLUB-WCU.", "example": "Convert the coordinate to text: [ 9.8508 12.3054]:"}
{"text": "Convert the coordinate to text: [  8.139  -16.3324]: The paper proposes an approach to optimize the placement of roadside LiDARs by selecting optimized positions within the scene for better perception performance, using a greedy algorithm based on perceptual gain.", "target": "The paper proposes an approach to optimize the placement of roadside LiDARs by selecting optimized positions within the scene for better perception performance, using a greedy algorithm based on perceptual gain.", "example": "Convert the coordinate to text: [  8.139  -16.3324]:"}
{"text": "Convert the coordinate to text: [  5.8172 -11.5548]: The authors propose a reconstructed neural volume from video that captures time-varying color, density, scene flow, semantics, and attention information. They compute pyramids to balance detail and whole-image context and apply saliency-aware clustering to decompose the scene.", "target": "The authors propose a reconstructed neural volume from video that captures time-varying color, density, scene flow, semantics, and attention information. They compute pyramids to balance detail and whole-image context and apply saliency-aware clustering to decompose the scene.", "example": "Convert the coordinate to text: [  5.8172 -11.5548]:"}
{"text": "Convert the coordinate to text: [ 4.9012 -2.5603]: This study proposes a novel causal diagram to provide a theoretical foundation for mainstream semi-supervised segmentation methods and introduces a causality-inspired semi-supervised learning approach (CauSSL) on top of co-training frameworks to improve SSL for medical image segmentation.", "target": "This study proposes a novel causal diagram to provide a theoretical foundation for mainstream semi-supervised segmentation methods and introduces a causality-inspired semi-supervised learning approach (CauSSL) on top of co-training frameworks to improve SSL for medical image segmentation.", "example": "Convert the coordinate to text: [ 4.9012 -2.5603]:"}
{"text": "Convert the coordinate to text: [ 11.5081 -18.0081]: The authors suggest a resolution to these anomalies using a simple multi-valued training target based on rigorous theoretical properties of the rotation-to-quaternion map of Bar-Itzhack.", "target": "The authors suggest a resolution to these anomalies using a simple multi-valued training target based on rigorous theoretical properties of the rotation-to-quaternion map of Bar-Itzhack.", "example": "Convert the coordinate to text: [ 11.5081 -18.0081]:"}
{"text": "Convert the coordinate to text: [ 3.8039 -1.3567]: The authors propose an end-to-end system that utilizes Pseudo-positive mining to separate proposals into labeled and unlabeled regions. The system uses self-supervised learning to process the unlabeled regions to prevent the negative effects of noisy pseudo-labels.", "target": "The authors propose an end-to-end system that utilizes Pseudo-positive mining to separate proposals into labeled and unlabeled regions. The system uses self-supervised learning to process the unlabeled regions to prevent the negative effects of noisy pseudo-labels.", "example": "Convert the coordinate to text: [ 3.8039 -1.3567]:"}
{"text": "Convert the coordinate to text: [  8.6042 -20.8048]: This paper introduces a novel method, DELIFFAS, which characterizes the appearance of the human as a surface light field linked to a controllable and deformable human mesh model. The core idea is to represent the light field around the human with a deformable two-surface parameterization.", "target": "This paper introduces a novel method, DELIFFAS, which characterizes the appearance of the human as a surface light field linked to a controllable and deformable human mesh model. The core idea is to represent the light field around the human with a deformable two-surface parameterization.", "example": "Convert the coordinate to text: [  8.6042 -20.8048]:"}
{"text": "Convert the coordinate to text: [11.4064  7.67  ]: The authors propose to leverage linear interpolation through the theory of nonexpansive operators for stabilization, resulting in the creation of a new optimization scheme called relaxed approximate proximal point (RAPP). This approach also leads to the rediscovery of the family of Lookahead algorithms.", "target": "The authors propose to leverage linear interpolation through the theory of nonexpansive operators for stabilization, resulting in the creation of a new optimization scheme called relaxed approximate proximal point (RAPP). This approach also leads to the rediscovery of the family of Lookahead algorithms.", "example": "Convert the coordinate to text: [11.4064  7.67  ]:"}
{"text": "Convert the coordinate to text: [11.8169 -2.2246]: In this study, the focus is on comparing the learnability of real-valued and complex-valued neurons via gradient descent, and it is shown that a complex-valued neuron can effectively learn functions expressed by any one real-valued neuron and any one complex-valued neuron.", "target": "In this study, the focus is on comparing the learnability of real-valued and complex-valued neurons via gradient descent, and it is shown that a complex-valued neuron can effectively learn functions expressed by any one real-valued neuron and any one complex-valued neuron.", "example": "Convert the coordinate to text: [11.8169 -2.2246]:"}
{"text": "Convert the coordinate to text: [ 3.215  -1.6409]: The authors argue that correlations among source tasks should be considered when extracting knowledge from them for better adaptation to target tasks and propose a Bayesian approach working with the posterior distribution of prompts across source tasks.", "target": "The authors argue that correlations among source tasks should be considered when extracting knowledge from them for better adaptation to target tasks and propose a Bayesian approach working with the posterior distribution of prompts across source tasks.", "example": "Convert the coordinate to text: [ 3.215  -1.6409]:"}
{"text": "Convert the coordinate to text: [  6.7422 -11.7677]: OpenSeeD, a simple Open-vocabulary Segmentation and Detection framework is proposed that jointly learns from different segmentation and detection datasets. It bridges the gaps by introducing a pre-trained text encoder for a common semantic space, a decoupled decoding to handle foreground and background disparity, and a conditioned mask decoding for generating masks for given boxes.", "target": "OpenSeeD, a simple Open-vocabulary Segmentation and Detection framework is proposed that jointly learns from different segmentation and detection datasets. It bridges the gaps by introducing a pre-trained text encoder for a common semantic space, a decoupled decoding to handle foreground and background disparity, and a conditioned mask decoding for generating masks for given boxes.", "example": "Convert the coordinate to text: [  6.7422 -11.7677]:"}
{"text": "Convert the coordinate to text: [ 1.6392 -5.6023]: The authors propose a new model called the Hierarchy-aware Tree Isomorphism Network (HiTIN) to enhance text representations using only syntactic information from the label hierarchy. They convert the label hierarchy into an unweighted tree structure with the guidance of structural entropy.", "target": "The authors propose a new model called the Hierarchy-aware Tree Isomorphism Network (HiTIN) to enhance text representations using only syntactic information from the label hierarchy. They convert the label hierarchy into an unweighted tree structure with the guidance of structural entropy.", "example": "Convert the coordinate to text: [ 1.6392 -5.6023]:"}
{"text": "Convert the coordinate to text: [-6.6936 -6.4124]: The authors present STT4SG-350, a corpus of Swiss German speech annotated with Standard German text at the sentence level collected via a web app, making it the largest public Swiss German speech corpus to date.", "target": "The authors present STT4SG-350, a corpus of Swiss German speech annotated with Standard German text at the sentence level collected via a web app, making it the largest public Swiss German speech corpus to date.", "example": "Convert the coordinate to text: [-6.6936 -6.4124]:"}
{"text": "Convert the coordinate to text: [-2.4864 -4.8328]: The authors aim to explore whether Code-LLMs, which deal with programming code that often contains explicit causal relations, show better causal reasoning abilities than text-only LLMs.", "target": "The authors aim to explore whether Code-LLMs, which deal with programming code that often contains explicit causal relations, show better causal reasoning abilities than text-only LLMs.", "example": "Convert the coordinate to text: [-2.4864 -4.8328]:"}
{"text": "Convert the coordinate to text: [-3.1299 -5.8777]: The authors propose using large language models as multi-dimensional evaluators using in-context learning, thus eliminating the need for large training datasets.", "target": "The authors propose using large language models as multi-dimensional evaluators using in-context learning, thus eliminating the need for large training datasets.", "example": "Convert the coordinate to text: [-3.1299 -5.8777]:"}
{"text": "Convert the coordinate to text: [-1.4223  0.1129]: To better detect and classify online sexism in a finer-grained manner, the authors propose a multi-task learning system using the pre-trained roberta-large and deberta-v3-large models.", "target": "To better detect and classify online sexism in a finer-grained manner, the authors propose a multi-task learning system using the pre-trained roberta-large and deberta-v3-large models.", "example": "Convert the coordinate to text: [-1.4223  0.1129]:"}
{"text": "Convert the coordinate to text: [-2.8939 -6.7462]: The authors utilize a large multilingual pretrained language model, XLM-T, and fine-tune it on the MINT dataset. This approach is unique as it involves predicting intimacy scores in tweets across different languages.", "target": "The authors utilize a large multilingual pretrained language model, XLM-T, and fine-tune it on the MINT dataset. This approach is unique as it involves predicting intimacy scores in tweets across different languages.", "example": "Convert the coordinate to text: [-2.8939 -6.7462]:"}
{"text": "Convert the coordinate to text: [18.5386 -3.1886]: The research focuses on studying the three classes (phrase, passage and multi) of spoilers and finding appropriate models to generate spoilers for each class.", "target": "The research focuses on studying the three classes (phrase, passage and multi) of spoilers and finding appropriate models to generate spoilers for each class.", "example": "Convert the coordinate to text: [18.5386 -3.1886]:"}
{"text": "Convert the coordinate to text: [13.2132 -4.8265]: This paper proposes DIP (Dead code Insertion based Black-box Attack for Programming Language Model), a new black-box attack method that generates adversarial examples using dead code insertion.", "target": "This paper proposes DIP (Dead code Insertion based Black-box Attack for Programming Language Model), a new black-box attack method that generates adversarial examples using dead code insertion.", "example": "Convert the coordinate to text: [13.2132 -4.8265]:"}
{"text": "Convert the coordinate to text: [ 9.9833 -0.9468]: A novel loss function called Energy Discrepancy (ED) is proposed which does not need computation of scores or expensive Markov chain Monte Carlo. This effectively interpolates between explicit score matching and negative log-likelihood loss.", "target": "A novel loss function called Energy Discrepancy (ED) is proposed which does not need computation of scores or expensive Markov chain Monte Carlo. This effectively interpolates between explicit score matching and negative log-likelihood loss.", "example": "Convert the coordinate to text: [ 9.9833 -0.9468]:"}
{"text": "Convert the coordinate to text: [ 3.6086 -3.8762]: The authors propose a novel knowledge distillation framework that introduces a class-relation representation for the novel classes based on the predicted class distribution of a model trained on familiar classes. They also create a learnable weighting function for flexible knowledge transfer based on semantic similarity.", "target": "The authors propose a novel knowledge distillation framework that introduces a class-relation representation for the novel classes based on the predicted class distribution of a model trained on familiar classes. They also create a learnable weighting function for flexible knowledge transfer based on semantic similarity.", "example": "Convert the coordinate to text: [ 3.6086 -3.8762]:"}
{"text": "Convert the coordinate to text: [14.2087  5.3774]: The authors introduce a Fused Gromov-Wasserstein (FGW) Mixture Model, called FraMe, to tackle the GDL problem from a generative viewpoint. The model uses a graph generation function based on the radial basis function kernel and FGW distance to create nonlinear embedding spaces.", "target": "The authors introduce a Fused Gromov-Wasserstein (FGW) Mixture Model, called FraMe, to tackle the GDL problem from a generative viewpoint. The model uses a graph generation function based on the radial basis function kernel and FGW distance to create nonlinear embedding spaces.", "example": "Convert the coordinate to text: [14.2087  5.3774]:"}
{"text": "Convert the coordinate to text: [  4.7539 -13.1841]: The authors propose a method, LoCUS, that balances retrieval and reusability by carefully constructing the retrieval set, omitting patches that map to distantly located real-world locations. It also offers regulation of the scale of learned features by adjusting the spatial tolerance, and uses a unified ranking-based objective optimizing for Average Precision (AP).", "target": "The authors propose a method, LoCUS, that balances retrieval and reusability by carefully constructing the retrieval set, omitting patches that map to distantly located real-world locations. It also offers regulation of the scale of learned features by adjusting the spatial tolerance, and uses a unified ranking-based objective optimizing for Average Precision (AP).", "example": "Convert the coordinate to text: [  4.7539 -13.1841]:"}
{"text": "Convert the coordinate to text: [  0.6068 -15.173 ]: The authors propose a foundation model named 'Brant' for modeling intracranial recordings which is the largest model in the field of brain signals. This model is pre-trained on a large corpus of intracranial data and is designed to capture long-term temporal dependency and spatial correlation from neural signals, combining the information in both time and frequency domains.", "target": "The authors propose a foundation model named 'Brant' for modeling intracranial recordings which is the largest model in the field of brain signals. This model is pre-trained on a large corpus of intracranial data and is designed to capture long-term temporal dependency and spatial correlation from neural signals, combining the information in both time and frequency domains.", "example": "Convert the coordinate to text: [  0.6068 -15.173 ]:"}
{"text": "Convert the coordinate to text: [-0.5531 -5.3106]: The authors introduce a universal prompt-based tuning method called Graph Prompt Feature (GPF) for pre-trained GNN models under any pre-training strategy. GPF operates on the input graph's feature space and can theoretically achieve an equivalent effect to any form of prompting function.", "target": "The authors introduce a universal prompt-based tuning method called Graph Prompt Feature (GPF) for pre-trained GNN models under any pre-training strategy. GPF operates on the input graph's feature space and can theoretically achieve an equivalent effect to any form of prompting function.", "example": "Convert the coordinate to text: [-0.5531 -5.3106]:"}
{"text": "Convert the coordinate to text: [ 3.5084 -0.4994]: The paper proposes novel ensembling methods for few-shot learning to reduce variance. It also introduces a new active learning criterion, inter-prompt uncertainty sampling with diversity, to select training examples for prompt-based learning.", "target": "The paper proposes novel ensembling methods for few-shot learning to reduce variance. It also introduces a new active learning criterion, inter-prompt uncertainty sampling with diversity, to select training examples for prompt-based learning.", "example": "Convert the coordinate to text: [ 3.5084 -0.4994]:"}
{"text": "Convert the coordinate to text: [ 0.3023 -3.1467]: The authors introduce a novel approach to context and knowledge weighting as an integral part of model training. They propose a Contextual Knowledge Learning (CKL) process that uses Latent Vectors for context and knowledge.", "target": "The authors introduce a novel approach to context and knowledge weighting as an integral part of model training. They propose a Contextual Knowledge Learning (CKL) process that uses Latent Vectors for context and knowledge.", "example": "Convert the coordinate to text: [ 0.3023 -3.1467]:"}
{"text": "Convert the coordinate to text: [ 2.9492 -8.8785]: The authors propose a model called Moment Sampling DETR (MS-DETR) that allows efficient moment-moment relation modeling by sampling a subset of moments, guided by learnable templates, within a DETR (DEtection TRansformer) framework.", "target": "The authors propose a model called Moment Sampling DETR (MS-DETR) that allows efficient moment-moment relation modeling by sampling a subset of moments, guided by learnable templates, within a DETR (DEtection TRansformer) framework.", "example": "Convert the coordinate to text: [ 2.9492 -8.8785]:"}
{"text": "Convert the coordinate to text: [ 3.3264 -7.5462]: The authors postulate the existence of sparsely connected sub-networks within a transformer, termed 'information pathways', which can be trained independently but are hard to prune due to their input-dependent nature. They propose the Stochastically Subsampled self-Attention (SSA), a training strategy that can reduce both the memory and computational cost of self-attention, while serving as a regularization method to improve generalization.", "target": "The authors postulate the existence of sparsely connected sub-networks within a transformer, termed 'information pathways', which can be trained independently but are hard to prune due to their input-dependent nature. They propose the Stochastically Subsampled self-Attention (SSA), a training strategy that can reduce both the memory and computational cost of self-attention, while serving as a regularization method to improve generalization.", "example": "Convert the coordinate to text: [ 3.3264 -7.5462]:"}
{"text": "Convert the coordinate to text: [12.5624  0.314 ]: The authors utilize the structure of state estimation and learning in graph-structured state-space models with (partially) unknown dynamics and limited historical data to develop a computationally efficient approach. They reformulate these models as Deep Gaussian Markov random fields (GMRFs) defined by simple spatial and temporal graph layers.", "target": "The authors utilize the structure of state estimation and learning in graph-structured state-space models with (partially) unknown dynamics and limited historical data to develop a computationally efficient approach. They reformulate these models as Deep Gaussian Markov random fields (GMRFs) defined by simple spatial and temporal graph layers.", "example": "Convert the coordinate to text: [12.5624  0.314 ]:"}
{"text": "Convert the coordinate to text: [ 4.0835 -0.8534]: The authors propose a novel class-adaptive re-sampling self-training framework, which re-samples the pseudo-labels for each class using precision and recall scores to alleviate the false negative problem.", "target": "The authors propose a novel class-adaptive re-sampling self-training framework, which re-samples the pseudo-labels for each class using precision and recall scores to alleviate the false negative problem.", "example": "Convert the coordinate to text: [ 4.0835 -0.8534]:"}
{"text": "Convert the coordinate to text: [ 7.4792 -2.1635]: The authors propose the Federated Conditional Policy (FedCP) method, which generates a conditional policy for each sample to separate the global information and personalized information in its features and then processes them by a global head and a personalized head, respectively.", "target": "The authors propose the Federated Conditional Policy (FedCP) method, which generates a conditional policy for each sample to separate the global information and personalized information in its features and then processes them by a global head and a personalized head, respectively.", "example": "Convert the coordinate to text: [ 7.4792 -2.1635]:"}
{"text": "Convert the coordinate to text: [-6.5319 -9.2581]: The researchers introduce a system for identifying complex entities and recognizing their types from the low-resource language Bangla, using a pre-trained language model built on a natural language processing framework.", "target": "The researchers introduce a system for identifying complex entities and recognizing their types from the low-resource language Bangla, using a pre-trained language model built on a natural language processing framework.", "example": "Convert the coordinate to text: [-6.5319 -9.2581]:"}
{"text": "Convert the coordinate to text: [-2.8888 -6.461 ]: This paper proposes a method for fine-tuning PMTs on multilingual data sequentially language by language, not basing on the concept of 'easy' and 'hard' samples, but drawing from psychological findings on how humans process and retain new information.", "target": "This paper proposes a method for fine-tuning PMTs on multilingual data sequentially language by language, not basing on the concept of 'easy' and 'hard' samples, but drawing from psychological findings on how humans process and retain new information.", "example": "Convert the coordinate to text: [-2.8888 -6.461 ]:"}
{"text": "Convert the coordinate to text: [-7.5551 -5.3089]: The authors propose modifications to the data and evaluation setup of the standard task of noun compound interpretation and investigate a new task, noun compound conceptualization, which requires a language model to paraphrase a novel or rare noun compound creatively.", "target": "The authors propose modifications to the data and evaluation setup of the standard task of noun compound interpretation and investigate a new task, noun compound conceptualization, which requires a language model to paraphrase a novel or rare noun compound creatively.", "example": "Convert the coordinate to text: [-7.5551 -5.3089]:"}
{"text": "Convert the coordinate to text: [16.1981  1.8395]: The authors propose a method called Pseudo Outlier Exposure (POE) which creates a surrogate OOD dataset by sequentially masking tokens related to ID classes, without requiring any external OOD data. This allows the creation of OOD samples with similar representations to ID data, aiding in the training of a rejection network.", "target": "The authors propose a method called Pseudo Outlier Exposure (POE) which creates a surrogate OOD dataset by sequentially masking tokens related to ID classes, without requiring any external OOD data. This allows the creation of OOD samples with similar representations to ID data, aiding in the training of a rejection network.", "example": "Convert the coordinate to text: [16.1981  1.8395]:"}
{"text": "Convert the coordinate to text: [ 3.7453 -4.096 ]: The authors apply focal distillation, a technique to avoid classification regressions, for model updates in a goal-oriented dialog system and assess its effectiveness for key language understanding tasks, including sentence classification and sequence labeling tasks.", "target": "The authors apply focal distillation, a technique to avoid classification regressions, for model updates in a goal-oriented dialog system and assess its effectiveness for key language understanding tasks, including sentence classification and sequence labeling tasks.", "example": "Convert the coordinate to text: [ 3.7453 -4.096 ]:"}
{"text": "Convert the coordinate to text: [-10.8628  -1.8738]: The authors propose Tab-CQA, a tabular CQA dataset created from Chinese financial reports that span across various sectors for the past 30 years.", "target": "The authors propose Tab-CQA, a tabular CQA dataset created from Chinese financial reports that span across various sectors for the past 30 years.", "example": "Convert the coordinate to text: [-10.8628  -1.8738]:"}
{"text": "Convert the coordinate to text: [-7.6644 -1.916 ]: The study aims to characterize instances of stigmatizing language in EMRs at scale using domain-informed Natural Language Processing (NLP) techniques, highlighting the differences between this task and similar bias-related tasks in the NLP community.", "target": "The study aims to characterize instances of stigmatizing language in EMRs at scale using domain-informed Natural Language Processing (NLP) techniques, highlighting the differences between this task and similar bias-related tasks in the NLP community.", "example": "Convert the coordinate to text: [-7.6644 -1.916 ]:"}
{"text": "Convert the coordinate to text: [ 4.01   -6.4466]: To deal with these issues, the authors propose an Adaptive Graph Representation-enhanced Attention Network (AGRAN) for next POI recommendation, which leverages graph structure learning to replace pre-defined static graphs, with the aim of learning more expressive POI representations.", "target": "To deal with these issues, the authors propose an Adaptive Graph Representation-enhanced Attention Network (AGRAN) for next POI recommendation, which leverages graph structure learning to replace pre-defined static graphs, with the aim of learning more expressive POI representations.", "example": "Convert the coordinate to text: [ 4.01   -6.4466]:"}
{"text": "Convert the coordinate to text: [ 7.3114 -3.7317]: The authors propose a subspace identification theory that facilitates domain adaptation by disentangling domain-invariant and domain-specific variables under less restrictive constraints. Based on this theory, they develop the Subspace Identification Guarantee (SIG) model that leverages variational inference and class-aware conditional alignment to accommodate target shifts where label distributions vary with domains.", "target": "The authors propose a subspace identification theory that facilitates domain adaptation by disentangling domain-invariant and domain-specific variables under less restrictive constraints. Based on this theory, they develop the Subspace Identification Guarantee (SIG) model that leverages variational inference and class-aware conditional alignment to accommodate target shifts where label distributions vary with domains.", "example": "Convert the coordinate to text: [ 7.3114 -3.7317]:"}
{"text": "Convert the coordinate to text: [11.0567 -9.919 ]: The authors propose a comprehensive empirical examination of Perceptual Artifacts Localization (PAL) across various image synthesis tasks. They also introduce a segmentation model and an innovative zoom-in inpainting pipeline to localize and rectify perceptual artifacts.", "target": "The authors propose a comprehensive empirical examination of Perceptual Artifacts Localization (PAL) across various image synthesis tasks. They also introduce a segmentation model and an innovative zoom-in inpainting pipeline to localize and rectify perceptual artifacts.", "example": "Convert the coordinate to text: [11.0567 -9.919 ]:"}
{"text": "Convert the coordinate to text: [12.6982  3.5359]: The authors propose a new architecture, Monarch Mixer (M2), based on Monarch matrices - a class of expressive structured matrices that are highly efficient on GPUs and scale sub-quadratically.", "target": "The authors propose a new architecture, Monarch Mixer (M2), based on Monarch matrices - a class of expressive structured matrices that are highly efficient on GPUs and scale sub-quadratically.", "example": "Convert the coordinate to text: [12.6982  3.5359]:"}
{"text": "Convert the coordinate to text: [ 3.1178 -2.3129]: The authors propose a single coherent Energy-Based Meta-Learning (EBML) framework that supports both detection and adaptation of OOD tasks whilst remaining compatible with off-the-shelf meta-learning backbones.", "target": "The authors propose a single coherent Energy-Based Meta-Learning (EBML) framework that supports both detection and adaptation of OOD tasks whilst remaining compatible with off-the-shelf meta-learning backbones.", "example": "Convert the coordinate to text: [ 3.1178 -2.3129]:"}
{"text": "Convert the coordinate to text: [-0.9886 -5.219 ]: The authors propose a novel method called APrompt for efficient adaptation of pre-trained language models. The APrompt incorporates query, key, and value prompts into the attention layer to guide attention computation during fine-tuning.", "target": "The authors propose a novel method called APrompt for efficient adaptation of pre-trained language models. The APrompt incorporates query, key, and value prompts into the attention layer to guide attention computation during fine-tuning.", "example": "Convert the coordinate to text: [-0.9886 -5.219 ]:"}
{"text": "Convert the coordinate to text: [ 5.1939 -5.2511]: The paper proposes to bridge this knowledge gap by offering a detailed tutorial that covers foundational concepts, new research frontiers, and applications of GNNs.", "target": "The paper proposes to bridge this knowledge gap by offering a detailed tutorial that covers foundational concepts, new research frontiers, and applications of GNNs.", "example": "Convert the coordinate to text: [ 5.1939 -5.2511]:"}
{"text": "Convert the coordinate to text: [ 0.2966 -9.3021]: The authors propose visualization generation as a multi-stage generative problem and present LIDA, a novel tool for generating grammar-agnostic visualizations and infographics using pipelines based on large language models (LLMs) and image generation models (IGMs).", "target": "The authors propose visualization generation as a multi-stage generative problem and present LIDA, a novel tool for generating grammar-agnostic visualizations and infographics using pipelines based on large language models (LLMs) and image generation models (IGMs).", "example": "Convert the coordinate to text: [ 0.2966 -9.3021]:"}
{"text": "Convert the coordinate to text: [ 5.7978 13.4648]: The authors propose a modification to a variant of S4 that enables us to initialise and reset the hidden state in parallel, allowing applicability to reinforcement learning tasks.", "target": "The authors propose a modification to a variant of S4 that enables us to initialise and reset the hidden state in parallel, allowing applicability to reinforcement learning tasks.", "example": "Convert the coordinate to text: [ 5.7978 13.4648]:"}
{"text": "Convert the coordinate to text: [-5.5851 -5.6257]: The paper reports on the LeWiDi series of shared tasks, which instead of eliminating disagreements from annotated corpora, aims at creating NLP models by preserving these disagreements and using them in the model training process.", "target": "The paper reports on the LeWiDi series of shared tasks, which instead of eliminating disagreements from annotated corpora, aims at creating NLP models by preserving these disagreements and using them in the model training process.", "example": "Convert the coordinate to text: [-5.5851 -5.6257]:"}
{"text": "Convert the coordinate to text: [-2.6071 -5.0805]: This paper explores the automatic evaluation of attribution in LLMs, and introduces two methods for automatic evaluation: prompting LLMs and fine-tuning smaller LMs, making use of data from existing tasks such as question answering and fact-checking.", "target": "This paper explores the automatic evaluation of attribution in LLMs, and introduces two methods for automatic evaluation: prompting LLMs and fine-tuning smaller LMs, making use of data from existing tasks such as question answering and fact-checking.", "example": "Convert the coordinate to text: [-2.6071 -5.0805]:"}
{"text": "Convert the coordinate to text: [13.4114 -4.6757]: The authors point out that adversaries can inject a backdoor into neural code search models, causing them to return buggy or vulnerable code with security/privacy issues and propose an attack called BADCODE, which features a special trigger generation and injection procedure to make the attack more effective and stealthy.", "target": "The authors point out that adversaries can inject a backdoor into neural code search models, causing them to return buggy or vulnerable code with security/privacy issues and propose an attack called BADCODE, which features a special trigger generation and injection procedure to make the attack more effective and stealthy.", "example": "Convert the coordinate to text: [13.4114 -4.6757]:"}
{"text": "Convert the coordinate to text: [-2.2367 -5.2573]: The authors propose Targeted Data Generation (TDG), a framework that automatically identifies challenging subgroups, and generates new data for those subgroups using large language models (LLMs) with a human in the loop.", "target": "The authors propose Targeted Data Generation (TDG), a framework that automatically identifies challenging subgroups, and generates new data for those subgroups using large language models (LLMs) with a human in the loop.", "example": "Convert the coordinate to text: [-2.2367 -5.2573]:"}
{"text": "Convert the coordinate to text: [-10.1745  -3.4402]: The authors introduce a new keyboard interface in UMR-Writer 2.0 to complement the original mouse interface, with a focus on speeding up the annotation process for experienced annotators and addressing issues existing in the old interface.", "target": "The authors introduce a new keyboard interface in UMR-Writer 2.0 to complement the original mouse interface, with a focus on speeding up the annotation process for experienced annotators and addressing issues existing in the old interface.", "example": "Convert the coordinate to text: [-10.1745  -3.4402]:"}
{"text": "Convert the coordinate to text: [-0.3469  1.078 ]: The authors argue for the importance of highlighting uncertainty in the results of language model prompting which display bias modes resembling cognitive biases, proposing that users can be made aware of the level of uncertainty through straightforward quantifying metrics.", "target": "The authors argue for the importance of highlighting uncertainty in the results of language model prompting which display bias modes resembling cognitive biases, proposing that users can be made aware of the level of uncertainty through straightforward quantifying metrics.", "example": "Convert the coordinate to text: [-0.3469  1.078 ]:"}
{"text": "Convert the coordinate to text: [12.6495 -6.7305]: The authors propose a new fine-tuning framework, G-Tuning, which integrates a generative adversarial network into the fine-tuning process to assist in the transformation of the complete latent representation.", "target": "The authors propose a new fine-tuning framework, G-Tuning, which integrates a generative adversarial network into the fine-tuning process to assist in the transformation of the complete latent representation.", "example": "Convert the coordinate to text: [12.6495 -6.7305]:"}
{"text": "Convert the coordinate to text: [-7.5469 -7.9165]: The authors propose a deep active learning method for morphological inflection and morphophonological processing.", "target": "The authors propose a deep active learning method for morphological inflection and morphophonological processing.", "example": "Convert the coordinate to text: [-7.5469 -7.9165]:"}
{"text": "Convert the coordinate to text: [  9.0606 -19.3873]: The authors propose a parameterized cost volume to encode the entire disparity space using a multi-Gaussian distribution. Disparity distribution of each pixel is parameterized by weights, means, and variances, which used to sample disparity candidates for cost computation and to calculate the disparity output.", "target": "The authors propose a parameterized cost volume to encode the entire disparity space using a multi-Gaussian distribution. Disparity distribution of each pixel is parameterized by weights, means, and variances, which used to sample disparity candidates for cost computation and to calculate the disparity output.", "example": "Convert the coordinate to text: [  9.0606 -19.3873]:"}
{"text": "Convert the coordinate to text: [  3.0817 -10.9073]: A novel method is proposed for generating pixel-level semantic segmentation labels using the Stable Diffusion (SD) text-to-image generative model. The authors introduce three new techniques - class-prompt appending, class-prompt cross-attention, and self-attention exponentiation - to enable segmentation map generation for synthetic images.", "target": "A novel method is proposed for generating pixel-level semantic segmentation labels using the Stable Diffusion (SD) text-to-image generative model. The authors introduce three new techniques - class-prompt appending, class-prompt cross-attention, and self-attention exponentiation - to enable segmentation map generation for synthetic images.", "example": "Convert the coordinate to text: [  3.0817 -10.9073]:"}
{"text": "Convert the coordinate to text: [ 7.015 13.521]: The authors propose a new algorithm, Belief-Projection-Based Q-learning (BPQL), which addresses the state-space explosion problem by evaluating the values of the critic for which the input state size is equal to the original state-space size rather than that of the augmented one.", "target": "The authors propose a new algorithm, Belief-Projection-Based Q-learning (BPQL), which addresses the state-space explosion problem by evaluating the values of the critic for which the input state size is equal to the original state-space size rather than that of the augmented one.", "example": "Convert the coordinate to text: [ 7.015 13.521]:"}
{"text": "Convert the coordinate to text: [15.042  0.755]: The researchers propose Birder, a 1-bit adaptive optimizer that avoids the need for warmup and variant computation. Additionally, the authors create Hierarchical-1-bit-All-Reduce to further reduce communication volume.", "target": "The researchers propose Birder, a 1-bit adaptive optimizer that avoids the need for warmup and variant computation. Additionally, the authors create Hierarchical-1-bit-All-Reduce to further reduce communication volume.", "example": "Convert the coordinate to text: [15.042  0.755]:"}
{"text": "Convert the coordinate to text: [ 5.2347 -6.7441]: The authors propose a new architecture, Gated Recurrent Memory Reader (GRMR), that integrates traditional extractive MRC models into a generalized sequence-to-sequence framework. The model is designed to generate extractive answers turn by turn from encoded passage and consider historical memory deeply and selectively, instead of superficial and redundant concatenation of previous questions and answers used by previous models.", "target": "The authors propose a new architecture, Gated Recurrent Memory Reader (GRMR), that integrates traditional extractive MRC models into a generalized sequence-to-sequence framework. The model is designed to generate extractive answers turn by turn from encoded passage and consider historical memory deeply and selectively, instead of superficial and redundant concatenation of previous questions and answers used by previous models.", "example": "Convert the coordinate to text: [ 5.2347 -6.7441]:"}
{"text": "Convert the coordinate to text: [-1.0055 -5.092 ]: The authors identify the new problem of robust prompt optimization for LLMs against distribution shifts and propose the Generalized Prompt Optimization framework, aiming to ensure that prompts optimized on a labeled source group generalize well to an unlabeled target group.", "target": "The authors identify the new problem of robust prompt optimization for LLMs against distribution shifts and propose the Generalized Prompt Optimization framework, aiming to ensure that prompts optimized on a labeled source group generalize well to an unlabeled target group.", "example": "Convert the coordinate to text: [-1.0055 -5.092 ]:"}
{"text": "Convert the coordinate to text: [11.9725 -8.7681]: The paper introduces a deep Reinforcement Learning (RL) based architecture that breaks down the one-step style transfer process into a series of steps for the NST task, offering better control over the degree of style transfer.", "target": "The paper introduces a deep Reinforcement Learning (RL) based architecture that breaks down the one-step style transfer process into a series of steps for the NST task, offering better control over the degree of style transfer.", "example": "Convert the coordinate to text: [11.9725 -8.7681]:"}
{"text": "Convert the coordinate to text: [-7.4303 -7.6034]: The authors present MasakhaPOS, the largest part-of-speech (POS) dataset for 20 typologically diverse African languages, and propose the use of conditional random field and several multilingual pre-trained language models for POS tagging in these languages.", "target": "The authors present MasakhaPOS, the largest part-of-speech (POS) dataset for 20 typologically diverse African languages, and propose the use of conditional random field and several multilingual pre-trained language models for POS tagging in these languages.", "example": "Convert the coordinate to text: [-7.4303 -7.6034]:"}
{"text": "Convert the coordinate to text: [-5.6107  9.9003]: The authors present BIG-C (Bemba Image Grounded Conversations), a large multimodal dataset for Bemba that contains multi-turn dialogues between Bemba speakers based on images, transcribed and translated into English.", "target": "The authors present BIG-C (Bemba Image Grounded Conversations), a large multimodal dataset for Bemba that contains multi-turn dialogues between Bemba speakers based on images, transcribed and translated into English.", "example": "Convert the coordinate to text: [-5.6107  9.9003]:"}
{"text": "Convert the coordinate to text: [-1.647  -6.3236]: The authors argue that the problem arises because the fine-tuning process learns language invariant representations which is good for classification tasks but detrimental for generation tasks. Therefore, they propose a simple method to regularize the model from learning language invariant representations and a method to select model checkpoints without a development set in the target language, to improve generation quality.", "target": "The authors argue that the problem arises because the fine-tuning process learns language invariant representations which is good for classification tasks but detrimental for generation tasks. Therefore, they propose a simple method to regularize the model from learning language invariant representations and a method to select model checkpoints without a development set in the target language, to improve generation quality.", "example": "Convert the coordinate to text: [-1.647  -6.3236]:"}
{"text": "Convert the coordinate to text: [-2.4076 -3.7157]: The authors propose EG3P (Explanation Graph Generation via Generative Pre-training over synthetic graphs), a novel pre-trained framework for the task of explanation graph generation. EG3P includes a text-to-graph generative task to pre-train the model and an automatic synthetic corpus generation strategy to scale up the quality of the corpus without the need for costly manual annotation.", "target": "The authors propose EG3P (Explanation Graph Generation via Generative Pre-training over synthetic graphs), a novel pre-trained framework for the task of explanation graph generation. EG3P includes a text-to-graph generative task to pre-train the model and an automatic synthetic corpus generation strategy to scale up the quality of the corpus without the need for costly manual annotation.", "example": "Convert the coordinate to text: [-2.4076 -3.7157]:"}
{"text": "Convert the coordinate to text: [-0.633   6.5359]: This paper introduces a step-by-step planning approach for intermediate solution generation to improve the correctness and coherence of intermediate steps. The approach plans the next solution step based on the MWP and the previous solution steps by predicting the necessary math operation needed to proceed.", "target": "This paper introduces a step-by-step planning approach for intermediate solution generation to improve the correctness and coherence of intermediate steps. The approach plans the next solution step based on the MWP and the previous solution steps by predicting the necessary math operation needed to proceed.", "example": "Convert the coordinate to text: [-0.633   6.5359]:"}
{"text": "Convert the coordinate to text: [ 2.2375 -1.3741]: The authors propose Clustering-enhanced Linear Discriminative Analysis (CELDA), a novel weak-supervision signal approach that enhances text classification accuracy without the need for accessing internal weights, gradients of the LM model, or data labels. The two core ideas of CELDA are to extract a refined pseudo-labeled dataset from an unlabeled dataset, and train a lightweight, robust model on top of the LM.", "target": "The authors propose Clustering-enhanced Linear Discriminative Analysis (CELDA), a novel weak-supervision signal approach that enhances text classification accuracy without the need for accessing internal weights, gradients of the LM model, or data labels. The two core ideas of CELDA are to extract a refined pseudo-labeled dataset from an unlabeled dataset, and train a lightweight, robust model on top of the LM.", "example": "Convert the coordinate to text: [ 2.2375 -1.3741]:"}
{"text": "Convert the coordinate to text: [ 8.2437 11.3412]: The authors propose adversarial constrained bidding which does not rely on i.i.d. assumptions. Instead, they propose a strategy to align the training distribution of environments with potential test distributions, thereby minimizing policy regret. They propose a method called Minimax Regret Optimization (MiRO) that involves a teacher and a learner where the teacher finds adversarial environments for tutoring, and the learner meta-learns their policy over the given distribution of environments.", "target": "The authors propose adversarial constrained bidding which does not rely on i.i.d. assumptions. Instead, they propose a strategy to align the training distribution of environments with potential test distributions, thereby minimizing policy regret. They propose a method called Minimax Regret Optimization (MiRO) that involves a teacher and a learner where the teacher finds adversarial environments for tutoring, and the learner meta-learns their policy over the given distribution of environments.", "example": "Convert the coordinate to text: [ 8.2437 11.3412]:"}
{"text": "Convert the coordinate to text: [-4.3113 -7.9598]: The paper introduces EvolveMT, an ensemble machine translation system that dynamically adapts to alterations in domain or machine translation engines using online learning techniques and does not require additional training.", "target": "The paper introduces EvolveMT, an ensemble machine translation system that dynamically adapts to alterations in domain or machine translation engines using online learning techniques and does not require additional training.", "example": "Convert the coordinate to text: [-4.3113 -7.9598]:"}
{"text": "Convert the coordinate to text: [ 4.9014 -2.912 ]: The authors present a novel fully differentiable architecture, based on the Mixture of Experts model, capable of training high-performance classifiers when examples from each class are presented separately.", "target": "The authors present a novel fully differentiable architecture, based on the Mixture of Experts model, capable of training high-performance classifiers when examples from each class are presented separately.", "example": "Convert the coordinate to text: [ 4.9014 -2.912 ]:"}
{"text": "Convert the coordinate to text: [ 3.2336 -5.8875]: The authors introduce GNNRR (Graph Neural Network for Rhetorical Roles Prediction), a model that leverages long context representation and can model cross-information for long texts within legal documents.", "target": "The authors introduce GNNRR (Graph Neural Network for Rhetorical Roles Prediction), a model that leverages long context representation and can model cross-information for long texts within legal documents.", "example": "Convert the coordinate to text: [ 3.2336 -5.8875]:"}
{"text": "Convert the coordinate to text: [-6.6217 11.3487]: The authors propose a synchronous conversational corrective feedback (CCF) method, allowing for self-correction and providing metalinguistic explanations (ME). They also suggest that in chatbot-driven language-learning tools, corrective feedback is more effectively delivered through means other than the social chatbot, such as a GUI interface.", "target": "The authors propose a synchronous conversational corrective feedback (CCF) method, allowing for self-correction and providing metalinguistic explanations (ME). They also suggest that in chatbot-driven language-learning tools, corrective feedback is more effectively delivered through means other than the social chatbot, such as a GUI interface.", "example": "Convert the coordinate to text: [-6.6217 11.3487]:"}
{"text": "Convert the coordinate to text: [ 6.2383 -3.7301]: The authors propose a switch knowledge distillation for domain generalization, along with a generalization-switch (GSwitch) model which infuses user and product information by flexibly encoding domain-invariant and domain-specific features to learn the reviews of both existing and unseen users.", "target": "The authors propose a switch knowledge distillation for domain generalization, along with a generalization-switch (GSwitch) model which infuses user and product information by flexibly encoding domain-invariant and domain-specific features to learn the reviews of both existing and unseen users.", "example": "Convert the coordinate to text: [ 6.2383 -3.7301]:"}
{"text": "Convert the coordinate to text: [-2.3956 -7.6917]: EdiRCS, a new text-editing based CQR model, is introduced which selects most of its rewrite tokens from the dialogue in a non-autoregressive fashion. It then generates a few new tokens to supplement the final rewrite, which substantially enhances efficiency.", "target": "EdiRCS, a new text-editing based CQR model, is introduced which selects most of its rewrite tokens from the dialogue in a non-autoregressive fashion. It then generates a few new tokens to supplement the final rewrite, which substantially enhances efficiency.", "example": "Convert the coordinate to text: [-2.3956 -7.6917]:"}
{"text": "Convert the coordinate to text: [ 1.2144 -3.4782]: The authors propose that carefully curating a subset of training data can stabilize ICL performance without needing any other changes to the ICL algorithm. They introduce two methods, CondAcc and Datamodels, that score training examples individually and then select the highest-scoring ones.", "target": "The authors propose that carefully curating a subset of training data can stabilize ICL performance without needing any other changes to the ICL algorithm. They introduce two methods, CondAcc and Datamodels, that score training examples individually and then select the highest-scoring ones.", "example": "Convert the coordinate to text: [ 1.2144 -3.4782]:"}
{"text": "Convert the coordinate to text: [-0.8032  0.721 ]: The authors introduce FairPrism, a dataset of 5,000 examples of AI-generated English text associated with detailed human annotations covering a various set of harms relating to gender and sexuality. FairPrism accounts for stereotyping and demeaning harms, targeted demographic groups, and appropriateness for different applications and interactive contexts.", "target": "The authors introduce FairPrism, a dataset of 5,000 examples of AI-generated English text associated with detailed human annotations covering a various set of harms relating to gender and sexuality. FairPrism accounts for stereotyping and demeaning harms, targeted demographic groups, and appropriateness for different applications and interactive contexts.", "example": "Convert the coordinate to text: [-0.8032  0.721 ]:"}
{"text": "Convert the coordinate to text: [-3.314  16.5445]: The authors present City Brain Lab (CBLab), a toolkit for scalable traffic simulation that aims to overcome the limitations of existing traffic simulators. CBLab consists of three components: CBEngine, a simulator for large-scale traffic, CBData, a global traffic dataset, and CBScenario, an interactive environment for traffic control policy development.", "target": "The authors present City Brain Lab (CBLab), a toolkit for scalable traffic simulation that aims to overcome the limitations of existing traffic simulators. CBLab consists of three components: CBEngine, a simulator for large-scale traffic, CBData, a global traffic dataset, and CBScenario, an interactive environment for traffic control policy development.", "example": "Convert the coordinate to text: [-3.314  16.5445]:"}
{"text": "Convert the coordinate to text: [-12.9969   2.4234]: The authors introduce ONEPROVENANCE, an efficient system for extracting provenance from query event logs, which addresses the problems of current approaches by identifying query execution dependencies, extracting provenance using novel event transformations, and introducing effective filtering optimizations.", "target": "The authors introduce ONEPROVENANCE, an efficient system for extracting provenance from query event logs, which addresses the problems of current approaches by identifying query execution dependencies, extracting provenance using novel event transformations, and introducing effective filtering optimizations.", "example": "Convert the coordinate to text: [-12.9969   2.4234]:"}
{"text": "Convert the coordinate to text: [10.1785  8.0586]: In this paper, the authors establish optimal rates for user-level DP-SCO in both the central and local models of DP, and propose algorithms that combine new user-level DP mean estimation techniques with carefully designed first-order stochastic optimization methods.", "target": "In this paper, the authors establish optimal rates for user-level DP-SCO in both the central and local models of DP, and propose algorithms that combine new user-level DP mean estimation techniques with carefully designed first-order stochastic optimization methods.", "example": "Convert the coordinate to text: [10.1785  8.0586]:"}
{"text": "Convert the coordinate to text: [ 9.6781 -0.4317]: The authors propose a method called Mirror Diffusion Models (MDM), capable of generating data on convex constrained sets with the same tractability as existing models, thanks to learning diffusion processes in a dual space made from a mirror map, which is a standard Euclidean space.", "target": "The authors propose a method called Mirror Diffusion Models (MDM), capable of generating data on convex constrained sets with the same tractability as existing models, thanks to learning diffusion processes in a dual space made from a mirror map, which is a standard Euclidean space.", "example": "Convert the coordinate to text: [ 9.6781 -0.4317]:"}
{"text": "Convert the coordinate to text: [2.1961 3.274 ]: This study explores the Markov Assumption under time-delayed causally-related processes in a nonstationary setting, showing that under mild conditions, the independent latent components can be recovered from their nonlinear mixture without observing auxiliary variables. The authors also introduce NCTRL, an estimation framework, for reconstructing time-delayed latent causal variables and identifying their relations from only the measured sequential data.", "target": "This study explores the Markov Assumption under time-delayed causally-related processes in a nonstationary setting, showing that under mild conditions, the independent latent components can be recovered from their nonlinear mixture without observing auxiliary variables. The authors also introduce NCTRL, an estimation framework, for reconstructing time-delayed latent causal variables and identifying their relations from only the measured sequential data.", "example": "Convert the coordinate to text: [2.1961 3.274 ]:"}
{"text": "Convert the coordinate to text: [ 10.7735 -16.3523]: The authors introduce DynPoint, an algorithm developed to enable the swift synthesis of novel views for unconstrained monocular videos. Its unique approach involves predicting the explicit 3D correspondence between neighboring frames to facilitate information aggregation, rather than encoding all of the scenario information into a latent representation.", "target": "The authors introduce DynPoint, an algorithm developed to enable the swift synthesis of novel views for unconstrained monocular videos. Its unique approach involves predicting the explicit 3D correspondence between neighboring frames to facilitate information aggregation, rather than encoding all of the scenario information into a latent representation.", "example": "Convert the coordinate to text: [ 10.7735 -16.3523]:"}
{"text": "Convert the coordinate to text: [ -1.5181 -13.4328]: The authors propose a VAE-based prototype learning scheme called a prototypical VAE, or P-VAE, that encodes a multi-center GMM-like posterior where each distribution centers at a prototype. Alongside, they design the Geometric-informative Prototypical VAE (GP-VAE) and the Class-specific Prototypical VAE (CP-VAE) to effectively handle varying geometric components and object categories.", "target": "The authors propose a VAE-based prototype learning scheme called a prototypical VAE, or P-VAE, that encodes a multi-center GMM-like posterior where each distribution centers at a prototype. Alongside, they design the Geometric-informative Prototypical VAE (GP-VAE) and the Class-specific Prototypical VAE (CP-VAE) to effectively handle varying geometric components and object categories.", "example": "Convert the coordinate to text: [ -1.5181 -13.4328]:"}
{"text": "Convert the coordinate to text: [ 5.4893 -2.8194]: The authors propose studying the interplay between data augmentation, network architecture, and training algorithm in SSL with an analysis of generalization performance.", "target": "The authors propose studying the interplay between data augmentation, network architecture, and training algorithm in SSL with an analysis of generalization performance.", "example": "Convert the coordinate to text: [ 5.4893 -2.8194]:"}
{"text": "Convert the coordinate to text: [-1.7774  4.5681]: This paper presents DeepSeer, an interactive system providing both global and local explanations of RNN behavior for model understanding and debugging. The central part of DeepSeer is a state abstraction method that bundles similar hidden states in an RNN model and abstracts it as a finite state machine.", "target": "This paper presents DeepSeer, an interactive system providing both global and local explanations of RNN behavior for model understanding and debugging. The central part of DeepSeer is a state abstraction method that bundles similar hidden states in an RNN model and abstracts it as a finite state machine.", "example": "Convert the coordinate to text: [-1.7774  4.5681]:"}
{"text": "Convert the coordinate to text: [8.3808 0.359 ]: The authors introduce a linear classification model, QLDS, where the low density separation assumption is implemented via quadratic margin maximization, establishing a bridge between supervised and unsupervised learning methods.", "target": "The authors introduce a linear classification model, QLDS, where the low density separation assumption is implemented via quadratic margin maximization, establishing a bridge between supervised and unsupervised learning methods.", "example": "Convert the coordinate to text: [8.3808 0.359 ]:"}
{"text": "Convert the coordinate to text: [ 1.8785 -6.7731]: Inspired by recent work on neural databases, the authors propose Multimodal Neural Databases (MMNDBs), a new framework that can answer complex database-style queries involving reasoning processes across different input modalities.", "target": "Inspired by recent work on neural databases, the authors propose Multimodal Neural Databases (MMNDBs), a new framework that can answer complex database-style queries involving reasoning processes across different input modalities.", "example": "Convert the coordinate to text: [ 1.8785 -6.7731]:"}
{"text": "Convert the coordinate to text: [-4.5457 -3.1346]: The paper explores the impact of global document context and its relationship with local context in the context of Named Entity Recognition.", "target": "The paper explores the impact of global document context and its relationship with local context in the context of Named Entity Recognition.", "example": "Convert the coordinate to text: [-4.5457 -3.1346]:"}
{"text": "Convert the coordinate to text: [-0.2859 -4.151 ]: The authors introduce a zero-shot framework that identifies and corrects factual errors in an input by formulating questions about it, searching for trustworthy answers in the evidence provided, and assessing the accuracy of each correction based on its consistency with said evidence.", "target": "The authors introduce a zero-shot framework that identifies and corrects factual errors in an input by formulating questions about it, searching for trustworthy answers in the evidence provided, and assessing the accuracy of each correction based on its consistency with said evidence.", "example": "Convert the coordinate to text: [-0.2859 -4.151 ]:"}
{"text": "Convert the coordinate to text: [ 1.0674 -9.564 ]: This paper tackles the more realistic problem of inference-time image-free UMMT, in which the model is trained with text-image pairs and tested solely with text. The authors propose a new mechanism using scene graphs (SG) to represent both text and images during training and a visual scene hallucination mechanism to generate pseudo-visual SG from text during inference.", "target": "This paper tackles the more realistic problem of inference-time image-free UMMT, in which the model is trained with text-image pairs and tested solely with text. The authors propose a new mechanism using scene graphs (SG) to represent both text and images during training and a visual scene hallucination mechanism to generate pseudo-visual SG from text during inference.", "example": "Convert the coordinate to text: [ 1.0674 -9.564 ]:"}
{"text": "Convert the coordinate to text: [-8.2476 -4.9375]: This study investigates if two pragmatic features (specificity and affect) systematically vary in different intergroup contexts, thus connecting this new framing of bias to language output.", "target": "This study investigates if two pragmatic features (specificity and affect) systematically vary in different intergroup contexts, thus connecting this new framing of bias to language output.", "example": "Convert the coordinate to text: [-8.2476 -4.9375]:"}
{"text": "Convert the coordinate to text: [ 2.2247 -4.1476]: The authors introduce a new CSKG completion framework, Contrastive Pretraining and Node Clustering (CPNC). CPNC utilizes contrastive learning for better semantic node representation and clusters nodes with the same concept into latent concepts.", "target": "The authors introduce a new CSKG completion framework, Contrastive Pretraining and Node Clustering (CPNC). CPNC utilizes contrastive learning for better semantic node representation and clusters nodes with the same concept into latent concepts.", "example": "Convert the coordinate to text: [ 2.2247 -4.1476]:"}
{"text": "Convert the coordinate to text: [-1.9065 -8.0342]: The paper proposes a model that consists of two encoders guided by CTC to predict the source and target texts respectively, aiming to integrate the advantages of end-to-end speech translation and non-autoregressive generation. To address the challenges presented, the authors develop a prediction-aware encoding approach and a cross-layer attention approach.", "target": "The paper proposes a model that consists of two encoders guided by CTC to predict the source and target texts respectively, aiming to integrate the advantages of end-to-end speech translation and non-autoregressive generation. To address the challenges presented, the authors develop a prediction-aware encoding approach and a cross-layer attention approach.", "example": "Convert the coordinate to text: [-1.9065 -8.0342]:"}
{"text": "Convert the coordinate to text: [3.075  0.2805]: The authors proposed an approach to predict the maximum achievable model performance based on a small amount of training samples, serving as an early indicator during data annotation for data quality and sample size determination.", "target": "The authors proposed an approach to predict the maximum achievable model performance based on a small amount of training samples, serving as an early indicator during data annotation for data quality and sample size determination.", "example": "Convert the coordinate to text: [3.075  0.2805]:"}
{"text": "Convert the coordinate to text: [-10.5891  -1.8794]: This research introduces a novel setup for code generation where under-specification of a natural language description is resolved by asking clarification questions. A new dataset, CodeClarQA, containing pairs of natural language descriptions and code with created synthetic clarification questions and answers is also introduced.", "target": "This research introduces a novel setup for code generation where under-specification of a natural language description is resolved by asking clarification questions. A new dataset, CodeClarQA, containing pairs of natural language descriptions and code with created synthetic clarification questions and answers is also introduced.", "example": "Convert the coordinate to text: [-10.5891  -1.8794]:"}
{"text": "Convert the coordinate to text: [-3.2012 -5.4271]: The authors propose an active learning pipeline for the Natural Language Understanding (NLU) component of a conversational agent, which helps in the offline detection of classification errors by leveraging two strong classifiers, and performs topic modeling on the potentially misclassified samples to facilitate data analysis and reveal error patterns.", "target": "The authors propose an active learning pipeline for the Natural Language Understanding (NLU) component of a conversational agent, which helps in the offline detection of classification errors by leveraging two strong classifiers, and performs topic modeling on the potentially misclassified samples to facilitate data analysis and reveal error patterns.", "example": "Convert the coordinate to text: [-3.2012 -5.4271]:"}
{"text": "Convert the coordinate to text: [-1.6331 -6.4257]: The authors propose a fine-tuned DeBERTa transformer-based classification approach to identify the desired human value category, by utilising different training strategies to enhance contextual representation for this downstream task.", "target": "The authors propose a fine-tuned DeBERTa transformer-based classification approach to identify the desired human value category, by utilising different training strategies to enhance contextual representation for this downstream task.", "example": "Convert the coordinate to text: [-1.6331 -6.4257]:"}
{"text": "Convert the coordinate to text: [-1.441  0.14 ]: In response to this challenge, the authors introduce a system for online sexism detection, utilising a fine-tuned RoBERTa model for this specific problem.", "target": "In response to this challenge, the authors introduce a system for online sexism detection, utilising a fine-tuned RoBERTa model for this specific problem.", "example": "Convert the coordinate to text: [-1.441  0.14 ]:"}
{"text": "Convert the coordinate to text: [-3.0412 -3.8484]: The authors propose a system based on binary classification for a given statement and its related clinical trial. The system uses a human-defined prompt to assemble the information found in the statement, section name, and clinical trials. The pre-trained language models are then fine-tuned based on the prompted input sentences to learn the inference relationship between the statement and clinical trial.", "target": "The authors propose a system based on binary classification for a given statement and its related clinical trial. The system uses a human-defined prompt to assemble the information found in the statement, section name, and clinical trials. The pre-trained language models are then fine-tuned based on the prompted input sentences to learn the inference relationship between the statement and clinical trial.", "example": "Convert the coordinate to text: [-3.0412 -3.8484]:"}
{"text": "Convert the coordinate to text: [ 3.5223 -4.0837]: The authors introduce a novel approach called adaptive contrastive knowledge distillation (ACKD) for BERT compression, which explicitly learns discriminative student features through a newly proposed contrastive distillation loss (CDL). They also propose a strategy called sample adaptive reweighting (SAR) to focus on hard samples with less discriminative features.", "target": "The authors introduce a novel approach called adaptive contrastive knowledge distillation (ACKD) for BERT compression, which explicitly learns discriminative student features through a newly proposed contrastive distillation loss (CDL). They also propose a strategy called sample adaptive reweighting (SAR) to focus on hard samples with less discriminative features.", "example": "Convert the coordinate to text: [ 3.5223 -4.0837]:"}
{"text": "Convert the coordinate to text: [-1.7215 -5.1097]: In response to the difficulties in manually extracting temporal information from discharge summaries, the researchers propose using state-of-the-art NLP methods: prompt-based learning on Generative Pre-trained Transformers (GPTs) and fine-tuning on pre-trained language models (PLMs) such as BERT to automatically and temporally classify treatment events.", "target": "In response to the difficulties in manually extracting temporal information from discharge summaries, the researchers propose using state-of-the-art NLP methods: prompt-based learning on Generative Pre-trained Transformers (GPTs) and fine-tuning on pre-trained language models (PLMs) such as BERT to automatically and temporally classify treatment events.", "example": "Convert the coordinate to text: [-1.7215 -5.1097]:"}
{"text": "Convert the coordinate to text: [-3.9742 -1.8515]: This paper proposes a novel joint extraction methodology called Token-Token Bidirectional Event Completed Graph (TT-BECG) that uses the relation eType-Role1-Role2 as the edge type, which determines which tokens act as argument roles in an event of a specific event type.", "target": "This paper proposes a novel joint extraction methodology called Token-Token Bidirectional Event Completed Graph (TT-BECG) that uses the relation eType-Role1-Role2 as the edge type, which determines which tokens act as argument roles in an event of a specific event type.", "example": "Convert the coordinate to text: [-3.9742 -1.8515]:"}
{"text": "Convert the coordinate to text: [-0.4829 -4.2246]: The paper introduces a less explored setting, Zero-shot Conversational Question Generation (ZeroCQG), which requires no human-labeled conversations for training, and proposes a multi-stage knowledge transfer framework, Synthesize, Prompt, and trAnsfer with pRe-Trained lAnguage model (SPARTA) to leverage knowledge from single-turn question generation instances.", "target": "The paper introduces a less explored setting, Zero-shot Conversational Question Generation (ZeroCQG), which requires no human-labeled conversations for training, and proposes a multi-stage knowledge transfer framework, Synthesize, Prompt, and trAnsfer with pRe-Trained lAnguage model (SPARTA) to leverage knowledge from single-turn question generation instances.", "example": "Convert the coordinate to text: [-0.4829 -4.2246]:"}
{"text": "Convert the coordinate to text: [ 8.4207 -3.0059]: The paper introduces a generalized Graph Information Bottleneck (GIB) form that includes a label-independent graph variable, equivalent to the vanilla GIB. It also proposes a graph mixup method called MixupExplainer, theoretically guaranteed to resolve the distribution shifting issue.", "target": "The paper introduces a generalized Graph Information Bottleneck (GIB) form that includes a label-independent graph variable, equivalent to the vanilla GIB. It also proposes a graph mixup method called MixupExplainer, theoretically guaranteed to resolve the distribution shifting issue.", "example": "Convert the coordinate to text: [ 8.4207 -3.0059]:"}
{"text": "Convert the coordinate to text: [-9.0546 -3.8383]: The paper introduces Nugget, a novel system that encodes language into a representation based on a dynamically selected subset of input tokens.", "target": "The paper introduces Nugget, a novel system that encodes language into a representation based on a dynamically selected subset of input tokens.", "example": "Convert the coordinate to text: [-9.0546 -3.8383]:"}
{"text": "Convert the coordinate to text: [8.9482 5.6911]: The authors conduct an error analysis to demonstrate how to reduce both bias and variance in error terms, and propose a new estimator called Quantiled Expansion Mean (QEM) and a new DRL algorithm, QEMRL, from the statistical perspective.", "target": "The authors conduct an error analysis to demonstrate how to reduce both bias and variance in error terms, and propose a new estimator called Quantiled Expansion Mean (QEM) and a new DRL algorithm, QEMRL, from the statistical perspective.", "example": "Convert the coordinate to text: [8.9482 5.6911]:"}
{"text": "Convert the coordinate to text: [12.0359 -2.8762]: The researchers conducted the first robustness analysis of Neuron Explanation Methods under a unified pipeline, revealing that these explanations can be significantly corrupted by random noises and well-designed perturbations added to their probing data.", "target": "The researchers conducted the first robustness analysis of Neuron Explanation Methods under a unified pipeline, revealing that these explanations can be significantly corrupted by random noises and well-designed perturbations added to their probing data.", "example": "Convert the coordinate to text: [12.0359 -2.8762]:"}
{"text": "Convert the coordinate to text: [15.5618 -0.0392]: A lifelong quantization process, LifeQuant, is proposed to address the forgetting catastrophe problem in quantization-aware training, through minimizing the space shift during quantization with a methodology called Proximal Quantization Space Search (ProxQ) and the use of replay data during the retraining on new tasks.", "target": "A lifelong quantization process, LifeQuant, is proposed to address the forgetting catastrophe problem in quantization-aware training, through minimizing the space shift during quantization with a methodology called Proximal Quantization Space Search (ProxQ) and the use of replay data during the retraining on new tasks.", "example": "Convert the coordinate to text: [15.5618 -0.0392]:"}
{"text": "Convert the coordinate to text: [ 8.8349 -3.7006]: A learning algorithm called Feedback-Feedforward Alignment (FFA) is proposed, which attempts to co-optimize the feedforward and feedback pathways, each optimizing its own objectives. This algorithm manages to repurpose the computational graph of credit assignment into a goal-driven feedback pathway, enhancing its bio-plausibility.", "target": "A learning algorithm called Feedback-Feedforward Alignment (FFA) is proposed, which attempts to co-optimize the feedforward and feedback pathways, each optimizing its own objectives. This algorithm manages to repurpose the computational graph of credit assignment into a goal-driven feedback pathway, enhancing its bio-plausibility.", "example": "Convert the coordinate to text: [ 8.8349 -3.7006]:"}
{"text": "Convert the coordinate to text: [ 4.7125 -5.4563]: This paper questions the need for complete subgraph enumeration and proposes the idea that a model can achieve similar levels of expressivity by considering only a subset of the subgraphs. It then introduces the Magnetic Graph Neural Network (MAG-GNN), a GNN that uses reinforcement learning (RL) to identify the optimal subset of subgraphs.", "target": "This paper questions the need for complete subgraph enumeration and proposes the idea that a model can achieve similar levels of expressivity by considering only a subset of the subgraphs. It then introduces the Magnetic Graph Neural Network (MAG-GNN), a GNN that uses reinforcement learning (RL) to identify the optimal subset of subgraphs.", "example": "Convert the coordinate to text: [ 4.7125 -5.4563]:"}
{"text": "Convert the coordinate to text: [ 4.6869 -3.08  ]: The authors propose Dataset-Aware Mixture-of-Experts (DAMEX), where they train the experts to become an 'expert' of a dataset by learning to route each dataset tokens to its mapped expert.", "target": "The authors propose Dataset-Aware Mixture-of-Experts (DAMEX), where they train the experts to become an 'expert' of a dataset by learning to route each dataset tokens to its mapped expert.", "example": "Convert the coordinate to text: [ 4.6869 -3.08  ]:"}
{"text": "Convert the coordinate to text: [ 6.0254 12.8424]: The authors introduce COMPASS, an RL approach that parameterizes a distribution of diverse and specialized policies based on a continuous latent space, with the intuition to anticipate performant search at inference time during pre-training.", "target": "The authors introduce COMPASS, an RL approach that parameterizes a distribution of diverse and specialized policies based on a continuous latent space, with the intuition to anticipate performant search at inference time during pre-training.", "example": "Convert the coordinate to text: [ 6.0254 12.8424]:"}
{"text": "Convert the coordinate to text: [-7.5559  1.7299]: This study identifies an overlooked issue in previous ULTR methods where the bias tower can confuse the relevance tower due to underlying true relevance. The authors propose three methods to better disentangle relevance and bias in learning to rank systems.", "target": "This study identifies an overlooked issue in previous ULTR methods where the bias tower can confuse the relevance tower due to underlying true relevance. The authors propose three methods to better disentangle relevance and bias in learning to rank systems.", "example": "Convert the coordinate to text: [-7.5559  1.7299]:"}
{"text": "Convert the coordinate to text: [-12.7037   6.2792]: The authors propose the use of computational notebooks as co-design tools to facilitate engagement between machine learning models and end user groups, with the application focusing on predicting health risk in diabetes care.", "target": "The authors propose the use of computational notebooks as co-design tools to facilitate engagement between machine learning models and end user groups, with the application focusing on predicting health risk in diabetes care.", "example": "Convert the coordinate to text: [-12.7037   6.2792]:"}
{"text": "Convert the coordinate to text: [ 6.3366 -3.488 ]: The paper proposes lightweight strategies for domain adaptation of LLMs specifically for RRS, with approaches including pretraining and prompting variations, and parameter-efficient fine-tuning methods such as prefix tuning and LoRA.", "target": "The paper proposes lightweight strategies for domain adaptation of LLMs specifically for RRS, with approaches including pretraining and prompting variations, and parameter-efficient fine-tuning methods such as prefix tuning and LoRA.", "example": "Convert the coordinate to text: [ 6.3366 -3.488 ]:"}
{"text": "Convert the coordinate to text: [-10.4016  14.3641]: The authors use emerging technologies such as Augmented Reality and gamified learning to design HeritageSite AR, an exploration game for onsite cultural heritage learning and visits, applied to Relics of Arhat Monastery and Twin Pagoda.", "target": "The authors use emerging technologies such as Augmented Reality and gamified learning to design HeritageSite AR, an exploration game for onsite cultural heritage learning and visits, applied to Relics of Arhat Monastery and Twin Pagoda.", "example": "Convert the coordinate to text: [-10.4016  14.3641]:"}
{"text": "Convert the coordinate to text: [-2.1574 -8.4536]: The authors propose a new multi-modal masked language model called Masked Audio Text Encoder (MATE) for rescoring in ASR systems, which incorporates acoustic representations into the input space of MLM and uses contrastive learning to align the modalities.", "target": "The authors propose a new multi-modal masked language model called Masked Audio Text Encoder (MATE) for rescoring in ASR systems, which incorporates acoustic representations into the input space of MLM and uses contrastive learning to align the modalities.", "example": "Convert the coordinate to text: [-2.1574 -8.4536]:"}
{"text": "Convert the coordinate to text: [-2.0464  2.5715]: The authors propose a Ranker-Generator framework that learns to rank the utterances by comparing them in pairs and learning from the global orders, then uses the top-ranked utterances as the generator's input.", "target": "The authors propose a Ranker-Generator framework that learns to rank the utterances by comparing them in pairs and learning from the global orders, then uses the top-ranked utterances as the generator's input.", "example": "Convert the coordinate to text: [-2.0464  2.5715]:"}
{"text": "Convert the coordinate to text: [12.7196 11.3985]: The paper presents a new approach for explaining GPs, built upon the concept of Shapley values extended to stochastic cooperative games. The approach produces explanations that are random variables and comes with a tractable covariance function.", "target": "The paper presents a new approach for explaining GPs, built upon the concept of Shapley values extended to stochastic cooperative games. The approach produces explanations that are random variables and comes with a tractable covariance function.", "example": "Convert the coordinate to text: [12.7196 11.3985]:"}
{"text": "Convert the coordinate to text: [ 8.2999 -0.4832]: The authors propose DotHash, an unbiased estimator for the intersection size of two sets that can be used to estimate the Jaccard index and as the first method that can also estimate the Adamic-Adar index and a family of related metrics.", "target": "The authors propose DotHash, an unbiased estimator for the intersection size of two sets that can be used to estimate the Jaccard index and as the first method that can also estimate the Adamic-Adar index and a family of related metrics.", "example": "Convert the coordinate to text: [ 8.2999 -0.4832]:"}
{"text": "Convert the coordinate to text: [ 5.6541 -3.4868]: This paper presents MM-DAG, a mechanism to learn multiple DAGs jointly in a multi-task, multi-modal setting. A multi-modal regression for linear causal relationship description of different variables and a new Causality Difference (CD) measure is introduced.", "target": "This paper presents MM-DAG, a mechanism to learn multiple DAGs jointly in a multi-task, multi-modal setting. A multi-modal regression for linear causal relationship description of different variables and a new Causality Difference (CD) measure is introduced.", "example": "Convert the coordinate to text: [ 5.6541 -3.4868]:"}
{"text": "Convert the coordinate to text: [-5.4993 10.3983]: This paper proposes the Knowledge-Augmented Dialogue System (KADS), a data-efficient dialogue system that leverages explicit instructions derived from agent guidelines such as company policies or customer service manuals.", "target": "This paper proposes the Knowledge-Augmented Dialogue System (KADS), a data-efficient dialogue system that leverages explicit instructions derived from agent guidelines such as company policies or customer service manuals.", "example": "Convert the coordinate to text: [-5.4993 10.3983]:"}
{"text": "Convert the coordinate to text: [-8.5582 -6.1358]: The authors propose an information-theoretical model of syntactic generalization that can separate the probability distribution of a corpus into distinct components for semantic context and structure, with the structure being independent from the semantic context. They develop the concept of abstraction via a relaxation of the independence property and implement it as an optimization objective.", "target": "The authors propose an information-theoretical model of syntactic generalization that can separate the probability distribution of a corpus into distinct components for semantic context and structure, with the structure being independent from the semantic context. They develop the concept of abstraction via a relaxation of the independence property and implement it as an optimization objective.", "example": "Convert the coordinate to text: [-8.5582 -6.1358]:"}
{"text": "Convert the coordinate to text: [ 0.2256 -9.3559]: Several text augmentation techniques like prompting, WordNet synonyms, and text generation are proposed to reduce word ambiguity and enhance image selection.", "target": "Several text augmentation techniques like prompting, WordNet synonyms, and text generation are proposed to reduce word ambiguity and enhance image selection.", "example": "Convert the coordinate to text: [ 0.2256 -9.3559]:"}
{"text": "Convert the coordinate to text: [18.5341 -3.1847]: The authors propose and compare two transfer learning techniques - standard fine-tuning and prompting - for creating a machine learning classifier to identify the type of spoiler needed to neutralize clickbait posts.", "target": "The authors propose and compare two transfer learning techniques - standard fine-tuning and prompting - for creating a machine learning classifier to identify the type of spoiler needed to neutralize clickbait posts.", "example": "Convert the coordinate to text: [18.5341 -3.1847]:"}
{"text": "Convert the coordinate to text: [-1.4466  0.1196]: The authors propose a three-step approach for the SemEval-2023 Task 10 Explainable Detection of Online Sexism (EDOS) using lexicon-based models. The steps include lexicon construction based on Pointwise Mutual Information (PMI) and Shapley value, lexicon augmentation using an unannotated corpus and Large Language Models (LLMs), and lexical incorporation for Bag-of-Word (BoW) logistic regression and fine-tuning LLMs.", "target": "The authors propose a three-step approach for the SemEval-2023 Task 10 Explainable Detection of Online Sexism (EDOS) using lexicon-based models. The steps include lexicon construction based on Pointwise Mutual Information (PMI) and Shapley value, lexicon augmentation using an unannotated corpus and Large Language Models (LLMs), and lexical incorporation for Bag-of-Word (BoW) logistic regression and fine-tuning LLMs.", "example": "Convert the coordinate to text: [-1.4466  0.1196]:"}
{"text": "Convert the coordinate to text: [-2.2267 -5.965 ]: The authors propose to fine-tune pretrained PRIMERA models independently to generate technical abstracts and lay summaries of biomedical articles.", "target": "The authors propose to fine-tune pretrained PRIMERA models independently to generate technical abstracts and lay summaries of biomedical articles.", "example": "Convert the coordinate to text: [-2.2267 -5.965 ]:"}
{"text": "Convert the coordinate to text: [-9.9278 -1.7518]: The authors propose the Query Adaptive Anchor Representation (QAAR) model for inductive relation prediction. The model defines query adaptive anchors, independent of any specific entity, and uses transferable entity-independent features to produce entity embeddings for emerging unseen entities.", "target": "The authors propose the Query Adaptive Anchor Representation (QAAR) model for inductive relation prediction. The model defines query adaptive anchors, independent of any specific entity, and uses transferable entity-independent features to produce entity embeddings for emerging unseen entities.", "example": "Convert the coordinate to text: [-9.9278 -1.7518]:"}
{"text": "Convert the coordinate to text: [-8.7258 -2.2849]: The authors provide a focused review of human evaluation experiments reported in NLP papers over the past five years, assessed for their ability to be rerun. They also consider the reproducibility of human evaluations where those are repeatable in the first place.", "target": "The authors provide a focused review of human evaluation experiments reported in NLP papers over the past five years, assessed for their ability to be rerun. They also consider the reproducibility of human evaluations where those are repeatable in the first place.", "example": "Convert the coordinate to text: [-8.7258 -2.2849]:"}
{"text": "Convert the coordinate to text: [-8.1764  1.6867]: This paper explores a real-world zero-shot text search case for information seeking within scientific papers, and discusses the potential misalignment between single-metric performance evaluation and the subjectivity of relevancy in fulfilling a user's needs.", "target": "This paper explores a real-world zero-shot text search case for information seeking within scientific papers, and discusses the potential misalignment between single-metric performance evaluation and the subjectivity of relevancy in fulfilling a user's needs.", "example": "Convert the coordinate to text: [-8.1764  1.6867]:"}
{"text": "Convert the coordinate to text: [ 2.3289 -3.983 ]: The authors propose a novel approach to VLP called Semantic Awared Contrastive Learning (SACL), where different negative samples are assigned different contrastive weights based on their semantic similarity with the anchor sample.", "target": "The authors propose a novel approach to VLP called Semantic Awared Contrastive Learning (SACL), where different negative samples are assigned different contrastive weights based on their semantic similarity with the anchor sample.", "example": "Convert the coordinate to text: [ 2.3289 -3.983 ]:"}
{"text": "Convert the coordinate to text: [ 5.5012 -9.166 ]: The paper introduces Temporally Consistent Transformer (TECO), a generative model that aims to improve long-term consistency and reduce sampling time in video generation. It also presents three challenging video datasets with long-range dependencies for the purpose of benchmarking.", "target": "The paper introduces Temporally Consistent Transformer (TECO), a generative model that aims to improve long-term consistency and reduce sampling time in video generation. It also presents three challenging video datasets with long-range dependencies for the purpose of benchmarking.", "example": "Convert the coordinate to text: [ 5.5012 -9.166 ]:"}
{"text": "Convert the coordinate to text: [ 9.5052 -2.0415]: The authors propose Bucks for Buckets (B4B), an active defense that prevents model stealing of encoders during the attack without compromising the representation quality for legitimate API users. The B4B mechanism adjusts the utility of returned representations depending on a user's coverage of the embedding space.", "target": "The authors propose Bucks for Buckets (B4B), an active defense that prevents model stealing of encoders during the attack without compromising the representation quality for legitimate API users. The B4B mechanism adjusts the utility of returned representations depending on a user's coverage of the embedding space.", "example": "Convert the coordinate to text: [ 9.5052 -2.0415]:"}
{"text": "Convert the coordinate to text: [  7.5519 -21.169 ]: This paper proposes a learning-based illumination planning method that jointly considers these factors via integrating a neural network and a generalized image formation model. The illumination planning is formulated with reinforcement learning to explore the light space in a photometric stereo-aware and reward-driven manner.", "target": "This paper proposes a learning-based illumination planning method that jointly considers these factors via integrating a neural network and a generalized image formation model. The illumination planning is formulated with reinforcement learning to explore the light space in a photometric stereo-aware and reward-driven manner.", "example": "Convert the coordinate to text: [  7.5519 -21.169 ]:"}
{"text": "Convert the coordinate to text: [7.6678 9.0565]: The paper proposes a novel robust Bayesian Optimization algorithm, AIRBO, which can effectively identify a robust optimum that performs consistently well under arbitrary input uncertainty.", "target": "The paper proposes a novel robust Bayesian Optimization algorithm, AIRBO, which can effectively identify a robust optimum that performs consistently well under arbitrary input uncertainty.", "example": "Convert the coordinate to text: [7.6678 9.0565]:"}
{"text": "Convert the coordinate to text: [ 4.9838 -4.5889]: The authors propose a new setting for learning a deep GGM from aggregate graph statistics. They develop an architecture for training a deep GGM to match these statistics while preserving local differential privacy guarantees.", "target": "The authors propose a new setting for learning a deep GGM from aggregate graph statistics. They develop an architecture for training a deep GGM to match these statistics while preserving local differential privacy guarantees.", "example": "Convert the coordinate to text: [ 4.9838 -4.5889]:"}
{"text": "Convert the coordinate to text: [14.5661  5.1066]: The authors establish a connection between slot attention and optimal transport. From this perspective, they propose MESH (Minimize Entropy of Sinkhorn), a cross-attention module that blends the tie-breaking properties of unregularized optimal transport with the speed of regularized optimal transport.", "target": "The authors establish a connection between slot attention and optimal transport. From this perspective, they propose MESH (Minimize Entropy of Sinkhorn), a cross-attention module that blends the tie-breaking properties of unregularized optimal transport with the speed of regularized optimal transport.", "example": "Convert the coordinate to text: [14.5661  5.1066]:"}
{"text": "Convert the coordinate to text: [ 2.0296 -9.4518]: The authors propose a novel task graph generation approach that combines the reasoning capabilities of instruction-tuned language models with clustering and ranking components, with the aim of accurately identifying key steps and their dependencies in a completely unsupervised manner from instructional video text transcripts.", "target": "The authors propose a novel task graph generation approach that combines the reasoning capabilities of instruction-tuned language models with clustering and ranking components, with the aim of accurately identifying key steps and their dependencies in a completely unsupervised manner from instructional video text transcripts.", "example": "Convert the coordinate to text: [ 2.0296 -9.4518]:"}
{"text": "Convert the coordinate to text: [ 0.6052 -0.2836]: The authors introduce disco, an open-source Python library designed to facilitate the widespread use of distributional control techniques in language models and other generative models.", "target": "The authors introduce disco, an open-source Python library designed to facilitate the widespread use of distributional control techniques in language models and other generative models.", "example": "Convert the coordinate to text: [ 0.6052 -0.2836]:"}
{"text": "Convert the coordinate to text: [-5.0386 -3.9818]: The authors propose CaML, an algorithm that automates EIO-LCA using semantic text similarity matching. It leverages the text descriptions of the product and the industry sector. The algorithm then uses a pre-trained sentence transformer model to rank potential industry sector matches for a product.", "target": "The authors propose CaML, an algorithm that automates EIO-LCA using semantic text similarity matching. It leverages the text descriptions of the product and the industry sector. The algorithm then uses a pre-trained sentence transformer model to rank potential industry sector matches for a product.", "example": "Convert the coordinate to text: [-5.0386 -3.9818]:"}
{"text": "Convert the coordinate to text: [-7.6301 -4.1875]: The study presents an investigation on how larger language models performance in interpreting metaphoric sentences is enhanced when the action of the metaphorical sentence is more embodied.", "target": "The study presents an investigation on how larger language models performance in interpreting metaphoric sentences is enhanced when the action of the metaphorical sentence is more embodied.", "example": "Convert the coordinate to text: [-7.6301 -4.1875]:"}
{"text": "Convert the coordinate to text: [-5.7596 10.2798]: This paper introduces TITAN, a multi-domain task-oriented dialogue dataset constructed from the MultiWOZ 2.1 corpus that incorporates mixed-initiative strategies, where the agent can either ask clarification questions actively or provide relevant information to address failure situations and implicit user requests.", "target": "This paper introduces TITAN, a multi-domain task-oriented dialogue dataset constructed from the MultiWOZ 2.1 corpus that incorporates mixed-initiative strategies, where the agent can either ask clarification questions actively or provide relevant information to address failure situations and implicit user requests.", "example": "Convert the coordinate to text: [-5.7596 10.2798]:"}
{"text": "Convert the coordinate to text: [-1.1086 -5.1279]: The authors propose a new approach using prompt-tuning to control the extraction rates of memorized content in LLMs, and present two prompt training strategies to respectively increase and decrease these extraction rates.", "target": "The authors propose a new approach using prompt-tuning to control the extraction rates of memorized content in LLMs, and present two prompt training strategies to respectively increase and decrease these extraction rates.", "example": "Convert the coordinate to text: [-1.1086 -5.1279]:"}
{"text": "Convert the coordinate to text: [-1.0736 -4.4431]: The authors propose a model-agnostic framework, the ORder Insensitive Generation (ORIG), which aims to make models more robust to different persona orders and improve the consistency of response generation.", "target": "The authors propose a model-agnostic framework, the ORder Insensitive Generation (ORIG), which aims to make models more robust to different persona orders and improve the consistency of response generation.", "example": "Convert the coordinate to text: [-1.0736 -4.4431]:"}
{"text": "Convert the coordinate to text: [13.2684 -0.4298]: The study presents an alternative framework designed to preserve invariant measures of chaotic attractors that characterize the time-invariant statistical properties of the dynamics. It introduces two novel approaches to training with noisy data, a loss based on the optimal transport distance between the observed dynamics and the neural operator outputs, and a contrastive learning framework.", "target": "The study presents an alternative framework designed to preserve invariant measures of chaotic attractors that characterize the time-invariant statistical properties of the dynamics. It introduces two novel approaches to training with noisy data, a loss based on the optimal transport distance between the observed dynamics and the neural operator outputs, and a contrastive learning framework.", "example": "Convert the coordinate to text: [13.2684 -0.4298]:"}
{"text": "Convert the coordinate to text: [-6.1933 11.901 ]: The study introduces the Cultural Codes dataset, which helps operationalize sociocultural pragmatic inference in a simple word reference game. This is achieved by using Codenames Duet, a multi-turn collaborative two-player game and associating it with players' backgrounds.", "target": "The study introduces the Cultural Codes dataset, which helps operationalize sociocultural pragmatic inference in a simple word reference game. This is achieved by using Codenames Duet, a multi-turn collaborative two-player game and associating it with players' backgrounds.", "example": "Convert the coordinate to text: [-6.1933 11.901 ]:"}
{"text": "Convert the coordinate to text: [-5.2365 -2.7091]: This study approaches quotation attribution in a new way, treating it as four interconnected sub-tasks: character identification, coreference resolution, quotation identification, and speaker attribution.", "target": "This study approaches quotation attribution in a new way, treating it as four interconnected sub-tasks: character identification, coreference resolution, quotation identification, and speaker attribution.", "example": "Convert the coordinate to text: [-5.2365 -2.7091]:"}
{"text": "Convert the coordinate to text: [18.538  -3.1856]: Task 5 at SemEval 2023, also known as the second PAN Clickbait Challenge, aims to support users by automatically generating short spoilers for clickbait posts.", "target": "Task 5 at SemEval 2023, also known as the second PAN Clickbait Challenge, aims to support users by automatically generating short spoilers for clickbait posts.", "example": "Convert the coordinate to text: [18.538  -3.1856]:"}
{"text": "Convert the coordinate to text: [ 5.8421 -0.3892]: The authors propose Exponential Penalty Mean Squared Loss (EPM) to enhance the learning ability of difficult samples during the training process, and they apply frozen Tuning and contrastive learning based on Language for fine-tuning and model ensemble.", "target": "The authors propose Exponential Penalty Mean Squared Loss (EPM) to enhance the learning ability of difficult samples during the training process, and they apply frozen Tuning and contrastive learning based on Language for fine-tuning and model ensemble.", "example": "Convert the coordinate to text: [ 5.8421 -0.3892]:"}
{"text": "Convert the coordinate to text: [14.0543  0.181 ]: The authors propose DEQNAR, a method to directly solve for the equilibrium state of NAR models leveraging deep equilibrium networks and black-box root-finding solvers, with back-propagation through the equilibrium point via implicit differentiation with constant memory.", "target": "The authors propose DEQNAR, a method to directly solve for the equilibrium state of NAR models leveraging deep equilibrium networks and black-box root-finding solvers, with back-propagation through the equilibrium point via implicit differentiation with constant memory.", "example": "Convert the coordinate to text: [14.0543  0.181 ]:"}
{"text": "Convert the coordinate to text: [-4.6106  0.5156]: The authors propose a model named Disentangled Opinion Clustering (DOC) for vaccination opinion mining from social media. The DOC model, using disentangling attention mechanisms and a Swapping-Autoencoder, discerns users' stances from opinions and is designed to handle unseen aspect categories via a clustering approach, leveraging Sentence-BERT encodings.", "target": "The authors propose a model named Disentangled Opinion Clustering (DOC) for vaccination opinion mining from social media. The DOC model, using disentangling attention mechanisms and a Swapping-Autoencoder, discerns users' stances from opinions and is designed to handle unseen aspect categories via a clustering approach, leveraging Sentence-BERT encodings.", "example": "Convert the coordinate to text: [-4.6106  0.5156]:"}
{"text": "Convert the coordinate to text: [-0.8608 -4.1531]: This study explores various forms of indirect supervision for NLP, including supervision from a related task, sparsely occurring or incidental signals, and multi-modal supervision.", "target": "This study explores various forms of indirect supervision for NLP, including supervision from a related task, sparsely occurring or incidental signals, and multi-modal supervision.", "example": "Convert the coordinate to text: [-0.8608 -4.1531]:"}
{"text": "Convert the coordinate to text: [-1.0121 -3.1836]: To address these limitations, the authors propose a novel method for TKG reasoning, named Latent relations Learning for TKG (L2TKG), which utilizes a Structural Encoder (SE) to create representations of entities at each timestamp, and a Latent Relations Learning (LRL) module to discover and exploit the intra- and inter-time latent relations.", "target": "To address these limitations, the authors propose a novel method for TKG reasoning, named Latent relations Learning for TKG (L2TKG), which utilizes a Structural Encoder (SE) to create representations of entities at each timestamp, and a Latent Relations Learning (LRL) module to discover and exploit the intra- and inter-time latent relations.", "example": "Convert the coordinate to text: [-1.0121 -3.1836]:"}
{"text": "Convert the coordinate to text: [ 0.447  -9.2284]: The authors propose MultiCapCLIP, a zero-shot approach that can generate visual captions for different scenarios and languages without needing any labeled vision-caption pairs of downstream datasets. The model only requires text data for input and conducts two main steps: retrieving concept prompts and auto-encoding the prompts to output captions in a desired language.", "target": "The authors propose MultiCapCLIP, a zero-shot approach that can generate visual captions for different scenarios and languages without needing any labeled vision-caption pairs of downstream datasets. The model only requires text data for input and conducts two main steps: retrieving concept prompts and auto-encoding the prompts to output captions in a desired language.", "example": "Convert the coordinate to text: [ 0.447  -9.2284]:"}
{"text": "Convert the coordinate to text: [-1.1312 -5.2665]: The authors propose a novel method for selecting suitable prompt templates in zero-shot text classification, called Perplexity Selection (Perplection). The proposed approach hypothesizes that language discrepancy can be used as a measure for the effectiveness of prompt templates.", "target": "The authors propose a novel method for selecting suitable prompt templates in zero-shot text classification, called Perplexity Selection (Perplection). The proposed approach hypothesizes that language discrepancy can be used as a measure for the effectiveness of prompt templates.", "example": "Convert the coordinate to text: [-1.1312 -5.2665]:"}
{"text": "Convert the coordinate to text: [-16.4391   2.0772]: The paper introduces Taurus MM, a shared-storage multi-master database optimized for cloud environments, featuring two novel algorithms aimed at reducing network traffic and several additional optimizations.", "target": "The paper introduces Taurus MM, a shared-storage multi-master database optimized for cloud environments, featuring two novel algorithms aimed at reducing network traffic and several additional optimizations.", "example": "Convert the coordinate to text: [-16.4391   2.0772]:"}
{"text": "Convert the coordinate to text: [-9.5899  9.9337]: The authors elaborate on the utility of shared tasks as a means to combine research and teaching, capitalizing on students' interdisciplinary skills, promoting teamwork, and engaging them in creative work that can produce original research contributions.", "target": "The authors elaborate on the utility of shared tasks as a means to combine research and teaching, capitalizing on students' interdisciplinary skills, promoting teamwork, and engaging them in creative work that can produce original research contributions.", "example": "Convert the coordinate to text: [-9.5899  9.9337]:"}
{"text": "Convert the coordinate to text: [-0.9623 -5.3302]: The study explores if prompt-tuning - a method that protects pre-trained weights and learns task-specific embeddings - can generate representations that better account for the brain's language representations than fine-tuning.", "target": "The study explores if prompt-tuning - a method that protects pre-trained weights and learns task-specific embeddings - can generate representations that better account for the brain's language representations than fine-tuning.", "example": "Convert the coordinate to text: [-0.9623 -5.3302]:"}
{"text": "Convert the coordinate to text: [-0.8571 -9.2844]: The researchers propose a method that uses multi-modal features extracted by various pre-trained models. These models are combined to capture effective emotion information and includes the use of MAE encoder pre-trained with a large-scale face dataset.", "target": "The researchers propose a method that uses multi-modal features extracted by various pre-trained models. These models are combined to capture effective emotion information and includes the use of MAE encoder pre-trained with a large-scale face dataset.", "example": "Convert the coordinate to text: [-0.8571 -9.2844]:"}
{"text": "Convert the coordinate to text: [ 7.0766 -0.3922]: The paper introduces a new method, Self-Expanded Equalization (SEE), designed to generalize the DML model to both unseen categories and domains. This is achieved through a 'min-max' strategy combined with a proxy-based loss providing diverse out-of-distribution samples.", "target": "The paper introduces a new method, Self-Expanded Equalization (SEE), designed to generalize the DML model to both unseen categories and domains. This is achieved through a 'min-max' strategy combined with a proxy-based loss providing diverse out-of-distribution samples.", "example": "Convert the coordinate to text: [ 7.0766 -0.3922]:"}
{"text": "Convert the coordinate to text: [  6.8361 -13.0545]: The authors propose a novel approach, CoDet, that reformulates region-word alignment as a co-occurring object discovery problem. It doesn't rely on pre-aligned vision-language space but rather uses visual similarities to discover co-occurring objects and align them with the shared concept.", "target": "The authors propose a novel approach, CoDet, that reformulates region-word alignment as a co-occurring object discovery problem. It doesn't rely on pre-aligned vision-language space but rather uses visual similarities to discover co-occurring objects and align them with the shared concept.", "example": "Convert the coordinate to text: [  6.8361 -13.0545]:"}
{"text": "Convert the coordinate to text: [-0.5434 -6.0285]: The authors propose Adacom, a novel approach for on-the-fly model adaptation which aims to improve the performance of comment generators. The approach is designed to detect if the model might have compromised performance on a target code and adapt the model on the fly by re-training the helpful samples and unlearning the harmful ones.", "target": "The authors propose Adacom, a novel approach for on-the-fly model adaptation which aims to improve the performance of comment generators. The approach is designed to detect if the model might have compromised performance on a target code and adapt the model on the fly by re-training the helpful samples and unlearning the harmful ones.", "example": "Convert the coordinate to text: [-0.5434 -6.0285]:"}
{"text": "Convert the coordinate to text: [ 6.7237 13.5472]: The paper introduces Representation Distinction (RD), a strategy to improve offline RL algorithm performance by distinguishing between the representations of in-sample and out-of-distribution (OOD) state-action pairs generated by the learning policy.", "target": "The paper introduces Representation Distinction (RD), a strategy to improve offline RL algorithm performance by distinguishing between the representations of in-sample and out-of-distribution (OOD) state-action pairs generated by the learning policy.", "example": "Convert the coordinate to text: [ 6.7237 13.5472]:"}
{"text": "Convert the coordinate to text: [-0.999  -5.1773]: The authors propose SwapPrompt, a framework that leverages self-supervised contrastive learning for test-time prompt adaptation. SwapPrompt uses dual prompts with an online prompt and target prompt, retaining historical information, and applies a swapped prediction mechanism to enhance the online prompt through contrastive learning.", "target": "The authors propose SwapPrompt, a framework that leverages self-supervised contrastive learning for test-time prompt adaptation. SwapPrompt uses dual prompts with an online prompt and target prompt, retaining historical information, and applies a swapped prediction mechanism to enhance the online prompt through contrastive learning.", "example": "Convert the coordinate to text: [-0.999  -5.1773]:"}
{"text": "Convert the coordinate to text: [ 8.5198 -7.8289]: The authors introduce a new Lightweight, Efficient and eXplainable-by-design convolutional neural network (LEXNet) for Internet traffic classification. This relies on a new residual block for lightness and efficiency, and a prototype layer for explainability.", "target": "The authors introduce a new Lightweight, Efficient and eXplainable-by-design convolutional neural network (LEXNet) for Internet traffic classification. This relies on a new residual block for lightness and efficiency, and a prototype layer for explainability.", "example": "Convert the coordinate to text: [ 8.5198 -7.8289]:"}
{"text": "Convert the coordinate to text: [-10.4698  14.9466]: The authors introduce AutomataStage, an Augmented Reality (AR) mediated creativity support tool for hands-on multidisciplinary learning that uses a video see-through interface to facilitate the creation of Interactive Automata.", "target": "The authors introduce AutomataStage, an Augmented Reality (AR) mediated creativity support tool for hands-on multidisciplinary learning that uses a video see-through interface to facilitate the creation of Interactive Automata.", "example": "Convert the coordinate to text: [-10.4698  14.9466]:"}
{"text": "Convert the coordinate to text: [-4.4639 -8.4781]: The authors propose a new paradigm called 'subword segmental machine translation (SSMT)', which unifies subword segmentation and machine translation in a single trainable model. The model learns to segment target sentence words and generate target sentences simultaneously.", "target": "The authors propose a new paradigm called 'subword segmental machine translation (SSMT)', which unifies subword segmentation and machine translation in a single trainable model. The model learns to segment target sentence words and generate target sentences simultaneously.", "example": "Convert the coordinate to text: [-4.4639 -8.4781]:"}
{"text": "Convert the coordinate to text: [-3.2732 -2.942 ]: The paper proposes Multi-grained Knowledge Retriever (MAKER), a system that decouples knowledge retrieval from response generation. MAKER includes an entity selector for searching relevant entities and an attribute selector for filtering out irrelevant attributes.", "target": "The paper proposes Multi-grained Knowledge Retriever (MAKER), a system that decouples knowledge retrieval from response generation. MAKER includes an entity selector for searching relevant entities and an attribute selector for filtering out irrelevant attributes.", "example": "Convert the coordinate to text: [-3.2732 -2.942 ]:"}
{"text": "Convert the coordinate to text: [-0.9306 -5.0441]: Instead of using multiple prompts for ensembling as in ConnPrompt, the authors propose designing auxiliary tasks and using task enlightenment prompt learning for IDRR, resulting in a model called TEPrompt, which fuses learned features from three related tasks for IDRR.", "target": "Instead of using multiple prompts for ensembling as in ConnPrompt, the authors propose designing auxiliary tasks and using task enlightenment prompt learning for IDRR, resulting in a model called TEPrompt, which fuses learned features from three related tasks for IDRR.", "example": "Convert the coordinate to text: [-0.9306 -5.0441]:"}
{"text": "Convert the coordinate to text: [-2.356  0.188]: The authors propose SeeGULL, a broad-coverage stereotype dataset, constructed using the generative capabilities of large language models such as PaLM and GPT-3. The validation of these stereotypes is performed by a globally diverse pool of raters.", "target": "The authors propose SeeGULL, a broad-coverage stereotype dataset, constructed using the generative capabilities of large language models such as PaLM and GPT-3. The validation of these stereotypes is performed by a globally diverse pool of raters.", "example": "Convert the coordinate to text: [-2.356  0.188]:"}
{"text": "Convert the coordinate to text: [-4.2668 -8.7056]: The authors propose Differentiable Segmentation (DiSeg) for SimulST, which directly learns segmentation from the translation model. DiSeg turns hard segmentation into differentiable forms through expectation training, enabling it to be jointly trained with the translation model to learn translation-beneficial segmentation.", "target": "The authors propose Differentiable Segmentation (DiSeg) for SimulST, which directly learns segmentation from the translation model. DiSeg turns hard segmentation into differentiable forms through expectation training, enabling it to be jointly trained with the translation model to learn translation-beneficial segmentation.", "example": "Convert the coordinate to text: [-4.2668 -8.7056]:"}
{"text": "Convert the coordinate to text: [ -1.5572 -13.0738]: A novel learning-based automatic evaluation metric (CMN) is proposed, which robustly evaluates open-domain dialogues by combining a Conditional Variational Autoencoders (CVAEs), a Next Sentence Prediction (NSP) objective, and employing Mutual Information (MI) to model the semantic similarity of text in latent space.", "target": "A novel learning-based automatic evaluation metric (CMN) is proposed, which robustly evaluates open-domain dialogues by combining a Conditional Variational Autoencoders (CVAEs), a Next Sentence Prediction (NSP) objective, and employing Mutual Information (MI) to model the semantic similarity of text in latent space.", "example": "Convert the coordinate to text: [ -1.5572 -13.0738]:"}
{"text": "Convert the coordinate to text: [-0.7103 -8.1792]: This paper investigates whether layout-infused LMs maintain their performance when encountering documents with unfamiliar distributions of layout features.", "target": "This paper investigates whether layout-infused LMs maintain their performance when encountering documents with unfamiliar distributions of layout features.", "example": "Convert the coordinate to text: [-0.7103 -8.1792]:"}
{"text": "Convert the coordinate to text: [-3.1125 -6.7626]: The authors propose the SACL-XLMR, a generalized multilingual system for sentiment analysis on low-resource languages. Specifically, a lexicon-based multilingual BERT is designed to facilitate language adaptation and sentiment-aware representation learning. They also apply a supervised adversarial contrastive learning technique.", "target": "The authors propose the SACL-XLMR, a generalized multilingual system for sentiment analysis on low-resource languages. Specifically, a lexicon-based multilingual BERT is designed to facilitate language adaptation and sentiment-aware representation learning. They also apply a supervised adversarial contrastive learning technique.", "example": "Convert the coordinate to text: [-3.1125 -6.7626]:"}
{"text": "Convert the coordinate to text: [-1.4791  0.1022]: In the SemEval-2023 Task 10: Explainable Detection of Online Sexism (EDOS), this paper presents an approach for classifying textual content as sexist or not sexist, using a RoBERTa-based architecture with finetuned hyperparameters.", "target": "In the SemEval-2023 Task 10: Explainable Detection of Online Sexism (EDOS), this paper presents an approach for classifying textual content as sexist or not sexist, using a RoBERTa-based architecture with finetuned hyperparameters.", "example": "Convert the coordinate to text: [-1.4791  0.1022]:"}
{"text": "Convert the coordinate to text: [-5.9207 -0.5464]: The study proposes the use of an attention-based approach complemented by document processing techniques for judgment prediction, and treating the prediction of explanation as an extractive text summarization problem.", "target": "The study proposes the use of an attention-based approach complemented by document processing techniques for judgment prediction, and treating the prediction of explanation as an extractive text summarization problem.", "example": "Convert the coordinate to text: [-5.9207 -0.5464]:"}
{"text": "Convert the coordinate to text: [-2.6787 -9.8125]: This paper proposes Prosody-TTS, a two-stage pipeline aimed at enhancing prosody modeling and sampling. It introduces a self-supervised masked autoencoder for prosodic representation modeling without text transcriptions or local prosody attributes, and a diffusion model for sampling diverse prosodic patterns in the latent space.", "target": "This paper proposes Prosody-TTS, a two-stage pipeline aimed at enhancing prosody modeling and sampling. It introduces a self-supervised masked autoencoder for prosodic representation modeling without text transcriptions or local prosody attributes, and a diffusion model for sampling diverse prosodic patterns in the latent space.", "example": "Convert the coordinate to text: [-2.6787 -9.8125]:"}
{"text": "Convert the coordinate to text: [ 2.8124 -1.1507]: To mitigate the issue of model bias towards new users, the authors propose a two-phase framework. In the fixing phase, they use four active learning strategies to identify important samples from new users. In the self-training phase, a teacher model trained from the first phase is used to annotate semi-supervised samples to expand the training data with relevant cohort utterances.", "target": "To mitigate the issue of model bias towards new users, the authors propose a two-phase framework. In the fixing phase, they use four active learning strategies to identify important samples from new users. In the self-training phase, a teacher model trained from the first phase is used to annotate semi-supervised samples to expand the training data with relevant cohort utterances.", "example": "Convert the coordinate to text: [ 2.8124 -1.1507]:"}
{"text": "Convert the coordinate to text: [4.2804 0.4606]: This paper recognizes the need to account for both epistemic and aleatoric uncertainty to create robust uncertainty estimation methods for ambiguous tasks, and proposes a new hybrid UE method blending the two.", "target": "This paper recognizes the need to account for both epistemic and aleatoric uncertainty to create robust uncertainty estimation methods for ambiguous tasks, and proposes a new hybrid UE method blending the two.", "example": "Convert the coordinate to text: [4.2804 0.4606]:"}
{"text": "Convert the coordinate to text: [-3.4831 -6.3689]: The paper introduces MINT, a Multi-view row-INteractive Time-aware framework for detecting fraudulent behaviors from time-series structured data. MINT builds a time-aware behavior graph for user's time-series relational data and uses it to understand user's short-term, medium-term, and long-term intentions.", "target": "The paper introduces MINT, a Multi-view row-INteractive Time-aware framework for detecting fraudulent behaviors from time-series structured data. MINT builds a time-aware behavior graph for user's time-series relational data and uses it to understand user's short-term, medium-term, and long-term intentions.", "example": "Convert the coordinate to text: [-3.4831 -6.3689]:"}
{"text": "Convert the coordinate to text: [3.7895 0.6566]: The authors propose an approach to offline learn the AR models locally in each page on incomplete data and online aggregate the stored models in different pages considering inserted and updated data points. This differs to the standard approach, where data points are first merged and ordered by timestamps before applying learning algorithms.", "target": "The authors propose an approach to offline learn the AR models locally in each page on incomplete data and online aggregate the stored models in different pages considering inserted and updated data points. This differs to the standard approach, where data points are first merged and ordered by timestamps before applying learning algorithms.", "example": "Convert the coordinate to text: [3.7895 0.6566]:"}
{"text": "Convert the coordinate to text: [ 1.5176 -7.4637]: This paper proposes enhancing the Transformer's local context modeling ability via convolution operations, and automating input feature selection and operation application using an evolutionary neural architecture search approach for balance between local and global context modeling in Knowledge Tracing.", "target": "This paper proposes enhancing the Transformer's local context modeling ability via convolution operations, and automating input feature selection and operation application using an evolutionary neural architecture search approach for balance between local and global context modeling in Knowledge Tracing.", "example": "Convert the coordinate to text: [ 1.5176 -7.4637]:"}
{"text": "Convert the coordinate to text: [ 6.1579 -0.9958]: A new UCE (Unified Cross-Entropy) loss function is proposed for training face recognition models. This function is built on a constraint making sure that all positive sample-to-class similarities shall be larger than the negative ones.", "target": "A new UCE (Unified Cross-Entropy) loss function is proposed for training face recognition models. This function is built on a constraint making sure that all positive sample-to-class similarities shall be larger than the negative ones.", "example": "Convert the coordinate to text: [ 6.1579 -0.9958]:"}
{"text": "Convert the coordinate to text: [  8.3986 -11.6565]: This paper proposes a novel framework, MemorySeg, for semantic segmentation of a temporal sequence of LiDAR point clouds. They handle past information using a memory network, and also introduce a new regularizer to penalize prediction variations in the point cloud neighbourhood. MemorySeg builds a sparse 3D latent representation of the surroundings.", "target": "This paper proposes a novel framework, MemorySeg, for semantic segmentation of a temporal sequence of LiDAR point clouds. They handle past information using a memory network, and also introduce a new regularizer to penalize prediction variations in the point cloud neighbourhood. MemorySeg builds a sparse 3D latent representation of the surroundings.", "example": "Convert the coordinate to text: [  8.3986 -11.6565]:"}
{"text": "Convert the coordinate to text: [  8.0317 -12.997 ]: The authors introduce a generalizable 3D segmentation framework based on implicit representation that takes in multi-view image features and semantic maps as inputs to avoid overfitting to scene-specific geometric and semantic information. A novel soft voting mechanism is proposed to aggregate the 2D semantic information from different views for each 3D point.", "target": "The authors introduce a generalizable 3D segmentation framework based on implicit representation that takes in multi-view image features and semantic maps as inputs to avoid overfitting to scene-specific geometric and semantic information. A novel soft voting mechanism is proposed to aggregate the 2D semantic information from different views for each 3D point.", "example": "Convert the coordinate to text: [  8.0317 -12.997 ]:"}
{"text": "Convert the coordinate to text: [ 8.5171 -9.5036]: The authors propose a hierarchical encoder-decoder network (HEDNet) for 3D object detection, leveraging encoder-decoder blocks to capture long-range dependencies among features in the spatial space, especially for large and distant objects.", "target": "The authors propose a hierarchical encoder-decoder network (HEDNet) for 3D object detection, leveraging encoder-decoder blocks to capture long-range dependencies among features in the spatial space, especially for large and distant objects.", "example": "Convert the coordinate to text: [ 8.5171 -9.5036]:"}
{"text": "Convert the coordinate to text: [ 3.6963 -3.896 ]: The paper proposes a Targeted Knowledge Distillation Framework (TKDF), applying knowledge distillation to improve performance. It trains a slower but more accurate SLU model as a teacher model, then introduces an evaluator and uses the curriculum learning strategy to select proper targets for the student model.", "target": "The paper proposes a Targeted Knowledge Distillation Framework (TKDF), applying knowledge distillation to improve performance. It trains a slower but more accurate SLU model as a teacher model, then introduces an evaluator and uses the curriculum learning strategy to select proper targets for the student model.", "example": "Convert the coordinate to text: [ 3.6963 -3.896 ]:"}
{"text": "Convert the coordinate to text: [-1.5612 -6.444 ]: This study introduces a new pre-training framework, GENIE, a pretrained diffusion language model that gradually transforms a random noise sequence into coherent text. It incorporates an encoder and a diffusion-based decoder.", "target": "This study introduces a new pre-training framework, GENIE, a pretrained diffusion language model that gradually transforms a random noise sequence into coherent text. It incorporates an encoder and a diffusion-based decoder.", "example": "Convert the coordinate to text: [-1.5612 -6.444 ]:"}
{"text": "Convert the coordinate to text: [ 3.4458 -7.0974]: The authors propose the TWo-stage Interest Network (TWIN), which addresses the inconsistency by using a Consistency-Preserved GSU (CP-GSU) that adopts the identical target-behavior relevance metric as the Target Attention in ESU. This is achieved by a novel attention mechanism using behavior feature splitting for computational efficiency.", "target": "The authors propose the TWo-stage Interest Network (TWIN), which addresses the inconsistency by using a Consistency-Preserved GSU (CP-GSU) that adopts the identical target-behavior relevance metric as the Target Attention in ESU. This is achieved by a novel attention mechanism using behavior feature splitting for computational efficiency.", "example": "Convert the coordinate to text: [ 3.4458 -7.0974]:"}
{"text": "Convert the coordinate to text: [8.1111 9.2116]: To address this, the authors propose the first adaptive algorithm selection strategy for deep active learning called Thompson ActIve Learning algORithm selection (TAILOR). TAILOR iteratively and adaptively chooses among a set of candidate active learning algorithms.", "target": "To address this, the authors propose the first adaptive algorithm selection strategy for deep active learning called Thompson ActIve Learning algORithm selection (TAILOR). TAILOR iteratively and adaptively chooses among a set of candidate active learning algorithms.", "example": "Convert the coordinate to text: [8.1111 9.2116]:"}
{"text": "Convert the coordinate to text: [ 3.2127 -1.3154]: To address the problem of poor generalizability and incomparability of models due to diverging annotation schemes, the authors propose applying extremely weak supervision that only relies on the class name rather than on class samples from the annotated data.", "target": "To address the problem of poor generalizability and incomparability of models due to diverging annotation schemes, the authors propose applying extremely weak supervision that only relies on the class name rather than on class samples from the annotated data.", "example": "Convert the coordinate to text: [ 3.2127 -1.3154]:"}
{"text": "Convert the coordinate to text: [7.7316 2.9766]: The authors propose DEnsity, a novel method to evaluate a response by employing density estimation on the feature space derived from a neural classifier, which measures how likely a response would appear in the distribution of human conversations.", "target": "The authors propose DEnsity, a novel method to evaluate a response by employing density estimation on the feature space derived from a neural classifier, which measures how likely a response would appear in the distribution of human conversations.", "example": "Convert the coordinate to text: [7.7316 2.9766]:"}
{"text": "Convert the coordinate to text: [-4.3466 -3.0508]: This study categorizes mentions linking to NIL as 'Missing Entity' and 'Non-Entity Phrase', and also proposes a new entity linking dataset, NEL, which is focused on the NIL prediction problem. The authors construct NEL using ambiguous entities and mentions linking to NIL in the Wikipedia corpus by human annotation and entity masking.", "target": "This study categorizes mentions linking to NIL as 'Missing Entity' and 'Non-Entity Phrase', and also proposes a new entity linking dataset, NEL, which is focused on the NIL prediction problem. The authors construct NEL using ambiguous entities and mentions linking to NIL in the Wikipedia corpus by human annotation and entity masking.", "example": "Convert the coordinate to text: [-4.3466 -3.0508]:"}
{"text": "Convert the coordinate to text: [-2.4928 -7.2757]: A novel pre-training paradigm called Continuous Integrate-and-Fire Pre-Training (CIF-PT) is proposed, which relies on a frame-to-token alignment for creating bridges between the representations of speech and text.", "target": "A novel pre-training paradigm called Continuous Integrate-and-Fire Pre-Training (CIF-PT) is proposed, which relies on a frame-to-token alignment for creating bridges between the representations of speech and text.", "example": "Convert the coordinate to text: [-2.4928 -7.2757]:"}
{"text": "Convert the coordinate to text: [-0.5456  0.8378]: The authors introduce NLPositionality, a framework for characterizing design biases and quantifying the positionality of NLP datasets and models by continuously collecting annotations from a diverse pool of volunteer participants on LabintheWild and statistically quantifying alignment with dataset labels and model predictions.", "target": "The authors introduce NLPositionality, a framework for characterizing design biases and quantifying the positionality of NLP datasets and models by continuously collecting annotations from a diverse pool of volunteer participants on LabintheWild and statistically quantifying alignment with dataset labels and model predictions.", "example": "Convert the coordinate to text: [-0.5456  0.8378]:"}
{"text": "Convert the coordinate to text: [ 0.5942 -8.8583]: Video-LLaMA is a multi-modal framework that augments LLMs with the capability of understanding both visual and auditory content in videos. It extends pre-trained encoders and LLMs to a video encoder (Video Q-former) for capturing temporal changes and an audio encoder (Audio Q-former) for integrating audio-visual signals.", "target": "Video-LLaMA is a multi-modal framework that augments LLMs with the capability of understanding both visual and auditory content in videos. It extends pre-trained encoders and LLMs to a video encoder (Video Q-former) for capturing temporal changes and an audio encoder (Audio Q-former) for integrating audio-visual signals.", "example": "Convert the coordinate to text: [ 0.5942 -8.8583]:"}
{"text": "Convert the coordinate to text: [ 6.6312 -3.93  ]: The main idea of this paper is to adapt PLMs both effectively and efficiently by only tuning a few parameters. They propose a novel architecture, Mixture-of-Domain-Adapters (MixDA), that decouples the feed-forward networks (FFNs) maintaining the old-domain knowledge and injects domain-specific knowledge in parallel.", "target": "The main idea of this paper is to adapt PLMs both effectively and efficiently by only tuning a few parameters. They propose a novel architecture, Mixture-of-Domain-Adapters (MixDA), that decouples the feed-forward networks (FFNs) maintaining the old-domain knowledge and injects domain-specific knowledge in parallel.", "example": "Convert the coordinate to text: [ 6.6312 -3.93  ]:"}
{"text": "Convert the coordinate to text: [6.2946 2.1875]: The authors propose an effective training framework INK that smooths the representation space by adjusting representations of kNN neighbors with a small number of new parameters.", "target": "The authors propose an effective training framework INK that smooths the representation space by adjusting representations of kNN neighbors with a small number of new parameters.", "example": "Convert the coordinate to text: [6.2946 2.1875]:"}
{"text": "Convert the coordinate to text: [-10.1465  -1.8431]: The authors propose a new task of commonsense question generation and a new question generation model. It simultaneously considers asking content, expressive ways, and answering complexity by retrieving text-related commonsense context and disentangling key factors that control questions in terms of reasoning content and verbalized way. A discriminator is developed to promote deep results by considering their answering complexity.", "target": "The authors propose a new task of commonsense question generation and a new question generation model. It simultaneously considers asking content, expressive ways, and answering complexity by retrieving text-related commonsense context and disentangling key factors that control questions in terms of reasoning content and verbalized way. A discriminator is developed to promote deep results by considering their answering complexity.", "example": "Convert the coordinate to text: [-10.1465  -1.8431]:"}
{"text": "Convert the coordinate to text: [ 0.6176 -5.7268]: The authors propose a human attention guided approach to identify and mitigate shortcut learning in large language models, leveraging an attention-based measurement to capture both model and data bias and identify shortcut tokens by investigating both human and neural attention.", "target": "The authors propose a human attention guided approach to identify and mitigate shortcut learning in large language models, leveraging an attention-based measurement to capture both model and data bias and identify shortcut tokens by investigating both human and neural attention.", "example": "Convert the coordinate to text: [ 0.6176 -5.7268]:"}
{"text": "Convert the coordinate to text: [-0.1345 -8.8108]: The paper proposes a Prompt Generation approach to improve the robustness of language-image models like CLIP to contextual ambiguities, enabling these models to better correlate between the textual and visual aspects of different word senses.", "target": "The paper proposes a Prompt Generation approach to improve the robustness of language-image models like CLIP to contextual ambiguities, enabling these models to better correlate between the textual and visual aspects of different word senses.", "example": "Convert the coordinate to text: [-0.1345 -8.8108]:"}
{"text": "Convert the coordinate to text: [-3.1697 -6.5545]: The authors examine the effectiveness of various approaches including Support Vector Machines (SVM), translation, and an ensemble of pre-trained multilingual sentiment models for sentiment analysis in low-resource African languages.", "target": "The authors examine the effectiveness of various approaches including Support Vector Machines (SVM), translation, and an ensemble of pre-trained multilingual sentiment models for sentiment analysis in low-resource African languages.", "example": "Convert the coordinate to text: [-3.1697 -6.5545]:"}
{"text": "Convert the coordinate to text: [-1.1499 -4.9245]: The authors explored the likelihood of interpreting continuous prompts as the weightings of discrete prompts through joint optimization of prompt fidelity and downstream fidelity.", "target": "The authors explored the likelihood of interpreting continuous prompts as the weightings of discrete prompts through joint optimization of prompt fidelity and downstream fidelity.", "example": "Convert the coordinate to text: [-1.1499 -4.9245]:"}
{"text": "Convert the coordinate to text: [0.6452 1.0236]: The paper proposes a debiasing framework called IEGDB that comprehensively detects the dataset biases to induce a set of biased features, and then purifies the biased features with the guidance of information entropy.", "target": "The paper proposes a debiasing framework called IEGDB that comprehensively detects the dataset biases to induce a set of biased features, and then purifies the biased features with the guidance of information entropy.", "example": "Convert the coordinate to text: [0.6452 1.0236]:"}
{"text": "Convert the coordinate to text: [-3.3301  2.9999]: The authors propose to position the integrated re-ranking model on devices, enabling the full exploitation of real-time behaviors. They present the first on-Device Integrated Re-ranking framework, DIR, which includes a multi-sequence behavior modeling module to extract user's source-level preferences, and a preference-adaptive re-ranking module to incorporate personalized source-level preferences into re-ranking.", "target": "The authors propose to position the integrated re-ranking model on devices, enabling the full exploitation of real-time behaviors. They present the first on-Device Integrated Re-ranking framework, DIR, which includes a multi-sequence behavior modeling module to extract user's source-level preferences, and a preference-adaptive re-ranking module to incorporate personalized source-level preferences into re-ranking.", "example": "Convert the coordinate to text: [-3.3301  2.9999]:"}
{"text": "Convert the coordinate to text: [ 0.7295 -2.2684]: The paper introduces CELL-E 2, a novel bidirectional transformer that not only generates images depicting protein subcellular localization from the amino acid sequences, but can also reverse the process, generating sequences from images, thus enabling de novo protein design.", "target": "The paper introduces CELL-E 2, a novel bidirectional transformer that not only generates images depicting protein subcellular localization from the amino acid sequences, but can also reverse the process, generating sequences from images, thus enabling de novo protein design.", "example": "Convert the coordinate to text: [ 0.7295 -2.2684]:"}
{"text": "Convert the coordinate to text: [ 5.1121 -5.6203]: The authors propose the 'Trico-training' method, which utilizes a multilayer perceptron (MLP) classifier and two graph convolutional network (GCN) classifiers (namely, inter-view GCN and intra-view GCN classifiers) to minimize both inter-domain and intra-domain discrepancies.", "target": "The authors propose the 'Trico-training' method, which utilizes a multilayer perceptron (MLP) classifier and two graph convolutional network (GCN) classifiers (namely, inter-view GCN and intra-view GCN classifiers) to minimize both inter-domain and intra-domain discrepancies.", "example": "Convert the coordinate to text: [ 5.1121 -5.6203]:"}
{"text": "Convert the coordinate to text: [-1.6731 -2.0593]: The authors propose to investigate the semi-structured nature of clinical notes and develop an automatic algorithm to segment them into sections. They introduce a contrastive pre-training approach on sections using a soft multi-label similarity metric based on tree edit distance and design a masked section training strategy for ICD coding models to locate relevant sections.", "target": "The authors propose to investigate the semi-structured nature of clinical notes and develop an automatic algorithm to segment them into sections. They introduce a contrastive pre-training approach on sections using a soft multi-label similarity metric based on tree edit distance and design a masked section training strategy for ICD coding models to locate relevant sections.", "example": "Convert the coordinate to text: [-1.6731 -2.0593]:"}
{"text": "Convert the coordinate to text: [ 2.4317 -9.4828]: The paper introduces a novel Visually-Asymmetric coNsistenCy Learning (VanCL) approach that enhances the models' ability to capture fine-grained visual and layout features by incorporating color priors.", "target": "The paper introduces a novel Visually-Asymmetric coNsistenCy Learning (VanCL) approach that enhances the models' ability to capture fine-grained visual and layout features by incorporating color priors.", "example": "Convert the coordinate to text: [ 2.4317 -9.4828]:"}
{"text": "Convert the coordinate to text: [ 0.3976 10.6498]: The authors propose to bring the aforementioned two lines of work together and study the case with an LTL _f agent goal and a GR(1) environment specification. They then add safety conditions for both the environment and the agent.", "target": "The authors propose to bring the aforementioned two lines of work together and study the case with an LTL _f agent goal and a GR(1) environment specification. They then add safety conditions for both the environment and the agent.", "example": "Convert the coordinate to text: [ 0.3976 10.6498]:"}
{"text": "Convert the coordinate to text: [ 6.1087 14.7302]: The authors suggest InforMARL, a novel architecture for multi-agent reinforcement learning (MARL) which uses local information intelligently to compute paths for all the agents in a decentralized manner. It aggregates information about the local neighborhood of agents for both the actor and the critic using a graph neural network and can be used in conjunction with any standard MARL algorithm.", "target": "The authors suggest InforMARL, a novel architecture for multi-agent reinforcement learning (MARL) which uses local information intelligently to compute paths for all the agents in a decentralized manner. It aggregates information about the local neighborhood of agents for both the actor and the critic using a graph neural network and can be used in conjunction with any standard MARL algorithm.", "example": "Convert the coordinate to text: [ 6.1087 14.7302]:"}
{"text": "Convert the coordinate to text: [ 8.6426 11.6369]: The paper proposes TSEETC, a learning algorithm based on Thompson Sampling with Episodic Explore-Then-Commit that operates in exploration and exploitation phases to sequentially choose which arms to pull so as to maximize the expected cumulative rewards collected.", "target": "The paper proposes TSEETC, a learning algorithm based on Thompson Sampling with Episodic Explore-Then-Commit that operates in exploration and exploitation phases to sequentially choose which arms to pull so as to maximize the expected cumulative rewards collected.", "example": "Convert the coordinate to text: [ 8.6426 11.6369]:"}
{"text": "Convert the coordinate to text: [-6.0318 11.5863]: The authors present FIREBALL, a large dataset with nearly 25,000 unique sessions from real D&D gameplay on Discord, capturing language, game commands, and true game state information with the use of Avrae bot.", "target": "The authors present FIREBALL, a large dataset with nearly 25,000 unique sessions from real D&D gameplay on Discord, capturing language, game commands, and true game state information with the use of Avrae bot.", "example": "Convert the coordinate to text: [-6.0318 11.5863]:"}
{"text": "Convert the coordinate to text: [-5.8292 -0.7287]: We propose a two-step abstractive summarisation framework that involves neural topic modeling with an iterative clustering procedure to generate key points that align with human identification of key points.", "target": "We propose a two-step abstractive summarisation framework that involves neural topic modeling with an iterative clustering procedure to generate key points that align with human identification of key points.", "example": "Convert the coordinate to text: [-5.8292 -0.7287]:"}
{"text": "Convert the coordinate to text: [ 7.8834 -2.9481]: The authors propose the Dynamics-Enhanced Generative Model (DyGen), which leverages dynamic patterns in the embedding space during the fine-tuning process of language models to improve noisy label predictions.", "target": "The authors propose the Dynamics-Enhanced Generative Model (DyGen), which leverages dynamic patterns in the embedding space during the fine-tuning process of language models to improve noisy label predictions.", "example": "Convert the coordinate to text: [ 7.8834 -2.9481]:"}
{"text": "Convert the coordinate to text: [-3.225  -6.5855]: The authors introduce multilingual multi-figurative language modelling and provide a benchmark for sentence-level figurative language detection that covers three common figures of speech and seven languages. They develop a framework for figurative language detection based on template-based prompt learning allowing for the unification of multiple detection tasks across multiple figures of speech and languages.", "target": "The authors introduce multilingual multi-figurative language modelling and provide a benchmark for sentence-level figurative language detection that covers three common figures of speech and seven languages. They develop a framework for figurative language detection based on template-based prompt learning allowing for the unification of multiple detection tasks across multiple figures of speech and languages.", "example": "Convert the coordinate to text: [-3.225  -6.5855]:"}
{"text": "Convert the coordinate to text: [-6.469  12.6503]: The authors propose a novel approach for empathetic response generation, which makes use of an adaptive module for selecting commonsense knowledge. This ensures consistency between the empathetic responses generated and the speaker's situation.", "target": "The authors propose a novel approach for empathetic response generation, which makes use of an adaptive module for selecting commonsense knowledge. This ensures consistency between the empathetic responses generated and the speaker's situation.", "example": "Convert the coordinate to text: [-6.469  12.6503]:"}
{"text": "Convert the coordinate to text: [ -6.9187 -10.169 ]: The study introduces SentiGOLD, a new, large-scale, standard Bangla multi-domain sentiment analysis dataset consisting of 70,000 samples across 30 domains and 5 sentiment classes, sourced from diverse online platforms.", "target": "The study introduces SentiGOLD, a new, large-scale, standard Bangla multi-domain sentiment analysis dataset consisting of 70,000 samples across 30 domains and 5 sentiment classes, sourced from diverse online platforms.", "example": "Convert the coordinate to text: [ -6.9187 -10.169 ]:"}
{"text": "Convert the coordinate to text: [-5.5899 -0.875 ]: To address the problem of errors in cross-lingual summarization, the authors propose ConvSumX, a cross-lingual conversation summarization benchmark, through a new annotation schema that explicitly considers source input context.", "target": "To address the problem of errors in cross-lingual summarization, the authors propose ConvSumX, a cross-lingual conversation summarization benchmark, through a new annotation schema that explicitly considers source input context.", "example": "Convert the coordinate to text: [-5.5899 -0.875 ]:"}
{"text": "Convert the coordinate to text: [-2.6561 -5.1128]: The authors propose DecompEval, a metric that uses instruction-style question answering and pre-trained language models (PLMs) to evaluate NLG tasks, aiming at enhancing the generalization ability and interpretability of the evaluation results.", "target": "The authors propose DecompEval, a metric that uses instruction-style question answering and pre-trained language models (PLMs) to evaluate NLG tasks, aiming at enhancing the generalization ability and interpretability of the evaluation results.", "example": "Convert the coordinate to text: [-2.6561 -5.1128]:"}
{"text": "Convert the coordinate to text: [-4.7077  9.5517]: This study investigates the comparison of three different neural architectures for question generation across two types of reading material: narratives and textbooks.", "target": "This study investigates the comparison of three different neural architectures for question generation across two types of reading material: narratives and textbooks.", "example": "Convert the coordinate to text: [-4.7077  9.5517]:"}
{"text": "Convert the coordinate to text: [ 2.7424 -8.1561]: The authors propose a self-supervised learning-powered loss function inspired by a linguistics theory of coherence and suggest combining features from an object and face detector to further enhance character features.", "target": "The authors propose a self-supervised learning-powered loss function inspired by a linguistics theory of coherence and suggest combining features from an object and face detector to further enhance character features.", "example": "Convert the coordinate to text: [ 2.7424 -8.1561]:"}
{"text": "Convert the coordinate to text: [-4.4515 -7.8124]: The authors propose to revisit the established paradigm in word-level QE for machine translation. They create a new benchmark dataset, named HJQE (Human Judgement on Quality Estimation), where expert translators annotate the poorly translated words based on their judgment.", "target": "The authors propose to revisit the established paradigm in word-level QE for machine translation. They create a new benchmark dataset, named HJQE (Human Judgement on Quality Estimation), where expert translators annotate the poorly translated words based on their judgment.", "example": "Convert the coordinate to text: [-4.4515 -7.8124]:"}
{"text": "Convert the coordinate to text: [-2.952 -6.941]: The authors investigate how different techniques of paraphrasing, such as back translation, specialized encoder-decoder models like Pegasus, and GPT-3 variants, can be used to improve performance in NER across varying levels of gold annotations and paraphrasing strength, using five datasets.", "target": "The authors investigate how different techniques of paraphrasing, such as back translation, specialized encoder-decoder models like Pegasus, and GPT-3 variants, can be used to improve performance in NER across varying levels of gold annotations and paraphrasing strength, using five datasets.", "example": "Convert the coordinate to text: [-2.952 -6.941]:"}
{"text": "Convert the coordinate to text: [ 2.0024 -7.4769]: Authors propose a novel feature-based framework named Coalition Tag Multi-View Mapping (CTMVM), which identifies and investigates two special features, Coalition Feature and Privileged Feature. The framework uses Shapley Value based Empowerment (SVE) and Privileged Knowledge Mapping (PKM), and an Adaptive Multi-View Mapping (AMVM) model.", "target": "Authors propose a novel feature-based framework named Coalition Tag Multi-View Mapping (CTMVM), which identifies and investigates two special features, Coalition Feature and Privileged Feature. The framework uses Shapley Value based Empowerment (SVE) and Privileged Knowledge Mapping (PKM), and an Adaptive Multi-View Mapping (AMVM) model.", "example": "Convert the coordinate to text: [ 2.0024 -7.4769]:"}
{"text": "Convert the coordinate to text: [ 4.0095 -5.9225]: This paper presents a new paradigm of higher-order constraints in social relations, formulated as triangular relational closed-loop structures, aka triangular constraints. These are used in a novel model, the triangular reasoning graph attention network (TRGAT). Additionally, node contrastive learning is introduced to improve feature representations of individuals.", "target": "This paper presents a new paradigm of higher-order constraints in social relations, formulated as triangular relational closed-loop structures, aka triangular constraints. These are used in a novel model, the triangular reasoning graph attention network (TRGAT). Additionally, node contrastive learning is introduced to improve feature representations of individuals.", "example": "Convert the coordinate to text: [ 4.0095 -5.9225]:"}
{"text": "Convert the coordinate to text: [ 0.9861 14.1019]: The authors introduce two models to study the one-dimensional multi-stage facility location problems with transient agents: where moving costs are ignored and when the facility's moving cost between adjacent stages is considered under the social cost objective.", "target": "The authors introduce two models to study the one-dimensional multi-stage facility location problems with transient agents: where moving costs are ignored and when the facility's moving cost between adjacent stages is considered under the social cost objective.", "example": "Convert the coordinate to text: [ 0.9861 14.1019]:"}
{"text": "Convert the coordinate to text: [13.9191 -0.1138]: The authors propose a new framework - Hierarchical Dynamic Graph Ordinary Differential Equation (HDG-ODE) - to tackle the 3D pose forecasting task from 2D skeleton representations in videos using a continuous-time model to predict the 3D joint positions at any time.", "target": "The authors propose a new framework - Hierarchical Dynamic Graph Ordinary Differential Equation (HDG-ODE) - to tackle the 3D pose forecasting task from 2D skeleton representations in videos using a continuous-time model to predict the 3D joint positions at any time.", "example": "Convert the coordinate to text: [13.9191 -0.1138]:"}
{"text": "Convert the coordinate to text: [9.6623 8.5176]: The authors elucidate this tolerance by looking at contrastive learning through the lens of distributionally robust optimization (DRO) and find key insights into its workings. They also propose a novel Adjusted InfoNCE loss (ADNCE) to counteract potential shortcomings in CL including over-conservatism and sensitivity to outliers.", "target": "The authors elucidate this tolerance by looking at contrastive learning through the lens of distributionally robust optimization (DRO) and find key insights into its workings. They also propose a novel Adjusted InfoNCE loss (ADNCE) to counteract potential shortcomings in CL including over-conservatism and sensitivity to outliers.", "example": "Convert the coordinate to text: [9.6623 8.5176]:"}
{"text": "Convert the coordinate to text: [7.8351 8.6822]: The authors model an evaluation process as a transformation of a distribution of the true utility of an individual for a task to an observed distribution and solve it as a loss minimization problem with an information constraint. The model incorporates a resource-information trade-off parameter in the information constraint and a risk-averseness parameter in the loss function.", "target": "The authors model an evaluation process as a transformation of a distribution of the true utility of an individual for a task to an observed distribution and solve it as a loss minimization problem with an information constraint. The model incorporates a resource-information trade-off parameter in the information constraint and a risk-averseness parameter in the loss function.", "example": "Convert the coordinate to text: [7.8351 8.6822]:"}
{"text": "Convert the coordinate to text: [6.8926 9.9403]: This study proposes re-parameterization of the DEC with the confidence radius, leading to the formation of the Estimation-To-Decisions algorithm (Anytime-E2D) which optimizes the exploration-exploitation trade-off online.", "target": "This study proposes re-parameterization of the DEC with the confidence radius, leading to the formation of the Estimation-To-Decisions algorithm (Anytime-E2D) which optimizes the exploration-exploitation trade-off online.", "example": "Convert the coordinate to text: [6.8926 9.9403]:"}
{"text": "Convert the coordinate to text: [  1.9336 -10.3106]: The paper proposes CLIP4HOI, a novel framework developed on the vision-language model CLIP, for adaptable zero-shot HOI detection, which independently identifies humans and objects and processes all feasible human-object pairs. It also adapts the CLIP model into a fine-grained HOI classifier for proposal discrimination, avoiding data-sensitive knowledge distillation.", "target": "The paper proposes CLIP4HOI, a novel framework developed on the vision-language model CLIP, for adaptable zero-shot HOI detection, which independently identifies humans and objects and processes all feasible human-object pairs. It also adapts the CLIP model into a fine-grained HOI classifier for proposal discrimination, avoiding data-sensitive knowledge distillation.", "example": "Convert the coordinate to text: [  1.9336 -10.3106]:"}
{"text": "Convert the coordinate to text: [  2.8783 -11.2423]: The authors propose the 4D Panoptic Scene Graph (PSG-4D), a new data representation technique that abstracts 4D sensory data into nodes and edges representing entities with location and status information and their temporal relations in a dynamic 4D environment.", "target": "The authors propose the 4D Panoptic Scene Graph (PSG-4D), a new data representation technique that abstracts 4D sensory data into nodes and edges representing entities with location and status information and their temporal relations in a dynamic 4D environment.", "example": "Convert the coordinate to text: [  2.8783 -11.2423]:"}
{"text": "Convert the coordinate to text: [ 6.4707 -0.9714]: The authors propose a new pairwise sigmoid loss for image-text pre-training which operates solely on image-text pairs and does not require a global view of the pairwise similarities for normalization.", "target": "The authors propose a new pairwise sigmoid loss for image-text pre-training which operates solely on image-text pairs and does not require a global view of the pairwise similarities for normalization.", "example": "Convert the coordinate to text: [ 6.4707 -0.9714]:"}
{"text": "Convert the coordinate to text: [ 0.3124 -6.9061]: The authors suggest exploring how model width affects the Transformer model, introducing a parameter-efficient multi-path structure. They also add three additional operations: a normalization at the end of each path, a low-cost operation to produce more features, and a learnable weighted mechanism for more flexible feature fusion.", "target": "The authors suggest exploring how model width affects the Transformer model, introducing a parameter-efficient multi-path structure. They also add three additional operations: a normalization at the end of each path, a low-cost operation to produce more features, and a learnable weighted mechanism for more flexible feature fusion.", "example": "Convert the coordinate to text: [ 0.3124 -6.9061]:"}
{"text": "Convert the coordinate to text: [-6.3388 -5.5086]: The authors introduce the 'Smart Word Suggestions' (SWS) task and benchmark, focusing on identifying words or phrases that require improvement and providing substitutions in an end-to-end manner.", "target": "The authors introduce the 'Smart Word Suggestions' (SWS) task and benchmark, focusing on identifying words or phrases that require improvement and providing substitutions in an end-to-end manner.", "example": "Convert the coordinate to text: [-6.3388 -5.5086]:"}
{"text": "Convert the coordinate to text: [-3.6768 -6.7398]: The authors propose a two-step approach to overcome the issue of data scarcity which includes fine-tuning language models on a corpus of German Easy Language, a specific style of German, and then using these models as decoders in a sequence-to-sequence simplification task.", "target": "The authors propose a two-step approach to overcome the issue of data scarcity which includes fine-tuning language models on a corpus of German Easy Language, a specific style of German, and then using these models as decoders in a sequence-to-sequence simplification task.", "example": "Convert the coordinate to text: [-3.6768 -6.7398]:"}
{"text": "Convert the coordinate to text: [-10.0153  -8.5847]: The authors propose the adaptation of Weir's definition of a controllable CFG to define controllable pushdown automata (PDAs), leading to new characterizations of $\\mathcal{L}_2$ as languages generated by various combinations of PDAs and CFGs.", "target": "The authors propose the adaptation of Weir's definition of a controllable CFG to define controllable pushdown automata (PDAs), leading to new characterizations of $\\mathcal{L}_2$ as languages generated by various combinations of PDAs and CFGs.", "example": "Convert the coordinate to text: [-10.0153  -8.5847]:"}
{"text": "Convert the coordinate to text: [-3.0985  0.8773]: The authors propose a novel multi-source semantic graph-based Multimodal sarcasm explanation scheme, named TEAM. This method extracts object-level semantic metadata from the input image rather than just using global visual features, and it also uses ConceptNet to obtain external knowledge related to the input text and the extracted object meta-data.", "target": "The authors propose a novel multi-source semantic graph-based Multimodal sarcasm explanation scheme, named TEAM. This method extracts object-level semantic metadata from the input image rather than just using global visual features, and it also uses ConceptNet to obtain external knowledge related to the input text and the extracted object meta-data.", "example": "Convert the coordinate to text: [-3.0985  0.8773]:"}
{"text": "Convert the coordinate to text: [ 1.6902 -0.747 ]: The authors propose a new concept of 'ground truth' as the distribution of all labels that a population of annotators could provide and introduce DisCo (Distribution from Context), a simple neural model that predicts this distribution.", "target": "The authors propose a new concept of 'ground truth' as the distribution of all labels that a population of annotators could provide and introduce DisCo (Distribution from Context), a simple neural model that predicts this distribution.", "example": "Convert the coordinate to text: [ 1.6902 -0.747 ]:"}
{"text": "Convert the coordinate to text: [-1.111  -6.6212]: The authors propose a three-level encoder-based classification architecture that works by fine-tuning a BERT-based pre-trained encoder, and post-processing the embeddings extracted from its last layers, using transformer encoder layers and RNNs. For the explanation of the predicted class, they develop an explanation extraction algorithm, exploiting the idea of a model\u2019s occlusion sensitivity.", "target": "The authors propose a three-level encoder-based classification architecture that works by fine-tuning a BERT-based pre-trained encoder, and post-processing the embeddings extracted from its last layers, using transformer encoder layers and RNNs. For the explanation of the predicted class, they develop an explanation extraction algorithm, exploiting the idea of a model\u2019s occlusion sensitivity.", "example": "Convert the coordinate to text: [-1.111  -6.6212]:"}
{"text": "Convert the coordinate to text: [ 0.0778 -8.9439]: This paper explores various methods for injecting the early shallow event representations into contemporary multimodal deep learning-based models, to understand procedures in combination with modern vision-and-language models.", "target": "This paper explores various methods for injecting the early shallow event representations into contemporary multimodal deep learning-based models, to understand procedures in combination with modern vision-and-language models.", "example": "Convert the coordinate to text: [ 0.0778 -8.9439]:"}
{"text": "Convert the coordinate to text: [12.3007 -5.124 ]: The authors propose a strategy of adding perturbations towards High-Sample-Density-Regions (HSDR) of the target class, as these regions show more consistent performance across neural networks trained on the same dataset. They suggest adding perturbations to easy samples in the target class enhances the targeted adversarial transferability of existing attack methods.", "target": "The authors propose a strategy of adding perturbations towards High-Sample-Density-Regions (HSDR) of the target class, as these regions show more consistent performance across neural networks trained on the same dataset. They suggest adding perturbations to easy samples in the target class enhances the targeted adversarial transferability of existing attack methods.", "example": "Convert the coordinate to text: [12.3007 -5.124 ]:"}
{"text": "Convert the coordinate to text: [  9.0227 -16.3022]: The authors propose a new method for learning the SDF directly from point clouds even without the presence of normals. The key idea is to align the gradient and the Hessian of the SDF to provide an efficient mechanism for governing gradient directions and accurately reflecting underlying shape variations.", "target": "The authors propose a new method for learning the SDF directly from point clouds even without the presence of normals. The key idea is to align the gradient and the Hessian of the SDF to provide an efficient mechanism for governing gradient directions and accurately reflecting underlying shape variations.", "example": "Convert the coordinate to text: [  9.0227 -16.3022]:"}
{"text": "Convert the coordinate to text: [-2.1452 11.7709]: The authors suggest combining semantic knowledge from a language model and grounded models of the environment to construct an action sequence, which is decoded as a probabilistic filtering problem, to enable language models to be effective in embodied settings.", "target": "The authors suggest combining semantic knowledge from a language model and grounded models of the environment to construct an action sequence, which is decoded as a probabilistic filtering problem, to enable language models to be effective in embodied settings.", "example": "Convert the coordinate to text: [-2.1452 11.7709]:"}
{"text": "Convert the coordinate to text: [  3.0317 -10.7491]: UnionDet, a one-stage meta-architecture for Human-Object Interaction (HOI) detection is proposed. This new architecture introduces a novel union-level detector that directly captures the region of interaction, bypassing additional steps in the current models.", "target": "UnionDet, a one-stage meta-architecture for Human-Object Interaction (HOI) detection is proposed. This new architecture introduces a novel union-level detector that directly captures the region of interaction, bypassing additional steps in the current models.", "example": "Convert the coordinate to text: [  3.0317 -10.7491]:"}
{"text": "Convert the coordinate to text: [-6.3174 -4.9215]: The authors propose the integration of Lexicase Selection, a method from evolutionary computation, into the context of deep learning to enhance generalization. They specifically propose a new optimization framework named Gradient Lexicase Selection, which combines gradient descent and lexicase selection.", "target": "The authors propose the integration of Lexicase Selection, a method from evolutionary computation, into the context of deep learning to enhance generalization. They specifically propose a new optimization framework named Gradient Lexicase Selection, which combines gradient descent and lexicase selection.", "example": "Convert the coordinate to text: [-6.3174 -4.9215]:"}
{"text": "Convert the coordinate to text: [-1.3513 -7.3583]: This study proposes Language-Specific Transformer Layers (LSLs), intended to increase model capacity while keeping the computation amount constant and the number of parameters used in the forward pass. Some layers of the encoder are source or target language-specific, with the remaining layers shared.", "target": "This study proposes Language-Specific Transformer Layers (LSLs), intended to increase model capacity while keeping the computation amount constant and the number of parameters used in the forward pass. Some layers of the encoder are source or target language-specific, with the remaining layers shared.", "example": "Convert the coordinate to text: [-1.3513 -7.3583]:"}
{"text": "Convert the coordinate to text: [-5.9476 -5.3193]: This study investigates how the marking of a word's neighboring words affect the explainee's perception of the word's importance in the context of a saliency explanation.", "target": "This study investigates how the marking of a word's neighboring words affect the explainee's perception of the word's importance in the context of a saliency explanation.", "example": "Convert the coordinate to text: [-5.9476 -5.3193]:"}
{"text": "Convert the coordinate to text: [-0.3752 -6.5067]: The authors propose a novel unified topic-guided encoder-decoder (UTGED) framework. Instead of using tags like age, the UTEGD framework models latent topics to reflect salient user interests. These topics are then used to guide the encoding of a user's history and to control the decoding of their self-introduction.", "target": "The authors propose a novel unified topic-guided encoder-decoder (UTGED) framework. Instead of using tags like age, the UTEGD framework models latent topics to reflect salient user interests. These topics are then used to guide the encoding of a user's history and to control the decoding of their self-introduction.", "example": "Convert the coordinate to text: [-0.3752 -6.5067]:"}
{"text": "Convert the coordinate to text: [-1.2038  0.2124]: The authors develop parallel datasets of texts with masculine, feminine, and singular 'they' gender terms to quantify gender bias, and propose a data augmentation technique for the singular 'they', as well as a refinement of a similar augmentation technique for masculine and feminine terms.", "target": "The authors develop parallel datasets of texts with masculine, feminine, and singular 'they' gender terms to quantify gender bias, and propose a data augmentation technique for the singular 'they', as well as a refinement of a similar augmentation technique for masculine and feminine terms.", "example": "Convert the coordinate to text: [-1.2038  0.2124]:"}
{"text": "Convert the coordinate to text: [-1.4661  0.1307]: The authors propose a system for SemEval-2023 Task 10: Explainable Detection of Online Sexism that employs a consistency training framework and data augmentation as primary strategies for model training.", "target": "The authors propose a system for SemEval-2023 Task 10: Explainable Detection of Online Sexism that employs a consistency training framework and data augmentation as primary strategies for model training.", "example": "Convert the coordinate to text: [-1.4661  0.1307]:"}
{"text": "Convert the coordinate to text: [-7.6284 -8.3039]: The authors propose using grammar-based decoding to improve compositional generalization. They introduce CUDON, a large-scale dialogue dataset in the Chinese language, designed for evaluating compositional generalization of semantic parsing.", "target": "The authors propose using grammar-based decoding to improve compositional generalization. They introduce CUDON, a large-scale dialogue dataset in the Chinese language, designed for evaluating compositional generalization of semantic parsing.", "example": "Convert the coordinate to text: [-7.6284 -8.3039]:"}
{"text": "Convert the coordinate to text: [-5.1601 -0.4825]: A new framework to identify and remove low-quality training instances that lead to undesirable outputs in NLG tasks is introduced. The focus is particularly on faithfulness errors in text summarization.", "target": "A new framework to identify and remove low-quality training instances that lead to undesirable outputs in NLG tasks is introduced. The focus is particularly on faithfulness errors in text summarization.", "example": "Convert the coordinate to text: [-5.1601 -0.4825]:"}
{"text": "Convert the coordinate to text: [-2.6512  4.2297]: The authors tackle this problem by formulating it as a vertical federated learning problem, i.e., features are vertically distributed over different departments. They design a customized encryption scheme, the orthogonal matrix-based mask mechanism (O3M), for privacy protection in contextual bandit learning algorithms for recommendation systems.", "target": "The authors tackle this problem by formulating it as a vertical federated learning problem, i.e., features are vertically distributed over different departments. They design a customized encryption scheme, the orthogonal matrix-based mask mechanism (O3M), for privacy protection in contextual bandit learning algorithms for recommendation systems.", "example": "Convert the coordinate to text: [-2.6512  4.2297]:"}
{"text": "Convert the coordinate to text: [9.6954 9.1147]: The authors propose the first combinatorial algorithm for non-monotone submodular maximization subject to a knapsack constraint, which achieves an (8 + \u015d )-approximation under O (log n ) adaptive complexity and is optimal up to a factor of O (log log n ).", "target": "The authors propose the first combinatorial algorithm for non-monotone submodular maximization subject to a knapsack constraint, which achieves an (8 + \u015d )-approximation under O (log n ) adaptive complexity and is optimal up to a factor of O (log log n ).", "example": "Convert the coordinate to text: [9.6954 9.1147]:"}
{"text": "Convert the coordinate to text: [ 14.4468 -15.4395]: This paper introduces a method that uses semantic parsing and primitive extraction for accelerating the radiance field reconstruction process and offers a primitive-aware hybrid rendering strategy for volumetric and primitive rendering.", "target": "This paper introduces a method that uses semantic parsing and primitive extraction for accelerating the radiance field reconstruction process and offers a primitive-aware hybrid rendering strategy for volumetric and primitive rendering.", "example": "Convert the coordinate to text: [ 14.4468 -15.4395]:"}
{"text": "Convert the coordinate to text: [  6.8387 -12.5861]: The paper introduces object-centric embeddings (OCEs), which provide embeddings that capture spatial offsets between patches from the same object and uses them for object delineation and instance segmentation. The method primarily uses a self-supervised task for predicting spatial offset between image patches.", "target": "The paper introduces object-centric embeddings (OCEs), which provide embeddings that capture spatial offsets between patches from the same object and uses them for object delineation and instance segmentation. The method primarily uses a self-supervised task for predicting spatial offset between image patches.", "example": "Convert the coordinate to text: [  6.8387 -12.5861]:"}
{"text": "Convert the coordinate to text: [ 4.5781 13.5903]: This paper introduces a new method, ELDEN (Exploration via Local DepENdencies), an intrinsic reward that guides the discovery of new interactions between entities by capitalizing on local dependencies in environments with complex chained dependencies.", "target": "This paper introduces a new method, ELDEN (Exploration via Local DepENdencies), an intrinsic reward that guides the discovery of new interactions between entities by capitalizing on local dependencies in environments with complex chained dependencies.", "example": "Convert the coordinate to text: [ 4.5781 13.5903]:"}
{"text": "Convert the coordinate to text: [-2.5677 -5.5526]: The authors propose Explore-Instruct, a new method to enhance the data coverage used in specific domain instruction-tuning through active exploration using Large Language Models (LLMs)", "target": "The authors propose Explore-Instruct, a new method to enhance the data coverage used in specific domain instruction-tuning through active exploration using Large Language Models (LLMs)", "example": "Convert the coordinate to text: [-2.5677 -5.5526]:"}
{"text": "Convert the coordinate to text: [0.3535 1.8436]: Rather than relying on the marginal rank test, the authors suggest using a flexible classification approach that learns test statistics from data, which offers an interpretable divergence measure of miscalibration calculated from classification accuracy.", "target": "Rather than relying on the marginal rank test, the authors suggest using a flexible classification approach that learns test statistics from data, which offers an interpretable divergence measure of miscalibration calculated from classification accuracy.", "example": "Convert the coordinate to text: [0.3535 1.8436]:"}
{"text": "Convert the coordinate to text: [12.6548  6.8105]: The authors propose an in-depth study on the impact of stochasticity and large step sizes on the implicit regularization of gradient descent (GD) and stochastic gradient descent (SGD) over 2-layer diagonal linear networks.", "target": "The authors propose an in-depth study on the impact of stochasticity and large step sizes on the implicit regularization of gradient descent (GD) and stochastic gradient descent (SGD) over 2-layer diagonal linear networks.", "example": "Convert the coordinate to text: [12.6548  6.8105]:"}
{"text": "Convert the coordinate to text: [0.6941 1.0312]: The paper reveals the shortcomings of previous approaches when hidden confounding is present and proposes a unified multi-task learning approach to remove such confounding using unbiased ratings to calibrate the learned nominal propensities and nominal error imputations from biased data.", "target": "The paper reveals the shortcomings of previous approaches when hidden confounding is present and proposes a unified multi-task learning approach to remove such confounding using unbiased ratings to calibrate the learned nominal propensities and nominal error imputations from biased data.", "example": "Convert the coordinate to text: [0.6941 1.0312]:"}
{"text": "Convert the coordinate to text: [-6.2571 12.6813]: The authors propose a novel task, G4C, to study teacher-student interactions in Dungeons and Dragons (D&D), involving modeling of the Dungeon Master (DM)'s intent to guide players, the DM's guidance utterance expressing this intent, and a theory-of-mind (ToM) model anticipating players\u2019 reactions to the guidance.", "target": "The authors propose a novel task, G4C, to study teacher-student interactions in Dungeons and Dragons (D&D), involving modeling of the Dungeon Master (DM)'s intent to guide players, the DM's guidance utterance expressing this intent, and a theory-of-mind (ToM) model anticipating players\u2019 reactions to the guidance.", "example": "Convert the coordinate to text: [-6.2571 12.6813]:"}
{"text": "Convert the coordinate to text: [15.944   2.0157]: The authors propose a causality-based framework named the 'Covariance and Variance Optimization framework' or OVO, for debiasing in the context of entity and relation extraction tasks. The framework has two main components: Covariance Optimizing (COP) and Variance Optimizing (VOP).", "target": "The authors propose a causality-based framework named the 'Covariance and Variance Optimization framework' or OVO, for debiasing in the context of entity and relation extraction tasks. The framework has two main components: Covariance Optimizing (COP) and Variance Optimizing (VOP).", "example": "Convert the coordinate to text: [15.944   2.0157]:"}
{"text": "Convert the coordinate to text: [ -0.1706 -15.4142]: The authors propose a hybrid BCI control system that uses electroencephalography, electrooculography, and gyroscope signals. The system enables the user to control aspects such as start, stop, turning, acceleration, and deceleration of a car.", "target": "The authors propose a hybrid BCI control system that uses electroencephalography, electrooculography, and gyroscope signals. The system enables the user to control aspects such as start, stop, turning, acceleration, and deceleration of a car.", "example": "Convert the coordinate to text: [ -0.1706 -15.4142]:"}
{"text": "Convert the coordinate to text: [-5.4499 10.8512]: The authors propose a framework, Multiple User SimulaTors (MUST), that leverages multiple user simulators to optimize ToD systems, addressing the issue of a ToD system being over-fitted to certain user simulators while being under-fitted to others.", "target": "The authors propose a framework, Multiple User SimulaTors (MUST), that leverages multiple user simulators to optimize ToD systems, addressing the issue of a ToD system being over-fitted to certain user simulators while being under-fitted to others.", "example": "Convert the coordinate to text: [-5.4499 10.8512]:"}
{"text": "Convert the coordinate to text: [3.4053 0.4973]: The authors propose 'Post-Abstention', a task that allows models to re-attempt the abstained instances with the aim to increase the 'coverage' of the system without significantly sacrificing its 'accuracy'.", "target": "The authors propose 'Post-Abstention', a task that allows models to re-attempt the abstained instances with the aim to increase the 'coverage' of the system without significantly sacrificing its 'accuracy'.", "example": "Convert the coordinate to text: [3.4053 0.4973]:"}
{"text": "Convert the coordinate to text: [-3.8548 -7.0613]: This paper investigates the role of incidental bilingualism -- unintentional consumption of bilingual signals, including translation examples -- in explaining the translation capabilities of large language models, using the Pathways Language Model (PaLM) as a case study.", "target": "This paper investigates the role of incidental bilingualism -- unintentional consumption of bilingual signals, including translation examples -- in explaining the translation capabilities of large language models, using the Pathways Language Model (PaLM) as a case study.", "example": "Convert the coordinate to text: [-3.8548 -7.0613]:"}
{"text": "Convert the coordinate to text: [-1.0315 -5.1855]: The authors propose a new method known as Constrained Prompt generation (Co-Prompt), a discrete prompt optimization method that estimates the optimum for re-ranking and guides the generated texts from pre-trained language models toward optimal prompts, without requiring a parameter update.", "target": "The authors propose a new method known as Constrained Prompt generation (Co-Prompt), a discrete prompt optimization method that estimates the optimum for re-ranking and guides the generated texts from pre-trained language models toward optimal prompts, without requiring a parameter update.", "example": "Convert the coordinate to text: [-1.0315 -5.1855]:"}
{"text": "Convert the coordinate to text: [-4.5369 -6.6495]: This paper introduces the MultiSim benchmark, consisting of a collection of 27 resources in 12 distinct languages with over 1.7 million complex-simple sentence pairs.", "target": "This paper introduces the MultiSim benchmark, consisting of a collection of 27 resources in 12 distinct languages with over 1.7 million complex-simple sentence pairs.", "example": "Convert the coordinate to text: [-4.5369 -6.6495]:"}
{"text": "Convert the coordinate to text: [ 0.0451 -8.2785]: The authors propose a Deeply coupled Cross-modal Prompt learning (DCP) method based on CLIP that flexibly accommodates the interplay between vision and language with a Cross-Modal Prompt Attention (CMPA) mechanism.", "target": "The authors propose a Deeply coupled Cross-modal Prompt learning (DCP) method based on CLIP that flexibly accommodates the interplay between vision and language with a Cross-Modal Prompt Attention (CMPA) mechanism.", "example": "Convert the coordinate to text: [ 0.0451 -8.2785]:"}
{"text": "Convert the coordinate to text: [ -1.371  -13.3134]: The paper proposes PoGeVon, a model designed to overcome the limitations of existing methods by using a variational autoencoder (VAE) to predict missing values in both node time series features and graph structures. A new node position embedding based on random walk with restart (RWR) in the encoder and a decoder with 3-stage predictions from the perspective of multi-task learning are introduced.", "target": "The paper proposes PoGeVon, a model designed to overcome the limitations of existing methods by using a variational autoencoder (VAE) to predict missing values in both node time series features and graph structures. A new node position embedding based on random walk with restart (RWR) in the encoder and a decoder with 3-stage predictions from the perspective of multi-task learning are introduced.", "example": "Convert the coordinate to text: [ -1.371  -13.3134]:"}
{"text": "Convert the coordinate to text: [6.7763 8.9747]: This paper aims to provide a theoretical justification for the superior performance of learned indexes. It shows that under mild assumptions on data distribution, and the same space complexity as non-learned methods, learned indexes can answer queries in O(log log n) expected query time.", "target": "This paper aims to provide a theoretical justification for the superior performance of learned indexes. It shows that under mild assumptions on data distribution, and the same space complexity as non-learned methods, learned indexes can answer queries in O(log log n) expected query time.", "example": "Convert the coordinate to text: [6.7763 8.9747]:"}
{"text": "Convert the coordinate to text: [-5.2409 -1.1064]: The paper proposes applying disentangled representation learning to extractive summarization to separate the two key factors, context and pattern. This approach aims to improve generalization ability in low-resource settings.", "target": "The paper proposes applying disentangled representation learning to extractive summarization to separate the two key factors, context and pattern. This approach aims to improve generalization ability in low-resource settings.", "example": "Convert the coordinate to text: [-5.2409 -1.1064]:"}
{"text": "Convert the coordinate to text: [-5.6743 -9.5669]: The authors present the interim results of a transformer-based annotation pipeline for Ancient and Medieval Greek.", "target": "The authors present the interim results of a transformer-based annotation pipeline for Ancient and Medieval Greek.", "example": "Convert the coordinate to text: [-5.6743 -9.5669]:"}
{"text": "Convert the coordinate to text: [-1.3497  0.2507]: To address this deficit, the authors introduce Homo-MEX, a novel corpus for detecting LGBT+Phobia in Mexican Spanish.", "target": "To address this deficit, the authors introduce Homo-MEX, a novel corpus for detecting LGBT+Phobia in Mexican Spanish.", "example": "Convert the coordinate to text: [-1.3497  0.2507]:"}
{"text": "Convert the coordinate to text: [-0.4666 -6.4459]: The authors experiment with fine-tuning of hate-tuned Transformer-based models and priming for generative models and propose model-agnostic strategies such as data augmentation techniques combined with active learning and obfuscation of identity terms.", "target": "The authors experiment with fine-tuning of hate-tuned Transformer-based models and priming for generative models and propose model-agnostic strategies such as data augmentation techniques combined with active learning and obfuscation of identity terms.", "example": "Convert the coordinate to text: [-0.4666 -6.4459]:"}
{"text": "Convert the coordinate to text: [-6.2691 -1.8836]: The study proposes an annotation scheme of 16 classes for categorizing each sentence in patent descriptions based on their discursive roles.", "target": "The study proposes an annotation scheme of 16 classes for categorizing each sentence in patent descriptions based on their discursive roles.", "example": "Convert the coordinate to text: [-6.2691 -1.8836]:"}
{"text": "Convert the coordinate to text: [-3.7112 -8.3708]: Huawei Translation Service Center (HW-TSC) employs a multi-stage pre-training method to train a bilingual or multilingual neural machine translation (NMT) model as the basic model. They then use domain adaptation and reranking-based transductive learning methods to improve the formality control capability of the model with minimal impact on the general translation quality.", "target": "Huawei Translation Service Center (HW-TSC) employs a multi-stage pre-training method to train a bilingual or multilingual neural machine translation (NMT) model as the basic model. They then use domain adaptation and reranking-based transductive learning methods to improve the formality control capability of the model with minimal impact on the general translation quality.", "example": "Convert the coordinate to text: [-3.7112 -8.3708]:"}
{"text": "Convert the coordinate to text: [-2.151  -6.6574]: This paper proposes a method that reinforces the semantic awareness of a pre-trained language model by utilizing hierarchical structure information in a two-step fine-tuning mechanism, and also prunes unpromising directions in semantic structure parsing using inductive grammar.", "target": "This paper proposes a method that reinforces the semantic awareness of a pre-trained language model by utilizing hierarchical structure information in a two-step fine-tuning mechanism, and also prunes unpromising directions in semantic structure parsing using inductive grammar.", "example": "Convert the coordinate to text: [-2.151  -6.6574]:"}
{"text": "Convert the coordinate to text: [ 1.1284 -1.0241]: The paper presents a method called Dig out Discrimination information from Generated samples (DDG), which constructs positive and negative samples in vision and language modalities without requiring additional annotations, introduces a knowledge distillation mechanism to enhance the learning of original samples by positive ones and encourages VQA models to focus on vision and language modalities using the negative samples.", "target": "The paper presents a method called Dig out Discrimination information from Generated samples (DDG), which constructs positive and negative samples in vision and language modalities without requiring additional annotations, introduces a knowledge distillation mechanism to enhance the learning of original samples by positive ones and encourages VQA models to focus on vision and language modalities using the negative samples.", "example": "Convert the coordinate to text: [ 1.1284 -1.0241]:"}
{"text": "Convert the coordinate to text: [-2.3966 -5.5495]: The paper investigates the potential of applying closed-source large language models (LLMs), specifically ChatGPT, to VDM assignments in real-world security management scenarios.", "target": "The paper investigates the potential of applying closed-source large language models (LLMs), specifically ChatGPT, to VDM assignments in real-world security management scenarios.", "example": "Convert the coordinate to text: [-2.3966 -5.5495]:"}
{"text": "Convert the coordinate to text: [-7.6853 -8.9954]: This study analyzes how SSAs replace words in original sentences and observes that current SSAs often generate invalid adversarial samples due to ungrammatical substitutions or changes in the original sentence's semantics.", "target": "This study analyzes how SSAs replace words in original sentences and observes that current SSAs often generate invalid adversarial samples due to ungrammatical substitutions or changes in the original sentence's semantics.", "example": "Convert the coordinate to text: [-7.6853 -8.9954]:"}
{"text": "Convert the coordinate to text: [-7.1269 10.1824]: The authors introduce PersLEARN, a tool designed to help cultivate scientific perspectives, starting from a basic idea and progressing to a well-articulated framework. This is facilitated through interaction with a prompt-based model.", "target": "The authors introduce PersLEARN, a tool designed to help cultivate scientific perspectives, starting from a basic idea and progressing to a well-articulated framework. This is facilitated through interaction with a prompt-based model.", "example": "Convert the coordinate to text: [-7.1269 10.1824]:"}
{"text": "Convert the coordinate to text: [ 8.1506 -5.8724]: This study expands the understanding of frequency shortcuts in neural networks by investigating their behavior in classification tasks. It proposes a metric to measure class-wise frequency characteristics and a method to identify frequency shortcuts.", "target": "This study expands the understanding of frequency shortcuts in neural networks by investigating their behavior in classification tasks. It proposes a metric to measure class-wise frequency characteristics and a method to identify frequency shortcuts.", "example": "Convert the coordinate to text: [ 8.1506 -5.8724]:"}
{"text": "Convert the coordinate to text: [12.3464  3.5345]: The authors propose an innovative application of the matrix mechanism using lower-triangular matrices in the continual observation model. They provide a detailed factorization for the counting matrix and offer an explicit upper bound to the error.", "target": "The authors propose an innovative application of the matrix mechanism using lower-triangular matrices in the continual observation model. They provide a detailed factorization for the counting matrix and offer an explicit upper bound to the error.", "example": "Convert the coordinate to text: [12.3464  3.5345]:"}
{"text": "Convert the coordinate to text: [ 6.7688 -7.7672]: This paper presents DataDAM, a new method for efficient Dataset Distillation with Attention Matching. The method generates synthetic images by matching the spatial attention maps of real and synthetic data produced by various layers of a randomly initialized neural network.", "target": "This paper presents DataDAM, a new method for efficient Dataset Distillation with Attention Matching. The method generates synthetic images by matching the spatial attention maps of real and synthetic data produced by various layers of a randomly initialized neural network.", "example": "Convert the coordinate to text: [ 6.7688 -7.7672]:"}
{"text": "Convert the coordinate to text: [ 12.8466 -16.952 ]: The paper proposes a flux probing theory that draws insights from stochastic calculus to enable reconstruction of a pixel\u2019s time-varying flux from a stream of monotonically-increasing photon detection timestamps, illuminating a novel Fourier-domain flux reconstruction algorithm.", "target": "The paper proposes a flux probing theory that draws insights from stochastic calculus to enable reconstruction of a pixel\u2019s time-varying flux from a stream of monotonically-increasing photon detection timestamps, illuminating a novel Fourier-domain flux reconstruction algorithm.", "example": "Convert the coordinate to text: [ 12.8466 -16.952 ]:"}
{"text": "Convert the coordinate to text: [ 3.386  -9.4305]: This paper proposes a new framework, LongMoment-Detr, that tackles the challenge of moment detection in long tutorial videos by introducing the first dataset of untrimmed, long-form tutorial videos, the Behance Moment Detection (BMD) dataset.", "target": "This paper proposes a new framework, LongMoment-Detr, that tackles the challenge of moment detection in long tutorial videos by introducing the first dataset of untrimmed, long-form tutorial videos, the Behance Moment Detection (BMD) dataset.", "example": "Convert the coordinate to text: [ 3.386  -9.4305]:"}
{"text": "Convert the coordinate to text: [10.8496 -6.5649]: The authors propose a novel method called PIRNet that performs privacy-preserving image restoration in the steganographic domain. This includes a Lifting-based Invertible Hiding network to conceal the secret image and a Lifting-based Secure Restoration network to restore images in the steganographic domain.", "target": "The authors propose a novel method called PIRNet that performs privacy-preserving image restoration in the steganographic domain. This includes a Lifting-based Invertible Hiding network to conceal the secret image and a Lifting-based Secure Restoration network to restore images in the steganographic domain.", "example": "Convert the coordinate to text: [10.8496 -6.5649]:"}
{"text": "Convert the coordinate to text: [10.7299  2.2049]: The authors propose a novel spectral clustering algorithm based on a vertex embedding with $O(\\log(k))$ vectors computed by the power method, making the algorithm significantly faster.", "target": "The authors propose a novel spectral clustering algorithm based on a vertex embedding with $O(\\log(k))$ vectors computed by the power method, making the algorithm significantly faster.", "example": "Convert the coordinate to text: [10.7299  2.2049]:"}
{"text": "Convert the coordinate to text: [-6.7097  5.834 ]: The authors explore the relationship between the use of narrative style in a tweet and the spread of health misinformation on Twitter, proposing that the narrative usage may lead to increased user engagement even with misinformation.", "target": "The authors explore the relationship between the use of narrative style in a tweet and the spread of health misinformation on Twitter, proposing that the narrative usage may lead to increased user engagement even with misinformation.", "example": "Convert the coordinate to text: [-6.7097  5.834 ]:"}
{"text": "Convert the coordinate to text: [-0.9271 -6.8098]: The team proposes a cross-lingual transfer learning approach that uses a Head-First Fine-Tuning (HeFiT) method, which first updates the regression head parameters and then also updates the pretrained transformer encoder parameters at a reduced learning rate. They also investigate the impact of leveraging ChatGPT to generate synthetic examples in low-resource settings.", "target": "The team proposes a cross-lingual transfer learning approach that uses a Head-First Fine-Tuning (HeFiT) method, which first updates the regression head parameters and then also updates the pretrained transformer encoder parameters at a reduced learning rate. They also investigate the impact of leveraging ChatGPT to generate synthetic examples in low-resource settings.", "example": "Convert the coordinate to text: [-0.9271 -6.8098]:"}
{"text": "Convert the coordinate to text: [  9.8815 -17.8068]: The authors propose a framework called Zero-1-to-3, that is capable of changing the camera viewpoint of an object given just a single RGB image by capitalizing on geometric priors that large-scale diffusion models learn about natural images.", "target": "The authors propose a framework called Zero-1-to-3, that is capable of changing the camera viewpoint of an object given just a single RGB image by capitalizing on geometric priors that large-scale diffusion models learn about natural images.", "example": "Convert the coordinate to text: [  9.8815 -17.8068]:"}
{"text": "Convert the coordinate to text: [12.8945  2.3322]: The authors introduce COCKATIEL, a post-hoc, concept-based, model-agnostic XAI technique that uses Non-Negative Matrix Factorization (NMF) to discover the concepts the model leverages, and Sensitivity Analysis to estimate the importance of each of these concepts for the model.", "target": "The authors introduce COCKATIEL, a post-hoc, concept-based, model-agnostic XAI technique that uses Non-Negative Matrix Factorization (NMF) to discover the concepts the model leverages, and Sensitivity Analysis to estimate the importance of each of these concepts for the model.", "example": "Convert the coordinate to text: [12.8945  2.3322]:"}
{"text": "Convert the coordinate to text: [ 5.7006 14.9647]: The authors propose a decision-based MIM that utilizes reinforcement learning (RL) to automatically search for optimal image masking ratio and masking strategy. Each input patch is treated as an agent with a shared behavior policy, allowing for multi-agent collaboration.", "target": "The authors propose a decision-based MIM that utilizes reinforcement learning (RL) to automatically search for optimal image masking ratio and masking strategy. Each input patch is treated as an agent with a shared behavior policy, allowing for multi-agent collaboration.", "example": "Convert the coordinate to text: [ 5.7006 14.9647]:"}
{"text": "Convert the coordinate to text: [-4.8798 -7.4476]: The paper introduces disambiguated LCNMT (D-LCNMT), a robust two-stage framework, that firstly disambiguates constraints based on context, and then integrates the disambiguated constraints into LCNMT.", "target": "The paper introduces disambiguated LCNMT (D-LCNMT), a robust two-stage framework, that firstly disambiguates constraints based on context, and then integrates the disambiguated constraints into LCNMT.", "example": "Convert the coordinate to text: [-4.8798 -7.4476]:"}
{"text": "Convert the coordinate to text: [12.2211 -4.4857]: The authors introduce a novel training technique for the unsupervised selective rationalization architecture by injecting noise between the rationale generator and the predictor, aiming to limit the generation of implausible rationales.", "target": "The authors introduce a novel training technique for the unsupervised selective rationalization architecture by injecting noise between the rationale generator and the predictor, aiming to limit the generation of implausible rationales.", "example": "Convert the coordinate to text: [12.2211 -4.4857]:"}
{"text": "Convert the coordinate to text: [-6.008  -7.3191]: The authors propose the hypothesis that the effectiveness of a text classification representation is due to its alignment with the task, rather than its geometric properties of the space.", "target": "The authors propose the hypothesis that the effectiveness of a text classification representation is due to its alignment with the task, rather than its geometric properties of the space.", "example": "Convert the coordinate to text: [-6.008  -7.3191]:"}
{"text": "Convert the coordinate to text: [-1.8272  2.9962]: This paper introduces two strategies for rank-heterogeneous choice modelling in the context of school choice: adapting a context-dependent random utility model (CDM) that considers down-rank choices as occurring in context of earlier up-rank choices, and stratifying the choice modelling by rank, regularizing rank-adjacent models towards one another when appropriate.", "target": "This paper introduces two strategies for rank-heterogeneous choice modelling in the context of school choice: adapting a context-dependent random utility model (CDM) that considers down-rank choices as occurring in context of earlier up-rank choices, and stratifying the choice modelling by rank, regularizing rank-adjacent models towards one another when appropriate.", "example": "Convert the coordinate to text: [-1.8272  2.9962]:"}
{"text": "Convert the coordinate to text: [-11.1721   0.7633]: The authors propose Auto-Validate-by-History (AVH) to automatically detect data quality issues in recurring pipelines by leveraging historical execution statistics.", "target": "The authors propose Auto-Validate-by-History (AVH) to automatically detect data quality issues in recurring pipelines by leveraging historical execution statistics.", "example": "Convert the coordinate to text: [-11.1721   0.7633]:"}
{"text": "Convert the coordinate to text: [-8.0448 -2.01  ]: The paper proposes a boundary-relaxed annotation approach aiming to simplify the annotation process, potentially reducing the workload and speeding up the annotation process.", "target": "The paper proposes a boundary-relaxed annotation approach aiming to simplify the annotation process, potentially reducing the workload and speeding up the annotation process.", "example": "Convert the coordinate to text: [-8.0448 -2.01  ]:"}
{"text": "Convert the coordinate to text: [ 7.0824 -4.5167]: A new task, Cross-domain Query-based Visual Segmentation (CQVS), is examined, looking to adapt the segmentation model from a labeled domain to a new unlabeled domain. The paper also proposes a novel framework called Semantic-conditioned Dual Adaptation (SDA) to achieve precise feature- and relation-invariance across domains using a universal semantic structure.", "target": "A new task, Cross-domain Query-based Visual Segmentation (CQVS), is examined, looking to adapt the segmentation model from a labeled domain to a new unlabeled domain. The paper also proposes a novel framework called Semantic-conditioned Dual Adaptation (SDA) to achieve precise feature- and relation-invariance across domains using a universal semantic structure.", "example": "Convert the coordinate to text: [ 7.0824 -4.5167]:"}
{"text": "Convert the coordinate to text: [-3.9443  0.9076]: The authors propose a transformer language model combined with a lexicon of terms and emojis used in a post-processing filtering stage for sentiment analysis of Algerian dialect. The sentiment lexicons are manually extracted from tweets.", "target": "The authors propose a transformer language model combined with a lexicon of terms and emojis used in a post-processing filtering stage for sentiment analysis of Algerian dialect. The sentiment lexicons are manually extracted from tweets.", "example": "Convert the coordinate to text: [-3.9443  0.9076]:"}
{"text": "Convert the coordinate to text: [-1.4221  0.0377]: The authors tackle the problem of online sexism detection using large language models like RoBERTa and DeBERTa. They introduce Random Layer Adversarial Training (RLAT) for transformers, and utilise techniques like virtual adversarial training and contrastive learning for subtask A.", "target": "The authors tackle the problem of online sexism detection using large language models like RoBERTa and DeBERTa. They introduce Random Layer Adversarial Training (RLAT) for transformers, and utilise techniques like virtual adversarial training and contrastive learning for subtask A.", "example": "Convert the coordinate to text: [-1.4221  0.0377]:"}
{"text": "Convert the coordinate to text: [-3.1825 -8.5283]: The systems submitted by Xiaomi AI Lab for these three tracks are built using large-scale pre-trained models, which are then fine-tuned for specific downstream speech translation tasks; techniques such as data filtering, data augmentation, speech segmentation, and model ensemble are also implemented.", "target": "The systems submitted by Xiaomi AI Lab for these three tracks are built using large-scale pre-trained models, which are then fine-tuned for specific downstream speech translation tasks; techniques such as data filtering, data augmentation, speech segmentation, and model ensemble are also implemented.", "example": "Convert the coordinate to text: [-3.1825 -8.5283]:"}
{"text": "Convert the coordinate to text: [-4.4244 -4.8969]: The paper presents an approach for cross-domain automated measurement and context extraction using pre-trained language models, which are trained end-to-end on a constructed multi-source, multi-domain corpus.", "target": "The paper presents an approach for cross-domain automated measurement and context extraction using pre-trained language models, which are trained end-to-end on a constructed multi-source, multi-domain corpus.", "example": "Convert the coordinate to text: [-4.4244 -4.8969]:"}
{"text": "Convert the coordinate to text: [-1.8443 -3.1222]: The authors present FolkScope, an intention knowledge graph construction framework, to reveal the structure of humans\u2019 minds about purchasing items. They propose a new approach that leverages the generation power of large language models (LLMs) and human-in-the-loop annotation to semi-automatically construct the knowledge graph.", "target": "The authors present FolkScope, an intention knowledge graph construction framework, to reveal the structure of humans\u2019 minds about purchasing items. They propose a new approach that leverages the generation power of large language models (LLMs) and human-in-the-loop annotation to semi-automatically construct the knowledge graph.", "example": "Convert the coordinate to text: [-1.8443 -3.1222]:"}
{"text": "Convert the coordinate to text: [-10.3508  -0.7167]: The authors propose a unified contextual query rewriting model that can handle both friction reduction and contextual carryover. They also introduce multiple auxiliary tasks like trigger prediction and NLU interpretation to improve the rewrite performance.", "target": "The authors propose a unified contextual query rewriting model that can handle both friction reduction and contextual carryover. They also introduce multiple auxiliary tasks like trigger prediction and NLU interpretation to improve the rewrite performance.", "example": "Convert the coordinate to text: [-10.3508  -0.7167]:"}
{"text": "Convert the coordinate to text: [ 0.2531 -8.6978]: The authors propose a Knowledge-guided Fashion-domain Language-Image Pre-training (FLIP) framework that focuses on learning fine-grained representations in the e-commerce domain with the help of external knowledge (product attribute schema) to enhance pre-training efficiency.", "target": "The authors propose a Knowledge-guided Fashion-domain Language-Image Pre-training (FLIP) framework that focuses on learning fine-grained representations in the e-commerce domain with the help of external knowledge (product attribute schema) to enhance pre-training efficiency.", "example": "Convert the coordinate to text: [ 0.2531 -8.6978]:"}
{"text": "Convert the coordinate to text: [-3.3518 -7.9173]: In this study, the authors propose to improve the performance of transformer-based models for MT of spoken language text to SL glosses by using four strategies: data augmentation, semi-supervised Neural Machine Translation (NMT), transfer learning, and multilingual NMT.", "target": "In this study, the authors propose to improve the performance of transformer-based models for MT of spoken language text to SL glosses by using four strategies: data augmentation, semi-supervised Neural Machine Translation (NMT), transfer learning, and multilingual NMT.", "example": "Convert the coordinate to text: [-3.3518 -7.9173]:"}
{"text": "Convert the coordinate to text: [8.9613 3.0663]: The authors propose a new filter function based on a data-dependent kernel for TDA, aiming to address the problem of noise and varied densities.", "target": "The authors propose a new filter function based on a data-dependent kernel for TDA, aiming to address the problem of noise and varied densities.", "example": "Convert the coordinate to text: [8.9613 3.0663]:"}
{"text": "Convert the coordinate to text: [ 7.6947 -4.4983]: This paper introduces a new strategy called Adapter Re-Composing (ARC) for efficient pre-trained model adaptation. The strategy considers the reusability of adaptation parameters and introduces a parameter-sharing scheme using symmetric down-/up-projections to construct bottleneck operations, which are shared across layers. Learning low-dimensional re-scaling coefficients allows the re-composition of layer-adaptive adapters.", "target": "This paper introduces a new strategy called Adapter Re-Composing (ARC) for efficient pre-trained model adaptation. The strategy considers the reusability of adaptation parameters and introduces a parameter-sharing scheme using symmetric down-/up-projections to construct bottleneck operations, which are shared across layers. Learning low-dimensional re-scaling coefficients allows the re-composition of layer-adaptive adapters.", "example": "Convert the coordinate to text: [ 7.6947 -4.4983]:"}
{"text": "Convert the coordinate to text: [5.7338 0.5253]: The authors propose a novel class of training objectives based on convex functions, allowing text generation models to concentrate on highly probable outputs without the need to estimate the entire data distribution.", "target": "The authors propose a novel class of training objectives based on convex functions, allowing text generation models to concentrate on highly probable outputs without the need to estimate the entire data distribution.", "example": "Convert the coordinate to text: [5.7338 0.5253]:"}
{"text": "Convert the coordinate to text: [ 4.237  -0.8358]: In this paper, the authors propose a novel approach of using instance-dependent thresholds for pseudo-labeling, where thresholds are determined by the instance-level ambiguity and the instance-dependent error rates of pseudo-labels.", "target": "In this paper, the authors propose a novel approach of using instance-dependent thresholds for pseudo-labeling, where thresholds are determined by the instance-level ambiguity and the instance-dependent error rates of pseudo-labels.", "example": "Convert the coordinate to text: [ 4.237  -0.8358]:"}
{"text": "Convert the coordinate to text: [-3.7314 -1.2582]: The authors propose creating a graph structure based on the relative placements of events along the time axis to link all temporally-scoped sentences, as well as RemeMo (Relative Time Modeling), a model that explicitly connects all temporally-scoped facts by modeling the time relations between any two sentences.", "target": "The authors propose creating a graph structure based on the relative placements of events along the time axis to link all temporally-scoped sentences, as well as RemeMo (Relative Time Modeling), a model that explicitly connects all temporally-scoped facts by modeling the time relations between any two sentences.", "example": "Convert the coordinate to text: [-3.7314 -1.2582]:"}
{"text": "Convert the coordinate to text: [ 6.96   13.2437]: To address the OOD problem in offline RL, the authors propose a Constrained Policy optimization with Explicit Behavior density (CPED) method that leverages a flow-GAN model to explicitly estimate the density of the behavior policy.", "target": "To address the OOD problem in offline RL, the authors propose a Constrained Policy optimization with Explicit Behavior density (CPED) method that leverages a flow-GAN model to explicitly estimate the density of the behavior policy.", "example": "Convert the coordinate to text: [ 6.96   13.2437]:"}
{"text": "Convert the coordinate to text: [-3.9478 -1.3629]: This study proposes a new task of event-location tracking in narrative texts, which intends to extract the sequence of locations where the narrative unfolds and introduces several architectures with varying levels of context awareness.", "target": "This study proposes a new task of event-location tracking in narrative texts, which intends to extract the sequence of locations where the narrative unfolds and introduces several architectures with varying levels of context awareness.", "example": "Convert the coordinate to text: [-3.9478 -1.3629]:"}
{"text": "Convert the coordinate to text: [ 6.9911 -9.8882]: A novel two-stream deep neural network tracker is proposed that uses both spatial and temporal features and employs a new loss function called ranking loss. This system is designed to provide more precise bounding boxes for tracked objects, reducing tracking error.", "target": "A novel two-stream deep neural network tracker is proposed that uses both spatial and temporal features and employs a new loss function called ranking loss. This system is designed to provide more precise bounding boxes for tracked objects, reducing tracking error.", "example": "Convert the coordinate to text: [ 6.9911 -9.8882]:"}
{"text": "Convert the coordinate to text: [ 5.9224 13.6666]: The authors identify three common instances where this faulty reward assignment occurs: noise-induced spurious correlation, naturally occurring spurious correlation, and covariate shift. They claim these patterns may be amplified during the reinforcement learning training of the text generation model.", "target": "The authors identify three common instances where this faulty reward assignment occurs: noise-induced spurious correlation, naturally occurring spurious correlation, and covariate shift. They claim these patterns may be amplified during the reinforcement learning training of the text generation model.", "example": "Convert the coordinate to text: [ 5.9224 13.6666]:"}
{"text": "Convert the coordinate to text: [-3.2245 -5.4291]: This work investigates the distractibility of large language models, that is, how model problem-solving accuracy can be affected by irrelevant context. Additionally, the authors introduce the Grade-School Math with Irrelevant Context (GSM-IC), a dataset designed to measure this distractibility", "target": "This work investigates the distractibility of large language models, that is, how model problem-solving accuracy can be affected by irrelevant context. Additionally, the authors introduce the Grade-School Math with Irrelevant Context (GSM-IC), a dataset designed to measure this distractibility", "example": "Convert the coordinate to text: [-3.2245 -5.4291]:"}
{"text": "Convert the coordinate to text: [ 2.6449 -5.1276]: The authors propose a Parameter and Embedding Personalized Network (PEPNet) for multi-task recommendation in a multi-domain context. This approach utilizes features with strong biases as input and dynamically scales the bottom-layer embeddings and the top-layer DNN hidden units in the model through a gate mechanism.", "target": "The authors propose a Parameter and Embedding Personalized Network (PEPNet) for multi-task recommendation in a multi-domain context. This approach utilizes features with strong biases as input and dynamically scales the bottom-layer embeddings and the top-layer DNN hidden units in the model through a gate mechanism.", "example": "Convert the coordinate to text: [ 2.6449 -5.1276]:"}
{"text": "Convert the coordinate to text: [  1.3197 -13.5474]: The authors propose a learning approach - CADParser - that infers modeling sequences from a B-Rep CAD model, treating the CAD geometry as a graph and the construction workflow as a sequence. They also introduce a new large-scale dataset with diverse operations.", "target": "The authors propose a learning approach - CADParser - that infers modeling sequences from a B-Rep CAD model, treating the CAD geometry as a graph and the construction workflow as a sequence. They also introduce a new large-scale dataset with diverse operations.", "example": "Convert the coordinate to text: [  1.3197 -13.5474]:"}
{"text": "Convert the coordinate to text: [ 0.4289 -4.573 ]: The authors propose a new paradigm, self-supervised tuning, which solves zero-shot text classification tasks by tuning language models with unlabeled data. They introduce a new learning objective called first sentence prediction to bridge the gap between unlabeled data and text classification tasks.", "target": "The authors propose a new paradigm, self-supervised tuning, which solves zero-shot text classification tasks by tuning language models with unlabeled data. They introduce a new learning objective called first sentence prediction to bridge the gap between unlabeled data and text classification tasks.", "example": "Convert the coordinate to text: [ 0.4289 -4.573 ]:"}
{"text": "Convert the coordinate to text: [-6.1553 -0.8434]: The authors introduce SciReviewGen, a large-scale dataset for training automatic literature review generating models, consisting of over 10,000 literature reviews and 690,000 papers cited in these reviews.", "target": "The authors introduce SciReviewGen, a large-scale dataset for training automatic literature review generating models, consisting of over 10,000 literature reviews and 690,000 papers cited in these reviews.", "example": "Convert the coordinate to text: [-6.1553 -0.8434]:"}
{"text": "Convert the coordinate to text: [-5.6935  0.7261]: The authors propose a solution to the Argument Quadruplet Extraction task (AQE) which extracts four argumentative components: claims, evidence, evidence types, and stances.", "target": "The authors propose a solution to the Argument Quadruplet Extraction task (AQE) which extracts four argumentative components: claims, evidence, evidence types, and stances.", "example": "Convert the coordinate to text: [-5.6935  0.7261]:"}
{"text": "Convert the coordinate to text: [0.6519 1.3864]: The authors propose a novel counterfactual data augmentation approach using verb replacement for the identification of medical claims.", "target": "The authors propose a novel counterfactual data augmentation approach using verb replacement for the identification of medical claims.", "example": "Convert the coordinate to text: [0.6519 1.3864]:"}
{"text": "Convert the coordinate to text: [  2.6401 -10.6181]: The authors focus on Stable Diffusion, a leading open source text-to-image model, and propose a multi-positive contrastive learning method, StableRep, to deal with synthetic images generating from the same text prompt.", "target": "The authors focus on Stable Diffusion, a leading open source text-to-image model, and propose a multi-positive contrastive learning method, StableRep, to deal with synthetic images generating from the same text prompt.", "example": "Convert the coordinate to text: [  2.6401 -10.6181]:"}
{"text": "Convert the coordinate to text: [-0.2947  2.5917]: The authors propose a path-specific fair Recommender System (PSF-RS) which targets both fair and unfair correlations between sensitive features and observed ratings. The aim is to mitigate the biases and preserve the necessary diversity in recommendations.", "target": "The authors propose a path-specific fair Recommender System (PSF-RS) which targets both fair and unfair correlations between sensitive features and observed ratings. The aim is to mitigate the biases and preserve the necessary diversity in recommendations.", "example": "Convert the coordinate to text: [-0.2947  2.5917]:"}
{"text": "Convert the coordinate to text: [ 0.214  -3.6846]: In this paper, the authors propose a novel framework named HypEmo that integrates hyperbolic embeddings to improve the FEC task. This is achieved by learning label embeddings in hyperbolic space to capture their hierarchical structure, and then projecting contextualized representations to the hyperbolic space to compute the distance between samples and labels.", "target": "In this paper, the authors propose a novel framework named HypEmo that integrates hyperbolic embeddings to improve the FEC task. This is achieved by learning label embeddings in hyperbolic space to capture their hierarchical structure, and then projecting contextualized representations to the hyperbolic space to compute the distance between samples and labels.", "example": "Convert the coordinate to text: [ 0.214  -3.6846]:"}
{"text": "Convert the coordinate to text: [-4.1479 -7.2833]: The authors propose to create a multilingual code search dataset in four natural and four programming languages using a neural machine translation model.", "target": "The authors propose to create a multilingual code search dataset in four natural and four programming languages using a neural machine translation model.", "example": "Convert the coordinate to text: [-4.1479 -7.2833]:"}
{"text": "Convert the coordinate to text: [-2.4002  0.3479]: The authors introduce a weakly supervised classifier and dataset for detecting the language of white supremacist extremism. The classifier is trained on large datasets of text from explicitly white supremacist domains, with neutral and anti-racist data from similar domains used as counterexamples.", "target": "The authors introduce a weakly supervised classifier and dataset for detecting the language of white supremacist extremism. The classifier is trained on large datasets of text from explicitly white supremacist domains, with neutral and anti-racist data from similar domains used as counterexamples.", "example": "Convert the coordinate to text: [-2.4002  0.3479]:"}
{"text": "Convert the coordinate to text: [-7.432  -3.2844]: A new category of sensitive text called 'delicate text' is introduced and defined. A taxonomy of delicate text and a detailed annotation scheme are provided.", "target": "A new category of sensitive text called 'delicate text' is introduced and defined. A taxonomy of delicate text and a detailed annotation scheme are provided.", "example": "Convert the coordinate to text: [-7.432  -3.2844]:"}
{"text": "Convert the coordinate to text: [-1.7116 -6.4904]: The team uses base transformer models, specifically DistilBERT and BERT, to tackle the complex NEs recognition task in five languages. They establish DistilBERT as a baseline and use BERT to create an improved model.", "target": "The team uses base transformer models, specifically DistilBERT and BERT, to tackle the complex NEs recognition task in five languages. They establish DistilBERT as a baseline and use BERT to create an improved model.", "example": "Convert the coordinate to text: [-1.7116 -6.4904]:"}
{"text": "Convert the coordinate to text: [ 0.0382 -4.8882]: This paper presents a method called disentangled domain-slot attention for multi-domain dialogue state tracking, which allows extraction of domain-slot specific information in a context-dependent way by separating queries about domains and slots in the attention component.", "target": "This paper presents a method called disentangled domain-slot attention for multi-domain dialogue state tracking, which allows extraction of domain-slot specific information in a context-dependent way by separating queries about domains and slots in the attention component.", "example": "Convert the coordinate to text: [ 0.0382 -4.8882]:"}
{"text": "Convert the coordinate to text: [ 4.0374 -4.0042]: The authors propose an FDISTILL framework which formulates sequence-level knowledge distillation as minimizing a generalized f-divergence function. Four distilling variants under this framework are also proposed.", "target": "The authors propose an FDISTILL framework which formulates sequence-level knowledge distillation as minimizing a generalized f-divergence function. Four distilling variants under this framework are also proposed.", "example": "Convert the coordinate to text: [ 4.0374 -4.0042]:"}
{"text": "Convert the coordinate to text: [ 7.9591 -3.3041]: The authors propose consistency regularization training to improve Transformer's capability on compositional generalization without modifying the model architectures. This method promotes representation consistency across samples and prediction consistency for a single sample.", "target": "The authors propose consistency regularization training to improve Transformer's capability on compositional generalization without modifying the model architectures. This method promotes representation consistency across samples and prediction consistency for a single sample.", "example": "Convert the coordinate to text: [ 7.9591 -3.3041]:"}
{"text": "Convert the coordinate to text: [-4.504   1.6911]: The authors propose CrowdOpinion, an unsupervised learning approach that uses language features and label distributions to pool similar items into larger samples, thus making sense of subjective data in a way that accommodates annotator disagreements.", "target": "The authors propose CrowdOpinion, an unsupervised learning approach that uses language features and label distributions to pool similar items into larger samples, thus making sense of subjective data in a way that accommodates annotator disagreements.", "example": "Convert the coordinate to text: [-4.504   1.6911]:"}
{"text": "Convert the coordinate to text: [ 8.8102 -7.4262]: The authors propose a novel Reconstructed Convolution (RC) module that decouples channel-wise and spatial calculation, enabling the maintenance of $n  imes n$ receptive fields with $n^2$ 1D LUTs, resulting in considerably smaller LUT size.", "target": "The authors propose a novel Reconstructed Convolution (RC) module that decouples channel-wise and spatial calculation, enabling the maintenance of $n  imes n$ receptive fields with $n^2$ 1D LUTs, resulting in considerably smaller LUT size.", "example": "Convert the coordinate to text: [ 8.8102 -7.4262]:"}
{"text": "Convert the coordinate to text: [ 5.8769 -7.7787]: The authors propose a wave superposition inspired social pooling (Wave-pooling), which models each vehicle as a wave with amplitude and phase, to dynamically aggregate the high-order interactions from both local and global neighbor vehicles. The authors also introduce an encoder-decoder-based learning framework called WSiP, which integrates Wave-pooling.", "target": "The authors propose a wave superposition inspired social pooling (Wave-pooling), which models each vehicle as a wave with amplitude and phase, to dynamically aggregate the high-order interactions from both local and global neighbor vehicles. The authors also introduce an encoder-decoder-based learning framework called WSiP, which integrates Wave-pooling.", "example": "Convert the coordinate to text: [ 5.8769 -7.7787]:"}
{"text": "Convert the coordinate to text: [ 7.1099 -4.1818]: The authors propose the Informative Data Mining (IDM) framework, a new approach to one-shot domain adaptation for semantic segmentation. The IDM framework uses an uncertainty-based selection criterion for identifying the most informative samples in order to accelerate adaptation and lessen redundant training.", "target": "The authors propose the Informative Data Mining (IDM) framework, a new approach to one-shot domain adaptation for semantic segmentation. The IDM framework uses an uncertainty-based selection criterion for identifying the most informative samples in order to accelerate adaptation and lessen redundant training.", "example": "Convert the coordinate to text: [ 7.1099 -4.1818]:"}
{"text": "Convert the coordinate to text: [ 6.7889 -4.0634]: The authors propose the Unified Domain Incremental Learning (UDIL) framework, a unified approach to domain incremental learning with memory that allows for adaptive coefficients during training, promising a tighter generalization error bound.", "target": "The authors propose the Unified Domain Incremental Learning (UDIL) framework, a unified approach to domain incremental learning with memory that allows for adaptive coefficients during training, promising a tighter generalization error bound.", "example": "Convert the coordinate to text: [ 6.7889 -4.0634]:"}
{"text": "Convert the coordinate to text: [-5.3008 -1.5068]: In this paper, a novel retrieval model Longtriever is proposed that splits long documents into short blocks and then efficiently models the local semantics within a block and the global context semantics across blocks in a tightly-coupled manner. A pre-training phase is also introduced to empower Longtriever to better understand underlying semantic correlations.", "target": "In this paper, a novel retrieval model Longtriever is proposed that splits long documents into short blocks and then efficiently models the local semantics within a block and the global context semantics across blocks in a tightly-coupled manner. A pre-training phase is also introduced to empower Longtriever to better understand underlying semantic correlations.", "example": "Convert the coordinate to text: [-5.3008 -1.5068]:"}
{"text": "Convert the coordinate to text: [-3.1324 -4.5713]: The authors develop a taxonomy of disagreement in the conceptualization of NLP tasks and operationalization of model performance measurements. They propose a framework for constructing benchmarks and documenting their limitations.", "target": "The authors develop a taxonomy of disagreement in the conceptualization of NLP tasks and operationalization of model performance measurements. They propose a framework for constructing benchmarks and documenting their limitations.", "example": "Convert the coordinate to text: [-3.1324 -4.5713]:"}
{"text": "Convert the coordinate to text: [-1.9858 -4.3907]: The authors aim to bridge this gap by reformulating EAE as a problem of table generation and extending a state-of-the-art prompt-based EAE model into a non-autoregressive generation framework, TabEAE, which can extract the arguments of multiple events in parallel.", "target": "The authors aim to bridge this gap by reformulating EAE as a problem of table generation and extending a state-of-the-art prompt-based EAE model into a non-autoregressive generation framework, TabEAE, which can extract the arguments of multiple events in parallel.", "example": "Convert the coordinate to text: [-1.9858 -4.3907]:"}
{"text": "Convert the coordinate to text: [-1.1764  0.0503]: The authors propose MISGENDERED, a framework to evaluate large language models' ability to correctly use English gender-neutral pronouns and neo-pronouns used by individuals with non-binary gender identities.", "target": "The authors propose MISGENDERED, a framework to evaluate large language models' ability to correctly use English gender-neutral pronouns and neo-pronouns used by individuals with non-binary gender identities.", "example": "Convert the coordinate to text: [-1.1764  0.0503]:"}
{"text": "Convert the coordinate to text: [-1.3873  0.0994]: The authors propose a sexism detection system based on further domain-adaptive pre-training and Transformer-based models, comparing fine-tuning with multi-task learning to show that each subtask requires a different system configuration.", "target": "The authors propose a sexism detection system based on further domain-adaptive pre-training and Transformer-based models, comparing fine-tuning with multi-task learning to show that each subtask requires a different system configuration.", "example": "Convert the coordinate to text: [-1.3873  0.0994]:"}
{"text": "Convert the coordinate to text: [ 0.1561 -9.3428]: The authors propose a solution which first extends the textual context using word definitions contained in WordNet and in Open English WordNet. Second, it uses the CLIP model to select the most suitable image with the extended word context and additional information obtained from the BEiT image classification model.", "target": "The authors propose a solution which first extends the textual context using word definitions contained in WordNet and in Open English WordNet. Second, it uses the CLIP model to select the most suitable image with the extended word context and additional information obtained from the BEiT image classification model.", "example": "Convert the coordinate to text: [ 0.1561 -9.3428]:"}
{"text": "Convert the coordinate to text: [-5.5449 -0.785 ]: The paper redefines extractive summarization as a salient sentence set recognition task and proposes a set prediction network (SetSum). This network uses a fixed set of learnable queries to extract the entire sentence set of a summary, capturing dependencies between sentences, and employs a non-autoregressive decoder for parallel sentence prediction during both the training and inference process.", "target": "The paper redefines extractive summarization as a salient sentence set recognition task and proposes a set prediction network (SetSum). This network uses a fixed set of learnable queries to extract the entire sentence set of a summary, capturing dependencies between sentences, and employs a non-autoregressive decoder for parallel sentence prediction during both the training and inference process.", "example": "Convert the coordinate to text: [-5.5449 -0.785 ]:"}
{"text": "Convert the coordinate to text: [-5.9468 11.1871]: The key idea is the concept of 'goal awareness' in conversational systems, which is not only being responsive to users but also aware of the target conversational goal and capable of leading the conversation towards it, leading to higher-level intelligence and artificial consciousness.", "target": "The key idea is the concept of 'goal awareness' in conversational systems, which is not only being responsive to users but also aware of the target conversational goal and capable of leading the conversation towards it, leading to higher-level intelligence and artificial consciousness.", "example": "Convert the coordinate to text: [-5.9468 11.1871]:"}
{"text": "Convert the coordinate to text: [-8.7794 -2.2109]: The authors introduce a novel working environment for digital qualitative discourse analysis in DH known as D-WISE Tool Suite (DWTS), which leverages and combines state-of-the-art machine learning technologies from Natural Language Processing and Computer Vision.", "target": "The authors introduce a novel working environment for digital qualitative discourse analysis in DH known as D-WISE Tool Suite (DWTS), which leverages and combines state-of-the-art machine learning technologies from Natural Language Processing and Computer Vision.", "example": "Convert the coordinate to text: [-8.7794 -2.2109]:"}
{"text": "Convert the coordinate to text: [2.2096 4.539 ]: The authors propose a method for better data consumption that works by grouping similar items together and arranging the remaining items into a hierarchical, navigable Directed Acyclic Graph (DAG) structure.", "target": "The authors propose a method for better data consumption that works by grouping similar items together and arranging the remaining items into a hierarchical, navigable Directed Acyclic Graph (DAG) structure.", "example": "Convert the coordinate to text: [2.2096 4.539 ]:"}
{"text": "Convert the coordinate to text: [12.345  -5.2361]: The authors revisit the transferability of adversarial 3D point clouds and make an observation that an adversarial perturbation can be randomly factorized into two sub-perturbations, which can also be adversarial perturbations. This motivates them to consider the effects of the perturbation and its sub-perturbations simultaneously to increase the transferability.", "target": "The authors revisit the transferability of adversarial 3D point clouds and make an observation that an adversarial perturbation can be randomly factorized into two sub-perturbations, which can also be adversarial perturbations. This motivates them to consider the effects of the perturbation and its sub-perturbations simultaneously to increase the transferability.", "example": "Convert the coordinate to text: [12.345  -5.2361]:"}
{"text": "Convert the coordinate to text: [ 8.5009 -9.1592]: Authors introduce a novel architecture, Light Encoder and Heavy Decoder (LEHD), designed to dynamically capture relationships among nodes of varying sizes, thereby improving the generalization capability and applicability to larger scale problems.", "target": "Authors introduce a novel architecture, Light Encoder and Heavy Decoder (LEHD), designed to dynamically capture relationships among nodes of varying sizes, thereby improving the generalization capability and applicability to larger scale problems.", "example": "Convert the coordinate to text: [ 8.5009 -9.1592]:"}
{"text": "Convert the coordinate to text: [5.3002 7.2251]: The authors propose improved core-set construction algorithms for maximizing diversity under fairness/partition constraint. They consider two diversity measures: sum-of-pairwise distances and sum-of-nearest-neighbor distances. The authors also investigate the application of constrained diversity maximization to timely message summarization.", "target": "The authors propose improved core-set construction algorithms for maximizing diversity under fairness/partition constraint. They consider two diversity measures: sum-of-pairwise distances and sum-of-nearest-neighbor distances. The authors also investigate the application of constrained diversity maximization to timely message summarization.", "example": "Convert the coordinate to text: [5.3002 7.2251]:"}
{"text": "Convert the coordinate to text: [-2.808   3.0042]: The authors propose a contextual repeated selection (CRS) model that leverages recent advancements in choice modelling to bring a natural multimodality and richness to the rankings space.", "target": "The authors propose a contextual repeated selection (CRS) model that leverages recent advancements in choice modelling to bring a natural multimodality and richness to the rankings space.", "example": "Convert the coordinate to text: [-2.808   3.0042]:"}
{"text": "Convert the coordinate to text: [ 1.8047 11.7564]: This paper extends the Goal-oriented Script Generation task from the perspective of cognitive theory by proposing hierarchical organization of steps, often decomposing complex tasks into subgoals.", "target": "This paper extends the Goal-oriented Script Generation task from the perspective of cognitive theory by proposing hierarchical organization of steps, often decomposing complex tasks into subgoals.", "example": "Convert the coordinate to text: [ 1.8047 11.7564]:"}
{"text": "Convert the coordinate to text: [-4.4094  9.8956]: This study proposes modeling of media framing from communication sciences that capture elements of narratives such as conflict and resolution, as well as the narrative framing of key entities in the story as heroes, victims or villains.", "target": "This study proposes modeling of media framing from communication sciences that capture elements of narratives such as conflict and resolution, as well as the narrative framing of key entities in the story as heroes, victims or villains.", "example": "Convert the coordinate to text: [-4.4094  9.8956]:"}
{"text": "Convert the coordinate to text: [-0.9846 -7.0187]: The authors utilize causal intervention techniques to expose the functioning of these implicit situation models within transformer models, particularly how they help in interpreting ambiguous pronouns in the context of the Winograd Schema Challenge (WSC).", "target": "The authors utilize causal intervention techniques to expose the functioning of these implicit situation models within transformer models, particularly how they help in interpreting ambiguous pronouns in the context of the Winograd Schema Challenge (WSC).", "example": "Convert the coordinate to text: [-0.9846 -7.0187]:"}
{"text": "Convert the coordinate to text: [-9.7917  7.362 ]: This paper presents ProPILE, a probing tool designed to empower data subjects (owners of the PII) to evaluate potential PII leakage in LLM-based services by formulating prompts based on their own PII.", "target": "This paper presents ProPILE, a probing tool designed to empower data subjects (owners of the PII) to evaluate potential PII leakage in LLM-based services by formulating prompts based on their own PII.", "example": "Convert the coordinate to text: [-9.7917  7.362 ]:"}
{"text": "Convert the coordinate to text: [-1.3431  0.1445]: The study investigates the effect of explicit linguistic features and continuous pretraining on the performance of pretrained language models in sexism detection.", "target": "The study investigates the effect of explicit linguistic features and continuous pretraining on the performance of pretrained language models in sexism detection.", "example": "Convert the coordinate to text: [-1.3431  0.1445]:"}
{"text": "Convert the coordinate to text: [-1.3614  0.1311]: The authors propose using adversarial training with Graph Convolutional Networks (GCNs) for explainable detection of online sexism, hypothesizing that this approach may capture more stylistic information about sexist contents and improve model robustness and generalization ability.", "target": "The authors propose using adversarial training with Graph Convolutional Networks (GCNs) for explainable detection of online sexism, hypothesizing that this approach may capture more stylistic information about sexist contents and improve model robustness and generalization ability.", "example": "Convert the coordinate to text: [-1.3614  0.1311]:"}
{"text": "Convert the coordinate to text: [-4.68   -3.6741]: The authors propose to enhance an existing transformer-based Dutch event coreference resolution model by incorporating easily extractable discourse structure information, such as subsections, paragraphs, and text types, to provide more structure to the model.", "target": "The authors propose to enhance an existing transformer-based Dutch event coreference resolution model by incorporating easily extractable discourse structure information, such as subsections, paragraphs, and text types, to provide more structure to the model.", "example": "Convert the coordinate to text: [-4.68   -3.6741]:"}
{"text": "Convert the coordinate to text: [-5.7745 -0.8404]: The authors propose using abstractive text summarization for summarizing patient progress notes and experiment with state-of-the-art models like Pegasus, BART, and T5 along with pre-processing and data augmentation techniques.", "target": "The authors propose using abstractive text summarization for summarizing patient progress notes and experiment with state-of-the-art models like Pegasus, BART, and T5 along with pre-processing and data augmentation techniques.", "example": "Convert the coordinate to text: [-5.7745 -0.8404]:"}
{"text": "Convert the coordinate to text: [-6.7239 -1.2271]: The authors propose the Highlight-Guided Unsupervised Keyphrase Extraction model (HGUKE) which computes the relevance of phrase-document based on document highlights and further calculates cross-phrase relevance of all candidate phrases for keyphrase extraction.", "target": "The authors propose the Highlight-Guided Unsupervised Keyphrase Extraction model (HGUKE) which computes the relevance of phrase-document based on document highlights and further calculates cross-phrase relevance of all candidate phrases for keyphrase extraction.", "example": "Convert the coordinate to text: [-6.7239 -1.2271]:"}
{"text": "Convert the coordinate to text: [ 5.4442 -6.6979]: The proposed TransGTR is a transferable structure learning approach for traffic forecasting that learns and transfers the graph structures and forecasting models across cities. It comprises a node feature network, a structure generator, and a forecasting model.", "target": "The proposed TransGTR is a transferable structure learning approach for traffic forecasting that learns and transfers the graph structures and forecasting models across cities. It comprises a node feature network, a structure generator, and a forecasting model.", "example": "Convert the coordinate to text: [ 5.4442 -6.6979]:"}
{"text": "Convert the coordinate to text: [  8.9479 -10.1956]: The authors propose an Efficient edge-Preserving multi-view stereo Network (EPNet) with a Hierarchical Edge-Preserving Residual learning (HEPR) module for detailed depth estimation and Cross-view Photometric Consistency (CPC) for enhanced gradient flow for detailed structures.", "target": "The authors propose an Efficient edge-Preserving multi-view stereo Network (EPNet) with a Hierarchical Edge-Preserving Residual learning (HEPR) module for detailed depth estimation and Cross-view Photometric Consistency (CPC) for enhanced gradient flow for detailed structures.", "example": "Convert the coordinate to text: [  8.9479 -10.1956]:"}
{"text": "Convert the coordinate to text: [ 5.7239 -7.2602]: This paper introduces a simplified architecture for temporal sets prediction, the Simplified Fully Connected Networks (SFCNs), which are used to compute user representations from a user's sequence of sets by learning intra-set element relationships, inter-set temporal dependencies, and intra-embedding channel correlations.", "target": "This paper introduces a simplified architecture for temporal sets prediction, the Simplified Fully Connected Networks (SFCNs), which are used to compute user representations from a user's sequence of sets by learning intra-set element relationships, inter-set temporal dependencies, and intra-embedding channel correlations.", "example": "Convert the coordinate to text: [ 5.7239 -7.2602]:"}
{"text": "Convert the coordinate to text: [ 6.4525 -3.7261]: This paper proposes a novel domain-transfer meta task design paradigm to address the issue of slot overlap between domains. It distributes a basic domain to each target domain based on the coincidence degree of slot labels between these two domains. It also introduces a Task Adaptation Network to effectively transfer the historical information from the basic domain to the target domain.", "target": "This paper proposes a novel domain-transfer meta task design paradigm to address the issue of slot overlap between domains. It distributes a basic domain to each target domain based on the coincidence degree of slot labels between these two domains. It also introduces a Task Adaptation Network to effectively transfer the historical information from the basic domain to the target domain.", "example": "Convert the coordinate to text: [ 6.4525 -3.7261]:"}
{"text": "Convert the coordinate to text: [ 3.565  -0.9295]: They observed that if positive data is resampled in each training iteration to maintain balance between positive and unlabeled examples, it results in robust early-stage performance. Moreover, predictive trends for positive and negative classes exhibit different patterns. Hence, they adopted a holistic approach that interprets the scores of each example as a temporal point process (TPP), thus reframing the core problem of PUL as recognizing trends in these scores.", "target": "They observed that if positive data is resampled in each training iteration to maintain balance between positive and unlabeled examples, it results in robust early-stage performance. Moreover, predictive trends for positive and negative classes exhibit different patterns. Hence, they adopted a holistic approach that interprets the scores of each example as a temporal point process (TPP), thus reframing the core problem of PUL as recognizing trends in these scores.", "example": "Convert the coordinate to text: [ 3.565  -0.9295]:"}
{"text": "Convert the coordinate to text: [2.406  0.1958]: The authors propose a new approach that leverages knowledge from a clean set to identify harmful data, separate beneficial and detrimental information within that data, and then use the beneficial information to enhance the model's performance.", "target": "The authors propose a new approach that leverages knowledge from a clean set to identify harmful data, separate beneficial and detrimental information within that data, and then use the beneficial information to enhance the model's performance.", "example": "Convert the coordinate to text: [2.406  0.1958]:"}
{"text": "Convert the coordinate to text: [12.5211 -4.9308]: The authors propose a unified theoretical framework for studying transfer-based attacks, introducing an explanatory model known as the 'manifold attack model'. It formalizes popular beliefs and explains the existing empirical results regarding the transferability of adversarial examples.", "target": "The authors propose a unified theoretical framework for studying transfer-based attacks, introducing an explanatory model known as the 'manifold attack model'. It formalizes popular beliefs and explains the existing empirical results regarding the transferability of adversarial examples.", "example": "Convert the coordinate to text: [12.5211 -4.9308]:"}
{"text": "Convert the coordinate to text: [13.6718 -2.4787]: The authors developed a recurrent version of Dale's ANNs, a bio-inspired EI network architecture that respects Dale's Law. They also investigated why some EI networks learn poorly while others learn well, emphasizing the spectral properties of the recurrent weight matrix at initialization.", "target": "The authors developed a recurrent version of Dale's ANNs, a bio-inspired EI network architecture that respects Dale's Law. They also investigated why some EI networks learn poorly while others learn well, emphasizing the spectral properties of the recurrent weight matrix at initialization.", "example": "Convert the coordinate to text: [13.6718 -2.4787]:"}
{"text": "Convert the coordinate to text: [-5.1235 -5.4883]: This paper introduces a Linguistic Concept Learning benchmark (Licon), where concepts in diverse forms are defined by linguistic descriptions. Novel concepts' difficulty can be controlled by the number of attributes or the hierarchical relationships between concepts.", "target": "This paper introduces a Linguistic Concept Learning benchmark (Licon), where concepts in diverse forms are defined by linguistic descriptions. Novel concepts' difficulty can be controlled by the number of attributes or the hierarchical relationships between concepts.", "example": "Convert the coordinate to text: [-5.1235 -5.4883]:"}
{"text": "Convert the coordinate to text: [ 0.2481 -9.2747]: The authors introduce a Retrieval-augmented Visual Language Model, termed as Re-ViLM, built upon the Flamingo model. This model retrieves relevant knowledge from an external database for zero and in-context few-shot image-to-text generations, reducing the number of model parameters and simplifying the integration of new data.", "target": "The authors introduce a Retrieval-augmented Visual Language Model, termed as Re-ViLM, built upon the Flamingo model. This model retrieves relevant knowledge from an external database for zero and in-context few-shot image-to-text generations, reducing the number of model parameters and simplifying the integration of new data.", "example": "Convert the coordinate to text: [ 0.2481 -9.2747]:"}
{"text": "Convert the coordinate to text: [-12.1731  17.2512]: The authors propose a voice-based interactive method using a conductive folding stand and a phone camera to enable BLV individuals to access both capacitive and infrared touchscreens of SSTs, a solution that overcomes false triggering by guiding users to touch the target.", "target": "The authors propose a voice-based interactive method using a conductive folding stand and a phone camera to enable BLV individuals to access both capacitive and infrared touchscreens of SSTs, a solution that overcomes false triggering by guiding users to touch the target.", "example": "Convert the coordinate to text: [-12.1731  17.2512]:"}
{"text": "Convert the coordinate to text: [  1.2396 -10.2917]: The authors propose the InfoMetIC, an Informative Metric for Reference-free Image Caption evaluation, which provides detailed feedback by identifying incorrect words and unmentioned image regions at a fine-grained level. InfoMetIC also gives a text precision score, a vision recall score, and an overall quality score at a coarse-grained level.", "target": "The authors propose the InfoMetIC, an Informative Metric for Reference-free Image Caption evaluation, which provides detailed feedback by identifying incorrect words and unmentioned image regions at a fine-grained level. InfoMetIC also gives a text precision score, a vision recall score, and an overall quality score at a coarse-grained level.", "example": "Convert the coordinate to text: [  1.2396 -10.2917]:"}
{"text": "Convert the coordinate to text: [-1.4126 -2.8409]: The researchers propose ACCENT, an evaluation metric for event commonsense that leverages commonsense knowledge bases (CSKBs). It extracts event-relation tuples from a dialogue and evaluates the response by scoring the tuples' compatibility with the CSKB.", "target": "The researchers propose ACCENT, an evaluation metric for event commonsense that leverages commonsense knowledge bases (CSKBs). It extracts event-relation tuples from a dialogue and evaluates the response by scoring the tuples' compatibility with the CSKB.", "example": "Convert the coordinate to text: [-1.4126 -2.8409]:"}
{"text": "Convert the coordinate to text: [ 1.353  -6.4276]: The authors present a linear decomposition of final hidden states from autoregressive language models based on each initial input token, which allows creating probability distributions that ablate the contribution of specific input tokens and tracking their influence over subsequent word predictions.", "target": "The authors present a linear decomposition of final hidden states from autoregressive language models based on each initial input token, which allows creating probability distributions that ablate the contribution of specific input tokens and tracking their influence over subsequent word predictions.", "example": "Convert the coordinate to text: [ 1.353  -6.4276]:"}
{"text": "Convert the coordinate to text: [-9.2961 -7.1211]: The authors have proposed a chart-based method to extract parse trees from masked language models (LMs), without needing to train separate parsers. The method calculates a score per span based on the distortion of contextual representations caused by linguistic perturbations.", "target": "The authors have proposed a chart-based method to extract parse trees from masked language models (LMs), without needing to train separate parsers. The method calculates a score per span based on the distortion of contextual representations caused by linguistic perturbations.", "example": "Convert the coordinate to text: [-9.2961 -7.1211]:"}
{"text": "Convert the coordinate to text: [11.6129 -5.3273]: The authors propose a strategy named 'Dual Augmentation' to improve the robustness of summarization systems against perturbations. It includes SummAttacker, which generates adversarial samples, and two methods of data augmentation: feeding the encoder with diverse cases in the input and introducing more diversity in the hidden states by manipulating the decoder input.", "target": "The authors propose a strategy named 'Dual Augmentation' to improve the robustness of summarization systems against perturbations. It includes SummAttacker, which generates adversarial samples, and two methods of data augmentation: feeding the encoder with diverse cases in the input and introducing more diversity in the hidden states by manipulating the decoder input.", "example": "Convert the coordinate to text: [11.6129 -5.3273]:"}
{"text": "Convert the coordinate to text: [-3.6945  1.4195]: The authors propose an approach for automatically extracting emotion triggers from text using unsupervised learning. This involves the development of new models that can jointly detect emotions and summarize their triggers.", "target": "The authors propose an approach for automatically extracting emotion triggers from text using unsupervised learning. This involves the development of new models that can jointly detect emotions and summarize their triggers.", "example": "Convert the coordinate to text: [-3.6945  1.4195]:"}
{"text": "Convert the coordinate to text: [ 4.6998 -5.7931]: The authors propose a Graph Convolutional Network(GCN)-based coherence model that can capture the structural similarities between documents by creating a graph structure for each document, mining different subgraph patterns, and constructing a heterogeneous graph for the training corpus based on shared subgraphs.", "target": "The authors propose a Graph Convolutional Network(GCN)-based coherence model that can capture the structural similarities between documents by creating a graph structure for each document, mining different subgraph patterns, and constructing a heterogeneous graph for the training corpus based on shared subgraphs.", "example": "Convert the coordinate to text: [ 4.6998 -5.7931]:"}
{"text": "Convert the coordinate to text: [-4.7378  6.1519]: The authors propose the key question: Can an attacker still sow discord and polarization in a social network when only the network topology is known? They answer this question by presenting approximation algorithms for identifying highly influential users who can significantly affect disagreement and polarization in the network.", "target": "The authors propose the key question: Can an attacker still sow discord and polarization in a social network when only the network topology is known? They answer this question by presenting approximation algorithms for identifying highly influential users who can significantly affect disagreement and polarization in the network.", "example": "Convert the coordinate to text: [-4.7378  6.1519]:"}
{"text": "Convert the coordinate to text: [-10.1582  -1.774 ]: To overcome these limitations, the authors propose two QA-based methods for biomedical relation extraction: a span QA-based method, which is extended and applied for drug-protein relation extraction using question templates and entity type markers, and a binary QA-based method that directly uses the entity information given in the relation extraction task.", "target": "To overcome these limitations, the authors propose two QA-based methods for biomedical relation extraction: a span QA-based method, which is extended and applied for drug-protein relation extraction using question templates and entity type markers, and a binary QA-based method that directly uses the entity information given in the relation extraction task.", "example": "Convert the coordinate to text: [-10.1582  -1.774 ]:"}
{"text": "Convert the coordinate to text: [18.5444 -3.1846]: The authors propose a method to classify spoiler type (phrase, passage, multi) and a question-answering method to generate spoilers satisfying curiosity incited by clickbait.", "target": "The authors propose a method to classify spoiler type (phrase, passage, multi) and a question-answering method to generate spoilers satisfying curiosity incited by clickbait.", "example": "Convert the coordinate to text: [18.5444 -3.1846]:"}
{"text": "Convert the coordinate to text: [-3.6542 -4.6409]: This study introduces a hierarchical similarity-aware approach that uses SBERT to compute similarity scores as an additional source of information between the input arguments and the lower level of labels in a human value hierarchical dataset.", "target": "This study introduces a hierarchical similarity-aware approach that uses SBERT to compute similarity scores as an additional source of information between the input arguments and the lower level of labels in a human value hierarchical dataset.", "example": "Convert the coordinate to text: [-3.6542 -4.6409]:"}
{"text": "Convert the coordinate to text: [-2.2711 -6.512 ]: The authors propose four different data augmentation-extension strategies for tackling the task, involving two types of augmentation methods (one based on modified synonym replacement, and one based on translations), and two ways of extending the training dataset (using filtered GPT-3 data and using data from a prior competition).", "target": "The authors propose four different data augmentation-extension strategies for tackling the task, involving two types of augmentation methods (one based on modified synonym replacement, and one based on translations), and two ways of extending the training dataset (using filtered GPT-3 data and using data from a prior competition).", "example": "Convert the coordinate to text: [-2.2711 -6.512 ]:"}
{"text": "Convert the coordinate to text: [-2.2172 -5.4251]: In this study, a system employing ChatGPT is designed to generate high-quality, personalized reading comprehension exercises for middle school English learners in China.", "target": "In this study, a system employing ChatGPT is designed to generate high-quality, personalized reading comprehension exercises for middle school English learners in China.", "example": "Convert the coordinate to text: [-2.2172 -5.4251]:"}
{"text": "Convert the coordinate to text: [ 5.9155 -1.8143]: The authors propose MMSD2.0, a corrected dataset that fixes the issues of the original MMSD by excluding spurious cues and re-annotating unreasonable samples. They also introduce a new framework known as multi-view CLIP designed to leverage multi-grained cues from multiple perspectives.", "target": "The authors propose MMSD2.0, a corrected dataset that fixes the issues of the original MMSD by excluding spurious cues and re-annotating unreasonable samples. They also introduce a new framework known as multi-view CLIP designed to leverage multi-grained cues from multiple perspectives.", "example": "Convert the coordinate to text: [ 5.9155 -1.8143]:"}
{"text": "Convert the coordinate to text: [-1.4197 -7.4508]: CoMix is proposed, a pretraining approach to improve the representation of code-mixed data in transformer models by using phonetic signals, a modified attention mechanism, and weak supervision guided generation by parts-of-speech constraints.", "target": "CoMix is proposed, a pretraining approach to improve the representation of code-mixed data in transformer models by using phonetic signals, a modified attention mechanism, and weak supervision guided generation by parts-of-speech constraints.", "example": "Convert the coordinate to text: [-1.4197 -7.4508]:"}
{"text": "Convert the coordinate to text: [-2.4804 11.6626]: The authors hypothesize that language may evolve from simple to difficult tasks and propose a curriculum learning method named task transfer, coupled with a novel architecture called symbolic mapping, to facilitate multi-agent language learning.", "target": "The authors hypothesize that language may evolve from simple to difficult tasks and propose a curriculum learning method named task transfer, coupled with a novel architecture called symbolic mapping, to facilitate multi-agent language learning.", "example": "Convert the coordinate to text: [-2.4804 11.6626]:"}
{"text": "Convert the coordinate to text: [-4.848   2.3164]: The authors propose a new method to use historical reviews belonging to the same user/product in initializing representations. They also propose a method for efficiently incorporating textual associations between users and products via a user-product cross-context module.", "target": "The authors propose a new method to use historical reviews belonging to the same user/product in initializing representations. They also propose a method for efficiently incorporating textual associations between users and products via a user-product cross-context module.", "example": "Convert the coordinate to text: [-4.848   2.3164]:"}
{"text": "Convert the coordinate to text: [-7.5368 -1.4807]: The authors propose the Disease Network Constructor (DNC), a system that uses natural language processing (NLP) techniques to automatically extract regulation events from scientific literature and visualize a disease network focused on idiopathic pulmonary fibrosis (IPF).", "target": "The authors propose the Disease Network Constructor (DNC), a system that uses natural language processing (NLP) techniques to automatically extract regulation events from scientific literature and visualize a disease network focused on idiopathic pulmonary fibrosis (IPF).", "example": "Convert the coordinate to text: [-7.5368 -1.4807]:"}
{"text": "Convert the coordinate to text: [-7.7642 -1.6312]: The paper proposes a novel framework called LWRS (Learn from Weak Readability Signals) that utilizes a set of heuristic signals to guide the model in calculating readability scores for ranking. This is achieved by heuristic-dependent descriptive aspects of text readability.", "target": "The paper proposes a novel framework called LWRS (Learn from Weak Readability Signals) that utilizes a set of heuristic signals to guide the model in calculating readability scores for ranking. This is achieved by heuristic-dependent descriptive aspects of text readability.", "example": "Convert the coordinate to text: [-7.7642 -1.6312]:"}
{"text": "Convert the coordinate to text: [14.5595  5.0631]: The study refined speculative decoding through the fresh perspective of optimal transport with membership cost and the maximal-coupling problem. This leads to a new formulation that generalizes speculative decoding to consider a set of k candidates at the token level, subsequently improving the optimal membership cost.", "target": "The study refined speculative decoding through the fresh perspective of optimal transport with membership cost and the maximal-coupling problem. This leads to a new formulation that generalizes speculative decoding to consider a set of k candidates at the token level, subsequently improving the optimal membership cost.", "example": "Convert the coordinate to text: [14.5595  5.0631]:"}
{"text": "Convert the coordinate to text: [12.1156 -4.9094]: The authors develop a new error theory to understand ensemble adversarial defense, and propose an effective approach named interactive global adversarial training (iGAT) which allocates adversarial examples to base classifiers and rescues the severest weaknesses of them.", "target": "The authors develop a new error theory to understand ensemble adversarial defense, and propose an effective approach named interactive global adversarial training (iGAT) which allocates adversarial examples to base classifiers and rescues the severest weaknesses of them.", "example": "Convert the coordinate to text: [12.1156 -4.9094]:"}
{"text": "Convert the coordinate to text: [ 4.3959 12.8712]: The authors propose a novel USD algorithm called DISCO-DANCE which selects a guide skill with the highest potential to reach unexplored states, guides other skills to follow, and disperses the guided skills to maximize their discriminability in these states.", "target": "The authors propose a novel USD algorithm called DISCO-DANCE which selects a guide skill with the highest potential to reach unexplored states, guides other skills to follow, and disperses the guided skills to maximize their discriminability in these states.", "example": "Convert the coordinate to text: [ 4.3959 12.8712]:"}
{"text": "Convert the coordinate to text: [ 3.9859 -2.7316]: The authors propose a novel Semi-Supervised Learning framework for AVSL, namely Dual Mean-Teacher (DMT), which comprises two teacher-student structures to tackle confirmation bias and utilizes both labeled and unlabeled data to generate high-quality pseudo-labels.", "target": "The authors propose a novel Semi-Supervised Learning framework for AVSL, namely Dual Mean-Teacher (DMT), which comprises two teacher-student structures to tackle confirmation bias and utilizes both labeled and unlabeled data to generate high-quality pseudo-labels.", "example": "Convert the coordinate to text: [ 3.9859 -2.7316]:"}
{"text": "Convert the coordinate to text: [11.2664 -6.2   ]: The authors propose a distribution mapping module that generates samples from a fair noise distribution. This module ensures semantically uniform outputs from pretrained generative model, creating an equal number of instances for each group, without requiring any real training data or retraining of the generator.", "target": "The authors propose a distribution mapping module that generates samples from a fair noise distribution. This module ensures semantically uniform outputs from pretrained generative model, creating an equal number of instances for each group, without requiring any real training data or retraining of the generator.", "example": "Convert the coordinate to text: [11.2664 -6.2   ]:"}
{"text": "Convert the coordinate to text: [-1.1851 -1.7418]: The paper proposes the DRGCoder, a new clinical coding system with enhanced explainability which uses a multi-task Transformer model to predict medical severity DRGs and highlight important text in discharge summaries.", "target": "The paper proposes the DRGCoder, a new clinical coding system with enhanced explainability which uses a multi-task Transformer model to predict medical severity DRGs and highlight important text in discharge summaries.", "example": "Convert the coordinate to text: [-1.1851 -1.7418]:"}
{"text": "Convert the coordinate to text: [-1.0579 -4.9437]: In response to the problems of Zero-shot-CoT, the authors propose Plan-and-Solve (PS) Prompting, an approach that devises a plan to divide a task into smaller subtasks, and then carries out the subtasks according to the plan. This is further extended into PS+ prompting, which provides more detailed instructions to address calculation errors and improve reasoning steps quality.", "target": "In response to the problems of Zero-shot-CoT, the authors propose Plan-and-Solve (PS) Prompting, an approach that devises a plan to divide a task into smaller subtasks, and then carries out the subtasks according to the plan. This is further extended into PS+ prompting, which provides more detailed instructions to address calculation errors and improve reasoning steps quality.", "example": "Convert the coordinate to text: [-1.0579 -4.9437]:"}
{"text": "Convert the coordinate to text: [-6.6933 10.9876]: In this study, the authors propose the use of the Motivational Interviewing Treatment Integrity (MITI) code to recognize conforming and non-conforming response types in online distress-support dialogues and suggest that some responses could be rephrased for greater adherence to the MI strategy.", "target": "In this study, the authors propose the use of the Motivational Interviewing Treatment Integrity (MITI) code to recognize conforming and non-conforming response types in online distress-support dialogues and suggest that some responses could be rephrased for greater adherence to the MI strategy.", "example": "Convert the coordinate to text: [-6.6933 10.9876]:"}
{"text": "Convert the coordinate to text: [-1.084  -0.0036]: The authors hypothesize that creating training data in the reverse direction, starting from gender-fair text, is more feasible for morphologically complex languages and propose using machine translation models to generate gender-biased text from actual gender-fair text through round-trip translation.", "target": "The authors hypothesize that creating training data in the reverse direction, starting from gender-fair text, is more feasible for morphologically complex languages and propose using machine translation models to generate gender-biased text from actual gender-fair text through round-trip translation.", "example": "Convert the coordinate to text: [-1.084  -0.0036]:"}
{"text": "Convert the coordinate to text: [-1.6704 -5.422 ]: The authors propose Inference-time Policy Adapters (IPA), a method to efficiently tailor a language model such as GPT-3 without fine-tuning it. IPA guides a large base model during decoding time through a lightweight policy adaptor trained to optimize an arbitrary user objective with reinforcement learning.", "target": "The authors propose Inference-time Policy Adapters (IPA), a method to efficiently tailor a language model such as GPT-3 without fine-tuning it. IPA guides a large base model during decoding time through a lightweight policy adaptor trained to optimize an arbitrary user objective with reinforcement learning.", "example": "Convert the coordinate to text: [-1.6704 -5.422 ]:"}
{"text": "Convert the coordinate to text: [-7.8113 -3.8072]: The authors examine how LMs reason with respective readings from two perspectives: syntactic-semantic and commonsense-world knowledge, using a controlled synthetic dataset WikiResNLI and a naturally occurring dataset NatResNLI that represent various explicit and implicit realizations of 'respectively'.", "target": "The authors examine how LMs reason with respective readings from two perspectives: syntactic-semantic and commonsense-world knowledge, using a controlled synthetic dataset WikiResNLI and a naturally occurring dataset NatResNLI that represent various explicit and implicit realizations of 'respectively'.", "example": "Convert the coordinate to text: [-7.8113 -3.8072]:"}
{"text": "Convert the coordinate to text: [-7.8648 -4.7834]: The authors investigate the use of fine-tuned large language models to pre-annotate data for a lexical extension task, aiming to add verbs to the ontology of event types and help annotators identify verbs that can not be assigned to any existing class to form a new class.", "target": "The authors investigate the use of fine-tuned large language models to pre-annotate data for a lexical extension task, aiming to add verbs to the ontology of event types and help annotators identify verbs that can not be assigned to any existing class to form a new class.", "example": "Convert the coordinate to text: [-7.8648 -4.7834]:"}
{"text": "Convert the coordinate to text: [-1.4952  0.1092]: The authors propose an ensemble approach for detecting sexist text that leverages 18 models, including DeBERTa-v3-base models with different input sequence lengths, a BERT-based model trained on identifying hate speech, and three more models pre-trained on the task\u2019s unlabeled data with varying input lengths.", "target": "The authors propose an ensemble approach for detecting sexist text that leverages 18 models, including DeBERTa-v3-base models with different input sequence lengths, a BERT-based model trained on identifying hate speech, and three more models pre-trained on the task\u2019s unlabeled data with varying input lengths.", "example": "Convert the coordinate to text: [-1.4952  0.1092]:"}
{"text": "Convert the coordinate to text: [-2.9501 -6.584 ]: The study aims to develop a sentiment analysis system, capable of identifying positive, negative, and neutral sentiments, for the low-resource African languages Hausa and Igbo, using the pre-trained language model AfriBERTa.", "target": "The study aims to develop a sentiment analysis system, capable of identifying positive, negative, and neutral sentiments, for the low-resource African languages Hausa and Igbo, using the pre-trained language model AfriBERTa.", "example": "Convert the coordinate to text: [-2.9501 -6.584 ]:"}
{"text": "Convert the coordinate to text: [-1.4316  0.1976]: The team participated in the shared task Explainable Detection of Online Sexism (EDOS) at SemEval 2023 and have proposed a model that identifies sexist comments and their type from English social media posts using provided dataset. Different transformer models such as BERT, DistilBERT and RoBERT are used in the proposed model.", "target": "The team participated in the shared task Explainable Detection of Online Sexism (EDOS) at SemEval 2023 and have proposed a model that identifies sexist comments and their type from English social media posts using provided dataset. Different transformer models such as BERT, DistilBERT and RoBERT are used in the proposed model.", "example": "Convert the coordinate to text: [-1.4316  0.1976]:"}
{"text": "Convert the coordinate to text: [ 0.8134 -8.8134]: TeamPN proposes a multi-modal and modular approach to this task, using recent multi-modal pre-trained models supported by real-time multi-modal knowledge graphs to enhance textual knowledge for the images and select the best matching image.", "target": "TeamPN proposes a multi-modal and modular approach to this task, using recent multi-modal pre-trained models supported by real-time multi-modal knowledge graphs to enhance textual knowledge for the images and select the best matching image.", "example": "Convert the coordinate to text: [ 0.8134 -8.8134]:"}
{"text": "Convert the coordinate to text: [-2.7493 -5.8448]: The authors propose an approach of annotating training data with very large language models (LLMs) to train smaller models that are better adapted to the problem of scarce data in specialized domains.", "target": "The authors propose an approach of annotating training data with very large language models (LLMs) to train smaller models that are better adapted to the problem of scarce data in specialized domains.", "example": "Convert the coordinate to text: [-2.7493 -5.8448]:"}
{"text": "Convert the coordinate to text: [ 4.9011 -5.7606]: The paper introduces a novel Bi-directional Directed Acyclic Graph neural network (BiDAG) which divides the reasoning process into prediction and calibration. This model considers the joint probability of all nodes by applying a graph neural network (GNN) to the query graph in the calibration process.", "target": "The paper introduces a novel Bi-directional Directed Acyclic Graph neural network (BiDAG) which divides the reasoning process into prediction and calibration. This model considers the joint probability of all nodes by applying a graph neural network (GNN) to the query graph in the calibration process.", "example": "Convert the coordinate to text: [ 4.9011 -5.7606]:"}
{"text": "Convert the coordinate to text: [-1.8898 -6.7593]: The paper explores the use of a sequence-to-sequence (seq2seq) language model architecture as a more compute-efficient alternative to the decoder-oriented approach such as GPT-3 for Korean language modeling.", "target": "The paper explores the use of a sequence-to-sequence (seq2seq) language model architecture as a more compute-efficient alternative to the decoder-oriented approach such as GPT-3 for Korean language modeling.", "example": "Convert the coordinate to text: [-1.8898 -6.7593]:"}
{"text": "Convert the coordinate to text: [-0.1063 -8.7857]: The paper introduces mCLIP, a dual-stream multilingual VLP model. This model aligns the CLIP model with a Multilingual Text Encoder (MTE) utilizing a novel Triangle Cross-modal Knowledge Distillation (TriKD) method to counter the English-centric bias.", "target": "The paper introduces mCLIP, a dual-stream multilingual VLP model. This model aligns the CLIP model with a Multilingual Text Encoder (MTE) utilizing a novel Triangle Cross-modal Knowledge Distillation (TriKD) method to counter the English-centric bias.", "example": "Convert the coordinate to text: [-0.1063 -8.7857]:"}
{"text": "Convert the coordinate to text: [-2.3516 -7.193 ]: The study investigates how morphological typology and tokenization method can influence the performance of attention-based transformers in language modeling. It also explores the impact of vocabulary size due to morphological characteristics on the LM perplexity and performance of downstream tasks.", "target": "The study investigates how morphological typology and tokenization method can influence the performance of attention-based transformers in language modeling. It also explores the impact of vocabulary size due to morphological characteristics on the LM perplexity and performance of downstream tasks.", "example": "Convert the coordinate to text: [-2.3516 -7.193 ]:"}
{"text": "Convert the coordinate to text: [-5.9252  0.6123]: The authors propose to study the role of stories in arguments by collecting and annotating StoryARG, a dataset sampled from existing computational argumentation corpora and structured around stories used in various contexts.", "target": "The authors propose to study the role of stories in arguments by collecting and annotating StoryARG, a dataset sampled from existing computational argumentation corpora and structured around stories used in various contexts.", "example": "Convert the coordinate to text: [-5.9252  0.6123]:"}
{"text": "Convert the coordinate to text: [13.5654 -1.4302]: This paper proposes a dynamics-inspired neuromorphic architecture that follows Hamilton's principle and converts weight-based neural structures into dynamics-based forms with finite sub-models. The relationships between these sub-models are measured using path integrals amongst their dynamical states, functioning similarly to neural weights.", "target": "This paper proposes a dynamics-inspired neuromorphic architecture that follows Hamilton's principle and converts weight-based neural structures into dynamics-based forms with finite sub-models. The relationships between these sub-models are measured using path integrals amongst their dynamical states, functioning similarly to neural weights.", "example": "Convert the coordinate to text: [13.5654 -1.4302]:"}
{"text": "Convert the coordinate to text: [ 2.9685 -4.1681]: The authors propose a novel phasic content fusing few-shot diffusion model with directional distribution consistency loss, aiming at different learning objectives at distinct training stages of the diffusion model, which includes a phasic training strategy, a novel directional distribution consistency loss and a cross-domain structure guidance strategy.", "target": "The authors propose a novel phasic content fusing few-shot diffusion model with directional distribution consistency loss, aiming at different learning objectives at distinct training stages of the diffusion model, which includes a phasic training strategy, a novel directional distribution consistency loss and a cross-domain structure guidance strategy.", "example": "Convert the coordinate to text: [ 2.9685 -4.1681]:"}
{"text": "Convert the coordinate to text: [ 0.3523 -9.4244]: The authors propose Fine-grained Late-interaction Multi-modal Retrieval (FLMR), which aims to significantly improve knowledge retrieval in RA-VQA. It addresses the limitations of RA-VQA's retriever by obtaining image representations that complement those from the image-to-text transformations and encodes images and questions using multi-dimensional embeddings to capture finer-grained relevance between queries and documents.", "target": "The authors propose Fine-grained Late-interaction Multi-modal Retrieval (FLMR), which aims to significantly improve knowledge retrieval in RA-VQA. It addresses the limitations of RA-VQA's retriever by obtaining image representations that complement those from the image-to-text transformations and encodes images and questions using multi-dimensional embeddings to capture finer-grained relevance between queries and documents.", "example": "Convert the coordinate to text: [ 0.3523 -9.4244]:"}
{"text": "Convert the coordinate to text: [3.9225 0.4778]: The authors propose a novel data selection pipeline and method, FreeSel, that utilizes pre-existing, general-purpose models to select data from a variety of datasets using single-pass inference without additional training.", "target": "The authors propose a novel data selection pipeline and method, FreeSel, that utilizes pre-existing, general-purpose models to select data from a variety of datasets using single-pass inference without additional training.", "example": "Convert the coordinate to text: [3.9225 0.4778]:"}
{"text": "Convert the coordinate to text: [-1.4755  2.6144]: The paper proposes two key ideas: firstly, an untargeted iterative self-critique and self-refinement method that doesn't need external influence, and secondly, a novel ranking metric called Performance, Refinement, and Inference Cost Score (PeRFICS) to help in finding the optimal model for a task considering the balance between improved performance and cost.", "target": "The paper proposes two key ideas: firstly, an untargeted iterative self-critique and self-refinement method that doesn't need external influence, and secondly, a novel ranking metric called Performance, Refinement, and Inference Cost Score (PeRFICS) to help in finding the optimal model for a task considering the balance between improved performance and cost.", "example": "Convert the coordinate to text: [-1.4755  2.6144]:"}
{"text": "Convert the coordinate to text: [ 0.0283 -8.9031]: The authors propose VL-Match, a Vision-Language framework that enhances Vision-Language Pretraining by implementing both token-level and instance-level matching.", "target": "The authors propose VL-Match, a Vision-Language framework that enhances Vision-Language Pretraining by implementing both token-level and instance-level matching.", "example": "Convert the coordinate to text: [ 0.0283 -8.9031]:"}
{"text": "Convert the coordinate to text: [12.9581  2.8587]: The paper proposes Streaming Factor Trajectory Learning (SFTL) for temporal tensor decomposition. It uses Gaussian processes to model the trajectory of factors to estimate their temporal evolution.", "target": "The paper proposes Streaming Factor Trajectory Learning (SFTL) for temporal tensor decomposition. It uses Gaussian processes to model the trajectory of factors to estimate their temporal evolution.", "example": "Convert the coordinate to text: [12.9581  2.8587]:"}
{"text": "Convert the coordinate to text: [-4.2034 -4.6316]: The authors present the concept of 'semantic independence' within text embeddings, and the related concept of 'partial orthogonality', as a way to formalize and analyze this concept.", "target": "The authors present the concept of 'semantic independence' within text embeddings, and the related concept of 'partial orthogonality', as a way to formalize and analyze this concept.", "example": "Convert the coordinate to text: [-4.2034 -4.6316]:"}
{"text": "Convert the coordinate to text: [-10.3393  -1.1605]: The paper conducts a systematic review of existing research on PQA, and categorizes PQA studies into four problem settings based on the form of provided answers.", "target": "The paper conducts a systematic review of existing research on PQA, and categorizes PQA studies into four problem settings based on the form of provided answers.", "example": "Convert the coordinate to text: [-10.3393  -1.1605]:"}
{"text": "Convert the coordinate to text: [-1.4652 -5.7857]: The paper proposes explanation-based finetuning as an approach to mitigate LLMs' reliance on spurious correlations. Unlike standard finetuning, the model is also finetuned to generate a free-text explanation supporting its answer.", "target": "The paper proposes explanation-based finetuning as an approach to mitigate LLMs' reliance on spurious correlations. Unlike standard finetuning, the model is also finetuned to generate a free-text explanation supporting its answer.", "example": "Convert the coordinate to text: [-1.4652 -5.7857]:"}
{"text": "Convert the coordinate to text: [-9.7586 -5.6153]: This paper introduces a dataset comprising 850 dialogues and 199,803 dependencies based on syntactic dependency and rhetorical structure theory (RST) to study dialogue-level dependency parsing for Chinese. It also examines zero-shot and few-shot scenarios to mitigate high annotation costs.", "target": "This paper introduces a dataset comprising 850 dialogues and 199,803 dependencies based on syntactic dependency and rhetorical structure theory (RST) to study dialogue-level dependency parsing for Chinese. It also examines zero-shot and few-shot scenarios to mitigate high annotation costs.", "example": "Convert the coordinate to text: [-9.7586 -5.6153]:"}
{"text": "Convert the coordinate to text: [-10.5882  -1.9837]: The authors propose a novel training paradigm for GenQA by using supervision from automatic QA evaluation models (GAVA). In their proposal, they include three strategies to transfer knowledge from QA evaluation models to a GenQA model.", "target": "The authors propose a novel training paradigm for GenQA by using supervision from automatic QA evaluation models (GAVA). In their proposal, they include three strategies to transfer knowledge from QA evaluation models to a GenQA model.", "example": "Convert the coordinate to text: [-10.5882  -1.9837]:"}
{"text": "Convert the coordinate to text: [-6.1834 10.8648]: This study investigates the impact of advanced linguistic dialogue behaviors on user preference and trust, using open-domain question answering systems as a test-bed for task-based dialog generation.", "target": "This study investigates the impact of advanced linguistic dialogue behaviors on user preference and trust, using open-domain question answering systems as a test-bed for task-based dialog generation.", "example": "Convert the coordinate to text: [-6.1834 10.8648]:"}
{"text": "Convert the coordinate to text: [-3.906 -1.507]: The authors introduce a comprehensive probing dataset, 'tempreason', to evaluate the temporal reasoning capability of large language models. Additionally, they propose a new learning framework based on temporal span extraction and time-sensitive reinforcement learning to improve these capabilities.", "target": "The authors introduce a comprehensive probing dataset, 'tempreason', to evaluate the temporal reasoning capability of large language models. Additionally, they propose a new learning framework based on temporal span extraction and time-sensitive reinforcement learning to improve these capabilities.", "example": "Convert the coordinate to text: [-3.906 -1.507]:"}
{"text": "Convert the coordinate to text: [-1.2082 -3.0857]: A novel TKGE model, Temporal knowledge graph embeddings via Archimedean Spiral Timeline (TeAST), is proposed which maps relations onto an Archimedean spiral timeline and transforms the quadruples completion into a 3rd-order tensor completion problem. This ensures relations occurring simultaneously are on the same timeline and evolve over time.", "target": "A novel TKGE model, Temporal knowledge graph embeddings via Archimedean Spiral Timeline (TeAST), is proposed which maps relations onto an Archimedean spiral timeline and transforms the quadruples completion into a 3rd-order tensor completion problem. This ensures relations occurring simultaneously are on the same timeline and evolve over time.", "example": "Convert the coordinate to text: [-1.2082 -3.0857]:"}
{"text": "Convert the coordinate to text: [-9.8199 -5.2698]: The authors conduct an empirical analysis to compare the discourse trees defined by the RST and QUD models.", "target": "The authors conduct an empirical analysis to compare the discourse trees defined by the RST and QUD models.", "example": "Convert the coordinate to text: [-9.8199 -5.2698]:"}
{"text": "Convert the coordinate to text: [-4.559   2.2671]: The paper presents a method for evaluating the intimacy level of tweets in ten languages, using multi-task learning and various tricks and strategies such as data augmentation.", "target": "The paper presents a method for evaluating the intimacy level of tweets in ten languages, using multi-task learning and various tricks and strategies such as data augmentation.", "example": "Convert the coordinate to text: [-4.559   2.2671]:"}
{"text": "Convert the coordinate to text: [-6.2906e+00  5.8160e-03]: The authors are exploring how the user interface impacts annotator agreement when judging summary quality.", "target": "The authors are exploring how the user interface impacts annotator agreement when judging summary quality.", "example": "Convert the coordinate to text: [-6.2906e+00  5.8160e-03]:"}
{"text": "Convert the coordinate to text: [-1.0354 -5.1775]: The authors conduct empirical exploration on each component of cross-lingual prompting resulting in 'Universal Prompting', which mitigates discrepancies between source-language training and target-language inference. Further, they propose 'DPA', a dual prompt augmentation framework, to alleviate the data scarcity issue in few-shot cross-lingual prompting.", "target": "The authors conduct empirical exploration on each component of cross-lingual prompting resulting in 'Universal Prompting', which mitigates discrepancies between source-language training and target-language inference. Further, they propose 'DPA', a dual prompt augmentation framework, to alleviate the data scarcity issue in few-shot cross-lingual prompting.", "example": "Convert the coordinate to text: [-1.0354 -5.1775]:"}
{"text": "Convert the coordinate to text: [ 0.9674 -5.1238]: The authors propose a new task called Target-Stance Extraction (TSE) that aims to extract the (target, stance) pair from a text without knowing the target in advance and benchmark the task with a two-stage framework.", "target": "The authors propose a new task called Target-Stance Extraction (TSE) that aims to extract the (target, stance) pair from a text without knowing the target in advance and benchmark the task with a two-stage framework.", "example": "Convert the coordinate to text: [ 0.9674 -5.1238]:"}
{"text": "Convert the coordinate to text: [-3.396  -4.0121]: The authors introduce the Grounded Multimodal Named Entity Recognition (GMNER) task, which aims to identify the named entities in text, their entity types, and their bounding box groundings in related images.", "target": "The authors introduce the Grounded Multimodal Named Entity Recognition (GMNER) task, which aims to identify the named entities in text, their entity types, and their bounding box groundings in related images.", "example": "Convert the coordinate to text: [-3.396  -4.0121]:"}
{"text": "Convert the coordinate to text: [-0.2212 -8.7576]: The authors propose 'Cola', a paradigm that uses a large language model (LLM) to coordinate multiple VLMs for improved visual reasoning. This coordination is achieved by having the LLM facilitate natural language communication between the VLMs, utilizing their different yet complementary capabilities.", "target": "The authors propose 'Cola', a paradigm that uses a large language model (LLM) to coordinate multiple VLMs for improved visual reasoning. This coordination is achieved by having the LLM facilitate natural language communication between the VLMs, utilizing their different yet complementary capabilities.", "example": "Convert the coordinate to text: [-0.2212 -8.7576]:"}
{"text": "Convert the coordinate to text: [ 11.7305 -14.4895]: The authors introduce Shape Non-rigid Kinematics (SNK), a method for non-rigid shape matching that does not require extensive training or ground truth data. SNK applies a reconstruction-based strategy using an encoder-decoder architecture to deform a source shape to closely match the target shape.", "target": "The authors introduce Shape Non-rigid Kinematics (SNK), a method for non-rigid shape matching that does not require extensive training or ground truth data. SNK applies a reconstruction-based strategy using an encoder-decoder architecture to deform a source shape to closely match the target shape.", "example": "Convert the coordinate to text: [ 11.7305 -14.4895]:"}
{"text": "Convert the coordinate to text: [0.3238 0.9468]: The paper critically evaluates the effectiveness of model debiasing strategies amidst concerns that debiasing could increase reliance on hidden biases rather than encouraging the learning of robust, task-relevant features.", "target": "The paper critically evaluates the effectiveness of model debiasing strategies amidst concerns that debiasing could increase reliance on hidden biases rather than encouraging the learning of robust, task-relevant features.", "example": "Convert the coordinate to text: [0.3238 0.9468]:"}
{"text": "Convert the coordinate to text: [-6.6581 -9.9404]: The study introduces the most extensive gold standard corpus for Bangla characters and words, collected from diverse document types and encompassing over four million human-annotated images. It leverages recent advancements in Deep Learning and OCR techniques for potentially enhancing the performance of Bangla OCR.", "target": "The study introduces the most extensive gold standard corpus for Bangla characters and words, collected from diverse document types and encompassing over four million human-annotated images. It leverages recent advancements in Deep Learning and OCR techniques for potentially enhancing the performance of Bangla OCR.", "example": "Convert the coordinate to text: [-6.6581 -9.9404]:"}
{"text": "Convert the coordinate to text: [2.2892 1.3138]: The authors propose to utilize a small amount of labeled anomaly data in anomaly detection, in a setting termed as weakly-supervised anomaly detection.", "target": "The authors propose to utilize a small amount of labeled anomaly data in anomaly detection, in a setting termed as weakly-supervised anomaly detection.", "example": "Convert the coordinate to text: [2.2892 1.3138]:"}
{"text": "Convert the coordinate to text: [12.2395  0.0486]: The authors introduce 'coarse-to-fine autoregressive networks' (C2FAR), which generate a hierarchical, coarse-to-fine discretization of a variable autoregressively, allowing for an exponential increase in precision for only a linear increase in complexity and making this method capable of handling both discrete and continuous series of arbitrary scale and distribution shape.", "target": "The authors introduce 'coarse-to-fine autoregressive networks' (C2FAR), which generate a hierarchical, coarse-to-fine discretization of a variable autoregressively, allowing for an exponential increase in precision for only a linear increase in complexity and making this method capable of handling both discrete and continuous series of arbitrary scale and distribution shape.", "example": "Convert the coordinate to text: [12.2395  0.0486]:"}
{"text": "Convert the coordinate to text: [ 12.8602 -16.9973]: The authors propose to put a standard stationary kernel on the divergence and curl-free components of a vector field obtained through a Helmholtz decomposition to better reflect the known physical properties of currents.", "target": "The authors propose to put a standard stationary kernel on the divergence and curl-free components of a vector field obtained through a Helmholtz decomposition to better reflect the known physical properties of currents.", "example": "Convert the coordinate to text: [ 12.8602 -16.9973]:"}
{"text": "Convert the coordinate to text: [-8.0918  9.6297]: This study explores the potential for enriching adaptive learning systems with elements of social learning and investigates how indicators of this type of learning can be included in such systems.", "target": "This study explores the potential for enriching adaptive learning systems with elements of social learning and investigates how indicators of this type of learning can be included in such systems.", "example": "Convert the coordinate to text: [-8.0918  9.6297]:"}
{"text": "Convert the coordinate to text: [-6.3355 13.6628]: This paper introduces Closer Worlds, a Machine Learning-assisted two-person game designed to foster emotionally intimate conversations through co-creative world-building.", "target": "This paper introduces Closer Worlds, a Machine Learning-assisted two-person game designed to foster emotionally intimate conversations through co-creative world-building.", "example": "Convert the coordinate to text: [-6.3355 13.6628]:"}
{"text": "Convert the coordinate to text: [-5.7494 -0.6362]: The authors introduce VCSum, a versatile Chinese meeting summarization dataset consisting of 239 real-life meetings (over 230 hours). The dataset provides annotations of topic segmentation, headlines, segmentation summaries, overall meeting summaries, and salient sentences.", "target": "The authors introduce VCSum, a versatile Chinese meeting summarization dataset consisting of 239 real-life meetings (over 230 hours). The dataset provides annotations of topic segmentation, headlines, segmentation summaries, overall meeting summaries, and salient sentences.", "example": "Convert the coordinate to text: [-5.7494 -0.6362]:"}
{"text": "Convert the coordinate to text: [-2.7639 -8.4599]: The authors propose AMPERE, a strategy to incorporate AMR into generation-based EAE models, by generating AMR-aware prefixes for every layer of the generation model. An adjusted copy mechanism is also introduced to help overcome potential noises brought by the AMR graph.", "target": "The authors propose AMPERE, a strategy to incorporate AMR into generation-based EAE models, by generating AMR-aware prefixes for every layer of the generation model. An adjusted copy mechanism is also introduced to help overcome potential noises brought by the AMR graph.", "example": "Convert the coordinate to text: [-2.7639 -8.4599]:"}
{"text": "Convert the coordinate to text: [  0.3416 -10.1334]: The authors present the VSTAR dataset, which is a large scale video-grounded dialogue understanding dataset based on 395 TV series, and propose two benchmarks for video-grounded dialogue understanding: scene segmentation and topic segmentation, along with one benchmark for video-grounded dialogue generation, emphasizing the importance of multimodal information.", "target": "The authors present the VSTAR dataset, which is a large scale video-grounded dialogue understanding dataset based on 395 TV series, and propose two benchmarks for video-grounded dialogue understanding: scene segmentation and topic segmentation, along with one benchmark for video-grounded dialogue generation, emphasizing the importance of multimodal information.", "example": "Convert the coordinate to text: [  0.3416 -10.1334]:"}
{"text": "Convert the coordinate to text: [-6.802  -7.1791]: The researchers constructed the first Japanese Lexical Complexity Prediction (LCP) dataset, providing separate complexity scores for Chinese/Korean annotators and others to cater to the readers' L1-specific needs.", "target": "The researchers constructed the first Japanese Lexical Complexity Prediction (LCP) dataset, providing separate complexity scores for Chinese/Korean annotators and others to cater to the readers' L1-specific needs.", "example": "Convert the coordinate to text: [-6.802  -7.1791]:"}
{"text": "Convert the coordinate to text: [-5.0333 -5.2353]: This study extends the exploration of linguistic representations to the task of cross-domain relation extraction, specifically in the context of procedural text in cooking and materials science domains. The paper suggests the possibility that linguistic representations may enhance generalizability via functioning as cross-domain pivots.", "target": "This study extends the exploration of linguistic representations to the task of cross-domain relation extraction, specifically in the context of procedural text in cooking and materials science domains. The paper suggests the possibility that linguistic representations may enhance generalizability via functioning as cross-domain pivots.", "example": "Convert the coordinate to text: [-5.0333 -5.2353]:"}
{"text": "Convert the coordinate to text: [-7.905  -1.0477]: The authors propose a new approach for understanding legal texts using data-oriented methods and the Longformer architecture.", "target": "The authors propose a new approach for understanding legal texts using data-oriented methods and the Longformer architecture.", "example": "Convert the coordinate to text: [-7.905  -1.0477]:"}
{"text": "Convert the coordinate to text: [-0.5623 -7.0384]: This paper aims to compare the performance of transformers models against low-resource dictionaries, and evaluates the effectiveness of learned dictionaries against expert-designed ones in the context of a shared task in the field of values.", "target": "This paper aims to compare the performance of transformers models against low-resource dictionaries, and evaluates the effectiveness of learned dictionaries against expert-designed ones in the context of a shared task in the field of values.", "example": "Convert the coordinate to text: [-0.5623 -7.0384]:"}
{"text": "Convert the coordinate to text: [-4.2147 -3.3417]: The authors participated in two out of three available sub-tasks of SemEval Task 6 \u2013 Rhetorical Role prediction (RR) and Legal Named Entity Recognition (L-NER) with the aim to develop lightweight and interpretable systems.", "target": "The authors participated in two out of three available sub-tasks of SemEval Task 6 \u2013 Rhetorical Role prediction (RR) and Legal Named Entity Recognition (L-NER) with the aim to develop lightweight and interpretable systems.", "example": "Convert the coordinate to text: [-4.2147 -3.3417]:"}
{"text": "Convert the coordinate to text: [-7.6121 11.0908]: The authors propose an enhancement to the tutoring systems by introducing a code scratchpad, which is expected to improve performance in tutoring tasks particularly in gradeschool mathematics.", "target": "The authors propose an enhancement to the tutoring systems by introducing a code scratchpad, which is expected to improve performance in tutoring tasks particularly in gradeschool mathematics.", "example": "Convert the coordinate to text: [-7.6121 11.0908]:"}
{"text": "Convert the coordinate to text: [ 9.7975 -8.9158]: The authors present a novel network for multi-contrast MRI arbitrary-scale SR called McASSR, which features a rectangle-window cross-attention transformer to establish longer-range dependencies in MR images without increasing computational complexity. It also includes a reference-aware implicit attention as an upsampling module, allowing for arbitrary-scale super-resolution and better use of reference image information.", "target": "The authors present a novel network for multi-contrast MRI arbitrary-scale SR called McASSR, which features a rectangle-window cross-attention transformer to establish longer-range dependencies in MR images without increasing computational complexity. It also includes a reference-aware implicit attention as an upsampling module, allowing for arbitrary-scale super-resolution and better use of reference image information.", "example": "Convert the coordinate to text: [ 9.7975 -8.9158]:"}
{"text": "Convert the coordinate to text: [ 4.7743 -1.7443]: The paper proposes an asymmetric two-stream architecture that robustly learns from noisy pseudo labels. The approach involves dual-head pseudo label denoising and cross-modal consistency regularization.", "target": "The paper proposes an asymmetric two-stream architecture that robustly learns from noisy pseudo labels. The approach involves dual-head pseudo label denoising and cross-modal consistency regularization.", "example": "Convert the coordinate to text: [ 4.7743 -1.7443]:"}
{"text": "Convert the coordinate to text: [ 4.5724 -4.3503]: This paper introduces the new problem of explainable GLAD, where the learning objective is to predict each graph sample's abnormality with corresponding reasons. To tackle this, the authors propose Self-Interpretable Graph aNomaly dETection model (SIGNET) that detects anomalous graphs while generating informative explanations.", "target": "This paper introduces the new problem of explainable GLAD, where the learning objective is to predict each graph sample's abnormality with corresponding reasons. To tackle this, the authors propose Self-Interpretable Graph aNomaly dETection model (SIGNET) that detects anomalous graphs while generating informative explanations.", "example": "Convert the coordinate to text: [ 4.5724 -4.3503]:"}
{"text": "Convert the coordinate to text: [8.0828 9.0755]: The paper proposes a novel, robust algorithm for handling the online learning with experts problem under memory constraints, while being robust to adaptive inputs.", "target": "The paper proposes a novel, robust algorithm for handling the online learning with experts problem under memory constraints, while being robust to adaptive inputs.", "example": "Convert the coordinate to text: [8.0828 9.0755]:"}
{"text": "Convert the coordinate to text: [ 7.3803 11.6422]: A novel algorithm for reinforcement learning is proposed for linear mixture MDPs, which measures performance using dynamic regret. This methodology improves upon the dynamic regret of existing models for adversarial linear mixture MDPs and adversarial tabular MDPs.", "target": "A novel algorithm for reinforcement learning is proposed for linear mixture MDPs, which measures performance using dynamic regret. This methodology improves upon the dynamic regret of existing models for adversarial linear mixture MDPs and adversarial tabular MDPs.", "example": "Convert the coordinate to text: [ 7.3803 11.6422]:"}
{"text": "Convert the coordinate to text: [ 9.4479 -5.283 ]: A new method called Convolutional Monge Mapping Normalization (CMMN) is proposed which filters the signals in order to adapt their Power Spectrum Density (PSD) to a Wasserstein barycenter estimated on training data.", "target": "A new method called Convolutional Monge Mapping Normalization (CMMN) is proposed which filters the signals in order to adapt their Power Spectrum Density (PSD) to a Wasserstein barycenter estimated on training data.", "example": "Convert the coordinate to text: [ 9.4479 -5.283 ]:"}
{"text": "Convert the coordinate to text: [-0.0335 -5.2968]: The authors propose to explicitly add speaker awareness to each utterance representation using a graph neural network to model how each speaker behaves within the local context of a conversation.", "target": "The authors propose to explicitly add speaker awareness to each utterance representation using a graph neural network to model how each speaker behaves within the local context of a conversation.", "example": "Convert the coordinate to text: [-0.0335 -5.2968]:"}
{"text": "Convert the coordinate to text: [ 9.0579 -5.2483]: The paper proposes a disorder-invariant implicit neural representation (DINER) which solves the frequency-related problem by re-arranging the coordinates of the input signal. It involves augmenting a hash-table to traditional INR to project the coordinates into the same distribution regardless of the arrangement order.", "target": "The paper proposes a disorder-invariant implicit neural representation (DINER) which solves the frequency-related problem by re-arranging the coordinates of the input signal. It involves augmenting a hash-table to traditional INR to project the coordinates into the same distribution regardless of the arrangement order.", "example": "Convert the coordinate to text: [ 9.0579 -5.2483]:"}
{"text": "Convert the coordinate to text: [7.5426 6.3208]: The authors propose a novel method called 'distance to random point' (DRP) coverage testing for estimating coverage probabilities of generative posterior estimators, differing from existing coverage-based methods that require posterior evaluations.", "target": "The authors propose a novel method called 'distance to random point' (DRP) coverage testing for estimating coverage probabilities of generative posterior estimators, differing from existing coverage-based methods that require posterior evaluations.", "example": "Convert the coordinate to text: [7.5426 6.3208]:"}
{"text": "Convert the coordinate to text: [-8.8206 -2.3646]: The paper investigates the needs of beginner NLP researchers and the factors impacting their ability to reproduce research, emphasizing the importance of good documentation, coding practice, and data accessibility rather than programming skills and paper comprehension.", "target": "The paper investigates the needs of beginner NLP researchers and the factors impacting their ability to reproduce research, emphasizing the importance of good documentation, coding practice, and data accessibility rather than programming skills and paper comprehension.", "example": "Convert the coordinate to text: [-8.8206 -2.3646]:"}
{"text": "Convert the coordinate to text: [-2.564  0.292]: The authors propose a large-scale cross-dataset comparison where they fine-tune language models on different hate speech detection datasets to examine dataset generalizability and ponder the idea of amalgamating datasets for a more robust model.", "target": "The authors propose a large-scale cross-dataset comparison where they fine-tune language models on different hate speech detection datasets to examine dataset generalizability and ponder the idea of amalgamating datasets for a more robust model.", "example": "Convert the coordinate to text: [-2.564  0.292]:"}
{"text": "Convert the coordinate to text: [ -1.4957 -13.366 ]: The authors propose Treatment Variational AutoEncoder (TVAE), which models a patient's potential treatment assignment and the factual and counterfactual outcomes as part of their intrinsic characteristics in a deep latent variable model. The model mitigates the selection bias and the scarcity of treatment cases using a reconstruction regularization scheme, semi-supervision, a disentangled and distribution-matched latent space, and a label-balancing generative strategy.", "target": "The authors propose Treatment Variational AutoEncoder (TVAE), which models a patient's potential treatment assignment and the factual and counterfactual outcomes as part of their intrinsic characteristics in a deep latent variable model. The model mitigates the selection bias and the scarcity of treatment cases using a reconstruction regularization scheme, semi-supervision, a disentangled and distribution-matched latent space, and a label-balancing generative strategy.", "example": "Convert the coordinate to text: [ -1.4957 -13.366 ]:"}
{"text": "Convert the coordinate to text: [-1.9344 -6.892 ]: The researchers submitted a model that used a transformer-based approach combined with data augmentation via machine translation to predict tweet intimacy.", "target": "The researchers submitted a model that used a transformer-based approach combined with data augmentation via machine translation to predict tweet intimacy.", "example": "Convert the coordinate to text: [-1.9344 -6.892 ]:"}
{"text": "Convert the coordinate to text: [-6.2134 -0.9997]: The authors participate in the BioLaySumm task and design a system to automatically generate lay summaries from a biomedical article's abstract and main text.", "target": "The authors participate in the BioLaySumm task and design a system to automatically generate lay summaries from a biomedical article's abstract and main text.", "example": "Convert the coordinate to text: [-6.2134 -0.9997]:"}
{"text": "Convert the coordinate to text: [-5.858  10.6802]: The paper introduces a novel task, Proactive News Grounded Conversation, where the dialogue system is designed to lead the conversation based on key news topics, and it also includes realistic scenarios of information-seeking and casual chat based on the news.", "target": "The paper introduces a novel task, Proactive News Grounded Conversation, where the dialogue system is designed to lead the conversation based on key news topics, and it also includes realistic scenarios of information-seeking and casual chat based on the news.", "example": "Convert the coordinate to text: [-5.858  10.6802]:"}
{"text": "Convert the coordinate to text: [ 3.9324 -2.9014]: The authors propose a new method called Task-adaptive Label Dependency Transfer (TLDT) that makes label dependency transferable and effectively adapt to new tasks by utilizing just a few samples, improving the existing optimization-based meta-learning methods.", "target": "The authors propose a new method called Task-adaptive Label Dependency Transfer (TLDT) that makes label dependency transferable and effectively adapt to new tasks by utilizing just a few samples, improving the existing optimization-based meta-learning methods.", "example": "Convert the coordinate to text: [ 3.9324 -2.9014]:"}
{"text": "Convert the coordinate to text: [-0.6077 -4.5135]: The authors propose an approach that leverages in-context learning to improve zero-shot persona consistency in dialogue generation models. The method includes pre-training a persona-augmented dialogue generation model and using an in-context prompting mechanism for zero-shot persona customization.", "target": "The authors propose an approach that leverages in-context learning to improve zero-shot persona consistency in dialogue generation models. The method includes pre-training a persona-augmented dialogue generation model and using an in-context prompting mechanism for zero-shot persona customization.", "example": "Convert the coordinate to text: [-0.6077 -4.5135]:"}
{"text": "Convert the coordinate to text: [16.2104  1.8121]: The authors propose a 'two-birds-one-stone' method which allows the model to decide early on whether to make a decision on OOD classification, ensuring accuracy while also speeding up inference. To adapt to dynamic inference, a new training method based on ensemble methods is also introduced.", "target": "The authors propose a 'two-birds-one-stone' method which allows the model to decide early on whether to make a decision on OOD classification, ensuring accuracy while also speeding up inference. To adapt to dynamic inference, a new training method based on ensemble methods is also introduced.", "example": "Convert the coordinate to text: [16.2104  1.8121]:"}
{"text": "Convert the coordinate to text: [-5.6341 10.8084]: The authors propose SIMMC-VR, an extension of the SIMMC-2.0 dataset, to a video-grounded task-oriented dialog dataset that captures real-world AI-assisted user scenarios in VR. They also propose a novel data collection paradigm that involves generating object-centric multimodal dialog flows with egocentric visual streams and visually-grounded templates, and manually paraphrasing the simulated dialogs for naturalness and diversity.", "target": "The authors propose SIMMC-VR, an extension of the SIMMC-2.0 dataset, to a video-grounded task-oriented dialog dataset that captures real-world AI-assisted user scenarios in VR. They also propose a novel data collection paradigm that involves generating object-centric multimodal dialog flows with egocentric visual streams and visually-grounded templates, and manually paraphrasing the simulated dialogs for naturalness and diversity.", "example": "Convert the coordinate to text: [-5.6341 10.8084]:"}
{"text": "Convert the coordinate to text: [ 1.7049 -3.2625]: Instead of relying on model architectures, this paper presents a domain-general and model-agnostic formulation of compositionality as a constraint on symmetries of data distributions, and introduces an augmentation scheme that imparts compositional inductive bias on any model.", "target": "Instead of relying on model architectures, this paper presents a domain-general and model-agnostic formulation of compositionality as a constraint on symmetries of data distributions, and introduces an augmentation scheme that imparts compositional inductive bias on any model.", "example": "Convert the coordinate to text: [ 1.7049 -3.2625]:"}
{"text": "Convert the coordinate to text: [ 4.045  -3.9997]: To alleviate the input mismatch problem in deep GNNs distillation, a lightweight stochastic extended module is proposed to model the distribution of missing input information for student GNNs. The missing information is modeled as an independent distribution from the graph level and a conditional distribution from the node level and combined into a balanced estimate as an additional input to student GNNs.", "target": "To alleviate the input mismatch problem in deep GNNs distillation, a lightweight stochastic extended module is proposed to model the distribution of missing input information for student GNNs. The missing information is modeled as an independent distribution from the graph level and a conditional distribution from the node level and combined into a balanced estimate as an additional input to student GNNs.", "example": "Convert the coordinate to text: [ 4.045  -3.9997]:"}
{"text": "Convert the coordinate to text: [ 1.8112 -7.9462]: The authors propose the Group Event Transformer (GET), a novel group-based vision Transformer backbone for event-based vision, which decouples temporal-polarity information from spatial information during the feature extraction process.", "target": "The authors propose the Group Event Transformer (GET), a novel group-based vision Transformer backbone for event-based vision, which decouples temporal-polarity information from spatial information during the feature extraction process.", "example": "Convert the coordinate to text: [ 1.8112 -7.9462]:"}
{"text": "Convert the coordinate to text: [ 2.486  -3.9841]: The authors propose a novel Contrastive Instance feature mining method, named CoIn, along with two modules - Multi-Class contrastive learning module (MCcont) and a feature-level pseudo-label mining framework - to help better identify indistinguishable features learned through limited supervision and to supervise the training of detectors with limited annotations.", "target": "The authors propose a novel Contrastive Instance feature mining method, named CoIn, along with two modules - Multi-Class contrastive learning module (MCcont) and a feature-level pseudo-label mining framework - to help better identify indistinguishable features learned through limited supervision and to supervise the training of detectors with limited annotations.", "example": "Convert the coordinate to text: [ 2.486  -3.9841]:"}
{"text": "Convert the coordinate to text: [ 11.8323 -15.3021]: The authors propose Guided Motion Diffusion (GMD), a method that incorporates spatial constraints into the motion generation process through a novel feature projection scheme and imputation formulation to enhance coherency between spatial information and local poses.", "target": "The authors propose Guided Motion Diffusion (GMD), a method that incorporates spatial constraints into the motion generation process through a novel feature projection scheme and imputation formulation to enhance coherency between spatial information and local poses.", "example": "Convert the coordinate to text: [ 11.8323 -15.3021]:"}
{"text": "Convert the coordinate to text: [11.9081 -2.4165]: This paper theoretically demonstrates that the coefficients of LSCs in UNet greatly influence the stability of the forward and backward propagation and robustness of UNet. The paper also recognizes the theoretical benefits of the LSC coefficient scaling of UNet in the stability of hidden features and gradient and also robustness.", "target": "This paper theoretically demonstrates that the coefficients of LSCs in UNet greatly influence the stability of the forward and backward propagation and robustness of UNet. The paper also recognizes the theoretical benefits of the LSC coefficient scaling of UNet in the stability of hidden features and gradient and also robustness.", "example": "Convert the coordinate to text: [11.9081 -2.4165]:"}
{"text": "Convert the coordinate to text: [9.0401 7.1349]: The paper advocates a new paradigm, Personalized Empirical Risk Minimization (PERM), which facilitates learning distinct models for each client. This is done by effectively estimating statistical discrepancy among data distributions and personalizing the aggregation of local empirical losses.", "target": "The paper advocates a new paradigm, Personalized Empirical Risk Minimization (PERM), which facilitates learning distinct models for each client. This is done by effectively estimating statistical discrepancy among data distributions and personalizing the aggregation of local empirical losses.", "example": "Convert the coordinate to text: [9.0401 7.1349]:"}
{"text": "Convert the coordinate to text: [ 9.3458 11.8151]: The authors propose two novel algorithms for this problem based on truncation and mean of medians, which can handle heavy-tailed rewards.", "target": "The authors propose two novel algorithms for this problem based on truncation and mean of medians, which can handle heavy-tailed rewards.", "example": "Convert the coordinate to text: [ 9.3458 11.8151]:"}
{"text": "Convert the coordinate to text: [ 8.6586 -5.3202]: The authors hypothesize the presence of latent force fields and propose to use neural fields to learn them. They propose to disentangle local object interactions, which are SE(n) equivariant and depend on relative states, from external global field effects, which depend on absolute states. They combine these concepts in a novel graph network that integrates field forces.", "target": "The authors hypothesize the presence of latent force fields and propose to use neural fields to learn them. They propose to disentangle local object interactions, which are SE(n) equivariant and depend on relative states, from external global field effects, which depend on absolute states. They combine these concepts in a novel graph network that integrates field forces.", "example": "Convert the coordinate to text: [ 8.6586 -5.3202]:"}
{"text": "Convert the coordinate to text: [6.6132 4.6057]: The authors propose simplifying the learning problem using a discrete set of surrogate environments and present a refined analysis of the information ratio using posterior consistency.", "target": "The authors propose simplifying the learning problem using a discrete set of surrogate environments and present a refined analysis of the information ratio using posterior consistency.", "example": "Convert the coordinate to text: [6.6132 4.6057]:"}
{"text": "Convert the coordinate to text: [ 5.6371 13.7621]: The authors propose a novel approach for curriculum RL named 'Diversify for Disagreement & Conquer (D2C)' that requires only a few examples of desired outcomes and can function in any environment.", "target": "The authors propose a novel approach for curriculum RL named 'Diversify for Disagreement & Conquer (D2C)' that requires only a few examples of desired outcomes and can function in any environment.", "example": "Convert the coordinate to text: [ 5.6371 13.7621]:"}
{"text": "Convert the coordinate to text: [12.5294 -0.9128]: To tackle the noise problem in deep neural networks, the authors introduce Double Gumbel Q-Learning, a Deep Q-Learning algorithm that is applicable for both discrete and continuous control.", "target": "To tackle the noise problem in deep neural networks, the authors introduce Double Gumbel Q-Learning, a Deep Q-Learning algorithm that is applicable for both discrete and continuous control.", "example": "Convert the coordinate to text: [12.5294 -0.9128]:"}
{"text": "Convert the coordinate to text: [-0.309  -5.1423]: This paper proposes generative post-processing networks (GenPPNs) as a solution to post-processing the utterance output by the NLG module. Additionally, a new measure is proposed, dialogue act contribution, to evaluate the contribution of GenPPN-generated utterances in dialogue.", "target": "This paper proposes generative post-processing networks (GenPPNs) as a solution to post-processing the utterance output by the NLG module. Additionally, a new measure is proposed, dialogue act contribution, to evaluate the contribution of GenPPN-generated utterances in dialogue.", "example": "Convert the coordinate to text: [-0.309  -5.1423]:"}
{"text": "Convert the coordinate to text: [13.0869  3.348 ]: The authors propose a new method, MARVEL, which adaptively allocates the parameter budget among weight matrices based on their importance, thus potentially improving the effectiveness of fine-tuning. MARVEL parameterizes incremental updates using singular value decomposition, allowing for the pruning of singular values of unimportant updates to reduce their parameter budget.", "target": "The authors propose a new method, MARVEL, which adaptively allocates the parameter budget among weight matrices based on their importance, thus potentially improving the effectiveness of fine-tuning. MARVEL parameterizes incremental updates using singular value decomposition, allowing for the pruning of singular values of unimportant updates to reduce their parameter budget.", "example": "Convert the coordinate to text: [13.0869  3.348 ]:"}
{"text": "Convert the coordinate to text: [ 5.4389 -9.8116]: The authors propose a new task of zero-shot text-to-video generation and devise a low-cost approach leveraging existing text-to-image synthesis methods, such as Stable Diffusion. They introduce two main modifications: enriching the latent codes of the generated frames with motion dynamics for time consistency; and reprogramming self-attention to use new cross-frame attention, ensuring preservation of the context, appearance, and identity of foreground objects.", "target": "The authors propose a new task of zero-shot text-to-video generation and devise a low-cost approach leveraging existing text-to-image synthesis methods, such as Stable Diffusion. They introduce two main modifications: enriching the latent codes of the generated frames with motion dynamics for time consistency; and reprogramming self-attention to use new cross-frame attention, ensuring preservation of the context, appearance, and identity of foreground objects.", "example": "Convert the coordinate to text: [ 5.4389 -9.8116]:"}
{"text": "Convert the coordinate to text: [-8.6867 11.0298]: This study analyses news articles pertaining to offside decisions made with SAOT during and around the tournament, with the aim of understanding public reactions and how they impacted the spectator experience.", "target": "This study analyses news articles pertaining to offside decisions made with SAOT during and around the tournament, with the aim of understanding public reactions and how they impacted the spectator experience.", "example": "Convert the coordinate to text: [-8.6867 11.0298]:"}
{"text": "Convert the coordinate to text: [ 1.5571 -6.0773]: The paper introduces StrAE, an autoencoding framework that leverages sentence structure to learn multi-level node embeddings. The introduced model uses different types of sentential structure and objectives, including a novel contrastive loss over structure.", "target": "The paper introduces StrAE, an autoencoding framework that leverages sentence structure to learn multi-level node embeddings. The introduced model uses different types of sentential structure and objectives, including a novel contrastive loss over structure.", "example": "Convert the coordinate to text: [ 1.5571 -6.0773]:"}
{"text": "Convert the coordinate to text: [-4.7063 10.2189]: The authors introduce STORYWARS, a new dataset of over 40,000 collaborative stories written by 9,400 different authors from an online platform together with, and they design 12 task types, comprising 7 understanding and 5 generation task types on STORYWARS covering all fully-supervised, few-shot, and zero-shot scenarios. They also present the INSTRUCTSTORY model with a method called instruction tuning.", "target": "The authors introduce STORYWARS, a new dataset of over 40,000 collaborative stories written by 9,400 different authors from an online platform together with, and they design 12 task types, comprising 7 understanding and 5 generation task types on STORYWARS covering all fully-supervised, few-shot, and zero-shot scenarios. They also present the INSTRUCTSTORY model with a method called instruction tuning.", "example": "Convert the coordinate to text: [-4.7063 10.2189]:"}
{"text": "Convert the coordinate to text: [ 5.3775 -5.1226]: The authors propose a novel dynamic hypergraph neural network that can adjust the number of hyperedges while optimizing the hypergraph structure. Instead of focusing on fixed hyperedge features, this model learns the feature distribution of hyperedges.", "target": "The authors propose a novel dynamic hypergraph neural network that can adjust the number of hyperedges while optimizing the hypergraph structure. Instead of focusing on fixed hyperedge features, this model learns the feature distribution of hyperedges.", "example": "Convert the coordinate to text: [ 5.3775 -5.1226]:"}
{"text": "Convert the coordinate to text: [-1.3372 -6.5395]: The authors propose three pre-training objectives that replicate the downstream fine-tuning task of contextual AS2, which enables Language Models (LMs) to be specialized when fine-tuning for contextual AS2.", "target": "The authors propose three pre-training objectives that replicate the downstream fine-tuning task of contextual AS2, which enables Language Models (LMs) to be specialized when fine-tuning for contextual AS2.", "example": "Convert the coordinate to text: [-1.3372 -6.5395]:"}
{"text": "Convert the coordinate to text: [ 1.4095 -0.8437]: The paper introduces ReLoop2, a self-correcting learning loop that enables fast model adaptation in online recommender systems through responsive error compensation. To achieve this, it incorporates an error memory module, inspired by the slow-fast complementary learning system observed in human brains, that stores error samples from incoming data streams.", "target": "The paper introduces ReLoop2, a self-correcting learning loop that enables fast model adaptation in online recommender systems through responsive error compensation. To achieve this, it incorporates an error memory module, inspired by the slow-fast complementary learning system observed in human brains, that stores error samples from incoming data streams.", "example": "Convert the coordinate to text: [ 1.4095 -0.8437]:"}
{"text": "Convert the coordinate to text: [-2.1824 -7.8847]: The authors propose Nonparametric Decoding (Np Decoding) which utilizes nonparametric contextualized vocab embeddings (external memory) rather than vanilla vocab embeddings as decoder vocab embeddings. This allows the generative retrieval model to utilize both the parametric and nonparametric space.", "target": "The authors propose Nonparametric Decoding (Np Decoding) which utilizes nonparametric contextualized vocab embeddings (external memory) rather than vanilla vocab embeddings as decoder vocab embeddings. This allows the generative retrieval model to utilize both the parametric and nonparametric space.", "example": "Convert the coordinate to text: [-2.1824 -7.8847]:"}
{"text": "Convert the coordinate to text: [ 3.6486 12.92  ]: The authors propose a language-first procedure planning framework. This involves first aligning the current and goal observations with corresponding steps and then using a pre-trained language model (LM) to predict the intermediate steps.", "target": "The authors propose a language-first procedure planning framework. This involves first aligning the current and goal observations with corresponding steps and then using a pre-trained language model (LM) to predict the intermediate steps.", "example": "Convert the coordinate to text: [ 3.6486 12.92  ]:"}
{"text": "Convert the coordinate to text: [-4.9088 10.196 ]: The authors propose a flexible global planning approach, in which a global path is generated as a natural language sentence, instead of a sequence of nodes, allowing the dialogue to be guided to the target with flexible turns.", "target": "The authors propose a flexible global planning approach, in which a global path is generated as a natural language sentence, instead of a sequence of nodes, allowing the dialogue to be guided to the target with flexible turns.", "example": "Convert the coordinate to text: [-4.9088 10.196 ]:"}
{"text": "Convert the coordinate to text: [ 2.3418 -4.1136]: A dual class knowledge propagation network is proposed to address the two problem limitations facing multi-label few-shot intent detection. This includes the introduction of a label-semantic augmentation module that uses class name information to learn well-separated representations for utterances with multiple intents.", "target": "A dual class knowledge propagation network is proposed to address the two problem limitations facing multi-label few-shot intent detection. This includes the introduction of a label-semantic augmentation module that uses class name information to learn well-separated representations for utterances with multiple intents.", "example": "Convert the coordinate to text: [ 2.3418 -4.1136]:"}
{"text": "Convert the coordinate to text: [-0.4276  1.429 ]: The authors propose a methodological blueprint for the evaluation of selective prediction in NLP tasks, which includes a novel metric called refinement for evaluating confidence functions.", "target": "The authors propose a methodological blueprint for the evaluation of selective prediction in NLP tasks, which includes a novel metric called refinement for evaluating confidence functions.", "example": "Convert the coordinate to text: [-0.4276  1.429 ]:"}
{"text": "Convert the coordinate to text: [ 4.9941 -5.3654]: The authors propose MetricGNN (MGNN), a spatial GNN model inspired by the congruent-insensitivity property of classifiers in the GNNs\u2019 classification phase. The universality of a GNN model in the spatial domain is demonstrated if it can generate embedding matrices that are congruent to any given embedding matrix, and this property is closely related to the Distance Geometry Problem (DGP).", "target": "The authors propose MetricGNN (MGNN), a spatial GNN model inspired by the congruent-insensitivity property of classifiers in the GNNs\u2019 classification phase. The universality of a GNN model in the spatial domain is demonstrated if it can generate embedding matrices that are congruent to any given embedding matrix, and this property is closely related to the Distance Geometry Problem (DGP).", "example": "Convert the coordinate to text: [ 4.9941 -5.3654]:"}
{"text": "Convert the coordinate to text: [10.5628 -2.6676]: The authors introduce Neural Galerkin schemes that update randomized sparse subsets of network parameters at each time step, motivated by dropout that addresses overfitting due to neuron co-adaptation.", "target": "The authors introduce Neural Galerkin schemes that update randomized sparse subsets of network parameters at each time step, motivated by dropout that addresses overfitting due to neuron co-adaptation.", "example": "Convert the coordinate to text: [10.5628 -2.6676]:"}
{"text": "Convert the coordinate to text: [  1.5599 -11.801 ]: The paper proposes a novel solution called Prototypical Mixing and Retrieval-based Refinement (TITAN) to resist label noise in image retrieval, that corrects label noise and mitigates the effects of the memorization simultaneously.", "target": "The paper proposes a novel solution called Prototypical Mixing and Retrieval-based Refinement (TITAN) to resist label noise in image retrieval, that corrects label noise and mitigates the effects of the memorization simultaneously.", "example": "Convert the coordinate to text: [  1.5599 -11.801 ]:"}
{"text": "Convert the coordinate to text: [11.5541 -2.1316]: The authors propose a unified analysis framework for understanding two-layer networks trained by gradient descent, pivoting on the principle of feature learning from gradients.", "target": "The authors propose a unified analysis framework for understanding two-layer networks trained by gradient descent, pivoting on the principle of feature learning from gradients.", "example": "Convert the coordinate to text: [11.5541 -2.1316]:"}
{"text": "Convert the coordinate to text: [ 2.0175 -6.2588]: The authors delve into the unexplored sphere of MGM by evaluating popular molecule tokenizers at varying levels of granularity, and explore the potential of adopting an expressive decoder in MGM. They also propose a novel MGM method called SimSGT, which features a Simple GNN-based Tokenizer (SGT) and an effective decoding strategy.", "target": "The authors delve into the unexplored sphere of MGM by evaluating popular molecule tokenizers at varying levels of granularity, and explore the potential of adopting an expressive decoder in MGM. They also propose a novel MGM method called SimSGT, which features a Simple GNN-based Tokenizer (SGT) and an effective decoding strategy.", "example": "Convert the coordinate to text: [ 2.0175 -6.2588]:"}
{"text": "Convert the coordinate to text: [13.4239 -2.5456]: The authors suggest mapping rate-based loss functions to time-based counterparts in order to better utilize the temporal information in SNNs. They propose an enhanced counting loss to replace the commonly used mean square counting loss and transfer the training of scale factor in weight standardization into thresholds.", "target": "The authors suggest mapping rate-based loss functions to time-based counterparts in order to better utilize the temporal information in SNNs. They propose an enhanced counting loss to replace the commonly used mean square counting loss and transfer the training of scale factor in weight standardization into thresholds.", "example": "Convert the coordinate to text: [13.4239 -2.5456]:"}
{"text": "Convert the coordinate to text: [ 0.7818 15.7452]: The authors propose a theoretical foundation for the no-underbidding phenomenon and study the Price of Anarchy of simultaneous 2nd price auctions (S2PA) under a new condition of no underbidding, meaning that agents never bid on items less than their marginal values.", "target": "The authors propose a theoretical foundation for the no-underbidding phenomenon and study the Price of Anarchy of simultaneous 2nd price auctions (S2PA) under a new condition of no underbidding, meaning that agents never bid on items less than their marginal values.", "example": "Convert the coordinate to text: [ 0.7818 15.7452]:"}
{"text": "Convert the coordinate to text: [-6.1901 -4.8939]: The paper introduces an unsupervised VWSD approach that uses gloss information of an external lexical knowledge-base, suggesting Bayesian inference to incorporate the sense definitions, when sense information of the answer is not provided.", "target": "The paper introduces an unsupervised VWSD approach that uses gloss information of an external lexical knowledge-base, suggesting Bayesian inference to incorporate the sense definitions, when sense information of the answer is not provided.", "example": "Convert the coordinate to text: [-6.1901 -4.8939]:"}
{"text": "Convert the coordinate to text: [-11.0232  15.5668]: The paper introduces QRUco, an approach to create interactive fiducial markers. QRUco uses thermochromic paint to embed three secondary markers into QR code finder patterns. Users can interact with these markers through rubbing or pressing/touching, which changes the appearance of the marker while leaving the primary QR code intact.", "target": "The paper introduces QRUco, an approach to create interactive fiducial markers. QRUco uses thermochromic paint to embed three secondary markers into QR code finder patterns. Users can interact with these markers through rubbing or pressing/touching, which changes the appearance of the marker while leaving the primary QR code intact.", "example": "Convert the coordinate to text: [-11.0232  15.5668]:"}
{"text": "Convert the coordinate to text: [ -0.6191 -10.0353]: The authors present CoFe, a test suite to study in-context compositional generalization and to identify the key factors that can make good in-context examples for compositional generalization.", "target": "The authors present CoFe, a test suite to study in-context compositional generalization and to identify the key factors that can make good in-context examples for compositional generalization.", "example": "Convert the coordinate to text: [ -0.6191 -10.0353]:"}
{"text": "Convert the coordinate to text: [ 4.8626 -3.2255]: The authors propose the Lifelong-MoE, an extensible Mixture-of-Experts architecture that dynamically adds model capacity while regularized pretraining. This model is able to adapt to data distribution shifts and preserve the previous knowledge.", "target": "The authors propose the Lifelong-MoE, an extensible Mixture-of-Experts architecture that dynamically adds model capacity while regularized pretraining. This model is able to adapt to data distribution shifts and preserve the previous knowledge.", "example": "Convert the coordinate to text: [ 4.8626 -3.2255]:"}
{"text": "Convert the coordinate to text: [-2.162  -5.4067]: The study aims to present a comprehensive evaluation of ChatGPT's performance on a variety of academic datasets, covering diverse tasks. This work marks the largest evaluation of ChatGPT in Natural Language Processing (NLP) benchmarks.", "target": "The study aims to present a comprehensive evaluation of ChatGPT's performance on a variety of academic datasets, covering diverse tasks. This work marks the largest evaluation of ChatGPT in Natural Language Processing (NLP) benchmarks.", "example": "Convert the coordinate to text: [-2.162  -5.4067]:"}
{"text": "Convert the coordinate to text: [  4.8738 -13.4554]: This paper introduces RegionGen, a data-driven framework for region generation that models this task as a multi-objective optimization problem to achieve key features like strong spatial semantic meaning and predictability.", "target": "This paper introduces RegionGen, a data-driven framework for region generation that models this task as a multi-objective optimization problem to achieve key features like strong spatial semantic meaning and predictability.", "example": "Convert the coordinate to text: [  4.8738 -13.4554]:"}
{"text": "Convert the coordinate to text: [ 5.117  -6.4432]: The concept proposed involves localizing ASTGNNs by sparsifying the spatial graph adjacency matrices via an Adaptive Graph Sparsification (AGS) algorithm, effectively transforming them into graph-less and purely temporal models.", "target": "The concept proposed involves localizing ASTGNNs by sparsifying the spatial graph adjacency matrices via an Adaptive Graph Sparsification (AGS) algorithm, effectively transforming them into graph-less and purely temporal models.", "example": "Convert the coordinate to text: [ 5.117  -6.4432]:"}
{"text": "Convert the coordinate to text: [-0.7113  0.6899]: The authors propose WinoQueer, a community-sourced benchmark specifically designed to measure anti-LGBTQ+ biases in large language models. The novelty lies in the method that generates a bias benchmark from a community survey.", "target": "The authors propose WinoQueer, a community-sourced benchmark specifically designed to measure anti-LGBTQ+ biases in large language models. The novelty lies in the method that generates a bias benchmark from a community survey.", "example": "Convert the coordinate to text: [-0.7113  0.6899]:"}
{"text": "Convert the coordinate to text: [-2.5613 -0.894 ]: The paper presents a semi-supervised neural topic modeling method, vONTSS, which uses von Mises-Fisher (vMF) based variational autoencoders and optimal transport that generates potential topics and optimizes topic-keyword quality and topic classification when a few keywords per topic are provided.", "target": "The paper presents a semi-supervised neural topic modeling method, vONTSS, which uses von Mises-Fisher (vMF) based variational autoencoders and optimal transport that generates potential topics and optimizes topic-keyword quality and topic classification when a few keywords per topic are provided.", "example": "Convert the coordinate to text: [-2.5613 -0.894 ]:"}
{"text": "Convert the coordinate to text: [-10.6224  -2.0003]: The authors tackle the task of automatically generating gap-focused questions (GFQs) which are essentially questions addressing the missing parts in students' answers.", "target": "The authors tackle the task of automatically generating gap-focused questions (GFQs) which are essentially questions addressing the missing parts in students' answers.", "example": "Convert the coordinate to text: [-10.6224  -2.0003]:"}
{"text": "Convert the coordinate to text: [18.5421 -3.189 ]: This paper focuses on classifying the spoiler type in clickbait posts, using BERT-base (cased) model and providing only the post content as the input, rather than both the post title and content.", "target": "This paper focuses on classifying the spoiler type in clickbait posts, using BERT-base (cased) model and providing only the post content as the input, rather than both the post title and content.", "example": "Convert the coordinate to text: [18.5421 -3.189 ]:"}
{"text": "Convert the coordinate to text: [-1.8408 -5.5708]: The authors propose a novel sequence tagging-based model for incomplete utterance rewriting, which better extracts information from the context, and introduce a speaker-aware embedding to model variations between speakers.", "target": "The authors propose a novel sequence tagging-based model for incomplete utterance rewriting, which better extracts information from the context, and introduce a speaker-aware embedding to model variations between speakers.", "example": "Convert the coordinate to text: [-1.8408 -5.5708]:"}
{"text": "Convert the coordinate to text: [-1.1465  4.5907]: This study addresses the failure of current methods by proposing a unified framework that simultaneously predicts node attributes and topology changes such as the appearance and disappearance of links, and the emergence and loss of nodes.", "target": "This study addresses the failure of current methods by proposing a unified framework that simultaneously predicts node attributes and topology changes such as the appearance and disappearance of links, and the emergence and loss of nodes.", "example": "Convert the coordinate to text: [-1.1465  4.5907]:"}
{"text": "Convert the coordinate to text: [ 1.869  -4.3846]: The authors propose Actionness Inconsistency-guided Contrastive Learning (AICL), which utilizes consistent segments in order to boost the representation learning of inconsistent segments in WTAL.", "target": "The authors propose Actionness Inconsistency-guided Contrastive Learning (AICL), which utilizes consistent segments in order to boost the representation learning of inconsistent segments in WTAL.", "example": "Convert the coordinate to text: [ 1.869  -4.3846]:"}
{"text": "Convert the coordinate to text: [-4.3756 12.9657]: The authors propose a novel senior-level undergraduate course designed to teach the integration of various AI techniques in uncertain environments, independent of robotics-focused topics like control and localization. They use an autonomous greenhouse as the real-world application context for discussions and student projects, considering its self-contained nature and clear performance metrics.", "target": "The authors propose a novel senior-level undergraduate course designed to teach the integration of various AI techniques in uncertain environments, independent of robotics-focused topics like control and localization. They use an autonomous greenhouse as the real-world application context for discussions and student projects, considering its self-contained nature and clear performance metrics.", "example": "Convert the coordinate to text: [-4.3756 12.9657]:"}
{"text": "Convert the coordinate to text: [-3.2336 -4.2516]: The authors introduce a Semantic-Structure-Preserving Consistency approach that aims to improve generalizability by preserving the modality-specific relationships in the joint embedding space. To capture these relationships, they propose to learn multiple anchors and represent the multifaceted relationship between samples with these anchors.", "target": "The authors introduce a Semantic-Structure-Preserving Consistency approach that aims to improve generalizability by preserving the modality-specific relationships in the joint embedding space. To capture these relationships, they propose to learn multiple anchors and represent the multifaceted relationship between samples with these anchors.", "example": "Convert the coordinate to text: [-3.2336 -4.2516]:"}
{"text": "Convert the coordinate to text: [ -1.4027 -13.2676]: The authors propose the Wasserstein Expansible Variational Autoencoder (WEVAE), which evaluates the statistical similarity between the probabilistic representation of new data and that of each mixture component to decide when to expand the model. This can prevent unnecessary expansion while preserving knowledge diversity among the trained components. The authors also introduce an energy-based sample selection approach.", "target": "The authors propose the Wasserstein Expansible Variational Autoencoder (WEVAE), which evaluates the statistical similarity between the probabilistic representation of new data and that of each mixture component to decide when to expand the model. This can prevent unnecessary expansion while preserving knowledge diversity among the trained components. The authors also introduce an energy-based sample selection approach.", "example": "Convert the coordinate to text: [ -1.4027 -13.2676]:"}
{"text": "Convert the coordinate to text: [ 2.2655 -1.9095]: The paper proposes a method to improve anomaly detection performance by sequentially learning multiple pretext tasks according to their difficulties, starting with the easy tasks and gradually adding more challenging ones. The proposed approach aims to reduce the difficulties of learning and avoid converging to sub-optimal solutions.", "target": "The paper proposes a method to improve anomaly detection performance by sequentially learning multiple pretext tasks according to their difficulties, starting with the easy tasks and gradually adding more challenging ones. The proposed approach aims to reduce the difficulties of learning and avoid converging to sub-optimal solutions.", "example": "Convert the coordinate to text: [ 2.2655 -1.9095]:"}
{"text": "Convert the coordinate to text: [3.2214 9.897 ]: The authors propose a new method for configuring heuristic algorithms that aims to maximize the utility provided to the end users instead of minimizing runtime. This utilitarian approach is characterized by having a utility that is bounded and monotonically decreases with runtime, allowing for empirical bounds on the performance of a configuration.", "target": "The authors propose a new method for configuring heuristic algorithms that aims to maximize the utility provided to the end users instead of minimizing runtime. This utilitarian approach is characterized by having a utility that is bounded and monotonically decreases with runtime, allowing for empirical bounds on the performance of a configuration.", "example": "Convert the coordinate to text: [3.2214 9.897 ]:"}
{"text": "Convert the coordinate to text: [13.2943 -2.4007]: A novel formalization of NSC is proposed that allows for directly fitting NSC generative models to recorded neuronal activity in response to natural images, formulating richer and more flexible generative models, and using standard metrics for quantitatively evaluate generative models under NSC.", "target": "A novel formalization of NSC is proposed that allows for directly fitting NSC generative models to recorded neuronal activity in response to natural images, formulating richer and more flexible generative models, and using standard metrics for quantitatively evaluate generative models under NSC.", "example": "Convert the coordinate to text: [13.2943 -2.4007]:"}
{"text": "Convert the coordinate to text: [-0.5121 -7.0657]: This paper introduces the MixEncoder paradigm for efficient sentence pair modeling, which utilizes a light-weight cross-attention mechanism that executes query encoding just once while modeling the query-candidate interaction in parallel.", "target": "This paper introduces the MixEncoder paradigm for efficient sentence pair modeling, which utilizes a light-weight cross-attention mechanism that executes query encoding just once while modeling the query-candidate interaction in parallel.", "example": "Convert the coordinate to text: [-0.5121 -7.0657]:"}
{"text": "Convert the coordinate to text: [-0.588  -7.4537]: The authors propose PuMer, a token reduction framework that uses text-informed Pruning and modality-aware Merging strategies to progressively reduce the tokens of input image and text, thereby improving model inference speed and reducing memory footprint.", "target": "The authors propose PuMer, a token reduction framework that uses text-informed Pruning and modality-aware Merging strategies to progressively reduce the tokens of input image and text, thereby improving model inference speed and reducing memory footprint.", "example": "Convert the coordinate to text: [-0.588  -7.4537]:"}
{"text": "Convert the coordinate to text: [-8.7405 -0.8301]: The authors address the issue of long-form answers by proposing a method to provide a concise version of the answer by summarizing it. The new method is called 'extract-and-decontextualize'.", "target": "The authors address the issue of long-form answers by proposing a method to provide a concise version of the answer by summarizing it. The new method is called 'extract-and-decontextualize'.", "example": "Convert the coordinate to text: [-8.7405 -0.8301]:"}
{"text": "Convert the coordinate to text: [-3.9285 -7.3927]: The authors propose an Extract-and-Attend approach to improve the translation of entities in NMT, which involves extracting translation candidates of source entities from a dictionary and having the NMT model attend to these candidates when generating the target sentence.", "target": "The authors propose an Extract-and-Attend approach to improve the translation of entities in NMT, which involves extracting translation candidates of source entities from a dictionary and having the NMT model attend to these candidates when generating the target sentence.", "example": "Convert the coordinate to text: [-3.9285 -7.3927]:"}
{"text": "Convert the coordinate to text: [-1.4472 -6.3068]: The authors propose the use of the Roberta model to obtain the word vector encoding of the document along with a multi-head attention mechanism to establish connections between labels and semantic components. Also, a contrastive learning-enhanced K-nearest neighbor mechanism is used to leverage the already existing instance information for prediction.", "target": "The authors propose the use of the Roberta model to obtain the word vector encoding of the document along with a multi-head attention mechanism to establish connections between labels and semantic components. Also, a contrastive learning-enhanced K-nearest neighbor mechanism is used to leverage the already existing instance information for prediction.", "example": "Convert the coordinate to text: [-1.4472 -6.3068]:"}
{"text": "Convert the coordinate to text: [-9.1441 -1.5298]: In this study, the authors develop ACTA, an automated short-answer grading system designed for high-stakes medical exams. The system employs neural similarity-based grading approaches and uses contrastive learning as a means to optimize the similarity metric.", "target": "In this study, the authors develop ACTA, an automated short-answer grading system designed for high-stakes medical exams. The system employs neural similarity-based grading approaches and uses contrastive learning as a means to optimize the similarity metric.", "example": "Convert the coordinate to text: [-9.1441 -1.5298]:"}
{"text": "Convert the coordinate to text: [-1.3384  0.4044]: The paper highlights the prevalence of aporophobia, a form of social bias against the poor, on social media and asserts that current NLP datasets and models are insufficient to combat this issue effectively.", "target": "The paper highlights the prevalence of aporophobia, a form of social bias against the poor, on social media and asserts that current NLP datasets and models are insufficient to combat this issue effectively.", "example": "Convert the coordinate to text: [-1.3384  0.4044]:"}
{"text": "Convert the coordinate to text: [-4.0434  1.1896]: This study seeks to undertake a quantitative analysis of the emotion content and distinct linguistic features in six works of Sir Henry Rider Haggard using sentence-level emotion analysis, and investigating the use of modifiers, deontic modals, and collocated terms.", "target": "This study seeks to undertake a quantitative analysis of the emotion content and distinct linguistic features in six works of Sir Henry Rider Haggard using sentence-level emotion analysis, and investigating the use of modifiers, deontic modals, and collocated terms.", "example": "Convert the coordinate to text: [-4.0434  1.1896]:"}
{"text": "Convert the coordinate to text: [-3.6944 -9.0559]: The authors' approach revolves around the use of direct architectures for both tasks: for simultaneous translation, they leverage knowledge from offline-trained models and apply a real-time inference policy; for automatic subtitling, they adapt the direct simultaneous translation model to generate appropriately formed subtitles and also produce necessary timestamps for subtitle synchronization.", "target": "The authors' approach revolves around the use of direct architectures for both tasks: for simultaneous translation, they leverage knowledge from offline-trained models and apply a real-time inference policy; for automatic subtitling, they adapt the direct simultaneous translation model to generate appropriately formed subtitles and also produce necessary timestamps for subtitle synchronization.", "example": "Convert the coordinate to text: [-3.6944 -9.0559]:"}
{"text": "Convert the coordinate to text: [-9.3011 -5.3717]: The paper presents an approach for SRL by decomposing the edge from a predicate word to argument span into predicate-to-head (P2H), predicate-to-tail (P2T), and head-to-tail (H2T) edges, leveraging a CRF-based higher-order dependency parser and Mean-Field Variational Inference (MFVI), and defining a TreeCRF distribution over all H2T edges, using the idea of partial marginalization to define structural training loss.", "target": "The paper presents an approach for SRL by decomposing the edge from a predicate word to argument span into predicate-to-head (P2H), predicate-to-tail (P2T), and head-to-tail (H2T) edges, leveraging a CRF-based higher-order dependency parser and Mean-Field Variational Inference (MFVI), and defining a TreeCRF distribution over all H2T edges, using the idea of partial marginalization to define structural training loss.", "example": "Convert the coordinate to text: [-9.3011 -5.3717]:"}
{"text": "Convert the coordinate to text: [ 0.5677 -4.5653]: The paper proposes a novel framework that incorporates conceptual knowledge for text classification in the extreme zero-shot setting. This approach endeavors to mitigate the limitations of ignoring domain-specific words and biases introduced by training data.", "target": "The paper proposes a novel framework that incorporates conceptual knowledge for text classification in the extreme zero-shot setting. This approach endeavors to mitigate the limitations of ignoring domain-specific words and biases introduced by training data.", "example": "Convert the coordinate to text: [ 0.5677 -4.5653]:"}
{"text": "Convert the coordinate to text: [ 2.5733 -2.6999]: The authors propose an Adaptive Compositional Continual Meta-Learning (ACML) algorithm that uses a compositional premise to associate tasks with subsets of mixture components, thus allowing meta-knowledge sharing across heterogeneous tasks. Additionally, the algorithm includes a component sparsification method to filter out redundant components.", "target": "The authors propose an Adaptive Compositional Continual Meta-Learning (ACML) algorithm that uses a compositional premise to associate tasks with subsets of mixture components, thus allowing meta-knowledge sharing across heterogeneous tasks. Additionally, the algorithm includes a component sparsification method to filter out redundant components.", "example": "Convert the coordinate to text: [ 2.5733 -2.6999]:"}
{"text": "Convert the coordinate to text: [  8.9466 -16.271 ]: This paper introduces MV-DeepSDF, a new framework that estimates the optimal Signed Distance Function (SDF) shape representation from multi-sweep point clouds to reconstruct vehicles in real-world scenarios, transforming the implicit space shape estimation problem into an element-to-set feature extraction problem.", "target": "This paper introduces MV-DeepSDF, a new framework that estimates the optimal Signed Distance Function (SDF) shape representation from multi-sweep point clouds to reconstruct vehicles in real-world scenarios, transforming the implicit space shape estimation problem into an element-to-set feature extraction problem.", "example": "Convert the coordinate to text: [  8.9466 -16.271 ]:"}
{"text": "Convert the coordinate to text: [ 4.869  -0.1438]: The paper introduces a new weakly supervised binary classification problem called confidence-difference (ConfDiff) classification. Here, they work with unlabeled data pairs that reflect a difference in the probabilities of a positive outcome, rather than knowing with certainty the classification of each instance.", "target": "The paper introduces a new weakly supervised binary classification problem called confidence-difference (ConfDiff) classification. Here, they work with unlabeled data pairs that reflect a difference in the probabilities of a positive outcome, rather than knowing with certainty the classification of each instance.", "example": "Convert the coordinate to text: [ 4.869  -0.1438]:"}
{"text": "Convert the coordinate to text: [10.7898 -3.4657]: The authors propose novel training methods to optimize neural min-sum (NMS) decoders to make them robust to the error-floor phenomenon. The methods include leveraging the boosting learning technique of ensemble networks, applying a block-wise training schedule to tackle the vanishing gradient issue, and assigning different weights to unsatisfied check nodes.", "target": "The authors propose novel training methods to optimize neural min-sum (NMS) decoders to make them robust to the error-floor phenomenon. The methods include leveraging the boosting learning technique of ensemble networks, applying a block-wise training schedule to tackle the vanishing gradient issue, and assigning different weights to unsatisfied check nodes.", "example": "Convert the coordinate to text: [10.7898 -3.4657]:"}
{"text": "Convert the coordinate to text: [ 9.4586 -8.3629]: The authors revisit the degradation process of pan-sharpening in Fourier space and develop a Pyramid Dual Domain Injection pan-sharpening Network that fully explores and exploits the distinguished information in both the spatial and frequency domains.", "target": "The authors revisit the degradation process of pan-sharpening in Fourier space and develop a Pyramid Dual Domain Injection pan-sharpening Network that fully explores and exploits the distinguished information in both the spatial and frequency domains.", "example": "Convert the coordinate to text: [ 9.4586 -8.3629]:"}
{"text": "Convert the coordinate to text: [-0.9252 -4.1996]: The authors propose a reformation of large-space discriminative NLU tasks as a learning-to-retrieve task, leading to a novel solution named Dense Decision Retrieval (DDR). DDR adopts a dual-encoder architecture that learns to predict by retrieving from a decision thesaurus.", "target": "The authors propose a reformation of large-space discriminative NLU tasks as a learning-to-retrieve task, leading to a novel solution named Dense Decision Retrieval (DDR). DDR adopts a dual-encoder architecture that learns to predict by retrieving from a decision thesaurus.", "example": "Convert the coordinate to text: [-0.9252 -4.1996]:"}
{"text": "Convert the coordinate to text: [12.4136 -5.5997]: This work introduces a platform named IMPRESS, which is designed to test the effectiveness of imperceptible perturbations as a protective measure against unauthorized data usage. The key observation is that these perturbations can create perceptible inconsistencies between the original image and the diffusion-reconstructed image, which can lead to a new optimization strategy for purifying the image.", "target": "This work introduces a platform named IMPRESS, which is designed to test the effectiveness of imperceptible perturbations as a protective measure against unauthorized data usage. The key observation is that these perturbations can create perceptible inconsistencies between the original image and the diffusion-reconstructed image, which can lead to a new optimization strategy for purifying the image.", "example": "Convert the coordinate to text: [12.4136 -5.5997]:"}
{"text": "Convert the coordinate to text: [-8.8952 -2.5937]: The authors introduce a new area of research called NLP+Vis, which aims to integrate natural language processing (NLP) and visualization. The tutorial focuses on using NLP for visualization tasks and applying visualization techniques to interpret and explain complex NLP models.", "target": "The authors introduce a new area of research called NLP+Vis, which aims to integrate natural language processing (NLP) and visualization. The tutorial focuses on using NLP for visualization tasks and applying visualization techniques to interpret and explain complex NLP models.", "example": "Convert the coordinate to text: [-8.8952 -2.5937]:"}
{"text": "Convert the coordinate to text: [ 3.7793 -4.5153]: This paper proposes a Multi-Level Graph Contrastive Prototypical Clustering (MLG-CPC) framework for end-to-end clustering, featuring a new Prototype Discrimination (ProDisc) objective function that allows for explicit capture of semantic information through cluster assignments.", "target": "This paper proposes a Multi-Level Graph Contrastive Prototypical Clustering (MLG-CPC) framework for end-to-end clustering, featuring a new Prototype Discrimination (ProDisc) objective function that allows for explicit capture of semantic information through cluster assignments.", "example": "Convert the coordinate to text: [ 3.7793 -4.5153]:"}
{"text": "Convert the coordinate to text: [-2.0233 -6.4071]: The authors propose a new continued pre-training strategy to teach pre-trained models to generate simple texts. The representative model BART is trained further to develop SimpleBart.", "target": "The authors propose a new continued pre-training strategy to teach pre-trained models to generate simple texts. The representative model BART is trained further to develop SimpleBart.", "example": "Convert the coordinate to text: [-2.0233 -6.4071]:"}
{"text": "Convert the coordinate to text: [-3.0441 -4.0572]: The authors propose that NLI models can outperform more complex metrics through a combination of task-adaptive data augmentation focused on faithfulness prediction in dialogue, consideration of both entailment and contradiction probabilities in NLI, and the use of Monte-Carlo dropout during inference.", "target": "The authors propose that NLI models can outperform more complex metrics through a combination of task-adaptive data augmentation focused on faithfulness prediction in dialogue, consideration of both entailment and contradiction probabilities in NLI, and the use of Monte-Carlo dropout during inference.", "example": "Convert the coordinate to text: [-3.0441 -4.0572]:"}
{"text": "Convert the coordinate to text: [ 0.5628 -9.2781]: The paper introduces LMCap, an image-blind few-shot multilingual captioning model that prompts a language model with retrieved captions without requiring any multilingual caption data.", "target": "The paper introduces LMCap, an image-blind few-shot multilingual captioning model that prompts a language model with retrieved captions without requiring any multilingual caption data.", "example": "Convert the coordinate to text: [ 0.5628 -9.2781]:"}
{"text": "Convert the coordinate to text: [-15.4856  14.3339]: The authors propose a new study for predicting the gaze target of children and interacting adults and introduce the ChildPlay dataset, which consists of annotated short video clips of children playing and interacting with adults in diverse, uncontrolled environments.", "target": "The authors propose a new study for predicting the gaze target of children and interacting adults and introduce the ChildPlay dataset, which consists of annotated short video clips of children playing and interacting with adults in diverse, uncontrolled environments.", "example": "Convert the coordinate to text: [-15.4856  14.3339]:"}
{"text": "Convert the coordinate to text: [-1.6437 -6.4953]: The authors aimed to refine and implement the transformer model and use the pre-trained BERT model for named entity recognition in English language.", "target": "The authors aimed to refine and implement the transformer model and use the pre-trained BERT model for named entity recognition in English language.", "example": "Convert the coordinate to text: [-1.6437 -6.4953]:"}
{"text": "Convert the coordinate to text: [ 2.9147 -5.7933]: This paper presents a solution to the outlined issue by proposing a Structure-Discourse Hierarchical Graph (SDHG) that conducts bottom-up information propagation. It uses sentence-level discourse graphs for each section driven by graph attention, constructs a section-level structure graph based on natural structures, and integrates different levels of representations into jointly answer and condition decoding.", "target": "This paper presents a solution to the outlined issue by proposing a Structure-Discourse Hierarchical Graph (SDHG) that conducts bottom-up information propagation. It uses sentence-level discourse graphs for each section driven by graph attention, constructs a section-level structure graph based on natural structures, and integrates different levels of representations into jointly answer and condition decoding.", "example": "Convert the coordinate to text: [ 2.9147 -5.7933]:"}
{"text": "Convert the coordinate to text: [ 5.1788 -3.3133]: The authors propose a new hybrid instance-filtering framework called BoostAug. It utilizes pre-trained language models to maintain a similar feature space with natural datasets and can be transferable to existing text augmentation methods.", "target": "The authors propose a new hybrid instance-filtering framework called BoostAug. It utilizes pre-trained language models to maintain a similar feature space with natural datasets and can be transferable to existing text augmentation methods.", "example": "Convert the coordinate to text: [ 5.1788 -3.3133]:"}
{"text": "Convert the coordinate to text: [-0.6983 -4.0756]: A novel Connective Prediction via Knowledge Distillation (CP-KD) approach is proposed which instructs large-scale pre-trained language models (PLMs) to mine the latent correlations between connectives and discourse relations, which is meaningful for IDRR.", "target": "A novel Connective Prediction via Knowledge Distillation (CP-KD) approach is proposed which instructs large-scale pre-trained language models (PLMs) to mine the latent correlations between connectives and discourse relations, which is meaningful for IDRR.", "example": "Convert the coordinate to text: [-0.6983 -4.0756]:"}
{"text": "Convert the coordinate to text: [ 2.6214 14.0287]: This study aims to analyze the rate of convergence of FP when applied to potential games and more specifically, identical payoff games.", "target": "This study aims to analyze the rate of convergence of FP when applied to potential games and more specifically, identical payoff games.", "example": "Convert the coordinate to text: [ 2.6214 14.0287]:"}
{"text": "Convert the coordinate to text: [-3.9802 -8.5534]: The authors propose a unified segment-to-segment framework (Seg2Seg) for simultaneous sequence generation. In this framework, the model alternates between waiting for a source segment and generating a target segment. A latent segment is introduced as the pivot between source and target, allowing the model to explore all potential source-target mappings.", "target": "The authors propose a unified segment-to-segment framework (Seg2Seg) for simultaneous sequence generation. In this framework, the model alternates between waiting for a source segment and generating a target segment. A latent segment is introduced as the pivot between source and target, allowing the model to explore all potential source-target mappings.", "example": "Convert the coordinate to text: [-3.9802 -8.5534]:"}
{"text": "Convert the coordinate to text: [ 9.4099 -7.9182]: The researchers introduce a high-order channel-wise operator, termed as Rubik's cube convolution, for image restoration. This operator expands the first-order channel-wise interactions seen in previous works to arbitrary high orders, generating a hierarchical receptive field.", "target": "The researchers introduce a high-order channel-wise operator, termed as Rubik's cube convolution, for image restoration. This operator expands the first-order channel-wise interactions seen in previous works to arbitrary high orders, generating a hierarchical receptive field.", "example": "Convert the coordinate to text: [ 9.4099 -7.9182]:"}
{"text": "Convert the coordinate to text: [-10.8026   5.9055]: The authors introduce TrojanSQL, an SQL injection framework tailored to exploit vulnerabilities in text-to-SQL systems, showing how state-of-the-art text-to-SQL parsers can be misled to produce harmful SQL statements.", "target": "The authors introduce TrojanSQL, an SQL injection framework tailored to exploit vulnerabilities in text-to-SQL systems, showing how state-of-the-art text-to-SQL parsers can be misled to produce harmful SQL statements.", "example": "Convert the coordinate to text: [-10.8026   5.9055]:"}
{"text": "Convert the coordinate to text: [ -0.1098 -15.3668]: The study proposes an online BCI with 120 commands and high speed created by hybridizing P300 and steady-state visual evoked potential (SSVEP) features. They use a time-frequency-phase encoding strategy to quickly encode the 120 commands.", "target": "The study proposes an online BCI with 120 commands and high speed created by hybridizing P300 and steady-state visual evoked potential (SSVEP) features. They use a time-frequency-phase encoding strategy to quickly encode the 120 commands.", "example": "Convert the coordinate to text: [ -0.1098 -15.3668]:"}
{"text": "Convert the coordinate to text: [-1.9899 -5.486 ]: The authors investigate the zero-shot temporal relation extraction capabilities of ChatGPT and design three different prompt techniques to evaluate the model.", "target": "The authors investigate the zero-shot temporal relation extraction capabilities of ChatGPT and design three different prompt techniques to evaluate the model.", "example": "Convert the coordinate to text: [-1.9899 -5.486 ]:"}
{"text": "Convert the coordinate to text: [  2.7563 -10.9788]: This paper proposes using the scene graph parsed from text as a proxy for a scene graph for images, introduces a graph decomposition and augmentation framework, and suggests a coarse-to-fine contrastive learning objective that aligns sentences of varying complexities to the same image.", "target": "This paper proposes using the scene graph parsed from text as a proxy for a scene graph for images, introduces a graph decomposition and augmentation framework, and suggests a coarse-to-fine contrastive learning objective that aligns sentences of varying complexities to the same image.", "example": "Convert the coordinate to text: [  2.7563 -10.9788]:"}
{"text": "Convert the coordinate to text: [-3.3485 -3.4987]: The authors introduce SETI (Systematicity Evaluation of Textual Inference), a benchmark that offers three different Natural Language Inference (NLI) tasks and respective datasets for examining various types of systematicity in PLM reasoning processes.", "target": "The authors introduce SETI (Systematicity Evaluation of Textual Inference), a benchmark that offers three different Natural Language Inference (NLI) tasks and respective datasets for examining various types of systematicity in PLM reasoning processes.", "example": "Convert the coordinate to text: [-3.3485 -3.4987]:"}
{"text": "Convert the coordinate to text: [-5.2647  2.4785]: The paper presents POPQUORN, a new dataset that contains 45,000 annotations from 1,484 annotators, representative in terms of sex, age, and race as the US population, to measure how annotator backgrounds, including those not previously studied, significantly influence their decision-making.", "target": "The paper presents POPQUORN, a new dataset that contains 45,000 annotations from 1,484 annotators, representative in terms of sex, age, and race as the US population, to measure how annotator backgrounds, including those not previously studied, significantly influence their decision-making.", "example": "Convert the coordinate to text: [-5.2647  2.4785]:"}
{"text": "Convert the coordinate to text: [7.8876 4.6486]: The authors propose a new method called $\beta$D-Bayes, which is a posterior sampling scheme from a generalized posterior targeting the minimization of the $\beta$-divergence between the model and the data generating process. This provides private estimation that applies broadly without requiring changes to the underlying model and consistently learns the data generating parameter.", "target": "The authors propose a new method called $\beta$D-Bayes, which is a posterior sampling scheme from a generalized posterior targeting the minimization of the $\beta$-divergence between the model and the data generating process. This provides private estimation that applies broadly without requiring changes to the underlying model and consistently learns the data generating parameter.", "example": "Convert the coordinate to text: [7.8876 4.6486]:"}
{"text": "Convert the coordinate to text: [18.5307 -3.1895]: In the SemEval-2023 challenge, the authors propose a system that generates a spoiler for these dramatic headlines, providing the information promised and eliminating the need for readers to go through the entire article. The system incorporates Multi-Task Learning and data augmentation through a distillation approach.", "target": "In the SemEval-2023 challenge, the authors propose a system that generates a spoiler for these dramatic headlines, providing the information promised and eliminating the need for readers to go through the entire article. The system incorporates Multi-Task Learning and data augmentation through a distillation approach.", "example": "Convert the coordinate to text: [18.5307 -3.1895]:"}
{"text": "Convert the coordinate to text: [ 5.7853 -0.9779]: The authors propose a dynamic loss function to better adapt to changing noise during the training process and incorporate token level contrastive learning to fully utilize noisy data and facilitate feature learning without relying on labels.", "target": "The authors propose a dynamic loss function to better adapt to changing noise during the training process and incorporate token level contrastive learning to fully utilize noisy data and facilitate feature learning without relying on labels.", "example": "Convert the coordinate to text: [ 5.7853 -0.9779]:"}
{"text": "Convert the coordinate to text: [-10.701   -1.7942]: The authors propose the Table-alignment-based Cell-selection and Reasoning model (TACR) for hybrid text and table QA, a mechanism that involves a table-question-alignment enhanced cell-selection method for fine-grained evidence retrieval and considers the row containing selected cells as context during answer reasoning.", "target": "The authors propose the Table-alignment-based Cell-selection and Reasoning model (TACR) for hybrid text and table QA, a mechanism that involves a table-question-alignment enhanced cell-selection method for fine-grained evidence retrieval and considers the row containing selected cells as context during answer reasoning.", "example": "Convert the coordinate to text: [-10.701   -1.7942]:"}
{"text": "Convert the coordinate to text: [-3.6   -6.693]: The authors propose a knowledge transfer method to better acquire new knowledge from diverse incremental language pairs. This method introduces knowledge from an external model into original ones to effectively learn new language pairs, completing the knowledge transfer process.", "target": "The authors propose a knowledge transfer method to better acquire new knowledge from diverse incremental language pairs. This method introduces knowledge from an external model into original ones to effectively learn new language pairs, completing the knowledge transfer process.", "example": "Convert the coordinate to text: [-3.6   -6.693]:"}
{"text": "Convert the coordinate to text: [-3.7393 -1.6847]: The authors propose a unified framework, called UNIEVENT, which organizes event relational reasoning tasks into a coordinate system with multiple axes to represent inter-event relations and reasoning formulations. A unified text-to-text generative model is then trained that utilizes coordinate-assigning prefixes for each task.", "target": "The authors propose a unified framework, called UNIEVENT, which organizes event relational reasoning tasks into a coordinate system with multiple axes to represent inter-event relations and reasoning formulations. A unified text-to-text generative model is then trained that utilizes coordinate-assigning prefixes for each task.", "example": "Convert the coordinate to text: [-3.7393 -1.6847]:"}
{"text": "Convert the coordinate to text: [ 7.4741 -2.1767]: A novel federated learning strategy is proposed that propagates adversarial robustness from users with ample resources to conduct adversarial training to those without sufficient resources, during federated learning.", "target": "A novel federated learning strategy is proposed that propagates adversarial robustness from users with ample resources to conduct adversarial training to those without sufficient resources, during federated learning.", "example": "Convert the coordinate to text: [ 7.4741 -2.1767]:"}
{"text": "Convert the coordinate to text: [14.4746 -0.4157]: In this paper, the authors propose a no-go theorem for learning an unknown quantum state with QNNs, even starting with a high-fidelity initial state. They reveal that when the loss value is under a certain threshold, the chances of avoiding local minima decrease exponentially with increase in qubit count and rise only polynomially with circuit depth.", "target": "In this paper, the authors propose a no-go theorem for learning an unknown quantum state with QNNs, even starting with a high-fidelity initial state. They reveal that when the loss value is under a certain threshold, the chances of avoiding local minima decrease exponentially with increase in qubit count and rise only polynomially with circuit depth.", "example": "Convert the coordinate to text: [14.4746 -0.4157]:"}
{"text": "Convert the coordinate to text: [8.3814 5.7891]: In this paper, the authors introduce a diffusion-based amortization method for long-run MCMC sampling and develop a novel learning algorithm for the latent space EBM based on it.", "target": "In this paper, the authors introduce a diffusion-based amortization method for long-run MCMC sampling and develop a novel learning algorithm for the latent space EBM based on it.", "example": "Convert the coordinate to text: [8.3814 5.7891]:"}
{"text": "Convert the coordinate to text: [  9.4144 -21.5074]: This paper proposes using time-varying exposures in quad-Bayer patterned sensors that allow long-exposure pixels to receive more photon energy. To handle dynamic scenes it proposes a single-shot HDR demosaicing method which takes time-varying multiple exposures as input and jointly solves both the demosaicing and deghosting problems.", "target": "This paper proposes using time-varying exposures in quad-Bayer patterned sensors that allow long-exposure pixels to receive more photon energy. To handle dynamic scenes it proposes a single-shot HDR demosaicing method which takes time-varying multiple exposures as input and jointly solves both the demosaicing and deghosting problems.", "example": "Convert the coordinate to text: [  9.4144 -21.5074]:"}
{"text": "Convert the coordinate to text: [ 9.419  -8.2458]: The paper proposes a new perspective of handling diffraction in UDC images by exploring feature restoration in both frequency and spatial domains. They introduce the Frequency and Spatial Interactive Learning Network (FSI), which includes Frequency-Spatial Joint (FSJ) modules for feature learning and a color transform module for color enhancement.", "target": "The paper proposes a new perspective of handling diffraction in UDC images by exploring feature restoration in both frequency and spatial domains. They introduce the Frequency and Spatial Interactive Learning Network (FSI), which includes Frequency-Spatial Joint (FSJ) modules for feature learning and a color transform module for color enhancement.", "example": "Convert the coordinate to text: [ 9.419  -8.2458]:"}
{"text": "Convert the coordinate to text: [ 7.2227 -4.3835]: This paper proposes an Unsupervised Domain Adaptation (UDA) approach for gait recognition that leverages adjacent-view sequences' overlapping views, allowing for gradual attainment of cross-view and cross-dressing capabilities without the need for pre-training on the labeled source domain.", "target": "This paper proposes an Unsupervised Domain Adaptation (UDA) approach for gait recognition that leverages adjacent-view sequences' overlapping views, allowing for gradual attainment of cross-view and cross-dressing capabilities without the need for pre-training on the labeled source domain.", "example": "Convert the coordinate to text: [ 7.2227 -4.3835]:"}
{"text": "Convert the coordinate to text: [-0.1286 -9.197 ]: The authors propose an attribute hallucination framework named CLIP-Cluster, which first hallucinates multiple representations for different attributes with the CLIP model, then pools them by learning neighbor-adaptive attention. They also introduce a text-driven attribute hallucination module and a neighbor-aware proxy generator.", "target": "The authors propose an attribute hallucination framework named CLIP-Cluster, which first hallucinates multiple representations for different attributes with the CLIP model, then pools them by learning neighbor-adaptive attention. They also introduce a text-driven attribute hallucination module and a neighbor-aware proxy generator.", "example": "Convert the coordinate to text: [-0.1286 -9.197 ]:"}
{"text": "Convert the coordinate to text: [ 8.3773 -8.0379]: The paper introduces FCCNs (Fully Complex-valued Convolutional Networks) with proper complex-valued image inputs, loss functions, and all complex-valued operations, including transforming fully-connected layers into convolutional ones, providing an end-to-end flow of complex-valued information.", "target": "The paper introduces FCCNs (Fully Complex-valued Convolutional Networks) with proper complex-valued image inputs, loss functions, and all complex-valued operations, including transforming fully-connected layers into convolutional ones, providing an end-to-end flow of complex-valued information.", "example": "Convert the coordinate to text: [ 8.3773 -8.0379]:"}
{"text": "Convert the coordinate to text: [ 6.5367 -3.6269]: This study presents a new way to integrate dataset pruning with transfer learning, proposing that existing DP methods are not suitable for the transfer learning framework. The authors introduce two new DP methods, label mapping and feature mapping, for supervised and self-supervised pretraining settings, reframing dataset pruning in the context of source-target domain mapping.", "target": "This study presents a new way to integrate dataset pruning with transfer learning, proposing that existing DP methods are not suitable for the transfer learning framework. The authors introduce two new DP methods, label mapping and feature mapping, for supervised and self-supervised pretraining settings, reframing dataset pruning in the context of source-target domain mapping.", "example": "Convert the coordinate to text: [ 6.5367 -3.6269]:"}
{"text": "Convert the coordinate to text: [8.4095 3.7421]: The goal of the research is to understand the underlying distribution in total variation distance. The main result is a Statistical Query (SQ) lower bound that suggests that known algorithms for this problem are essentially the best possible, even for the case of uniform mixtures.", "target": "The goal of the research is to understand the underlying distribution in total variation distance. The main result is a Statistical Query (SQ) lower bound that suggests that known algorithms for this problem are essentially the best possible, even for the case of uniform mixtures.", "example": "Convert the coordinate to text: [8.4095 3.7421]:"}
{"text": "Convert the coordinate to text: [ 8.0899 -6.4901]: The authors propose StreamNet, a memory-efficient network that utilizes a stream buffer to eliminate redundant computation in patch-based inference and provides an automatic parameter selection algorithm to optimise performance with minimal SRAM memory requirements.", "target": "The authors propose StreamNet, a memory-efficient network that utilizes a stream buffer to eliminate redundant computation in patch-based inference and provides an automatic parameter selection algorithm to optimise performance with minimal SRAM memory requirements.", "example": "Convert the coordinate to text: [ 8.0899 -6.4901]:"}
{"text": "Convert the coordinate to text: [2.2066 9.0823]: The authors propose HardSATGEN, a new approach that introduces a fine-grained control mechanism to the neural split-merge paradigm for SAT formula generation. This method aims to better recover structural and computational properties of industrial benchmarks, remedying issues identified with oversplit substructures and community structures in industrial formulae.", "target": "The authors propose HardSATGEN, a new approach that introduces a fine-grained control mechanism to the neural split-merge paradigm for SAT formula generation. This method aims to better recover structural and computational properties of industrial benchmarks, remedying issues identified with oversplit substructures and community structures in industrial formulae.", "example": "Convert the coordinate to text: [2.2066 9.0823]:"}
{"text": "Convert the coordinate to text: [-12.327    6.4509]: The authors propose a course designed to teach basic statistical tests on HCI-related data using a free open source tool, Jamovi, aimed at practitioners and researchers who do not enjoy mathematics.", "target": "The authors propose a course designed to teach basic statistical tests on HCI-related data using a free open source tool, Jamovi, aimed at practitioners and researchers who do not enjoy mathematics.", "example": "Convert the coordinate to text: [-12.327    6.4509]:"}
{"text": "Convert the coordinate to text: [ 10.7291 -15.8193]: The authors present a novel attack on motion estimation that uses adversarially optimized particles to simulate weather effects like snowflakes, rain streaks or fog clouds. This is achieved through a differentiable particle rendering system that consistently integrates particles over multiple time steps, into the 3D space, and with a photo-realistic appearance.", "target": "The authors present a novel attack on motion estimation that uses adversarially optimized particles to simulate weather effects like snowflakes, rain streaks or fog clouds. This is achieved through a differentiable particle rendering system that consistently integrates particles over multiple time steps, into the 3D space, and with a photo-realistic appearance.", "example": "Convert the coordinate to text: [ 10.7291 -15.8193]:"}
{"text": "Convert the coordinate to text: [-1.7499 -8.8045]: The authors propose HalOmi, a manually annotated benchmark dataset for hallucination and omission errors in machine translation covering 18 translation directions with varying resource levels and scripts. They also analyze different levels of partial and full hallucinations as well as omissions at both the sentence and word level.", "target": "The authors propose HalOmi, a manually annotated benchmark dataset for hallucination and omission errors in machine translation covering 18 translation directions with varying resource levels and scripts. They also analyze different levels of partial and full hallucinations as well as omissions at both the sentence and word level.", "example": "Convert the coordinate to text: [-1.7499 -8.8045]:"}
{"text": "Convert the coordinate to text: [-1.2369 -5.1446]: The paper introduces a novel technique named 'Multi-view Prompting' (MvP) that generates sentiment elements in various orders, leveraging the idea of problem-solving from multiple perspectives. It uses element order prompts to guide language models in generating multiple sentiment tuples with a voting system to select the most reasonable tuples.", "target": "The paper introduces a novel technique named 'Multi-view Prompting' (MvP) that generates sentiment elements in various orders, leveraging the idea of problem-solving from multiple perspectives. It uses element order prompts to guide language models in generating multiple sentiment tuples with a voting system to select the most reasonable tuples.", "example": "Convert the coordinate to text: [-1.2369 -5.1446]:"}
{"text": "Convert the coordinate to text: [-0.0882  1.253 ]: The authors propose a standardized protocol based on three criteria - Specification Polarity, Specification Importance, and Domain Transferability - to evaluate debiasing methods and their ability to consistently produce results in line with their intended specifications.", "target": "The authors propose a standardized protocol based on three criteria - Specification Polarity, Specification Importance, and Domain Transferability - to evaluate debiasing methods and their ability to consistently produce results in line with their intended specifications.", "example": "Convert the coordinate to text: [-0.0882  1.253 ]:"}
{"text": "Convert the coordinate to text: [9.4236 2.3702]: The authors propose a novel reproducing kernel Hilbert space (RKHS) that solely spans transformations into linear dynamical systems, resulting in a Koopman Kernel Regression (KKR) framework.", "target": "The authors propose a novel reproducing kernel Hilbert space (RKHS) that solely spans transformations into linear dynamical systems, resulting in a Koopman Kernel Regression (KKR) framework.", "example": "Convert the coordinate to text: [9.4236 2.3702]:"}
{"text": "Convert the coordinate to text: [-5.3759 -4.1862]: The authors present GENTLE, a mixed-genre English challenge corpus containing 17K tokens and consisting of eight unusual text types: dictionary entries, esports commentaries, legal documents, medical notes, poetry, mathematical proofs, syllabuses, and threat letters, manually annotated for popular NLP tasks.", "target": "The authors present GENTLE, a mixed-genre English challenge corpus containing 17K tokens and consisting of eight unusual text types: dictionary entries, esports commentaries, legal documents, medical notes, poetry, mathematical proofs, syllabuses, and threat letters, manually annotated for popular NLP tasks.", "example": "Convert the coordinate to text: [-5.3759 -4.1862]:"}
{"text": "Convert the coordinate to text: [3.2649 8.8601]: The authors propose a search algorithm, LambdaBeam, that constructs arbitrary lambda functions and composes operations within a given Domain-Specific Language (DSL), addressing the limitations of prior approaches.", "target": "The authors propose a search algorithm, LambdaBeam, that constructs arbitrary lambda functions and composes operations within a given Domain-Specific Language (DSL), addressing the limitations of prior approaches.", "example": "Convert the coordinate to text: [3.2649 8.8601]:"}
{"text": "Convert the coordinate to text: [-1.3934 -6.5013]: The paper presents RadLing, a specifically-trained language model using the Electra-small architecture, along with a key novel contribution of a 'knowledge-aware masking' which is a taxonomic knowledge-assisted pretraining task that dynamically masks tokens to inject knowledge during pretraining.", "target": "The paper presents RadLing, a specifically-trained language model using the Electra-small architecture, along with a key novel contribution of a 'knowledge-aware masking' which is a taxonomic knowledge-assisted pretraining task that dynamically masks tokens to inject knowledge during pretraining.", "example": "Convert the coordinate to text: [-1.3934 -6.5013]:"}
{"text": "Convert the coordinate to text: [-8.6985 -1.9783]: The authors conduct an analysis of 10,405 anonymous responses to the NLP Reproducibility Checklist, with a focus on exploring the factors that influence acceptance rates and reproducibility scores.", "target": "The authors conduct an analysis of 10,405 anonymous responses to the NLP Reproducibility Checklist, with a focus on exploring the factors that influence acceptance rates and reproducibility scores.", "example": "Convert the coordinate to text: [-8.6985 -1.9783]:"}
{"text": "Convert the coordinate to text: [-7.0147  6.988 ]: The study proposes a multi-task learning model that predicts future suicidality of BD patients by jointly learning current symptoms, utilizing a newly-constructed BD dataset clinically validated by psychiatrists and employing a temporal symptom-aware attention mechanism.", "target": "The study proposes a multi-task learning model that predicts future suicidality of BD patients by jointly learning current symptoms, utilizing a newly-constructed BD dataset clinically validated by psychiatrists and employing a temporal symptom-aware attention mechanism.", "example": "Convert the coordinate to text: [-7.0147  6.988 ]:"}
{"text": "Convert the coordinate to text: [4.2729 0.6961]: The authors propose using ensemble learning classifiers that combine the outputs of several Large Language Models without incorporating information about disagreements, either by building separate classifiers for each dataset or by merging the datasets.", "target": "The authors propose using ensemble learning classifiers that combine the outputs of several Large Language Models without incorporating information about disagreements, either by building separate classifiers for each dataset or by merging the datasets.", "example": "Convert the coordinate to text: [4.2729 0.6961]:"}
{"text": "Convert the coordinate to text: [-1.0555  0.51  ]: This paper investigates the performance accuracy of the Feedback Prize-winning models based on demographic factors such as student race/ethnicity, economic disadvantage, and English Language Learner status.", "target": "This paper investigates the performance accuracy of the Feedback Prize-winning models based on demographic factors such as student race/ethnicity, economic disadvantage, and English Language Learner status.", "example": "Convert the coordinate to text: [-1.0555  0.51  ]:"}
{"text": "Convert the coordinate to text: [-0.9667  7.9023]: The authors propose TeX2Solver, a system designed to partially automate the conversion of mathematical formulations of optimization problems from TeX document format into a solver modeling language with the aim of assisting users to build optimization models more efficiently.", "target": "The authors propose TeX2Solver, a system designed to partially automate the conversion of mathematical formulations of optimization problems from TeX document format into a solver modeling language with the aim of assisting users to build optimization models more efficiently.", "example": "Convert the coordinate to text: [-0.9667  7.9023]:"}
{"text": "Convert the coordinate to text: [-5.6834 -0.7379]: The authors propose the idea that abstractive summarization systems can be modelled as extractive summarization systems, introducing three novel algorithms based on the sequence-to-sequence architecture.", "target": "The authors propose the idea that abstractive summarization systems can be modelled as extractive summarization systems, introducing three novel algorithms based on the sequence-to-sequence architecture.", "example": "Convert the coordinate to text: [-5.6834 -0.7379]:"}
{"text": "Convert the coordinate to text: [-1.7475  0.8094]: The authors propose PyHealth, a comprehensive library designed to build, deploy, and validate deep learning pipelines for healthcare applications, covering various data modalities (such as electronic health records, physiological signals, medical images, and clinical text) and advanced DL models.", "target": "The authors propose PyHealth, a comprehensive library designed to build, deploy, and validate deep learning pipelines for healthcare applications, covering various data modalities (such as electronic health records, physiological signals, medical images, and clinical text) and advanced DL models.", "example": "Convert the coordinate to text: [-1.7475  0.8094]:"}
{"text": "Convert the coordinate to text: [ 10.426  -12.9423]: The authors propose an end-to-end approach that leverages learning of dense pixel-wise flow fields in pairs of ground and satellite images to calculate camera pose. The approach employs two separate convolution networks for feature extraction from ground and satellite images, projects the ground feature map to bird's eye view for preliminary alignment, and refines this with a residual convolution block.", "target": "The authors propose an end-to-end approach that leverages learning of dense pixel-wise flow fields in pairs of ground and satellite images to calculate camera pose. The approach employs two separate convolution networks for feature extraction from ground and satellite images, projects the ground feature map to bird's eye view for preliminary alignment, and refines this with a residual convolution block.", "example": "Convert the coordinate to text: [ 10.426  -12.9423]:"}
{"text": "Convert the coordinate to text: [ -1.4657 -13.2519]: The authors propose a method that solves the challenge by learning a latent distribution representing strong temporal priors using a Conditional Variational Autoencoder (CVAE) architecture with a transformer.", "target": "The authors propose a method that solves the challenge by learning a latent distribution representing strong temporal priors using a Conditional Variational Autoencoder (CVAE) architecture with a transformer.", "example": "Convert the coordinate to text: [ -1.4657 -13.2519]:"}
{"text": "Convert the coordinate to text: [10.7527 -6.2522]: The authors propose the BoundaryDiffusion method for efficient, effective and light-weight semantic control with frozen pre-trained DDMs, without needing to learn any extra networks. This method works by guiding the denoising trajectory towards the targeted boundary using a single-step operation.", "target": "The authors propose the BoundaryDiffusion method for efficient, effective and light-weight semantic control with frozen pre-trained DDMs, without needing to learn any extra networks. This method works by guiding the denoising trajectory towards the targeted boundary using a single-step operation.", "example": "Convert the coordinate to text: [10.7527 -6.2522]:"}
{"text": "Convert the coordinate to text: [-3.8807 -2.709 ]: The paper proposes VER, a model designed to verbalize entities and relations. It aims to build a system that accepts any entity or set of entities as input and generates a sentence describing them and their interrelations.", "target": "The paper proposes VER, a model designed to verbalize entities and relations. It aims to build a system that accepts any entity or set of entities as input and generates a sentence describing them and their interrelations.", "example": "Convert the coordinate to text: [-3.8807 -2.709 ]:"}
{"text": "Convert the coordinate to text: [ 6.4438 -3.8813]: The authors propose a novel domain adaptation framework improving the weakly supervised learning algorithm by leveraging retrieval-augmented generation (RAG) and exploring practical techniques such as knowledge distillation for more stable training.", "target": "The authors propose a novel domain adaptation framework improving the weakly supervised learning algorithm by leveraging retrieval-augmented generation (RAG) and exploring practical techniques such as knowledge distillation for more stable training.", "example": "Convert the coordinate to text: [ 6.4438 -3.8813]:"}
{"text": "Convert the coordinate to text: [ 5.907  -8.0143]: The authors present a new framework, FSNet (Full-duplex Strategy Network), which employs a relational cross-attention module (RCAM) to enable bidirectional message propagation across embedding subspace, and an additional bidirectional purification module (BPM) to update inconsistent features between spatial-temporal embeddings.", "target": "The authors present a new framework, FSNet (Full-duplex Strategy Network), which employs a relational cross-attention module (RCAM) to enable bidirectional message propagation across embedding subspace, and an additional bidirectional purification module (BPM) to update inconsistent features between spatial-temporal embeddings.", "example": "Convert the coordinate to text: [ 5.907  -8.0143]:"}
{"text": "Convert the coordinate to text: [-11.5709  12.0459]: The authors discuss their experience of co-organizing a community-based public-facing exhibition highlighting community members' personal and communal safety and surveillance narratives through photographs, as part of a photovoice research project. They also highlight the challenges encountered during the planning and execution of the exhibition.", "target": "The authors discuss their experience of co-organizing a community-based public-facing exhibition highlighting community members' personal and communal safety and surveillance narratives through photographs, as part of a photovoice research project. They also highlight the challenges encountered during the planning and execution of the exhibition.", "example": "Convert the coordinate to text: [-11.5709  12.0459]:"}
{"text": "Convert the coordinate to text: [ 7.4446 -2.1497]: The paper introduces FedAds, a first-of-its-kind benchmark for privacy-preserving CVR estimation using vFL, which aims to facilitate standardized assessments for vFL algorithms.", "target": "The paper introduces FedAds, a first-of-its-kind benchmark for privacy-preserving CVR estimation using vFL, which aims to facilitate standardized assessments for vFL algorithms.", "example": "Convert the coordinate to text: [ 7.4446 -2.1497]:"}
{"text": "Convert the coordinate to text: [-2.2939 -4.9483]: This paper introduces OpenSLU, an open-source toolkit for spoken language understanding. It aims to provide a unified, modularized, and extensible toolkit for SLU.", "target": "This paper introduces OpenSLU, an open-source toolkit for spoken language understanding. It aims to provide a unified, modularized, and extensible toolkit for SLU.", "example": "Convert the coordinate to text: [-2.2939 -4.9483]:"}
{"text": "Convert the coordinate to text: [13.6059 -4.4042]: The authors propose a new framework, SAME (a slowdown attack on multi-exit models), designed to lessen the efficiency of multi-exit models. This approach utilizes all internal predictions to guide the creation of adversarial samples, rather than solely relying on the final prediction.", "target": "The authors propose a new framework, SAME (a slowdown attack on multi-exit models), designed to lessen the efficiency of multi-exit models. This approach utilizes all internal predictions to guide the creation of adversarial samples, rather than solely relying on the final prediction.", "example": "Convert the coordinate to text: [13.6059 -4.4042]:"}
{"text": "Convert the coordinate to text: [-8.8359 -7.0357]: The authors present a new approach to semantic parsing which first.tags each input token with a multiset of output tokens, then arranges the tokens into an output sequence by parameterizing and predicting permutations. They also formulate predicting a permutation as solving a regularized linear program, and backpropagate through the solver without placing a priori restrictions on possible permutations.", "target": "The authors present a new approach to semantic parsing which first.tags each input token with a multiset of output tokens, then arranges the tokens into an output sequence by parameterizing and predicting permutations. They also formulate predicting a permutation as solving a regularized linear program, and backpropagate through the solver without placing a priori restrictions on possible permutations.", "example": "Convert the coordinate to text: [-8.8359 -7.0357]:"}
{"text": "Convert the coordinate to text: [-8.4749 -1.9452]: The authors investigate temporal patterns of citation in NLP, analyzing factors that correlate with citational attention or amnesia, and charting trends over time.", "target": "The authors investigate temporal patterns of citation in NLP, analyzing factors that correlate with citational attention or amnesia, and charting trends over time.", "example": "Convert the coordinate to text: [-8.4749 -1.9452]:"}
{"text": "Convert the coordinate to text: [-5.5633 10.1351]: The authors propose DialoGue Path Sampling (DialoGPS), the first many-to-many augmentation method for multi-turn dialogues. The method utilizes continuous semantic space to maintain coherent dialogue paths, contrasting the conventional discrete replacement based on semantic similarity.", "target": "The authors propose DialoGue Path Sampling (DialoGPS), the first many-to-many augmentation method for multi-turn dialogues. The method utilizes continuous semantic space to maintain coherent dialogue paths, contrasting the conventional discrete replacement based on semantic similarity.", "example": "Convert the coordinate to text: [-5.5633 10.1351]:"}
{"text": "Convert the coordinate to text: [-4.2952 -0.8533]: The paper introduces a new dataset comprised of 2,302 time period setting labeled works and 6,991 location setting labeled works intended for computational analysis of story settings.", "target": "The paper introduces a new dataset comprised of 2,302 time period setting labeled works and 6,991 location setting labeled works intended for computational analysis of story settings.", "example": "Convert the coordinate to text: [-4.2952 -0.8533]:"}
{"text": "Convert the coordinate to text: [-5.3875 -2.0351]: The authors propose to segment legal documents as per the rhetorical roles which can aid in processing such documents. They used a fine-tuned Legal-BERT to address this task.", "target": "The authors propose to segment legal documents as per the rhetorical roles which can aid in processing such documents. They used a fine-tuned Legal-BERT to address this task.", "example": "Convert the coordinate to text: [-5.3875 -2.0351]:"}
{"text": "Convert the coordinate to text: [18.5142 -3.194 ]: The authors developed a system that uses a simple seq2seq spoiler generation and post-hoc model for ensembling to handle the complex task of generating multipart spoilers.", "target": "The authors developed a system that uses a simple seq2seq spoiler generation and post-hoc model for ensembling to handle the complex task of generating multipart spoilers.", "example": "Convert the coordinate to text: [18.5142 -3.194 ]:"}
{"text": "Convert the coordinate to text: [-0.3609 -6.7053]: The authors propose the generation and evaluation of datasets using transformer and non-transformer models to augment the original provided dataset.", "target": "The authors propose the generation and evaluation of datasets using transformer and non-transformer models to augment the original provided dataset.", "example": "Convert the coordinate to text: [-0.3609 -6.7053]:"}
{"text": "Convert the coordinate to text: [-5.8043 -0.7117]: The authors propose a three-step abstractive model for summarizing biomedical articles which includes breaking the original document into sections, generating candidate summaries for each section and then re-ranking and selecting the best summary for each section.", "target": "The authors propose a three-step abstractive model for summarizing biomedical articles which includes breaking the original document into sections, generating candidate summaries for each section and then re-ranking and selecting the best summary for each section.", "example": "Convert the coordinate to text: [-5.8043 -0.7117]:"}
{"text": "Convert the coordinate to text: [-5.6418  4.6702]: The key idea is to predict participants' levels of influence in the IETF based on their email text, using tools such as LIWC and BERT, and identifying the linguistic differences, like specific LIWC categories, that correlate with high influence.", "target": "The key idea is to predict participants' levels of influence in the IETF based on their email text, using tools such as LIWC and BERT, and identifying the linguistic differences, like specific LIWC categories, that correlate with high influence.", "example": "Convert the coordinate to text: [-5.6418  4.6702]:"}
{"text": "Convert the coordinate to text: [ 1.3440e-03 -8.8527e+00]: The authors approach multimodal entity and relation extraction from a translation perspective. They draw an analogy to the cross-lingual divergence problem in machine translation and treat text and paired images as translations of each other.", "target": "The authors approach multimodal entity and relation extraction from a translation perspective. They draw an analogy to the cross-lingual divergence problem in machine translation and treat text and paired images as translations of each other.", "example": "Convert the coordinate to text: [ 1.3440e-03 -8.8527e+00]:"}
{"text": "Convert the coordinate to text: [-3.9971 -3.594 ]: This paper presents FEDLEGAL, the first real-world federated learning benchmark for legal NLP, which comprises five legal NLP tasks and one privacy task based on data from Chinese courts.", "target": "This paper presents FEDLEGAL, the first real-world federated learning benchmark for legal NLP, which comprises five legal NLP tasks and one privacy task based on data from Chinese courts.", "example": "Convert the coordinate to text: [-3.9971 -3.594 ]:"}
{"text": "Convert the coordinate to text: [-4.6864 -7.227 ]: The authors propose the collection of a few thousand professionally translated sentence pairs for low-resource languages to enhance the training of machine translation models.", "target": "The authors propose the collection of a few thousand professionally translated sentence pairs for low-resource languages to enhance the training of machine translation models.", "example": "Convert the coordinate to text: [-4.6864 -7.227 ]:"}
{"text": "Convert the coordinate to text: [-1.2649  4.176 ]: The paper presents a novel end-to-end semi-supervised model, the Group-based Fraud Detection Network (GFDN), that exploits the characteristics of group-based frauds for fraud detection.", "target": "The paper presents a novel end-to-end semi-supervised model, the Group-based Fraud Detection Network (GFDN), that exploits the characteristics of group-based frauds for fraud detection.", "example": "Convert the coordinate to text: [-1.2649  4.176 ]:"}
{"text": "Convert the coordinate to text: [6.963  7.4934]: The research introduces two novel inversion attacks to demonstrate the vulnerability of existing methods, following which they propose the first method for privatizing image features via local differential privacy.", "target": "The research introduces two novel inversion attacks to demonstrate the vulnerability of existing methods, following which they propose the first method for privatizing image features via local differential privacy.", "example": "Convert the coordinate to text: [6.963  7.4934]:"}
{"text": "Convert the coordinate to text: [ 10.2367 -20.5602]: The authors introduce the first dense SLAM system that utilizes a monocular camera and a light-weight ToF sensor, featuring a multi-modal implicit scene representation that supports rendering signals from both the RGB camera and the ToF sensor.", "target": "The authors introduce the first dense SLAM system that utilizes a monocular camera and a light-weight ToF sensor, featuring a multi-modal implicit scene representation that supports rendering signals from both the RGB camera and the ToF sensor.", "example": "Convert the coordinate to text: [ 10.2367 -20.5602]:"}
{"text": "Convert the coordinate to text: [ 9.7885 -1.2175]: The authors propose a nonparametric strategy for learning invariant representations based on the recently-proposed Nadaraya-Watson (NW) head, which makes predictions by comparing learned representations to elements of a support set consisting of labeled data.", "target": "The authors propose a nonparametric strategy for learning invariant representations based on the recently-proposed Nadaraya-Watson (NW) head, which makes predictions by comparing learned representations to elements of a support set consisting of labeled data.", "example": "Convert the coordinate to text: [ 9.7885 -1.2175]:"}
{"text": "Convert the coordinate to text: [  3.3084 -13.5807]: The authors propose GeoCLIP, a novel CLIP-inspired Image-to-GPS retrieval approach. GeoCLIP enforces alignment between the image and its corresponding GPS locations, and its location encoder treats the Earth as a continuous function, yielding a semantically rich high-dimensional feature suitable for beyond geo-localization tasks.", "target": "The authors propose GeoCLIP, a novel CLIP-inspired Image-to-GPS retrieval approach. GeoCLIP enforces alignment between the image and its corresponding GPS locations, and its location encoder treats the Earth as a continuous function, yielding a semantically rich high-dimensional feature suitable for beyond geo-localization tasks.", "example": "Convert the coordinate to text: [  3.3084 -13.5807]:"}
{"text": "Convert the coordinate to text: [  9.047  -11.3213]: The study proposes Spiking PointNet, the first spiking neural model designed for efficient deep learning on point clouds. The paper identifies and addresses two major challenges hindering the application of SNNs in point clouds: the intrinsic optimization obstacle of SNNs and the expensive memory and computation cost of PointNet.", "target": "The study proposes Spiking PointNet, the first spiking neural model designed for efficient deep learning on point clouds. The paper identifies and addresses two major challenges hindering the application of SNNs in point clouds: the intrinsic optimization obstacle of SNNs and the expensive memory and computation cost of PointNet.", "example": "Convert the coordinate to text: [  9.047  -11.3213]:"}
{"text": "Convert the coordinate to text: [-0.8443 11.7807]: The authors propose LACMA which combines contrasting learning to align the agent's hidden states with the instructions and the introduction of 'meta-actions' (ubiquitous action patterns that represent higher-level semantics) to bridge the semantic gap between language instructions and low-level action space.", "target": "The authors propose LACMA which combines contrasting learning to align the agent's hidden states with the instructions and the introduction of 'meta-actions' (ubiquitous action patterns that represent higher-level semantics) to bridge the semantic gap between language instructions and low-level action space.", "example": "Convert the coordinate to text: [-0.8443 11.7807]:"}
{"text": "Convert the coordinate to text: [7.0567 7.6912]: The paper proposes improvement of privacy bounds for shuffling models and one-iteration differentially private gradient descent (DP-GD) with random initializations using $f$-DP. This approach investigates the effects of random initialization on the privacy of one-iteration DP-GD.", "target": "The paper proposes improvement of privacy bounds for shuffling models and one-iteration differentially private gradient descent (DP-GD) with random initializations using $f$-DP. This approach investigates the effects of random initialization on the privacy of one-iteration DP-GD.", "example": "Convert the coordinate to text: [7.0567 7.6912]:"}
{"text": "Convert the coordinate to text: [-3.3665 -5.4517]: The authors propose an Automatic Product Copywriting Generation (APCG) system for e-commerce product recommendation platform which has two main components, a transformer-pointer network and copywriting quality control.", "target": "The authors propose an Automatic Product Copywriting Generation (APCG) system for e-commerce product recommendation platform which has two main components, a transformer-pointer network and copywriting quality control.", "example": "Convert the coordinate to text: [-3.3665 -5.4517]:"}
{"text": "Convert the coordinate to text: [  3.0231 -11.6395]: The study is focused on improving the capability of vision-language models to understand where objects are within an image and to group together visually related parts of an image. A minimal set of modifications is proposed to allow models to learn both semantic and spatial information.", "target": "The study is focused on improving the capability of vision-language models to understand where objects are within an image and to group together visually related parts of an image. A minimal set of modifications is proposed to allow models to learn both semantic and spatial information.", "example": "Convert the coordinate to text: [  3.0231 -11.6395]:"}
{"text": "Convert the coordinate to text: [-11.6987   1.4841]: The authors propose OntoLAMA, a set of inference-based probing tasks and datasets from ontology subsumption axioms involving both atomic and complex concepts, to investigate a language model's knowledge of ontologies.", "target": "The authors propose OntoLAMA, a set of inference-based probing tasks and datasets from ontology subsumption axioms involving both atomic and complex concepts, to investigate a language model's knowledge of ontologies.", "example": "Convert the coordinate to text: [-11.6987   1.4841]:"}
{"text": "Convert the coordinate to text: [-11.2075  -0.583 ]: The authors propose a pipeline that answers natural language questions about graph visualizations and provides visually represented answers.", "target": "The authors propose a pipeline that answers natural language questions about graph visualizations and provides visually represented answers.", "example": "Convert the coordinate to text: [-11.2075  -0.583 ]:"}
{"text": "Convert the coordinate to text: [-5.4576  1.8374]: Political scientists have recently made attempts to formalize their vocabulary. This has led to improvement in diagnosing and treating problems of democracy and changed the way countries write constitutions.", "target": "Political scientists have recently made attempts to formalize their vocabulary. This has led to improvement in diagnosing and treating problems of democracy and changed the way countries write constitutions.", "example": "Convert the coordinate to text: [-5.4576  1.8374]:"}
{"text": "Convert the coordinate to text: [-3.1732 -4.3007]: The paper compares the effectiveness of Sequence Labeling and Span Prediction methods in the context of Named Entity Recognition (NER). Additionally, it investigates the performance enhancements resulting from using the larger version of XLM RoBERTa.", "target": "The paper compares the effectiveness of Sequence Labeling and Span Prediction methods in the context of Named Entity Recognition (NER). Additionally, it investigates the performance enhancements resulting from using the larger version of XLM RoBERTa.", "example": "Convert the coordinate to text: [-3.1732 -4.3007]:"}
{"text": "Convert the coordinate to text: [ 0.2563 -4.8726]: This paper explores four different zero and few-shot intent classification approaches that take into account the constraint of low resources - domain adaptation, data augmentation, zero-shot intent classification using descriptions from large language models (LLMs), and parameter-efficient fine-tuning of instruction-finetuned language models.", "target": "This paper explores four different zero and few-shot intent classification approaches that take into account the constraint of low resources - domain adaptation, data augmentation, zero-shot intent classification using descriptions from large language models (LLMs), and parameter-efficient fine-tuning of instruction-finetuned language models.", "example": "Convert the coordinate to text: [ 0.2563 -4.8726]:"}
{"text": "Convert the coordinate to text: [ 0.1069 -6.6674]: The authors propose a plug-and-play, lightweight method named Graph-Induced Fine-Tuning (GIFT), which adapts Transformer-based pre-trained language models for universal MPC understanding. GIFT introduces four types of edges to distinguish relationships between utterances, integrating these graph-induced signals into attention mechanisms.", "target": "The authors propose a plug-and-play, lightweight method named Graph-Induced Fine-Tuning (GIFT), which adapts Transformer-based pre-trained language models for universal MPC understanding. GIFT introduces four types of edges to distinguish relationships between utterances, integrating these graph-induced signals into attention mechanisms.", "example": "Convert the coordinate to text: [ 0.1069 -6.6674]:"}
{"text": "Convert the coordinate to text: [-1.1584 -5.1752]: The paper proposes a Vertical Learning Paradigm (VLP) that extends embedding models for KGC tasks by allowing explicit copying of target information from related factual triples for more accurate prediction, complementing the implicit memory.", "target": "The paper proposes a Vertical Learning Paradigm (VLP) that extends embedding models for KGC tasks by allowing explicit copying of target information from related factual triples for more accurate prediction, complementing the implicit memory.", "example": "Convert the coordinate to text: [-1.1584 -5.1752]:"}
{"text": "Convert the coordinate to text: [14.892   4.8543]: The paper proposes a new method known as Cross-modal Mixup via Optimal Transport (CMOT), which overcomes the modality gap by finding the alignment between speech and text sequences via optimal transport, and then mixes up the sequences from different modalities at a token level.", "target": "The paper proposes a new method known as Cross-modal Mixup via Optimal Transport (CMOT), which overcomes the modality gap by finding the alignment between speech and text sequences via optimal transport, and then mixes up the sequences from different modalities at a token level.", "example": "Convert the coordinate to text: [14.892   4.8543]:"}
{"text": "Convert the coordinate to text: [-5.1699 10.4085]: The authors present SimSR, a novel method that uses model-based simulation to discover high-value response sets. This is done by simulating possible user responses using a learned world model.", "target": "The authors present SimSR, a novel method that uses model-based simulation to discover high-value response sets. This is done by simulating possible user responses using a learned world model.", "example": "Convert the coordinate to text: [-5.1699 10.4085]:"}
{"text": "Convert the coordinate to text: [4.9858 0.8713]: The authors propose a novel framework for weakly-supervised boosting, LocalBoost, which boosts the ensemble model from two dimensions (intra-source and inter-source) to effectively handle weak and noisy labels.", "target": "The authors propose a novel framework for weakly-supervised boosting, LocalBoost, which boosts the ensemble model from two dimensions (intra-source and inter-source) to effectively handle weak and noisy labels.", "example": "Convert the coordinate to text: [4.9858 0.8713]:"}
{"text": "Convert the coordinate to text: [-2.8749  3.5324]: The authors propose a non-dot-product retrieval approach called 'mixture of logits' (MoL), which models (user, item) similarity as an adaptive composition of elementary similarity functions. This method is capable of modeling complex and high-rank user-item interactions and also generalizes to the long tail.", "target": "The authors propose a non-dot-product retrieval approach called 'mixture of logits' (MoL), which models (user, item) similarity as an adaptive composition of elementary similarity functions. This method is capable of modeling complex and high-rank user-item interactions and also generalizes to the long tail.", "example": "Convert the coordinate to text: [-2.8749  3.5324]:"}
{"text": "Convert the coordinate to text: [-0.2444 -1.9387]: The authors propose ReactIE, a method that combines two weakly supervised pre-training approaches for identifying specific characteristics of chemical reactions; utilizing frequent patterns within the text as linguistic cues and adopting synthetic patent data as distant supervision.", "target": "The authors propose ReactIE, a method that combines two weakly supervised pre-training approaches for identifying specific characteristics of chemical reactions; utilizing frequent patterns within the text as linguistic cues and adopting synthetic patent data as distant supervision.", "example": "Convert the coordinate to text: [-0.2444 -1.9387]:"}
{"text": "Convert the coordinate to text: [-5.1246 -1.5274]: The authors present a study that compares neural and hybrid models for sentence-level ARA.", "target": "The authors present a study that compares neural and hybrid models for sentence-level ARA.", "example": "Convert the coordinate to text: [-5.1246 -1.5274]:"}
{"text": "Convert the coordinate to text: [-4.7742 -0.3431]: A solution to ValueEval, the shared contribution to SemEval 2023 Task 4, is proposed. The research focuses on investigating chain classifier architectures with pretrained contextualized embeddings to detect 20 different human values in written arguments.", "target": "A solution to ValueEval, the shared contribution to SemEval 2023 Task 4, is proposed. The research focuses on investigating chain classifier architectures with pretrained contextualized embeddings to detect 20 different human values in written arguments.", "example": "Convert the coordinate to text: [-4.7742 -0.3431]:"}
{"text": "Convert the coordinate to text: [ 0.6007 -4.1993]: The authors propose Semantic In-Context Learning (S-ICL) to address the issues of using private internal data and keeping language models updated with newly incoming data without the need for constant fine-tuning.", "target": "The authors propose Semantic In-Context Learning (S-ICL) to address the issues of using private internal data and keeping language models updated with newly incoming data without the need for constant fine-tuning.", "example": "Convert the coordinate to text: [ 0.6007 -4.1993]:"}
{"text": "Convert the coordinate to text: [-1.1139  5.6407]: This paper introduces a novel strategy for capturing feature interactions and uses it to build hierarchical explanations without the connecting rule. Additionally, the approach can convert non-hierarchical explanations such as LIME into their corresponding hierarchical versions.", "target": "This paper introduces a novel strategy for capturing feature interactions and uses it to build hierarchical explanations without the connecting rule. Additionally, the approach can convert non-hierarchical explanations such as LIME into their corresponding hierarchical versions.", "example": "Convert the coordinate to text: [-1.1139  5.6407]:"}
{"text": "Convert the coordinate to text: [-3.7248 -3.6032]: This study introduces the FiNE dataset, consisting of 30,000 sentences from various domains and containing 67,651 entities in 54 fine-grained flattened hierarchical categories. Also, they propose a novel approach for FG-CNER, called SoftFiNE, utilizing a custom-designed relevance scoring function based on label structures.", "target": "This study introduces the FiNE dataset, consisting of 30,000 sentences from various domains and containing 67,651 entities in 54 fine-grained flattened hierarchical categories. Also, they propose a novel approach for FG-CNER, called SoftFiNE, utilizing a custom-designed relevance scoring function based on label structures.", "example": "Convert the coordinate to text: [-3.7248 -3.6032]:"}
{"text": "Convert the coordinate to text: [-2.8702 -8.8312]: This work proposes modifications to LSTM training to improve vanilla LSTM's accuracy, and introduces a simple integration of end-of-speech (EOS) detection with CTC models, specifically to build accurate streaming ASR models for large-scale Hinglish (blend of Hindi and English) Voice Search.", "target": "This work proposes modifications to LSTM training to improve vanilla LSTM's accuracy, and introduces a simple integration of end-of-speech (EOS) detection with CTC models, specifically to build accurate streaming ASR models for large-scale Hinglish (blend of Hindi and English) Voice Search.", "example": "Convert the coordinate to text: [-2.8702 -8.8312]:"}
{"text": "Convert the coordinate to text: [-3.162  -8.3958]: In light of these challenges, the authors propose a new approach called CWSeg, which augments PLM-based methods through the use of cohort training and versatile decoding strategies.", "target": "In light of these challenges, the authors propose a new approach called CWSeg, which augments PLM-based methods through the use of cohort training and versatile decoding strategies.", "example": "Convert the coordinate to text: [-3.162  -8.3958]:"}
{"text": "Convert the coordinate to text: [-1.1512 -8.6155]: The authors propose to dissect ALiBi by using a novel tool based on a receptive field analysis, and based on this concept modify the vanilla Sinusoidal positional embedding to create 'Sandwich', the first parameter-free relative positional embedding design that truly length information uses longer than the training sequence.", "target": "The authors propose to dissect ALiBi by using a novel tool based on a receptive field analysis, and based on this concept modify the vanilla Sinusoidal positional embedding to create 'Sandwich', the first parameter-free relative positional embedding design that truly length information uses longer than the training sequence.", "example": "Convert the coordinate to text: [-1.1512 -8.6155]:"}
{"text": "Convert the coordinate to text: [-5.5663 10.3304]: The authors introduce the Reference-Assisted Dialogue Evaluation (RADE) approach under the multi-task learning framework, which uses a pre-created utterance as reference, not just the golden response, to alleviate the one-to-many problem in dialogue system evaluation.", "target": "The authors introduce the Reference-Assisted Dialogue Evaluation (RADE) approach under the multi-task learning framework, which uses a pre-created utterance as reference, not just the golden response, to alleviate the one-to-many problem in dialogue system evaluation.", "example": "Convert the coordinate to text: [-5.5663 10.3304]:"}
{"text": "Convert the coordinate to text: [ 11.3237 -12.8583]: The authors introduce 3D pose as an intermediary and propose the Pose and Mesh Co-Evolution network (PMCE), which decouples the task into two parts: 1) video-based 3D human pose estimation and 2) mesh vertices regression from the estimated 3D pose and temporal image feature.", "target": "The authors introduce 3D pose as an intermediary and propose the Pose and Mesh Co-Evolution network (PMCE), which decouples the task into two parts: 1) video-based 3D human pose estimation and 2) mesh vertices regression from the estimated 3D pose and temporal image feature.", "example": "Convert the coordinate to text: [ 11.3237 -12.8583]:"}
{"text": "Convert the coordinate to text: [ 2.1619 -4.1952]: The authors propose a Non-mutually exclusive Contrastive Learning (NCL) framework which uses a pivot structure with dual branches for role-switching of contour patches between positives and negatives, and a pivot-consistent loss to avoid spatial corruption from the role-switching process.", "target": "The authors propose a Non-mutually exclusive Contrastive Learning (NCL) framework which uses a pivot structure with dual branches for role-switching of contour patches between positives and negatives, and a pivot-consistent loss to avoid spatial corruption from the role-switching process.", "example": "Convert the coordinate to text: [ 2.1619 -4.1952]:"}
{"text": "Convert the coordinate to text: [ 7.3046 13.7014]: This paper introduces the Accountable Offline Controller (AOC), a system that uses the offline dataset as the Decision Corpus and makes accountable control based on a selection of examples, referred to as the Corpus Subset.", "target": "This paper introduces the Accountable Offline Controller (AOC), a system that uses the offline dataset as the Decision Corpus and makes accountable control based on a selection of examples, referred to as the Corpus Subset.", "example": "Convert the coordinate to text: [ 7.3046 13.7014]:"}
{"text": "Convert the coordinate to text: [12.4478  3.7651]: The authors propose an algorithm that exploits the low-rank structure of matrices to obtain a low rank and low precision factorization, where the total number of elements in the low-rank factors is significantly less than that in the original matrix.", "target": "The authors propose an algorithm that exploits the low-rank structure of matrices to obtain a low rank and low precision factorization, where the total number of elements in the low-rank factors is significantly less than that in the original matrix.", "example": "Convert the coordinate to text: [12.4478  3.7651]:"}
{"text": "Convert the coordinate to text: [-0.1039 -5.6252]: The study introduces a novel framework named Diffusion-Enhanced Topic Modeling using Encoder-Decoder-based LLMs (DeTiME), which leverages Encoder-Decoder-based LLMs to produce highly clusterable embeddings that can generate topics with superior clusterability and enhanced semantic coherence.", "target": "The study introduces a novel framework named Diffusion-Enhanced Topic Modeling using Encoder-Decoder-based LLMs (DeTiME), which leverages Encoder-Decoder-based LLMs to produce highly clusterable embeddings that can generate topics with superior clusterability and enhanced semantic coherence.", "example": "Convert the coordinate to text: [-0.1039 -5.6252]:"}
{"text": "Convert the coordinate to text: [11.3806  5.958 ]: In the context of  \ud835\udc592-regularized \ud835\udc40-estimation problem, the authors propose a novel grid point selection scheme and an adaptive stopping criterion for any given optimization algorithm that provides an approximated solution path with an approximation error guarantee.", "target": "In the context of  \ud835\udc592-regularized \ud835\udc40-estimation problem, the authors propose a novel grid point selection scheme and an adaptive stopping criterion for any given optimization algorithm that provides an approximated solution path with an approximation error guarantee.", "example": "Convert the coordinate to text: [11.3806  5.958 ]:"}
{"text": "Convert the coordinate to text: [1.4624 0.6684]: The authors propose the first automated error classification framework, a valuable tool to study how modeling choices affect error distributions.", "target": "The authors propose the first automated error classification framework, a valuable tool to study how modeling choices affect error distributions.", "example": "Convert the coordinate to text: [1.4624 0.6684]:"}
{"text": "Convert the coordinate to text: [ 1.3493 -2.3858]: This work investigates the efficacy of sequence modeling in creating useful trajectory representations to enhance policy learning, and proposes a two-stage framework wherein sequence models encode trajectory-level representations, which is next used to learn a goal-conditioned policy.", "target": "This work investigates the efficacy of sequence modeling in creating useful trajectory representations to enhance policy learning, and proposes a two-stage framework wherein sequence models encode trajectory-level representations, which is next used to learn a goal-conditioned policy.", "example": "Convert the coordinate to text: [ 1.3493 -2.3858]:"}
{"text": "Convert the coordinate to text: [ 1.2348 -4.179 ]: The researchers identify two major issues in existing contrastive learning for sentence embeddings - handling dropout noise and feature corruption. They propose two unique methods to deal with each issue.", "target": "The researchers identify two major issues in existing contrastive learning for sentence embeddings - handling dropout noise and feature corruption. They propose two unique methods to deal with each issue.", "example": "Convert the coordinate to text: [ 1.2348 -4.179 ]:"}
{"text": "Convert the coordinate to text: [-2.063 -7.099]: The authors propose ViSoBERT as a monolingual pre-trained language model specifically for Vietnamese social media texts. This model is pre-trained on a large-scale corpus of high-quality and diverse Vietnamese social media texts.", "target": "The authors propose ViSoBERT as a monolingual pre-trained language model specifically for Vietnamese social media texts. This model is pre-trained on a large-scale corpus of high-quality and diverse Vietnamese social media texts.", "example": "Convert the coordinate to text: [-2.063 -7.099]:"}
{"text": "Convert the coordinate to text: [5.557  4.4736]: The authors propose a new approach to constructing provably-optimal sparse regression trees based on dynamic programming with bounds and leveraging a novel lower bound based on an optimal solution to the k-Means clustering algorithm in one dimension over the set of labels.", "target": "The authors propose a new approach to constructing provably-optimal sparse regression trees based on dynamic programming with bounds and leveraging a novel lower bound based on an optimal solution to the k-Means clustering algorithm in one dimension over the set of labels.", "example": "Convert the coordinate to text: [5.557  4.4736]:"}
{"text": "Convert the coordinate to text: [12.5247 -7.4688]: The paper provides a systematic analysis of the domain adaptation problem of GANs with a focus on StyleGAN. As a result, the authors propose efficient and lightweight parameterizations of StyleGAN for domain adaptation, namely StyleSpace (StyleDomain directions) for similar domains and Affine$+$ and AffineLight$+$ parameterizations for dissimilar domains.", "target": "The paper provides a systematic analysis of the domain adaptation problem of GANs with a focus on StyleGAN. As a result, the authors propose efficient and lightweight parameterizations of StyleGAN for domain adaptation, namely StyleSpace (StyleDomain directions) for similar domains and Affine$+$ and AffineLight$+$ parameterizations for dissimilar domains.", "example": "Convert the coordinate to text: [12.5247 -7.4688]:"}
{"text": "Convert the coordinate to text: [ 11.1969 -12.6588]: The paper proposes PoseDA, an unsupervised domain adaptation framework for 3D human pose estimation, which uses global adaptation to align global positions of poses from the source domain to the target domain and local generalization to enhance the diversity of 2D-3D pose mapping.", "target": "The paper proposes PoseDA, an unsupervised domain adaptation framework for 3D human pose estimation, which uses global adaptation to align global positions of poses from the source domain to the target domain and local generalization to enhance the diversity of 2D-3D pose mapping.", "example": "Convert the coordinate to text: [ 11.1969 -12.6588]:"}
{"text": "Convert the coordinate to text: [9.1637 6.5321]: The authors study the model stability problem by examining how a model's predictions change as a consequence of stochasticity in the training process, even when it is retrained on the same data. They also propose new data-centric methods that exploit local stability estimates.", "target": "The authors study the model stability problem by examining how a model's predictions change as a consequence of stochasticity in the training process, even when it is retrained on the same data. They also propose new data-centric methods that exploit local stability estimates.", "example": "Convert the coordinate to text: [9.1637 6.5321]:"}
{"text": "Convert the coordinate to text: [-6.7763 -8.1968]: The authors propose to construct the first Classical-Chinese-to-Kanbun dataset in the world and introduce two tasks, character reordering and machine translation, both of which are significant in Kanbun comprehension.", "target": "The authors propose to construct the first Classical-Chinese-to-Kanbun dataset in the world and introduce two tasks, character reordering and machine translation, both of which are significant in Kanbun comprehension.", "example": "Convert the coordinate to text: [-6.7763 -8.1968]:"}
{"text": "Convert the coordinate to text: [-1.1088 -5.6975]: In this paper, the authors explore intent-conditioned counterspeech generation. They develop IntentCONAN, a diversified intent-specific counterspeech dataset, and propose QUARC, a two-stage framework for intent-conditioned counterspeech generation that leverages vector-quantized representations and a novel fusion module called PerFuMe.", "target": "In this paper, the authors explore intent-conditioned counterspeech generation. They develop IntentCONAN, a diversified intent-specific counterspeech dataset, and propose QUARC, a two-stage framework for intent-conditioned counterspeech generation that leverages vector-quantized representations and a novel fusion module called PerFuMe.", "example": "Convert the coordinate to text: [-1.1088 -5.6975]:"}
{"text": "Convert the coordinate to text: [-4.7636  8.7591]: The authors propose the \"Ask an Expert\" framework where the model is trained with access to an expert which can be consulted at each turn. The model is optimized to either utilize or ignore advice given the context and dialogue history.", "target": "The authors propose the \"Ask an Expert\" framework where the model is trained with access to an expert which can be consulted at each turn. The model is optimized to either utilize or ignore advice given the context and dialogue history.", "example": "Convert the coordinate to text: [-4.7636  8.7591]:"}
{"text": "Convert the coordinate to text: [ 6.1896 -5.544 ]: From the perspective of spectral transformation, the authors analyse the important factors a graph filter should consider for superior performance. Building on these findings, they develop JGCF, an efficient method for collaborative filtering based on Jacobi polynomial bases and frequency decomposition strategies.", "target": "From the perspective of spectral transformation, the authors analyse the important factors a graph filter should consider for superior performance. Building on these findings, they develop JGCF, an efficient method for collaborative filtering based on Jacobi polynomial bases and frequency decomposition strategies.", "example": "Convert the coordinate to text: [ 6.1896 -5.544 ]:"}
{"text": "Convert the coordinate to text: [-2.941 -2.462]: The study puts forth a new setting, actively supervised clustering for OpenRE, where clustering learning and relation labeling are alternately performed. This provides necessary clustering guidance without a significant increase in human effort. A key component of this setting involves choosing which instances to label, for which the authors develop a new strategy suitable for dynamically discovering clusters of unknown relations.", "target": "The study puts forth a new setting, actively supervised clustering for OpenRE, where clustering learning and relation labeling are alternately performed. This provides necessary clustering guidance without a significant increase in human effort. A key component of this setting involves choosing which instances to label, for which the authors develop a new strategy suitable for dynamically discovering clusters of unknown relations.", "example": "Convert the coordinate to text: [-2.941 -2.462]:"}
{"text": "Convert the coordinate to text: [13.3901 -4.7382]: This paper introduces task-agnostic backdoor attacks for code pre-trained models, pre-training the model with two learning strategies (Poisoned Seq2Seq learning and token representation learning) to support the multi-target attack of downstream code understanding and generation tasks.", "target": "This paper introduces task-agnostic backdoor attacks for code pre-trained models, pre-training the model with two learning strategies (Poisoned Seq2Seq learning and token representation learning) to support the multi-target attack of downstream code understanding and generation tasks.", "example": "Convert the coordinate to text: [13.3901 -4.7382]:"}
{"text": "Convert the coordinate to text: [-5.1396  2.4692]: The paper proposes a MUlti-Step Evidence Retrieval enhancement (MUSER) framework for fake news detection, which simulates the steps a human would take including reading news, summarizing, consulting materials, and inferring if the news is true or fake. This model can model dependencies among multiple pieces of evidence and perform multi-step associations.", "target": "The paper proposes a MUlti-Step Evidence Retrieval enhancement (MUSER) framework for fake news detection, which simulates the steps a human would take including reading news, summarizing, consulting materials, and inferring if the news is true or fake. This model can model dependencies among multiple pieces of evidence and perform multi-step associations.", "example": "Convert the coordinate to text: [-5.1396  2.4692]:"}
{"text": "Convert the coordinate to text: [-2.6931 -6.238 ]: The key idea is to extend the ability of large language models to generalize from few-shot examples and to produce strong classifiers using the engineering approach of parameter-efficient tuning.", "target": "The key idea is to extend the ability of large language models to generalize from few-shot examples and to produce strong classifiers using the engineering approach of parameter-efficient tuning.", "example": "Convert the coordinate to text: [-2.6931 -6.238 ]:"}
{"text": "Convert the coordinate to text: [ 3.6288 -9.1726]: This paper provides a novel scene-robust NLVL framework that can handle videos and queries in novel scenes. It proposes a comprehensive intra- and inter-sample distance metric for complex multi-modal feature space, and an asymmetric multi-modal alignment loss for different information densities of text and vision.", "target": "This paper provides a novel scene-robust NLVL framework that can handle videos and queries in novel scenes. It proposes a comprehensive intra- and inter-sample distance metric for complex multi-modal feature space, and an asymmetric multi-modal alignment loss for different information densities of text and vision.", "example": "Convert the coordinate to text: [ 3.6288 -9.1726]:"}
{"text": "Convert the coordinate to text: [11.8594 -4.9599]: The authors propose a Contrastive learning regularization method using Adversarial examples for Alleviating the Pathology (ConAAP), which calibrates the sentence representation of out-of-distribution examples. ConAAP generates positive and negative examples following the attribution results, and uses adversarial examples to introduce direction information in regularization.", "target": "The authors propose a Contrastive learning regularization method using Adversarial examples for Alleviating the Pathology (ConAAP), which calibrates the sentence representation of out-of-distribution examples. ConAAP generates positive and negative examples following the attribution results, and uses adversarial examples to introduce direction information in regularization.", "example": "Convert the coordinate to text: [11.8594 -4.9599]:"}
{"text": "Convert the coordinate to text: [11.9424 -4.8666]: The authors propose a new training algorithm, Benign Adversarial Training (BAT). This algorithm is designed to avoid fitting 'harmful' atypical samples and instead fits as many 'benign' atypical samples as possible.", "target": "The authors propose a new training algorithm, Benign Adversarial Training (BAT). This algorithm is designed to avoid fitting 'harmful' atypical samples and instead fits as many 'benign' atypical samples as possible.", "example": "Convert the coordinate to text: [11.9424 -4.8666]:"}
{"text": "Convert the coordinate to text: [ 4.5309 -8.7978]: The paper introduces Iterated Integrated Attributions (IIA), a novel method to generate precise and focused explanation maps for the predictions of vision models by employing iterative integration across the input image, the internal representations from the models, and their gradients.", "target": "The paper introduces Iterated Integrated Attributions (IIA), a novel method to generate precise and focused explanation maps for the predictions of vision models by employing iterative integration across the input image, the internal representations from the models, and their gradients.", "example": "Convert the coordinate to text: [ 4.5309 -8.7978]:"}
{"text": "Convert the coordinate to text: [  6.2273 -10.5691]: The authors propose an efficient mask propagation framework for VSS, called MPVSS, which reduces computational costs by generating accurate binary masks and class predictions on sparse key frames and reusing these predictions for non-key frames.", "target": "The authors propose an efficient mask propagation framework for VSS, called MPVSS, which reduces computational costs by generating accurate binary masks and class predictions on sparse key frames and reusing these predictions for non-key frames.", "example": "Convert the coordinate to text: [  6.2273 -10.5691]:"}
{"text": "Convert the coordinate to text: [9.8606 6.2807]: The authors argue that the cause of miscalibration and unboundedness in prior estimators for learning-to-defer is due to symmetric surrogate losses, not softmax. The authors propose a consistent, asymmetric softmax-based surrogate loss that can produce valid estimates without unboundedness.", "target": "The authors argue that the cause of miscalibration and unboundedness in prior estimators for learning-to-defer is due to symmetric surrogate losses, not softmax. The authors propose a consistent, asymmetric softmax-based surrogate loss that can produce valid estimates without unboundedness.", "example": "Convert the coordinate to text: [9.8606 6.2807]:"}
{"text": "Convert the coordinate to text: [10.7731 -3.593 ]: The paper proposes that the domination of skip connections in DARTS results from parametric operations overfitting the training data while architecture parameters are trained on the validation data and proposes the operation-level early stopping (OLES) method to counter this issue without adding computational overhead.", "target": "The paper proposes that the domination of skip connections in DARTS results from parametric operations overfitting the training data while architecture parameters are trained on the validation data and proposes the operation-level early stopping (OLES) method to counter this issue without adding computational overhead.", "example": "Convert the coordinate to text: [10.7731 -3.593 ]:"}
{"text": "Convert the coordinate to text: [ 10.2617 -15.2927]: The paper presents a new visual localization technique that uses only a few positioned images to achieve accurate localization. It employs NeRF-provided coarse pseudo-3D labels, a coordinate regression network, and an image-based visual servo (IBVS) with scene prior provided by NeRF for pose optimization.", "target": "The paper presents a new visual localization technique that uses only a few positioned images to achieve accurate localization. It employs NeRF-provided coarse pseudo-3D labels, a coordinate regression network, and an image-based visual servo (IBVS) with scene prior provided by NeRF for pose optimization.", "example": "Convert the coordinate to text: [ 10.2617 -15.2927]:"}
{"text": "Convert the coordinate to text: [-1.6915 -6.2081]: This study aims to compare the performance of a set of financial BERT-like models to their fully fine-tuned counterparts by leveraging different parameter-efficient tuning methods.", "target": "This study aims to compare the performance of a set of financial BERT-like models to their fully fine-tuned counterparts by leveraging different parameter-efficient tuning methods.", "example": "Convert the coordinate to text: [-1.6915 -6.2081]:"}
{"text": "Convert the coordinate to text: [-0.8093  0.4641]: The authors develop the Prompt Association Test (P-AT), a novel resource for detecting social biases in IFLMs. The P-AT, inspired by WEAT, adapts the measurement of social biases to IFLMs using promptized classification tasks and an associated metric, the bias score.", "target": "The authors develop the Prompt Association Test (P-AT), a novel resource for detecting social biases in IFLMs. The P-AT, inspired by WEAT, adapts the measurement of social biases to IFLMs using promptized classification tasks and an associated metric, the bias score.", "example": "Convert the coordinate to text: [-0.8093  0.4641]:"}
{"text": "Convert the coordinate to text: [ 12.9992 -11.6413]: The authors propose an end-to-end framework for simultaneously supporting face attribute edits, facial motions and deformations, and facial identity control for video generation. This is achieved through the use of a hybrid latent-space that uniquely encodes a given frame into a pair of latents; one for Identity and the other for Facial deformation.", "target": "The authors propose an end-to-end framework for simultaneously supporting face attribute edits, facial motions and deformations, and facial identity control for video generation. This is achieved through the use of a hybrid latent-space that uniquely encodes a given frame into a pair of latents; one for Identity and the other for Facial deformation.", "example": "Convert the coordinate to text: [ 12.9992 -11.6413]:"}
{"text": "Convert the coordinate to text: [-2.9628 -6.7093]: The team explored different strategies for training pretrained language models under low resource settings, with a focus on cross-lingual/multi-task training and collecting an external balanced dataset for genre and framing detection.", "target": "The team explored different strategies for training pretrained language models under low resource settings, with a focus on cross-lingual/multi-task training and collecting an external balanced dataset for genre and framing detection.", "example": "Convert the coordinate to text: [-2.9628 -6.7093]:"}
{"text": "Convert the coordinate to text: [10.0154  0.5933]: The author proposes a new method of estimating the Riemannian metric - the quantity that defines straight lines and derivatives on the manifold - through a local regression approach based on a Taylor expansion for the squared geodesic distances. This approach accommodates various types of responses including continuous, binary, and comparative.", "target": "The author proposes a new method of estimating the Riemannian metric - the quantity that defines straight lines and derivatives on the manifold - through a local regression approach based on a Taylor expansion for the squared geodesic distances. This approach accommodates various types of responses including continuous, binary, and comparative.", "example": "Convert the coordinate to text: [10.0154  0.5933]:"}
{"text": "Convert the coordinate to text: [ 14.769  -15.0695]: The authors propose SA3D, a novel framework for Segment Anything in 3D. Given a Neural Radiance Field (NeRF) model, it can provide 3D segmentation results of any target object with only one-shot manual prompting in a single rendered view.", "target": "The authors propose SA3D, a novel framework for Segment Anything in 3D. Given a Neural Radiance Field (NeRF) model, it can provide 3D segmentation results of any target object with only one-shot manual prompting in a single rendered view.", "example": "Convert the coordinate to text: [ 14.769  -15.0695]:"}
{"text": "Convert the coordinate to text: [ 1.743  -7.5795]: The paper shows that LayerNorm is vital to the expressivity of the multi-head attention layer in Transformers. Its importance derives from two aspects: projecting input vectors to a d-1 space that's orthogonal to the [1,1,...,1] vector, and scaling all vectors to the same norm of \u221ad.", "target": "The paper shows that LayerNorm is vital to the expressivity of the multi-head attention layer in Transformers. Its importance derives from two aspects: projecting input vectors to a d-1 space that's orthogonal to the [1,1,...,1] vector, and scaling all vectors to the same norm of \u221ad.", "example": "Convert the coordinate to text: [ 1.743  -7.5795]:"}
{"text": "Convert the coordinate to text: [-1.9321 -6.2635]: An ensemble approach for detecting human values from argument text is proposed which comprises a entailment-based model for determining the human values based on their descriptions, a Roberta-based classifier that predicts the set of human values from an argument, and another Roberta-based classifier to predict a reduced set of human values from an argument.", "target": "An ensemble approach for detecting human values from argument text is proposed which comprises a entailment-based model for determining the human values based on their descriptions, a Roberta-based classifier that predicts the set of human values from an argument, and another Roberta-based classifier to predict a reduced set of human values from an argument.", "example": "Convert the coordinate to text: [-1.9321 -6.2635]:"}
{"text": "Convert the coordinate to text: [-2.8424 -5.1319]: The authors propose a manual evaluation of various QA models, including LLMs, on a subset of NQ-open to reveal the true performance of these models, and examine the limitations of lexical matching evaluations, regex matching, and automated evaluation models.", "target": "The authors propose a manual evaluation of various QA models, including LLMs, on a subset of NQ-open to reveal the true performance of these models, and examine the limitations of lexical matching evaluations, regex matching, and automated evaluation models.", "example": "Convert the coordinate to text: [-2.8424 -5.1319]:"}
{"text": "Convert the coordinate to text: [ 6.6597 -3.5531]: The authors propose a new Discriminative-Invariant Representation Learning (DIRL) framework for unbiased recommendation. The framework incorporates label-conditional clustering and prior-guided contrasting into conventional invariant representation learning to mitigate the impact of data sparsity and label shift.", "target": "The authors propose a new Discriminative-Invariant Representation Learning (DIRL) framework for unbiased recommendation. The framework incorporates label-conditional clustering and prior-guided contrasting into conventional invariant representation learning to mitigate the impact of data sparsity and label shift.", "example": "Convert the coordinate to text: [ 6.6597 -3.5531]:"}
{"text": "Convert the coordinate to text: [ 0.3652 -8.5272]: The paper recasts the attribute extraction problem as a question-answering task and presents a scalable solution, called MXT, which consists of MAG (Multimodal Adaptation Gate), Xception network, and T5 encoder-decoder and uses both textual and visual characteristics of a product to generate its attributes.", "target": "The paper recasts the attribute extraction problem as a question-answering task and presents a scalable solution, called MXT, which consists of MAG (Multimodal Adaptation Gate), Xception network, and T5 encoder-decoder and uses both textual and visual characteristics of a product to generate its attributes.", "example": "Convert the coordinate to text: [ 0.3652 -8.5272]:"}
{"text": "Convert the coordinate to text: [-1.1413 -8.6953]: The paper introduces a Bayesian approach, called deep evidential emotion regression (DEER), to estimate the uncertainty in emotion attributes. The approach models the emotion attribute labels of an utterance as samples from an unknown Gaussian distribution, and it uses a deep neural network to predict the hyper-parameters of an utterance-specific normal-inverse gamma prior over the Gaussian likelihood.", "target": "The paper introduces a Bayesian approach, called deep evidential emotion regression (DEER), to estimate the uncertainty in emotion attributes. The approach models the emotion attribute labels of an utterance as samples from an unknown Gaussian distribution, and it uses a deep neural network to predict the hyper-parameters of an utterance-specific normal-inverse gamma prior over the Gaussian likelihood.", "example": "Convert the coordinate to text: [-1.1413 -8.6953]:"}
{"text": "Convert the coordinate to text: [ 2.16   -2.7223]: The authors propose a new method using deep model compression to capture the degree of relationship between each sample and its candidate classes, which helps quantify ambiguity in NLU tasks.", "target": "The authors propose a new method using deep model compression to capture the degree of relationship between each sample and its candidate classes, which helps quantify ambiguity in NLU tasks.", "example": "Convert the coordinate to text: [ 2.16   -2.7223]:"}
{"text": "Convert the coordinate to text: [ 1.7955 -5.2535]: The authors propose a multimodal intensive ZSL framework that matches regions of images with corresponding semantic embeddings via a designed dense attention module and self-calibration loss. This setup enables semantic transfer process of the ZSL framework to learn more differentiated knowledge between entities.", "target": "The authors propose a multimodal intensive ZSL framework that matches regions of images with corresponding semantic embeddings via a designed dense attention module and self-calibration loss. This setup enables semantic transfer process of the ZSL framework to learn more differentiated knowledge between entities.", "example": "Convert the coordinate to text: [ 1.7955 -5.2535]:"}
{"text": "Convert the coordinate to text: [ 2.6951 -3.1404]: The authors transform the CIL problem into a continual label generation problem, which drastically reduces CF and better retains the generalizable representations of pre-trained models. They introduce a new CIL method (VAG) that leverages the sparsity of vocabulary to focus the generation and creates pseudo-replay samples using label semantics.", "target": "The authors transform the CIL problem into a continual label generation problem, which drastically reduces CF and better retains the generalizable representations of pre-trained models. They introduce a new CIL method (VAG) that leverages the sparsity of vocabulary to focus the generation and creates pseudo-replay samples using label semantics.", "example": "Convert the coordinate to text: [ 2.6951 -3.1404]:"}
{"text": "Convert the coordinate to text: [-2.4565 -6.7262]: The authors participated in this task and offer several solutions involving the use of pre-trained models and their ensembles, including using mono- and multilingual models, training on various datasets, fine-tuning on additional genre classification tasks, and adjusting hyperparameters.", "target": "The authors participated in this task and offer several solutions involving the use of pre-trained models and their ensembles, including using mono- and multilingual models, training on various datasets, fine-tuning on additional genre classification tasks, and adjusting hyperparameters.", "example": "Convert the coordinate to text: [-2.4565 -6.7262]:"}
{"text": "Convert the coordinate to text: [-2.1143 -5.9882]: Drawing from the BioBART model, the authors suggest pre-training a general domain BART model with biomedical data for adapting to this specific domain, and using aggregated pre-training tasks to augment linguistic knowledge and enhance the abstractivity of the summaries.", "target": "Drawing from the BioBART model, the authors suggest pre-training a general domain BART model with biomedical data for adapting to this specific domain, and using aggregated pre-training tasks to augment linguistic knowledge and enhance the abstractivity of the summaries.", "example": "Convert the coordinate to text: [-2.1143 -5.9882]:"}
{"text": "Convert the coordinate to text: [-2.8533 -9.7298]: Using domestic Shiba Inu dogs as a subject, this paper extracts their vocal communications from a large number of YouTube videos, classifies these clips by different scenarios and locations, and transcribes the audio into phonetically symbolic scripts.", "target": "Using domestic Shiba Inu dogs as a subject, this paper extracts their vocal communications from a large number of YouTube videos, classifies these clips by different scenarios and locations, and transcribes the audio into phonetically symbolic scripts.", "example": "Convert the coordinate to text: [-2.8533 -9.7298]:"}
{"text": "Convert the coordinate to text: [6.0878 1.9317]: The authors propose a simple novel metric based on a nearest neighbors approach to quantify the overlap between training and evaluation sets which characterizes the adequacy of an individual dataset to evaluate model generalization.", "target": "The authors propose a simple novel metric based on a nearest neighbors approach to quantify the overlap between training and evaluation sets which characterizes the adequacy of an individual dataset to evaluate model generalization.", "example": "Convert the coordinate to text: [6.0878 1.9317]:"}
{"text": "Convert the coordinate to text: [0.9395 1.8719]: The paper proposes a more efficient approach to counterfactual training\u2014asking hypothetical questions whose answers have equivalent effects to counterfactual data. The authors suggest a hypothetical training framework that uses paired examples with different hypothetical questions to guide the model's learning.", "target": "The paper proposes a more efficient approach to counterfactual training\u2014asking hypothetical questions whose answers have equivalent effects to counterfactual data. The authors suggest a hypothetical training framework that uses paired examples with different hypothetical questions to guide the model's learning.", "example": "Convert the coordinate to text: [0.9395 1.8719]:"}
{"text": "Convert the coordinate to text: [-0.7934 -5.3059]: The authors aim to improve the generalization ability of AES models from the domain generalization perspective, and propose a prompt-aware neural AES model to extract both prompt-invariant and prompt-specific features. To further improve the generalization, they introduce a disentangled representation learning framework.", "target": "The authors aim to improve the generalization ability of AES models from the domain generalization perspective, and propose a prompt-aware neural AES model to extract both prompt-invariant and prompt-specific features. To further improve the generalization, they introduce a disentangled representation learning framework.", "example": "Convert the coordinate to text: [-0.7934 -5.3059]:"}
{"text": "Convert the coordinate to text: [ 4.6966 -4.6504]: This paper introduces a status-aware method for graph structure learning, called Graph Structure Learning via Progressive Strategy (PROSE). It proposes a progressive strategy which modifies node connections based on their global potency.", "target": "This paper introduces a status-aware method for graph structure learning, called Graph Structure Learning via Progressive Strategy (PROSE). It proposes a progressive strategy which modifies node connections based on their global potency.", "example": "Convert the coordinate to text: [ 4.6966 -4.6504]:"}
{"text": "Convert the coordinate to text: [ 12.6125 -15.4352]: The authors introduce a space-time local implicit neural function that can learn forward motion for a continuum of pixels from the perspective of learning individual motion trajectories, instead of learning a mixture of motion trajectories with backward motion.", "target": "The authors introduce a space-time local implicit neural function that can learn forward motion for a continuum of pixels from the perspective of learning individual motion trajectories, instead of learning a mixture of motion trajectories with backward motion.", "example": "Convert the coordinate to text: [ 12.6125 -15.4352]:"}
{"text": "Convert the coordinate to text: [ 5.2485 -1.1563]: The authors propose an efficient method for learning LTFs using LTFs, when given access to random bags of some label proportion in which feature-vectors are, conditioned on their labels, independently sampled from a Gaussian distribution. The method involves forming a matrix using covariances of the differences of feature-vectors sampled from the bags with and without replacement, and using subgaussian concentration bounds for efficient sampling and approximating the normal direction.", "target": "The authors propose an efficient method for learning LTFs using LTFs, when given access to random bags of some label proportion in which feature-vectors are, conditioned on their labels, independently sampled from a Gaussian distribution. The method involves forming a matrix using covariances of the differences of feature-vectors sampled from the bags with and without replacement, and using subgaussian concentration bounds for efficient sampling and approximating the normal direction.", "example": "Convert the coordinate to text: [ 5.2485 -1.1563]:"}
{"text": "Convert the coordinate to text: [-1.0128 -5.2684]: The authors propose a new locally differentially private mechanism called DP-Prompt, leveraging the power of pretrained large language models and zero-shot prompting to protect against author de-anonymization attacks while minimizing the impact on the downstream utility.", "target": "The authors propose a new locally differentially private mechanism called DP-Prompt, leveraging the power of pretrained large language models and zero-shot prompting to protect against author de-anonymization attacks while minimizing the impact on the downstream utility.", "example": "Convert the coordinate to text: [-1.0128 -5.2684]:"}
{"text": "Convert the coordinate to text: [ 1.472  -7.4852]: The authors put forward a causal interpretation of self-attention in the Transformer architecture, viewing it as a mechanism that estimates a structural equation model for a given input sequence of symbols, which can be then seen as a causal structure.", "target": "The authors put forward a causal interpretation of self-attention in the Transformer architecture, viewing it as a mechanism that estimates a structural equation model for a given input sequence of symbols, which can be then seen as a causal structure.", "example": "Convert the coordinate to text: [ 1.472  -7.4852]:"}
{"text": "Convert the coordinate to text: [-3.694   3.4512]: The authors argue this paradigm has limitations and propose reshaping sequential recommendation as a learning-to-generate paradigm, which is implemented via a guided diffusion model called DreamRec.", "target": "The authors argue this paradigm has limitations and propose reshaping sequential recommendation as a learning-to-generate paradigm, which is implemented via a guided diffusion model called DreamRec.", "example": "Convert the coordinate to text: [-3.694   3.4512]:"}
{"text": "Convert the coordinate to text: [ 5.1952 -5.3204]: This paper proposes Low-Rank Decomposition-based GNNs (LRD-GNNs), which challenge the common choice of using propagation-based GNNs. LRD-GNNs employ Low-Rank Decomposition on the attribute matrix and node attribute tensor constructed from selected similar ego-networks for better handling of homophily networks without label information.", "target": "This paper proposes Low-Rank Decomposition-based GNNs (LRD-GNNs), which challenge the common choice of using propagation-based GNNs. LRD-GNNs employ Low-Rank Decomposition on the attribute matrix and node attribute tensor constructed from selected similar ego-networks for better handling of homophily networks without label information.", "example": "Convert the coordinate to text: [ 5.1952 -5.3204]:"}
{"text": "Convert the coordinate to text: [5.8221 0.0468]: The paper proposes a closed boundary learning method that applies closed decision boundaries for classes of interest and designates the area outside these boundaries as the space for the Universum class. The closed boundaries are formulated as arbitrary shapes and a boundary learning loss function to handle misclassification is introduced.", "target": "The paper proposes a closed boundary learning method that applies closed decision boundaries for classes of interest and designates the area outside these boundaries as the space for the Universum class. The closed boundaries are formulated as arbitrary shapes and a boundary learning loss function to handle misclassification is introduced.", "example": "Convert the coordinate to text: [5.8221 0.0468]:"}
{"text": "Convert the coordinate to text: [-6.0676  2.1984]: This paper proposes the design of three interfaces -- the Annotated Article, the Recomposed Article, and the Question Grid -- aimed at assisting news readers in discovering coverage diversity while reading.", "target": "This paper proposes the design of three interfaces -- the Annotated Article, the Recomposed Article, and the Question Grid -- aimed at assisting news readers in discovering coverage diversity while reading.", "example": "Convert the coordinate to text: [-6.0676  2.1984]:"}
{"text": "Convert the coordinate to text: [ 3.7346 15.2093]: This paper introduces Chameleon, a plug-and-play compositional reasoning framework that enhances LLMs. Chameleon composes various tools, including LLM models, off-the-shelf vision models, web search engines, Python functions, and rule-based modules, to help address these challenges.", "target": "This paper introduces Chameleon, a plug-and-play compositional reasoning framework that enhances LLMs. Chameleon composes various tools, including LLM models, off-the-shelf vision models, web search engines, Python functions, and rule-based modules, to help address these challenges.", "example": "Convert the coordinate to text: [ 3.7346 15.2093]:"}
{"text": "Convert the coordinate to text: [-13.2994   9.1961]: The paper investigates the issue of directionality in 16 user interface items, demonstrating empirically the ambiguity problem in bidirectional interfaces and determining the potential influence of UI factors on how users interpret these items.", "target": "The paper investigates the issue of directionality in 16 user interface items, demonstrating empirically the ambiguity problem in bidirectional interfaces and determining the potential influence of UI factors on how users interpret these items.", "example": "Convert the coordinate to text: [-13.2994   9.1961]:"}
{"text": "Convert the coordinate to text: [13.0614 -4.4302]: This paper introduces a novel decision-based black-box attack framework, the DBA-GP, which incorporates both data-dependent gradient priors and time-dependent priors into the gradient estimation procedure. A new gradient updating strategy is proposed to adjust the direction of successive gradient iterations.", "target": "This paper introduces a novel decision-based black-box attack framework, the DBA-GP, which incorporates both data-dependent gradient priors and time-dependent priors into the gradient estimation procedure. A new gradient updating strategy is proposed to adjust the direction of successive gradient iterations.", "example": "Convert the coordinate to text: [13.0614 -4.4302]:"}
{"text": "Convert the coordinate to text: [-4.2809 -5.0113]: The authors propose a new approach to study semantic construal in grammatical constructions by projecting contextual word embeddings into three interpretable semantic spaces, each defined by a different set of psycholinguistic feature norms.", "target": "The authors propose a new approach to study semantic construal in grammatical constructions by projecting contextual word embeddings into three interpretable semantic spaces, each defined by a different set of psycholinguistic feature norms.", "example": "Convert the coordinate to text: [-4.2809 -5.0113]:"}
{"text": "Convert the coordinate to text: [-0.1048 -8.653 ]: This paper focuses on exploring the difference between BERT-style and CLIP-style text encoders using three experiments focusing on general text understanding, vision-centric text understanding, and text-to-image generation.", "target": "This paper focuses on exploring the difference between BERT-style and CLIP-style text encoders using three experiments focusing on general text understanding, vision-centric text understanding, and text-to-image generation.", "example": "Convert the coordinate to text: [-0.1048 -8.653 ]:"}
{"text": "Convert the coordinate to text: [14.1122  5.4304]: The authors propose using an optimal transport-based distributional robustness framework on model spaces. This involves examining a model distribution in a Wasserstein ball of a center model distribution that maximizes the loss and learning the optimal robust center model distribution.", "target": "The authors propose using an optimal transport-based distributional robustness framework on model spaces. This involves examining a model distribution in a Wasserstein ball of a center model distribution that maximizes the loss and learning the optimal robust center model distribution.", "example": "Convert the coordinate to text: [14.1122  5.4304]:"}
{"text": "Convert the coordinate to text: [-8.7136 -3.5858]: This position paper recognizes semantic underspecification as a crucial language feature that enhances its storage and processing efficiency and underscores the need for NLP models to effectively handle this attribute.", "target": "This position paper recognizes semantic underspecification as a crucial language feature that enhances its storage and processing efficiency and underscores the need for NLP models to effectively handle this attribute.", "example": "Convert the coordinate to text: [-8.7136 -3.5858]:"}
{"text": "Convert the coordinate to text: [-11.5651   5.7886]: Authors introduce WizMap, an interactive visualization tool to help researchers and practitioners explore and navigate large embeddings. WizMap employs a novel multi-resolution embedding summarization method and a familiar map-like interaction design.", "target": "Authors introduce WizMap, an interactive visualization tool to help researchers and practitioners explore and navigate large embeddings. WizMap employs a novel multi-resolution embedding summarization method and a familiar map-like interaction design.", "example": "Convert the coordinate to text: [-11.5651   5.7886]:"}
{"text": "Convert the coordinate to text: [-2.7751  0.484 ]: The authors propose a novel annotation scheme which factors hate speech into five separate discursive categories.", "target": "The authors propose a novel annotation scheme which factors hate speech into five separate discursive categories.", "example": "Convert the coordinate to text: [-2.7751  0.484 ]:"}
{"text": "Convert the coordinate to text: [-1.7715 -6.3487]: The authors propose a system that combines topic modeling and RoBERTa to encode sentences in each document, uses a BiLSTM layer to get contextualised sentence representations, and generates Rhetorical Role predictions for each sentence in each document by a final CRF layer.", "target": "The authors propose a system that combines topic modeling and RoBERTa to encode sentences in each document, uses a BiLSTM layer to get contextualised sentence representations, and generates Rhetorical Role predictions for each sentence in each document by a final CRF layer.", "example": "Convert the coordinate to text: [-1.7715 -6.3487]:"}
{"text": "Convert the coordinate to text: [-1.0169 -3.4091]: CoGen, a novel model combining temporal commonsense reasoning for each observation (before and after a real hypothesis) from pre-trained models with contextual filtering, has been proposed for both alphaNLI and alphaNLG tasks.", "target": "CoGen, a novel model combining temporal commonsense reasoning for each observation (before and after a real hypothesis) from pre-trained models with contextual filtering, has been proposed for both alphaNLI and alphaNLG tasks.", "example": "Convert the coordinate to text: [-1.0169 -3.4091]:"}
{"text": "Convert the coordinate to text: [-10.9487   1.4714]: The authors propose SupKG, a commonsense knowledge graph for Super Apps, developed from data sources in Alipay, aiming to characterize user behaviors across different business scenarios. The graph incorporates abundant spatiotemporal relations and intent-related entities answering the fundamental question of which service users need at what time and where.", "target": "The authors propose SupKG, a commonsense knowledge graph for Super Apps, developed from data sources in Alipay, aiming to characterize user behaviors across different business scenarios. The graph incorporates abundant spatiotemporal relations and intent-related entities answering the fundamental question of which service users need at what time and where.", "example": "Convert the coordinate to text: [-10.9487   1.4714]:"}
{"text": "Convert the coordinate to text: [13.1131 -0.0766]: The paper introduces a new framework that effectively learns slow and fast system dynamics in an integrated manner, using a novel intrinsic dimensionality (ID) driven learning method based on a time-lagged autoencoder framework to identify appropriate time scales to separate slow and fast variables and their IDs.", "target": "The paper introduces a new framework that effectively learns slow and fast system dynamics in an integrated manner, using a novel intrinsic dimensionality (ID) driven learning method based on a time-lagged autoencoder framework to identify appropriate time scales to separate slow and fast variables and their IDs.", "example": "Convert the coordinate to text: [13.1131 -0.0766]:"}
{"text": "Convert the coordinate to text: [ 9.45   -3.8021]: The authors propose an equivariant regularization technique that includes an averaging procedure and self-consistency loss to promote this equivariance in depth and normal networks.", "target": "The authors propose an equivariant regularization technique that includes an averaging procedure and self-consistency loss to promote this equivariance in depth and normal networks.", "example": "Convert the coordinate to text: [ 9.45   -3.8021]:"}
{"text": "Convert the coordinate to text: [5.6265 8.0504]: The authors propose G2MILP, which is a deep generative framework for MILP instances. The innovation here is that G2MILP represents MILP instances as bipartite graphs, and applies a masked variational autoencoder to iteratively corrupt and replace parts of the original graphs - creating novel and realistic MILP instances.", "target": "The authors propose G2MILP, which is a deep generative framework for MILP instances. The innovation here is that G2MILP represents MILP instances as bipartite graphs, and applies a masked variational autoencoder to iteratively corrupt and replace parts of the original graphs - creating novel and realistic MILP instances.", "example": "Convert the coordinate to text: [5.6265 8.0504]:"}
{"text": "Convert the coordinate to text: [-1.5531 -7.5238]: The paper argues for the preservation of spatial structure during tokenization and its explicit use in the information mixing phase, introducing two key contributions: Structure-aware Tokenization and Structure-aware Mixing, each of which can be incorporated into existing models with minimal effort.", "target": "The paper argues for the preservation of spatial structure during tokenization and its explicit use in the information mixing phase, introducing two key contributions: Structure-aware Tokenization and Structure-aware Mixing, each of which can be incorporated into existing models with minimal effort.", "example": "Convert the coordinate to text: [-1.5531 -7.5238]:"}
{"text": "Convert the coordinate to text: [ 8.3906 -8.6643]: The authors propose a novel Correlation-Driven feature Decomposition Fusion (CDDFuse) network, which uses Restormer blocks to extract cross-modality shallow features and dual-branch Transformer-CNN feature extractor with Lite Transformer (LT) blocks and Invertible Neural Networks (INN) blocks to handle different spatial frequencies of features.", "target": "The authors propose a novel Correlation-Driven feature Decomposition Fusion (CDDFuse) network, which uses Restormer blocks to extract cross-modality shallow features and dual-branch Transformer-CNN feature extractor with Lite Transformer (LT) blocks and Invertible Neural Networks (INN) blocks to handle different spatial frequencies of features.", "example": "Convert the coordinate to text: [ 8.3906 -8.6643]:"}
{"text": "Convert the coordinate to text: [-10.7953   1.3502]: The authors propose a pipeline for generating knowledge graphs representing different NASA SMD domains to serve as the foundation for dataset search engines, thereby aiding researchers in saving time and discovering new connections.", "target": "The authors propose a pipeline for generating knowledge graphs representing different NASA SMD domains to serve as the foundation for dataset search engines, thereby aiding researchers in saving time and discovering new connections.", "example": "Convert the coordinate to text: [-10.7953   1.3502]:"}
{"text": "Convert the coordinate to text: [-2.9386 -4.8968]: This paper introduces the concept of the 'belief conflict' in LLMs and attributes it to statistical shortcuts and negation reporting bias from language modeling pre-training, based on the models' relative proficiency in answering Boolean questions compared to constructing sentences with negative commonsense knowledge.", "target": "This paper introduces the concept of the 'belief conflict' in LLMs and attributes it to statistical shortcuts and negation reporting bias from language modeling pre-training, based on the models' relative proficiency in answering Boolean questions compared to constructing sentences with negative commonsense knowledge.", "example": "Convert the coordinate to text: [-2.9386 -4.8968]:"}
{"text": "Convert the coordinate to text: [ 2.3646 -6.3647]: The authors propose a memory model that performs rehearsal and anticipation while processing inputs to enhance memorization of important information, specifically for question answering tasks from streaming data. These mechanisms are self-applied during training through masked modeling tasks that focus on coreference information.", "target": "The authors propose a memory model that performs rehearsal and anticipation while processing inputs to enhance memorization of important information, specifically for question answering tasks from streaming data. These mechanisms are self-applied during training through masked modeling tasks that focus on coreference information.", "example": "Convert the coordinate to text: [ 2.3646 -6.3647]:"}
{"text": "Convert the coordinate to text: [ 5.5362 -1.808 ]: This study aims to address the wastage of outdated adapted weights by introducing the notion of recyclable tuning for continual pre-training, proposing both an initialization-based method and a distillation-based method for the task.", "target": "This study aims to address the wastage of outdated adapted weights by introducing the notion of recyclable tuning for continual pre-training, proposing both an initialization-based method and a distillation-based method for the task.", "example": "Convert the coordinate to text: [ 5.5362 -1.808 ]:"}
{"text": "Convert the coordinate to text: [12.9362  3.2098]: The authors propose Dash, an efficient and accurate method for PARAFAC2 decomposition that operates in a dual-way streaming setting. Dash works by carefully dividing terms related to old and new data to avoid unnecessary computations tied to old data. Applying a forgetting factor allows Dash to keep up with recent movements.", "target": "The authors propose Dash, an efficient and accurate method for PARAFAC2 decomposition that operates in a dual-way streaming setting. Dash works by carefully dividing terms related to old and new data to avoid unnecessary computations tied to old data. Applying a forgetting factor allows Dash to keep up with recent movements.", "example": "Convert the coordinate to text: [12.9362  3.2098]:"}
{"text": "Convert the coordinate to text: [ -0.3708 -10.116 ]: The authors propose a generative approach to the PAVI task, tweaking a pre-trained generative model, T5, to decode a set of attribute-value pairs as a target sequence from given product text, while considering ideas for composing an attribute-value pair and ordering the pairs for the task.", "target": "The authors propose a generative approach to the PAVI task, tweaking a pre-trained generative model, T5, to decode a set of attribute-value pairs as a target sequence from given product text, while considering ideas for composing an attribute-value pair and ordering the pairs for the task.", "example": "Convert the coordinate to text: [ -0.3708 -10.116 ]:"}
{"text": "Convert the coordinate to text: [-2.2689 -4.963 ]: The authors present a human-in-the-loop dashboard that enables users to generate diverse and challenging examples by drawing inspiration from GPT-3 suggestions and receive feedback from a trained NLI model to diagnose potential spurious features impacting NLI model reasoning.", "target": "The authors present a human-in-the-loop dashboard that enables users to generate diverse and challenging examples by drawing inspiration from GPT-3 suggestions and receive feedback from a trained NLI model to diagnose potential spurious features impacting NLI model reasoning.", "example": "Convert the coordinate to text: [-2.2689 -4.963 ]:"}
{"text": "Convert the coordinate to text: [-7.6421 -2.7524]: This study presents an initiative to generate tongue twisters by creating TwistList, a large annotated dataset of over 2.1K human-authored tongue twisters, and by proposing several benchmark models, or TwisterMisters, for the task.", "target": "This study presents an initiative to generate tongue twisters by creating TwistList, a large annotated dataset of over 2.1K human-authored tongue twisters, and by proposing several benchmark models, or TwisterMisters, for the task.", "example": "Convert the coordinate to text: [-7.6421 -2.7524]:"}
{"text": "Convert the coordinate to text: [ 0.1574 -9.1416]: The authors have proposed a new approach for tackling the Visual-WSD task that leverages the CLIP model, prompt engineering, and text-to-image models such as GLIDE and DALL-E 2 for both image retrieval and generation.", "target": "The authors have proposed a new approach for tackling the Visual-WSD task that leverages the CLIP model, prompt engineering, and text-to-image models such as GLIDE and DALL-E 2 for both image retrieval and generation.", "example": "Convert the coordinate to text: [ 0.1574 -9.1416]:"}
{"text": "Convert the coordinate to text: [-5.2322  1.2628]: A system is proposed that uses stance as an output instead to identify 20 human values from given arguments, testing the hypothesis if predicting stance would better assist in predicting the given human values.", "target": "A system is proposed that uses stance as an output instead to identify 20 human values from given arguments, testing the hypothesis if predicting stance would better assist in predicting the given human values.", "example": "Convert the coordinate to text: [-5.2322  1.2628]:"}
{"text": "Convert the coordinate to text: [-2.338  -6.5457]: The authors propose a solution to SemEval 2023 task 9 via a transfer learning approach that involves fine-tuning various pre-trained language models, implementing oversampling and undersampling techniques on an imbalanced dataset to gain higher prediction accuracy.", "target": "The authors propose a solution to SemEval 2023 task 9 via a transfer learning approach that involves fine-tuning various pre-trained language models, implementing oversampling and undersampling techniques on an imbalanced dataset to gain higher prediction accuracy.", "example": "Convert the coordinate to text: [-2.338  -6.5457]:"}
{"text": "Convert the coordinate to text: [-7.9727 -1.0453]: The authors propose a novel technique for automated scoring of MPT items that leverages highly structured rubrics, aiming to provide explainable scoring.", "target": "The authors propose a novel technique for automated scoring of MPT items that leverages highly structured rubrics, aiming to provide explainable scoring.", "example": "Convert the coordinate to text: [-7.9727 -1.0453]:"}
{"text": "Convert the coordinate to text: [-1.338  -6.4608]: The authors propose a framework called Bi-level Finetuning with Task-dependent Similarity Structure (BFTSS) which finetunes all parameters, including embeddings for unseen tokens, with task-dependent information from the training data only. They propose a bi-level optimization algorithm with a data-driven, task-dependent similarity structure.", "target": "The authors propose a framework called Bi-level Finetuning with Task-dependent Similarity Structure (BFTSS) which finetunes all parameters, including embeddings for unseen tokens, with task-dependent information from the training data only. They propose a bi-level optimization algorithm with a data-driven, task-dependent similarity structure.", "example": "Convert the coordinate to text: [-1.338  -6.4608]:"}
{"text": "Convert the coordinate to text: [-10.6313  -1.6136]: The authors propose the idea of leveraging the inherent question-answering (QA) component of meeting discussions and introduce MeetingQA, an extractive QA dataset consisting of questions asked by meeting participants and corresponding responses.", "target": "The authors propose the idea of leveraging the inherent question-answering (QA) component of meeting discussions and introduce MeetingQA, an extractive QA dataset consisting of questions asked by meeting participants and corresponding responses.", "example": "Convert the coordinate to text: [-10.6313  -1.6136]:"}
{"text": "Convert the coordinate to text: [-5.8533  0.74  ]: The authors propose a new large-scale dataset, ArgAnalysis35K, based on extensive Parliamentary Debating experience. It includes a wide range of topics and sources, and has high-quality argument-analysis pairs. They also introduce an innovative argument scoring system based on instance-level annotator reliability and propose a quantitative model of scoring the relevance of arguments to a range of topics.", "target": "The authors propose a new large-scale dataset, ArgAnalysis35K, based on extensive Parliamentary Debating experience. It includes a wide range of topics and sources, and has high-quality argument-analysis pairs. They also introduce an innovative argument scoring system based on instance-level annotator reliability and propose a quantitative model of scoring the relevance of arguments to a range of topics.", "example": "Convert the coordinate to text: [-5.8533  0.74  ]:"}
{"text": "Convert the coordinate to text: [ 3.2568 -6.5439]: The paper introduces Dual Graph ATtention networks (DualGATs) to concurrently consider the complementary aspects of discourse structure and speaker-aware context, aiming for more precise emotion recognition in conversations.", "target": "The paper introduces Dual Graph ATtention networks (DualGATs) to concurrently consider the complementary aspects of discourse structure and speaker-aware context, aiming for more precise emotion recognition in conversations.", "example": "Convert the coordinate to text: [ 3.2568 -6.5439]:"}
{"text": "Convert the coordinate to text: [-4.2218 -7.4555]: A novel approach is proposed to automatically generate distractors for cloze exercises using round-trip neural machine translation. A sentence is translated from English into a pivot language and then back to English, with distractors created by aligning the original sentence with its translated version.", "target": "A novel approach is proposed to automatically generate distractors for cloze exercises using round-trip neural machine translation. A sentence is translated from English into a pivot language and then back to English, with distractors created by aligning the original sentence with its translated version.", "example": "Convert the coordinate to text: [-4.2218 -7.4555]:"}
{"text": "Convert the coordinate to text: [-5.0182  2.1652]: The authors conduct an in-the-wild audit of multiple datasets for COVID-19 misinformation detection, demonstrating that models trained with several prominently cited recent datasets are susceptible to anticontent. They also propose a novel active learning pipeline that requires zero manual annotation and iteratively augments the training data with challenging anticontent to improve the robustness of these classifiers.", "target": "The authors conduct an in-the-wild audit of multiple datasets for COVID-19 misinformation detection, demonstrating that models trained with several prominently cited recent datasets are susceptible to anticontent. They also propose a novel active learning pipeline that requires zero manual annotation and iteratively augments the training data with challenging anticontent to improve the robustness of these classifiers.", "example": "Convert the coordinate to text: [-5.0182  2.1652]:"}
{"text": "Convert the coordinate to text: [ 6.6035 -2.5572]: This paper sets out to develop practical MIAs against large-scale multi-modal models. The authors introduce a simple baseline strategy by thresholding the cosine similarity between text and image features of a target point. They propose enhancing the baseline by aggregating cosine similarity across transformations of the target. They also present a new weakly supervised attack method that uses ground-truth non-members to further enhance the attack.", "target": "This paper sets out to develop practical MIAs against large-scale multi-modal models. The authors introduce a simple baseline strategy by thresholding the cosine similarity between text and image features of a target point. They propose enhancing the baseline by aggregating cosine similarity across transformations of the target. They also present a new weakly supervised attack method that uses ground-truth non-members to further enhance the attack.", "example": "Convert the coordinate to text: [ 6.6035 -2.5572]:"}
{"text": "Convert the coordinate to text: [ 7.434 -2.22 ]: The authors propose a global model that injects personalized prior knowledge into each client model to mitigate problems related to overlooked client-specific information in PFL.", "target": "The authors propose a global model that injects personalized prior knowledge into each client model to mitigate problems related to overlooked client-specific information in PFL.", "example": "Convert the coordinate to text: [ 7.434 -2.22 ]:"}
{"text": "Convert the coordinate to text: [ 4.3009 -0.8365]: The authors propose a novel method for instance-dependent PLL, that takes into account a latent label distribution constituted by the real number of each label, representing the degree to which each label describes the feature. They suggest that the latent label distribution is important labelling information in partially labeled examples and should be incorporated into predictive model training.", "target": "The authors propose a novel method for instance-dependent PLL, that takes into account a latent label distribution constituted by the real number of each label, representing the degree to which each label describes the feature. They suggest that the latent label distribution is important labelling information in partially labeled examples and should be incorporated into predictive model training.", "example": "Convert the coordinate to text: [ 4.3009 -0.8365]:"}
{"text": "Convert the coordinate to text: [-8.8097 13.5444]: The authors introduce CatHill, an interactive storytelling game that leverages Cognitive Behavioral Therapy (CBT) techniques and an innovative mouth-focused interface for college students experiencing mental health issues.", "target": "The authors introduce CatHill, an interactive storytelling game that leverages Cognitive Behavioral Therapy (CBT) techniques and an innovative mouth-focused interface for college students experiencing mental health issues.", "example": "Convert the coordinate to text: [-8.8097 13.5444]:"}
{"text": "Convert the coordinate to text: [-0.6246 -5.1551]: The paper introduces the concept of combining gradient descent with black-box tuning through knowledge distillation. It also proposes a novel method, GDFO, that harmonizes gradient descent and derivative-free optimization for optimizing task-specific continuous prompts.", "target": "The paper introduces the concept of combining gradient descent with black-box tuning through knowledge distillation. It also proposes a novel method, GDFO, that harmonizes gradient descent and derivative-free optimization for optimizing task-specific continuous prompts.", "example": "Convert the coordinate to text: [-0.6246 -5.1551]:"}
{"text": "Convert the coordinate to text: [-1.4442 -4.0943]: This study proposes a retrieval-enhanced framework, ReGen, to create training data with two strategies, Verbalizer Augmentation with Demonstrations and Self-consistency Guided Filtering, from general-domain unlabeled corpora by first conducting contrastive pretraining to learn an unsupervised dense retriever.", "target": "This study proposes a retrieval-enhanced framework, ReGen, to create training data with two strategies, Verbalizer Augmentation with Demonstrations and Self-consistency Guided Filtering, from general-domain unlabeled corpora by first conducting contrastive pretraining to learn an unsupervised dense retriever.", "example": "Convert the coordinate to text: [-1.4442 -4.0943]:"}
{"text": "Convert the coordinate to text: [-4.0123 -3.3293]: The authors propose a new method for EA, turning it into a bi-directional textual entailment task. They do this by transforming both relational and attribute triples into unified textual sequences and inputting these sequences into a pre-trained language model.", "target": "The authors propose a new method for EA, turning it into a bi-directional textual entailment task. They do this by transforming both relational and attribute triples into unified textual sequences and inputting these sequences into a pre-trained language model.", "example": "Convert the coordinate to text: [-4.0123 -3.3293]:"}
{"text": "Convert the coordinate to text: [-0.7752 -6.9059]: This study focuses on investigating the inner workings of the prediction head in Transformer language models, particularly on bias parameters. The study identifies that biases in word prediction heads play a significant role in the models' ability to reflect word frequency in a corpus.", "target": "This study focuses on investigating the inner workings of the prediction head in Transformer language models, particularly on bias parameters. The study identifies that biases in word prediction heads play a significant role in the models' ability to reflect word frequency in a corpus.", "example": "Convert the coordinate to text: [-0.7752 -6.9059]:"}
{"text": "Convert the coordinate to text: [-11.542  -1.152]: The authors introduce UKP-SQuARE, an interactive platform for QA education. This platform provides an environment where students can run, compare, and analyze various QA models from different perspectives, encouraging proactive learning through interactive exploration, experimentation, and practical assignments.", "target": "The authors introduce UKP-SQuARE, an interactive platform for QA education. This platform provides an environment where students can run, compare, and analyze various QA models from different perspectives, encouraging proactive learning through interactive exploration, experimentation, and practical assignments.", "example": "Convert the coordinate to text: [-11.542  -1.152]:"}
{"text": "Convert the coordinate to text: [-4.1683  0.5313]: This paper proposes an Aspect-oriented Method (AoM) to detect aspect-relevant semantic and sentiment information. AoM uses an aspect-aware attention module to select related textual tokens and image blocks and introduces sentiment embedding to aggregate sentiment information while modeling vision-text and text-text interactions via a graph convolutional network.", "target": "This paper proposes an Aspect-oriented Method (AoM) to detect aspect-relevant semantic and sentiment information. AoM uses an aspect-aware attention module to select related textual tokens and image blocks and introduces sentiment embedding to aggregate sentiment information while modeling vision-text and text-text interactions via a graph convolutional network.", "example": "Convert the coordinate to text: [-4.1683  0.5313]:"}
{"text": "Convert the coordinate to text: [ 9.3962 11.8179]: This work proposes the use of a strategy that tackles the challenge of heavy-tailed rewards in reinforcement learning with linear function approximation by developing a new algorithm, Heavy-OFUL, for heavy-tailed linear bandits, and extending it to the RL settings with linear function approximation through a proposed algorithm termed as Heavy-LSVI-UCB.", "target": "This work proposes the use of a strategy that tackles the challenge of heavy-tailed rewards in reinforcement learning with linear function approximation by developing a new algorithm, Heavy-OFUL, for heavy-tailed linear bandits, and extending it to the RL settings with linear function approximation through a proposed algorithm termed as Heavy-LSVI-UCB.", "example": "Convert the coordinate to text: [ 9.3962 11.8179]:"}
{"text": "Convert the coordinate to text: [-5.7522 11.8631]: The authors created the first shared task to measure the quality of responses generated by AI acting as teachers in an educational dialogue scenario.", "target": "The authors created the first shared task to measure the quality of responses generated by AI acting as teachers in an educational dialogue scenario.", "example": "Convert the coordinate to text: [-5.7522 11.8631]:"}
{"text": "Convert the coordinate to text: [-4.2869  2.665 ]: The authors propose ERRA (Explainable Recommendation by personalized Review retrieval and Aspect learning), a novel model that obtains additional information from the training sets for more accurate and informative explanation generation. The model incorporates an aspect enhancement component to better capture users' preferences.", "target": "The authors propose ERRA (Explainable Recommendation by personalized Review retrieval and Aspect learning), a novel model that obtains additional information from the training sets for more accurate and informative explanation generation. The model incorporates an aspect enhancement component to better capture users' preferences.", "example": "Convert the coordinate to text: [-4.2869  2.665 ]:"}
{"text": "Convert the coordinate to text: [-9.1847 -4.4302]: The authors survey different strategies for handling syntax dependencies in mathematical expressions and propose that mathematical expressions should be analyzed as a form of natural language, with guidelines for treating basic mathematical expressions analogous to English natural language.", "target": "The authors survey different strategies for handling syntax dependencies in mathematical expressions and propose that mathematical expressions should be analyzed as a form of natural language, with guidelines for treating basic mathematical expressions analogous to English natural language.", "example": "Convert the coordinate to text: [-9.1847 -4.4302]:"}
{"text": "Convert the coordinate to text: [-0.8933 -6.5296]: The authors proposed a solution which utilizes transfer learning from pre-trained transformer models and fine-tunes them on the MIMIC-III dataset for the task of abstractive report summarization.", "target": "The authors proposed a solution which utilizes transfer learning from pre-trained transformer models and fine-tunes them on the MIMIC-III dataset for the task of abstractive report summarization.", "example": "Convert the coordinate to text: [-0.8933 -6.5296]:"}
{"text": "Convert the coordinate to text: [0.5942 1.3395]: The authors propose a novel debiasing method from a counterfactual viewpoint called CLEVER, which is augmentation-free and mitigates biases at the inference stage. It involves training two models independently - a claim-evidence fusion model and a claim-only model - and then subtracting the output of the claim-only model from the output of the claim-evidence fusion model to counteract biases.", "target": "The authors propose a novel debiasing method from a counterfactual viewpoint called CLEVER, which is augmentation-free and mitigates biases at the inference stage. It involves training two models independently - a claim-evidence fusion model and a claim-only model - and then subtracting the output of the claim-only model from the output of the claim-evidence fusion model to counteract biases.", "example": "Convert the coordinate to text: [0.5942 1.3395]:"}
{"text": "Convert the coordinate to text: [13.092  -4.6858]: The authors propose a gradient control method to consolidate the attack effect of backdoor attacks in PET. This method comprises two strategies: one that controls the gradient magnitude distribution across layers within one task, and another that prevents the conflict of gradient directions between tasks.", "target": "The authors propose a gradient control method to consolidate the attack effect of backdoor attacks in PET. This method comprises two strategies: one that controls the gradient magnitude distribution across layers within one task, and another that prevents the conflict of gradient directions between tasks.", "example": "Convert the coordinate to text: [13.092  -4.6858]:"}
{"text": "Convert the coordinate to text: [-4.7729 -4.5412]: This study explores how the prototypicality of event participants affects the ability of Language Models (LMs) to handle elliptical sentences and to identify the omitted arguments at different degrees of thematic fit.", "target": "This study explores how the prototypicality of event participants affects the ability of Language Models (LMs) to handle elliptical sentences and to identify the omitted arguments at different degrees of thematic fit.", "example": "Convert the coordinate to text: [-4.7729 -4.5412]:"}
{"text": "Convert the coordinate to text: [ 6.4957 13.2652]: This paper proposes a method that uses reinforcement learning to search for an optimal sampling schedule for DPMs by utilizing a policy network to predict the next step based on the current state of the noisy image.", "target": "This paper proposes a method that uses reinforcement learning to search for an optimal sampling schedule for DPMs by utilizing a policy network to predict the next step based on the current state of the noisy image.", "example": "Convert the coordinate to text: [ 6.4957 13.2652]:"}
{"text": "Convert the coordinate to text: [-17.2474   1.8634]: The paper proposes PolarDB-SCC (PolarDB-Strongly Consistent Cluster), a new cloud-native database architecture that ensures strongly consistent reads with very low latency. The key idea is to eliminate unnecessary waits and reduce the necessary wait time on RO nodes while still supporting strong consistency, by tracking the RW node's modification timestamp at three progressively finer-grained levels.", "target": "The paper proposes PolarDB-SCC (PolarDB-Strongly Consistent Cluster), a new cloud-native database architecture that ensures strongly consistent reads with very low latency. The key idea is to eliminate unnecessary waits and reduce the necessary wait time on RO nodes while still supporting strong consistency, by tracking the RW node's modification timestamp at three progressively finer-grained levels.", "example": "Convert the coordinate to text: [-17.2474   1.8634]:"}
{"text": "Convert the coordinate to text: [ 13.0919 -16.1608]: The authors introduce Gaussian Attention (GA) into optical flow models to highlight local properties during representation learning and enforce motion affinity during matching. They propose a new Gaussian-Constrained Layer (GCL) and a Gaussian-Guided Attention Module (GGAM) for reliable motion analysis.", "target": "The authors introduce Gaussian Attention (GA) into optical flow models to highlight local properties during representation learning and enforce motion affinity during matching. They propose a new Gaussian-Constrained Layer (GCL) and a Gaussian-Guided Attention Module (GGAM) for reliable motion analysis.", "example": "Convert the coordinate to text: [ 13.0919 -16.1608]:"}
{"text": "Convert the coordinate to text: [ 9.6978 12.1041]: The authors propose to track the contributions of individual modules by recording the loss decrement after distillation each module and choose the module with a greater contribution to distill more frequently. This approach can be naturally formulated as a multi-armed bandit (MAB) problem, where modules and loss decrements are considered as arms and rewards.", "target": "The authors propose to track the contributions of individual modules by recording the loss decrement after distillation each module and choose the module with a greater contribution to distill more frequently. This approach can be naturally formulated as a multi-armed bandit (MAB) problem, where modules and loss decrements are considered as arms and rewards.", "example": "Convert the coordinate to text: [ 9.6978 12.1041]:"}
{"text": "Convert the coordinate to text: [16.1931  1.7781]: This paper investigates balancing performance between IID and OOD scenarios, proposing a novel Model Agnostic adaPters (MAP) method that incorporates the inductive bias of IID into OOD methods using auxiliary adapter layers.", "target": "This paper investigates balancing performance between IID and OOD scenarios, proposing a novel Model Agnostic adaPters (MAP) method that incorporates the inductive bias of IID into OOD methods using auxiliary adapter layers.", "example": "Convert the coordinate to text: [16.1931  1.7781]:"}
{"text": "Convert the coordinate to text: [ 9.5202 -2.973 ]: The authors introduce Characteristic Circuits (CCs), a new family of tractable probabilistic models that provides a unified formalization of distributions over heterogeneous data in the spectral domain, facilitating efficient probabilistic inference even when no closed-form density function is available.", "target": "The authors introduce Characteristic Circuits (CCs), a new family of tractable probabilistic models that provides a unified formalization of distributions over heterogeneous data in the spectral domain, facilitating efficient probabilistic inference even when no closed-form density function is available.", "example": "Convert the coordinate to text: [ 9.5202 -2.973 ]:"}
{"text": "Convert the coordinate to text: [6.4596 9.5661]: The paper introduces a novel approach for modeling the entire Pareto set using neural networks and establishes an equivalence between learning the complete Pareto set and maximizing the associated hypervolume.", "target": "The paper introduces a novel approach for modeling the entire Pareto set using neural networks and establishes an equivalence between learning the complete Pareto set and maximizing the associated hypervolume.", "example": "Convert the coordinate to text: [6.4596 9.5661]:"}
{"text": "Convert the coordinate to text: [14.5451  4.9145]: The authors introduce the Retrieval-AugMented MIL (RAM-MIL) framework, which integrates Optimal Transport (OT) as the distance metric for nearest neighbor retrieval. The development is driven by insights that reducing the input's intrinsic dimension can minimize the error in attention-based MIL, and there's a link between input intrinsic dimension and feature merging with retrieved data.", "target": "The authors introduce the Retrieval-AugMented MIL (RAM-MIL) framework, which integrates Optimal Transport (OT) as the distance metric for nearest neighbor retrieval. The development is driven by insights that reducing the input's intrinsic dimension can minimize the error in attention-based MIL, and there's a link between input intrinsic dimension and feature merging with retrieved data.", "example": "Convert the coordinate to text: [14.5451  4.9145]:"}
{"text": "Convert the coordinate to text: [ 3.6978 -3.9871]: The authors propose an All-In-One Knowledge Distillation (AIO-KD) framework for NMT that provides multiple students in a single run, by extracting fewer-layer subnetworks and jointly optimizing them with a strategy for mutual learning.", "target": "The authors propose an All-In-One Knowledge Distillation (AIO-KD) framework for NMT that provides multiple students in a single run, by extracting fewer-layer subnetworks and jointly optimizing them with a strategy for mutual learning.", "example": "Convert the coordinate to text: [ 3.6978 -3.9871]:"}
{"text": "Convert the coordinate to text: [3.9632 2.4799]: Yggdrasil Decision Forests was developed to address this need, a library implemented in C++, aimed at training, serving and interpreting decision forest models, available through various different programming languages, and created with four main design principles; simplicity of use, safety of use, modularity and high-level abstraction, and integration with other machine learning libraries.", "target": "Yggdrasil Decision Forests was developed to address this need, a library implemented in C++, aimed at training, serving and interpreting decision forest models, available through various different programming languages, and created with four main design principles; simplicity of use, safety of use, modularity and high-level abstraction, and integration with other machine learning libraries.", "example": "Convert the coordinate to text: [3.9632 2.4799]:"}
{"text": "Convert the coordinate to text: [-12.2975  14.9041]: The study centered on generating recommendations for implementing specific haptic technologies in sound and video art exhibitions to enhance the museum experience for Deaf and Hard of Hearing patrons.", "target": "The study centered on generating recommendations for implementing specific haptic technologies in sound and video art exhibitions to enhance the museum experience for Deaf and Hard of Hearing patrons.", "example": "Convert the coordinate to text: [-12.2975  14.9041]:"}
{"text": "Convert the coordinate to text: [-4.9274 -8.5846]: This study tackles the problem of singability by recasting lyric translation as a constrained translation task. It applies theory and techniques from the field of translation studies to prompt-driven NMT approaches and employs better adaptation methods to create an English-Chinese lyric translation system.", "target": "This study tackles the problem of singability by recasting lyric translation as a constrained translation task. It applies theory and techniques from the field of translation studies to prompt-driven NMT approaches and employs better adaptation methods to create an English-Chinese lyric translation system.", "example": "Convert the coordinate to text: [-4.9274 -8.5846]:"}
{"text": "Convert the coordinate to text: [12.3039  7.7869]: The paper presents an analysis of second-order non-homogeneous PDEs, then introduces MultiAdam, a scale-invariant optimizer that leverages gradient momentum to balance the loss terms parameter-wisely.", "target": "The paper presents an analysis of second-order non-homogeneous PDEs, then introduces MultiAdam, a scale-invariant optimizer that leverages gradient momentum to balance the loss terms parameter-wisely.", "example": "Convert the coordinate to text: [12.3039  7.7869]:"}
{"text": "Convert the coordinate to text: [13.6051 -0.0883]: The paper introduces stabilized neural differential equations (SNDEs), a technique designed to enforce arbitrary manifold constraints for neural differential equations.", "target": "The paper introduces stabilized neural differential equations (SNDEs), a technique designed to enforce arbitrary manifold constraints for neural differential equations.", "example": "Convert the coordinate to text: [13.6051 -0.0883]:"}
{"text": "Convert the coordinate to text: [-2.4048  1.7798]: The authors propose the use of discernible patterns in how news events on the same topic appear over time to train a model that can adapt to future data. This led to the development of the Forecasting Temporal Trends (FTT) framework, which forecasts temporal distribution patterns of news data and helps the detector adapt to future distribution.", "target": "The authors propose the use of discernible patterns in how news events on the same topic appear over time to train a model that can adapt to future data. This led to the development of the Forecasting Temporal Trends (FTT) framework, which forecasts temporal distribution patterns of news data and helps the detector adapt to future distribution.", "example": "Convert the coordinate to text: [-2.4048  1.7798]:"}
{"text": "Convert the coordinate to text: [ 0.9599 -3.6133]: The authors propose to understand ICL via investigating the pretraining data. They introduce an iterative, gradient-based approach to pinpoint a small subset of the pretraining data supportive of ICL.", "target": "The authors propose to understand ICL via investigating the pretraining data. They introduce an iterative, gradient-based approach to pinpoint a small subset of the pretraining data supportive of ICL.", "example": "Convert the coordinate to text: [ 0.9599 -3.6133]:"}
{"text": "Convert the coordinate to text: [-4.4146 -7.8237]: The study compares the performance of three Machine Translation systems (Google, mBART-50 and M2M-100-big) in translating monolingual Vietnamese and Vietnamese-English code-switching and establishes a new benchmark analyzing the relationship between Machine translation and code-switching.", "target": "The study compares the performance of three Machine Translation systems (Google, mBART-50 and M2M-100-big) in translating monolingual Vietnamese and Vietnamese-English code-switching and establishes a new benchmark analyzing the relationship between Machine translation and code-switching.", "example": "Convert the coordinate to text: [-4.4146 -7.8237]:"}
{"text": "Convert the coordinate to text: [-1.1388 -8.2492]: Team e-Health CSIRO participated in the multimodal task and adapted an encoder-to-decoder model for CXR report generation to this subtask.", "target": "Team e-Health CSIRO participated in the multimodal task and adapted an encoder-to-decoder model for CXR report generation to this subtask.", "example": "Convert the coordinate to text: [-1.1388 -8.2492]:"}
{"text": "Convert the coordinate to text: [-7.6865 -0.7483]: The authors propose FARM, a novel framework that leverages external knowledge for trustworthy rationale generation in the context of safety. FARM focuses on missing knowledge to reason in specific scenarios and retrieves this information with attribution to trustworthy sources.", "target": "The authors propose FARM, a novel framework that leverages external knowledge for trustworthy rationale generation in the context of safety. FARM focuses on missing knowledge to reason in specific scenarios and retrieves this information with attribution to trustworthy sources.", "example": "Convert the coordinate to text: [-7.6865 -0.7483]:"}
{"text": "Convert the coordinate to text: [-6.9063 -6.7304]: The authors aim to automatically identify the functions of code-switching in Spanish-English speech by developing a new system and annotating a new dataset.", "target": "The authors aim to automatically identify the functions of code-switching in Spanish-English speech by developing a new system and annotating a new dataset.", "example": "Convert the coordinate to text: [-6.9063 -6.7304]:"}
{"text": "Convert the coordinate to text: [ 0.1114 -8.7495]: The authors propose FashionKLIP, an e-commerce knowledge-enhanced VLP model. The proposal includes the creation of a multi-modal conceptual knowledge graph from large-scale e-commerce image-text data, and the integration of this prior knowledge into the VLP model for cross-modal alignment at the conceptual level.", "target": "The authors propose FashionKLIP, an e-commerce knowledge-enhanced VLP model. The proposal includes the creation of a multi-modal conceptual knowledge graph from large-scale e-commerce image-text data, and the integration of this prior knowledge into the VLP model for cross-modal alignment at the conceptual level.", "example": "Convert the coordinate to text: [ 0.1114 -8.7495]:"}
{"text": "Convert the coordinate to text: [-2.4394 -6.1239]: The authors propose Unified Pre-training Architecture for Political Actor Modeling based on language (UPPAM), a new method of representing political actors by aggregating their statements and learning mappings from the language used to the actor representation. This is instead of learning the representation of specific individuals.", "target": "The authors propose Unified Pre-training Architecture for Political Actor Modeling based on language (UPPAM), a new method of representing political actors by aggregating their statements and learning mappings from the language used to the actor representation. This is instead of learning the representation of specific individuals.", "example": "Convert the coordinate to text: [-2.4394 -6.1239]:"}
{"text": "Convert the coordinate to text: [-5.8902 -0.6615]: The authors propose a two-stage framework called SIMSUM for automated document-level text simplification, designed with explicit summarization and simplification models that guide the generation using the main keywords of a source text.", "target": "The authors propose a two-stage framework called SIMSUM for automated document-level text simplification, designed with explicit summarization and simplification models that guide the generation using the main keywords of a source text.", "example": "Convert the coordinate to text: [-5.8902 -0.6615]:"}
{"text": "Convert the coordinate to text: [ 6.8445 13.7785]: The study progresses this area by studying the smooth Q-Learning dynamics, revealing that exploration by agents results in the convergence of Q-Learning to a neighborhood of an equilibrium.", "target": "The study progresses this area by studying the smooth Q-Learning dynamics, revealing that exploration by agents results in the convergence of Q-Learning to a neighborhood of an equilibrium.", "example": "Convert the coordinate to text: [ 6.8445 13.7785]:"}
{"text": "Convert the coordinate to text: [-2.6867 -4.28  ]: The authors propose SparseEmbed, a first-stage retrieval model that combines the strengths of both sparse and dense representations. This new model is designed to learn sparse lexical representations with contextual embeddings.", "target": "The authors propose SparseEmbed, a first-stage retrieval model that combines the strengths of both sparse and dense representations. This new model is designed to learn sparse lexical representations with contextual embeddings.", "example": "Convert the coordinate to text: [-2.6867 -4.28  ]:"}
{"text": "Convert the coordinate to text: [  4.5306 -14.7439]: The authors present a new method called AnimeInbet, which transforms raster line drawings into graphs of endpoints and reframes the inbetweening process as a graph fusion problem with vertex repositioning, capturing the sparsity and unique structure of line drawings while preserving the details during inbetweening.", "target": "The authors present a new method called AnimeInbet, which transforms raster line drawings into graphs of endpoints and reframes the inbetweening process as a graph fusion problem with vertex repositioning, capturing the sparsity and unique structure of line drawings while preserving the details during inbetweening.", "example": "Convert the coordinate to text: [  4.5306 -14.7439]:"}
{"text": "Convert the coordinate to text: [ 2.1198 -4.4433]: This paper proposes Cross-modality Aligned Prototypes (CAPro), a unified prototypical contrastive learning framework that leverages textual prototypes from the distinct concept definition of classes to select clean images via text matching and disambiguate the formation of visual prototypes. The framework also works to complete and enhance individual texts through the visual feature space.", "target": "This paper proposes Cross-modality Aligned Prototypes (CAPro), a unified prototypical contrastive learning framework that leverages textual prototypes from the distinct concept definition of classes to select clean images via text matching and disambiguate the formation of visual prototypes. The framework also works to complete and enhance individual texts through the visual feature space.", "example": "Convert the coordinate to text: [ 2.1198 -4.4433]:"}
{"text": "Convert the coordinate to text: [13.9884  0.0475]: The paper delves into deep equilibrium model (DEQ), an infinite-layer neural network with shared weight matrices across layers. The authors establish that as the width of DEQ layers approaches infinity, it converges to a Gaussian process, achieving what is termed as the Neural Network and Gaussian Process (NNGP) correspondence.", "target": "The paper delves into deep equilibrium model (DEQ), an infinite-layer neural network with shared weight matrices across layers. The authors establish that as the width of DEQ layers approaches infinity, it converges to a Gaussian process, achieving what is termed as the Neural Network and Gaussian Process (NNGP) correspondence.", "example": "Convert the coordinate to text: [13.9884  0.0475]:"}
{"text": "Convert the coordinate to text: [  9.5881 -16.3646]: To resolve these issues, the authors propose learning neural implicit representations from multi-view RGBD images through volume rendering with a new feature called 'attentive depth fusion prior'. This feature enables neural networks to perceive coarse 3D structures from the Truncated Signed Distance Function (TSDF) fused from all available depth images.", "target": "To resolve these issues, the authors propose learning neural implicit representations from multi-view RGBD images through volume rendering with a new feature called 'attentive depth fusion prior'. This feature enables neural networks to perceive coarse 3D structures from the Truncated Signed Distance Function (TSDF) fused from all available depth images.", "example": "Convert the coordinate to text: [  9.5881 -16.3646]:"}
{"text": "Convert the coordinate to text: [ 7.1212 -4.2597]: The authors introduce the graph spectral alignment (SPA) framework, which addresses the inter-domain and intra-domain tradeoff in UDA. The framework treats the domain adaptation problem as a graph problem and uses a coarse graph alignment mechanism with a novel spectral regularizer, and a fine-grained message propagation module for enhanced discriminability in the target domain.", "target": "The authors introduce the graph spectral alignment (SPA) framework, which addresses the inter-domain and intra-domain tradeoff in UDA. The framework treats the domain adaptation problem as a graph problem and uses a coarse graph alignment mechanism with a novel spectral regularizer, and a fine-grained message propagation module for enhanced discriminability in the target domain.", "example": "Convert the coordinate to text: [ 7.1212 -4.2597]:"}
{"text": "Convert the coordinate to text: [14.4407 -2.3387]: The authors propose a microcircuit model and Hebbian learning rule within an adaptive control theory framework, assuming errors are encoded in top-down dis-inhibitory synaptic afferents. This helps resolve the discrepancy in the problem of credit assignment.", "target": "The authors propose a microcircuit model and Hebbian learning rule within an adaptive control theory framework, assuming errors are encoded in top-down dis-inhibitory synaptic afferents. This helps resolve the discrepancy in the problem of credit assignment.", "example": "Convert the coordinate to text: [14.4407 -2.3387]:"}
{"text": "Convert the coordinate to text: [10.4657  7.9702]: The authors propose an online convex optimization approach with adaptivity on both high and lower levels and novel ingredients such as a carefully designed optimism able to unify diverse function types, and cascaded corrections for algorithmic stability.", "target": "The authors propose an online convex optimization approach with adaptivity on both high and lower levels and novel ingredients such as a carefully designed optimism able to unify diverse function types, and cascaded corrections for algorithmic stability.", "example": "Convert the coordinate to text: [10.4657  7.9702]:"}
{"text": "Convert the coordinate to text: [11.6077 -2.0921]: The authors propose a unique explicit penalty that mirrors the implicit bias in deep network, which only acts when certain adaptive gradient optimizers like Adam are used. This combination enables a one-layer network to achieve low-rank approximations with an error rate comparable to those of deep linear networks, making depth no longer a necessity for learning.", "target": "The authors propose a unique explicit penalty that mirrors the implicit bias in deep network, which only acts when certain adaptive gradient optimizers like Adam are used. This combination enables a one-layer network to achieve low-rank approximations with an error rate comparable to those of deep linear networks, making depth no longer a necessity for learning.", "example": "Convert the coordinate to text: [11.6077 -2.0921]:"}
{"text": "Convert the coordinate to text: [10.5638 -6.9016]: The authors propose NUWA-XL, a novel Diffusion over Diffusion architecture for long video generation that uses a 'coarse-to-fine' process instead of sequential generation, allowing for parallel generation at the same granularity.", "target": "The authors propose NUWA-XL, a novel Diffusion over Diffusion architecture for long video generation that uses a 'coarse-to-fine' process instead of sequential generation, allowing for parallel generation at the same granularity.", "example": "Convert the coordinate to text: [10.5638 -6.9016]:"}
{"text": "Convert the coordinate to text: [-11.0441   6.8066]: The study attempts to provide empirical evidence on the influence of the number of researchers and data type on the qualitative coding process by replicating and extending a previous study, and having a number of students and researchers analyze the data.", "target": "The study attempts to provide empirical evidence on the influence of the number of researchers and data type on the qualitative coding process by replicating and extending a previous study, and having a number of students and researchers analyze the data.", "example": "Convert the coordinate to text: [-11.0441   6.8066]:"}
{"text": "Convert the coordinate to text: [-2.7073 -6.8396]: The authors propose to tackle this problem by leveraging back-translation as data augmentation strategies along with multi-lingual transformer models for detecting persuasion techniques.", "target": "The authors propose to tackle this problem by leveraging back-translation as data augmentation strategies along with multi-lingual transformer models for detecting persuasion techniques.", "example": "Convert the coordinate to text: [-2.7073 -6.8396]:"}
{"text": "Convert the coordinate to text: [-2.144 -5.019]: The authors critically evaluate the claims of superhuman abilities by PLMs and question what the current benchmarks are truly evaluating.", "target": "The authors critically evaluate the claims of superhuman abilities by PLMs and question what the current benchmarks are truly evaluating.", "example": "Convert the coordinate to text: [-2.144 -5.019]:"}
{"text": "Convert the coordinate to text: [  1.1293 -10.1538]: The authors propose to use a small number of aligned image-text pairs as anchors, and represent each unaligned image and text by its similarities to these anchors, hence creating relative representations. They develop a WVLP framework named RELIT that retrieves and generates high-quality weakly-aligned image-text pairs from large-scale image-only and text-only data using relative representation.", "target": "The authors propose to use a small number of aligned image-text pairs as anchors, and represent each unaligned image and text by its similarities to these anchors, hence creating relative representations. They develop a WVLP framework named RELIT that retrieves and generates high-quality weakly-aligned image-text pairs from large-scale image-only and text-only data using relative representation.", "example": "Convert the coordinate to text: [  1.1293 -10.1538]:"}
{"text": "Convert the coordinate to text: [ 3.0734 -4.0311]: The paper proposes Cross-Lingual Knowledge Distillation (CLKD), a method to train AS2 models for low-resource languages without the need of labeled data for the target language, by distilling knowledge from a strong English AS2 model.", "target": "The paper proposes Cross-Lingual Knowledge Distillation (CLKD), a method to train AS2 models for low-resource languages without the need of labeled data for the target language, by distilling knowledge from a strong English AS2 model.", "example": "Convert the coordinate to text: [ 3.0734 -4.0311]:"}
{"text": "Convert the coordinate to text: [ 7.7159 13.0041]: By viewing the TD learning algorithm through the lens of optimization, the authors argue that TD can be seen as an iterative optimization algorithm, where the function to be minimized changes per iteration, and that the convergence or divergence behavior of the algorithm is determined by two identified forces.", "target": "By viewing the TD learning algorithm through the lens of optimization, the authors argue that TD can be seen as an iterative optimization algorithm, where the function to be minimized changes per iteration, and that the convergence or divergence behavior of the algorithm is determined by two identified forces.", "example": "Convert the coordinate to text: [ 7.7159 13.0041]:"}
{"text": "Convert the coordinate to text: [-4.872  -0.2715]: The authors propose a class-token attention-based model specifically for SemEval 2023 Task 4, which focuses on human value detection within argumentative texts.", "target": "The authors propose a class-token attention-based model specifically for SemEval 2023 Task 4, which focuses on human value detection within argumentative texts.", "example": "Convert the coordinate to text: [-4.872  -0.2715]:"}
{"text": "Convert the coordinate to text: [-3.2513 -6.1501]: Team Minanto fine-tuned a cross-lingual model for Named Entity Recognition (NER) on English data, experimenting with a monolingual model and input of external data from earlier NER tasks.", "target": "Team Minanto fine-tuned a cross-lingual model for Named Entity Recognition (NER) on English data, experimenting with a monolingual model and input of external data from earlier NER tasks.", "example": "Convert the coordinate to text: [-3.2513 -6.1501]:"}
{"text": "Convert the coordinate to text: [-3.7375 -9.0426]: The authors reveal the structure of their system submitted to the IWSLT 2023 multilingual speech translation track featuring a CNN and Transformer. They also pre-train encoder parameters using speech recognition tasks and further train the multilingual speech translation model using a speech translation corpus.", "target": "The authors reveal the structure of their system submitted to the IWSLT 2023 multilingual speech translation track featuring a CNN and Transformer. They also pre-train encoder parameters using speech recognition tasks and further train the multilingual speech translation model using a speech translation corpus.", "example": "Convert the coordinate to text: [-3.7375 -9.0426]:"}
{"text": "Convert the coordinate to text: [-10.2331  -3.3626]: Effidit is introduced as a digital writing assistant that uses AI and NLP technologies to facilitate users in creating high-quality text more efficiently through three modules: text completion, hint recommendation, and writing refinement.", "target": "Effidit is introduced as a digital writing assistant that uses AI and NLP technologies to facilitate users in creating high-quality text more efficiently through three modules: text completion, hint recommendation, and writing refinement.", "example": "Convert the coordinate to text: [-10.2331  -3.3626]:"}
{"text": "Convert the coordinate to text: [-2.1081 -3.4439]: The authors propose a novel DECI model, SENDIR, which does not require any prior knowledge. The basic idea is to discriminate event pairs in the same sentence or span multiple sentences by assuming their different information density.", "target": "The authors propose a novel DECI model, SENDIR, which does not require any prior knowledge. The basic idea is to discriminate event pairs in the same sentence or span multiple sentences by assuming their different information density.", "example": "Convert the coordinate to text: [-2.1081 -3.4439]:"}
{"text": "Convert the coordinate to text: [ 1.341 -7.566]: The authors introduce multitasking vision transformer adapters that learn generalizable task affinities applicable to novel tasks and domains, and an integrated task-adapted attention mechanism in their framework to coincide gradient-based task similarities with attention-based ones.", "target": "The authors introduce multitasking vision transformer adapters that learn generalizable task affinities applicable to novel tasks and domains, and an integrated task-adapted attention mechanism in their framework to coincide gradient-based task similarities with attention-based ones.", "example": "Convert the coordinate to text: [ 1.341 -7.566]:"}
{"text": "Convert the coordinate to text: [0.9409 3.144 ]: The authors aim to elucidate the correlation between multivariate time-series causal discovery and event sequence causal discovery and provide a comprehensive review of the existing solutions.", "target": "The authors aim to elucidate the correlation between multivariate time-series causal discovery and event sequence causal discovery and provide a comprehensive review of the existing solutions.", "example": "Convert the coordinate to text: [0.9409 3.144 ]:"}
{"text": "Convert the coordinate to text: [-7.1484  3.5596]: The authors propose a novel multilingual dataset of Wikipedia editor discussions along with their reasoning in three languages. The dataset contains the stances of the editors (keep, delete, merge, comment), along with the stated reason, and a content moderation policy, for each edit decision.", "target": "The authors propose a novel multilingual dataset of Wikipedia editor discussions along with their reasoning in three languages. The dataset contains the stances of the editors (keep, delete, merge, comment), along with the stated reason, and a content moderation policy, for each edit decision.", "example": "Convert the coordinate to text: [-7.1484  3.5596]:"}
{"text": "Convert the coordinate to text: [-3.6606 -5.938 ]: The authors introduce a Romanian Clickbait Corpus (RoCliCo) comprising of 8,313 manually annotated news samples with clickbait and non-clickbait labels. They also propose a novel BERT-based contrastive learning model that learns to encode news titles and contents into a deep metric space.", "target": "The authors introduce a Romanian Clickbait Corpus (RoCliCo) comprising of 8,313 manually annotated news samples with clickbait and non-clickbait labels. They also propose a novel BERT-based contrastive learning model that learns to encode news titles and contents into a deep metric space.", "example": "Convert the coordinate to text: [-3.6606 -5.938 ]:"}
{"text": "Convert the coordinate to text: [5.6776 6.7615]: The authors propose an early stopping criterion that computes the regular training objective on a fixed set of inputs for all training iterations, aiming to speed up the training of text-to-image personalization methods.", "target": "The authors propose an early stopping criterion that computes the regular training objective on a fixed set of inputs for all training iterations, aiming to speed up the training of text-to-image personalization methods.", "example": "Convert the coordinate to text: [5.6776 6.7615]:"}
{"text": "Convert the coordinate to text: [6.8438 7.649 ]: The authors propose a much-improved system \u2013 the 'DP-BART', which uses a novel clipping technique, iterative pruning and additional training of internal representations to significantly reduce the amount of noise required for differential privacy guarantees.", "target": "The authors propose a much-improved system \u2013 the 'DP-BART', which uses a novel clipping technique, iterative pruning and additional training of internal representations to significantly reduce the amount of noise required for differential privacy guarantees.", "example": "Convert the coordinate to text: [6.8438 7.649 ]:"}
{"text": "Convert the coordinate to text: [-0.3159 -6.6919]: The key idea of the paper is to utilize an ensemble of fine-tuned transformer-based models and to experiment with data augmentation and semi-supervised learning to alleviate class imbalance and improve the generalization capability of the model.", "target": "The key idea of the paper is to utilize an ensemble of fine-tuned transformer-based models and to experiment with data augmentation and semi-supervised learning to alleviate class imbalance and improve the generalization capability of the model.", "example": "Convert the coordinate to text: [-0.3159 -6.6919]:"}
{"text": "Convert the coordinate to text: [-1.2075 -4.9163]: The authors propose a novel TKGC model called Pre-trained Language Model with Prompts for TKGC (PPT) that converts quadruples into pre-trained language model inputs and intervals between timestamps into different prompts, allowing for more effective use of information from temporal knowledge graphs.", "target": "The authors propose a novel TKGC model called Pre-trained Language Model with Prompts for TKGC (PPT) that converts quadruples into pre-trained language model inputs and intervals between timestamps into different prompts, allowing for more effective use of information from temporal knowledge graphs.", "example": "Convert the coordinate to text: [-1.2075 -4.9163]:"}
{"text": "Convert the coordinate to text: [-10.417   -2.0253]: The authors propose a new pre-training objective involving cross-document question answering, which pushes the language model to answer questions from one document while peeking into other topically-related documents, and also to recover the sentence from which the question originated by leveraging cross-document information. This novel multi-document QA formulation allows the model to handle tasks involving both short and long text generation.", "target": "The authors propose a new pre-training objective involving cross-document question answering, which pushes the language model to answer questions from one document while peeking into other topically-related documents, and also to recover the sentence from which the question originated by leveraging cross-document information. This novel multi-document QA formulation allows the model to handle tasks involving both short and long text generation.", "example": "Convert the coordinate to text: [-10.417   -2.0253]:"}
{"text": "Convert the coordinate to text: [ 5.128  -5.1273]: This paper proposes an effective and principled approach to the problem of Graph Learning with Weak Information (GLWI). The authors suggest a dual-channel GNN framework, D$^2$PT, which facilitates long-range information propagation on both the input graph with incomplete structure and a global graph encoding global semantic similarities.", "target": "This paper proposes an effective and principled approach to the problem of Graph Learning with Weak Information (GLWI). The authors suggest a dual-channel GNN framework, D$^2$PT, which facilitates long-range information propagation on both the input graph with incomplete structure and a global graph encoding global semantic similarities.", "example": "Convert the coordinate to text: [ 5.128  -5.1273]:"}
{"text": "Convert the coordinate to text: [-3.2977  3.2745]: The authors propose a counterfactual data simulation method for CRS, known as CFCRS, to tackle the issue of data scarcity. It incorporates user preferences into the dialogue while maintaining the conversation flow.", "target": "The authors propose a counterfactual data simulation method for CRS, known as CFCRS, to tackle the issue of data scarcity. It incorporates user preferences into the dialogue while maintaining the conversation flow.", "example": "Convert the coordinate to text: [-3.2977  3.2745]:"}
{"text": "Convert the coordinate to text: [-6.5085 -0.5512]: The authors extend the concept of Argumentative Zoning to the domain of materials science research, presenting a new dataset of 50 manually annotated articles with a materials-science focused multi-label annotation scheme for AZ.", "target": "The authors extend the concept of Argumentative Zoning to the domain of materials science research, presenting a new dataset of 50 manually annotated articles with a materials-science focused multi-label annotation scheme for AZ.", "example": "Convert the coordinate to text: [-6.5085 -0.5512]:"}
{"text": "Convert the coordinate to text: [-4.1817 -3.5768]: NetEase.AI proposed an entity recognition system that integrates a text error correction system and external knowledge for better recognition of complex entities in noisy scenarios and entities outside the knowledge base.", "target": "NetEase.AI proposed an entity recognition system that integrates a text error correction system and external knowledge for better recognition of complex entities in noisy scenarios and entities outside the knowledge base.", "example": "Convert the coordinate to text: [-4.1817 -3.5768]:"}
{"text": "Convert the coordinate to text: [-1.309   0.1062]: The authors propose a method that leverages DeBERTaV3 classifier; they train it with all labels provided by the EDOS dataset and apply the predicted probability distribution on vector labels to represent category and sexist distributions, and calculate the hierarchical loss for optimization.", "target": "The authors propose a method that leverages DeBERTaV3 classifier; they train it with all labels provided by the EDOS dataset and apply the predicted probability distribution on vector labels to represent category and sexist distributions, and calculate the hierarchical loss for optimization.", "example": "Convert the coordinate to text: [-1.309   0.1062]:"}
{"text": "Convert the coordinate to text: [-2.8625 -6.742 ]: A language-centric domain adaptation approach is proposed, based on adversarial training, using a smaller version of Afro-XLM-Roberta as a generator model and a feed-forward network as a discriminator for the sentiment classification tasks.", "target": "A language-centric domain adaptation approach is proposed, based on adversarial training, using a smaller version of Afro-XLM-Roberta as a generator model and a feed-forward network as a discriminator for the sentiment classification tasks.", "example": "Convert the coordinate to text: [-2.8625 -6.742 ]:"}
{"text": "Convert the coordinate to text: [-5.9469 11.05  ]: The authors introduce an open-source platform named DeepPavlov Dream that is designed for the development of complex dialog systems like Generative AI Assistants, utilizing a modular approach and supporting multiple NLP components and conversational skills.", "target": "The authors introduce an open-source platform named DeepPavlov Dream that is designed for the development of complex dialog systems like Generative AI Assistants, utilizing a modular approach and supporting multiple NLP components and conversational skills.", "example": "Convert the coordinate to text: [-5.9469 11.05  ]:"}
{"text": "Convert the coordinate to text: [ 0.9901 -3.6541]: The authors propose a k-Nearest-Neighbor Transfer Learning (kNN-TL) approach for low-resource NMT, which leverages the parent knowledge throughout the entire developing process of the child model.", "target": "The authors propose a k-Nearest-Neighbor Transfer Learning (kNN-TL) approach for low-resource NMT, which leverages the parent knowledge throughout the entire developing process of the child model.", "example": "Convert the coordinate to text: [ 0.9901 -3.6541]:"}
{"text": "Convert the coordinate to text: [-7.2304  6.2828]: The authors propose DisasterNet, a family of causal Bayesian networks integrated with normalizing flows, to model the processes of how a major hazard triggers cascading hazards and impacts, and influences signal changes in remotely sensed observations.", "target": "The authors propose DisasterNet, a family of causal Bayesian networks integrated with normalizing flows, to model the processes of how a major hazard triggers cascading hazards and impacts, and influences signal changes in remotely sensed observations.", "example": "Convert the coordinate to text: [-7.2304  6.2828]:"}
{"text": "Convert the coordinate to text: [  1.2421 -11.4118]: The authors conduct a comprehensive reproducibility study of the state of the art for image retrieval for argumentation and its subtask of stance detection, developing a unified and modular retrieval process.", "target": "The authors conduct a comprehensive reproducibility study of the state of the art for image retrieval for argumentation and its subtask of stance detection, developing a unified and modular retrieval process.", "example": "Convert the coordinate to text: [  1.2421 -11.4118]:"}
{"text": "Convert the coordinate to text: [10.4689 -6.3247]: The authors propose a novel method based on the Diffusion Model (DM) to predict the features of video frames for anomaly detection. The method is designed to learn the distribution of normal samples without the need for any additional high-level semantic feature extraction models.", "target": "The authors propose a novel method based on the Diffusion Model (DM) to predict the features of video frames for anomaly detection. The method is designed to learn the distribution of normal samples without the need for any additional high-level semantic feature extraction models.", "example": "Convert the coordinate to text: [10.4689 -6.3247]:"}
{"text": "Convert the coordinate to text: [  6.3199 -20.6125]: This study proposes a correction algorithm for multiple exposure, the luminance-aware color transform (LACT). It reasons the relative exposure condition between images to obtain luminance features and encodes transformation functions from the luminance features, allowing complex color transformations for both overexposure and underexposure images.", "target": "This study proposes a correction algorithm for multiple exposure, the luminance-aware color transform (LACT). It reasons the relative exposure condition between images to obtain luminance features and encodes transformation functions from the luminance features, allowing complex color transformations for both overexposure and underexposure images.", "example": "Convert the coordinate to text: [  6.3199 -20.6125]:"}
{"text": "Convert the coordinate to text: [ 5.6847 -1.1623]: The paper addresses the mentioned problems and limitations of prior work by proposing a representation calibration method called RCAL, which works with representations extracted by unsupervised contrastive learning. The method assumes that without incorrect labeling and class imbalance, the representations of instances in each class conform to a multivariate Gaussian distribution.", "target": "The paper addresses the mentioned problems and limitations of prior work by proposing a representation calibration method called RCAL, which works with representations extracted by unsupervised contrastive learning. The method assumes that without incorrect labeling and class imbalance, the representations of instances in each class conform to a multivariate Gaussian distribution.", "example": "Convert the coordinate to text: [ 5.6847 -1.1623]:"}
{"text": "Convert the coordinate to text: [2.075  1.6585]: The authors propose a framework for unsupervised time series anomaly detection that combines point-based and sequence-based reconstruction models. They also present a novel nominality score calculated from the ratio of a combined value of the reconstruction errors.", "target": "The authors propose a framework for unsupervised time series anomaly detection that combines point-based and sequence-based reconstruction models. They also present a novel nominality score calculated from the ratio of a combined value of the reconstruction errors.", "example": "Convert the coordinate to text: [2.075  1.6585]:"}
{"text": "Convert the coordinate to text: [7.7888 3.0149]: This study investigates an approach based on the pointwise learning of the Kohn-Sham charge density, as opposed to focusing solely on energy, to achieve combinatorial generalization.", "target": "This study investigates an approach based on the pointwise learning of the Kohn-Sham charge density, as opposed to focusing solely on energy, to achieve combinatorial generalization.", "example": "Convert the coordinate to text: [7.7888 3.0149]:"}
{"text": "Convert the coordinate to text: [  7.9021 -21.069 ]: The authors propose LightSim, a neural lighting camera simulation system that enables diverse, realistic, and controllable data generation. LightSim automatically builds lighting-aware digital twins from collected raw sensor data, decomposes the scene into dynamic actors and static background with accurate geometry, appearance, and estimated scene lighting.", "target": "The authors propose LightSim, a neural lighting camera simulation system that enables diverse, realistic, and controllable data generation. LightSim automatically builds lighting-aware digital twins from collected raw sensor data, decomposes the scene into dynamic actors and static background with accurate geometry, appearance, and estimated scene lighting.", "example": "Convert the coordinate to text: [  7.9021 -21.069 ]:"}
{"text": "Convert the coordinate to text: [-0.8903  6.4412]: The authors propose Conic10K, a challenging math problem dataset based on conic sections in Chinese senior high school education. The dataset only requires knowledge of conic sections, facilitating separate analysis of a model's knowledge and reasoning ability.", "target": "The authors propose Conic10K, a challenging math problem dataset based on conic sections in Chinese senior high school education. The dataset only requires knowledge of conic sections, facilitating separate analysis of a model's knowledge and reasoning ability.", "example": "Convert the coordinate to text: [-0.8903  6.4412]:"}
{"text": "Convert the coordinate to text: [ 7.2942 -5.8762]: The authors propose the Specformer, a model that encodes the set of all eigenvalues and performs self-attention in the spectral domain, resulting in a learnable set-to-set spectral filter. Furthermore, they also design a decoder with learnable bases to enable non-local graph convolution.", "target": "The authors propose the Specformer, a model that encodes the set of all eigenvalues and performs self-attention in the spectral domain, resulting in a learnable set-to-set spectral filter. Furthermore, they also design a decoder with learnable bases to enable non-local graph convolution.", "example": "Convert the coordinate to text: [ 7.2942 -5.8762]:"}
{"text": "Convert the coordinate to text: [-8.4867  5.4721]: This paper proposes the use of machine learning models to streamline the DNS censorship detection process, improve usability of large-scale datasets for censorship detection, and discover new instances of censorship and blocking signatures missed by heuristic methods.", "target": "This paper proposes the use of machine learning models to streamline the DNS censorship detection process, improve usability of large-scale datasets for censorship detection, and discover new instances of censorship and blocking signatures missed by heuristic methods.", "example": "Convert the coordinate to text: [-8.4867  5.4721]:"}
{"text": "Convert the coordinate to text: [-11.6553  -1.133 ]: They extend UKP-SQuARE, a platform for QA research, to support three families of multi-agent systems: agent selection, early-fusion of agents, and late-fusion of agents.", "target": "They extend UKP-SQuARE, a platform for QA research, to support three families of multi-agent systems: agent selection, early-fusion of agents, and late-fusion of agents.", "example": "Convert the coordinate to text: [-11.6553  -1.133 ]:"}
{"text": "Convert the coordinate to text: [ 2.5182 -2.6336]: The authors propose a novel perspective for continual learning by exploring the geometry of non-stationary data streams, expanding the geometry of the underlying space to match geometric structures induced by new data, while preventing forgetting by keeping the geometric structures of old data.", "target": "The authors propose a novel perspective for continual learning by exploring the geometry of non-stationary data streams, expanding the geometry of the underlying space to match geometric structures induced by new data, while preventing forgetting by keeping the geometric structures of old data.", "example": "Convert the coordinate to text: [ 2.5182 -2.6336]:"}
{"text": "Convert the coordinate to text: [  3.2764 -12.1291]: The authors create FilmSet, a high-quality, large-scale dataset tailored for film-style image stylization research, comprising three different film styles and over 5000 high-resolution images. Based on the features of these images, they also propose FilmNet, a novel framework for image stylization across frequency bands.", "target": "The authors create FilmSet, a high-quality, large-scale dataset tailored for film-style image stylization research, comprising three different film styles and over 5000 high-resolution images. Based on the features of these images, they also propose FilmNet, a novel framework for image stylization across frequency bands.", "example": "Convert the coordinate to text: [  3.2764 -12.1291]:"}
{"text": "Convert the coordinate to text: [-9.5365 -6.7263]: The authors introduce a novel neural semantic parsing generation method that constructs logical forms from the bottom up starting from the leaves, and this system incrementally builds up a set of potential semantic parses, expanding and processing only the most promising candidate at each step.", "target": "The authors introduce a novel neural semantic parsing generation method that constructs logical forms from the bottom up starting from the leaves, and this system incrementally builds up a set of potential semantic parses, expanding and processing only the most promising candidate at each step.", "example": "Convert the coordinate to text: [-9.5365 -6.7263]:"}
{"text": "Convert the coordinate to text: [ 3.8404 14.2708]: The authors propose the Two-pass model for AdaPtIve Revision (TAPIR) that introduces a method to obtain an incremental supervision signal for learning an adaptive revision policy.", "target": "The authors propose the Two-pass model for AdaPtIve Revision (TAPIR) that introduces a method to obtain an incremental supervision signal for learning an adaptive revision policy.", "example": "Convert the coordinate to text: [ 3.8404 14.2708]:"}
{"text": "Convert the coordinate to text: [0.5408 3.5413]: The authors propose a continuous-time graph learning method that connects different cascades via a universal sequence of user-cascade and user-user interactions, and then applies chronological learning on the sequence while maintaining dynamic states of users and cascades.", "target": "The authors propose a continuous-time graph learning method that connects different cascades via a universal sequence of user-cascade and user-user interactions, and then applies chronological learning on the sequence while maintaining dynamic states of users and cascades.", "example": "Convert the coordinate to text: [0.5408 3.5413]:"}
{"text": "Convert the coordinate to text: [-3.5381 -7.8443]: The paper introduces MTCue, a unique neural machine translation (NMT) framework that interprets all context, including discrete variables, as text. This approach allows MTCue to learn an abstract representation of context for transferability across different data settings and leveraging similar attributes in low-resource scenarios.", "target": "The paper introduces MTCue, a unique neural machine translation (NMT) framework that interprets all context, including discrete variables, as text. This approach allows MTCue to learn an abstract representation of context for transferability across different data settings and leveraging similar attributes in low-resource scenarios.", "example": "Convert the coordinate to text: [-3.5381 -7.8443]:"}
{"text": "Convert the coordinate to text: [-13.8145   0.0249]: This study suggests that integrating views, a query analyzer/planner, and provenance into semi-parametric architectures could enhance their performance, especially for question answering tasks.", "target": "This study suggests that integrating views, a query analyzer/planner, and provenance into semi-parametric architectures could enhance their performance, especially for question answering tasks.", "example": "Convert the coordinate to text: [-13.8145   0.0249]:"}
{"text": "Convert the coordinate to text: [-4.2644 -0.8177]: The authors identify the inconsistency in event extraction evaluations as a major challenge and propose a series of remedies to avoid these pitfalls, including specifying data preprocessing, standardizing outputs, and providing pipeline evaluation results.", "target": "The authors identify the inconsistency in event extraction evaluations as a major challenge and propose a series of remedies to avoid these pitfalls, including specifying data preprocessing, standardizing outputs, and providing pipeline evaluation results.", "example": "Convert the coordinate to text: [-4.2644 -0.8177]:"}
{"text": "Convert the coordinate to text: [ 6.1454 -0.3796]: This paper proposes to optimize the anomaly scoring function from the perspective of score distribution, introducing a loss function termed 'Overlap loss', offering better data diversity retention and better robustness in scenarios where unlabeled data contains anomalous noise.", "target": "This paper proposes to optimize the anomaly scoring function from the perspective of score distribution, introducing a loss function termed 'Overlap loss', offering better data diversity retention and better robustness in scenarios where unlabeled data contains anomalous noise.", "example": "Convert the coordinate to text: [ 6.1454 -0.3796]:"}
{"text": "Convert the coordinate to text: [-5.1157 -5.8022]: This study aims to create a unified framework to design and evaluate AADS models for the French language, which involves consolidating a large French narrative dataset annotated with Direct Speech (DS) per word, adapting various baselines, and performing an extensive evaluation focused on generalization.", "target": "This study aims to create a unified framework to design and evaluate AADS models for the French language, which involves consolidating a large French narrative dataset annotated with Direct Speech (DS) per word, adapting various baselines, and performing an extensive evaluation focused on generalization.", "example": "Convert the coordinate to text: [-5.1157 -5.8022]:"}
{"text": "Convert the coordinate to text: [ 2.1846 -7.0919]: The authors propose a cross-modality context fusion and semantic refinement network (CMCF-SRNet) to handle the limitations of existing methods. By using a cross-modal locality-constrained transformer to explore the multimodal interaction and a graph-based semantic refinement transformer, the proposed approach is designed to effectively capture the semantic relationship information between utterances.", "target": "The authors propose a cross-modality context fusion and semantic refinement network (CMCF-SRNet) to handle the limitations of existing methods. By using a cross-modal locality-constrained transformer to explore the multimodal interaction and a graph-based semantic refinement transformer, the proposed approach is designed to effectively capture the semantic relationship information between utterances.", "example": "Convert the coordinate to text: [ 2.1846 -7.0919]:"}
{"text": "Convert the coordinate to text: [-6.3682 -9.9448]: The study explores the feasibility of applying a GEC model in the language learning context, with the hypothesis that a GEC model corrects only errors and leaves correct answers unchanged.", "target": "The study explores the feasibility of applying a GEC model in the language learning context, with the hypothesis that a GEC model corrects only errors and leaves correct answers unchanged.", "example": "Convert the coordinate to text: [-6.3682 -9.9448]:"}
{"text": "Convert the coordinate to text: [ 1.2014 -4.1179]: The authors propose the 'EvidenceSCL' system that uses pair-level supervised contrastive learning to classify pairs of sentences addressing the goals of the NLI4CT task.", "target": "The authors propose the 'EvidenceSCL' system that uses pair-level supervised contrastive learning to classify pairs of sentences addressing the goals of the NLI4CT task.", "example": "Convert the coordinate to text: [ 1.2014 -4.1179]:"}
{"text": "Convert the coordinate to text: [-4.1718 -7.1527]: This study performs an extensive investigation using back-translation to train models from 60 languages into English, majority of which are moderate or low-resource languages.", "target": "This study performs an extensive investigation using back-translation to train models from 60 languages into English, majority of which are moderate or low-resource languages.", "example": "Convert the coordinate to text: [-4.1718 -7.1527]:"}
{"text": "Convert the coordinate to text: [-3.6688 -2.3678]: This paper introduces a new ECE framework that combines a more dedicated rule-based system, based on constituency parsing tree to discover causal patterns, with a neural model trained on the rule-annotated dataset. This enables high extraction performance and generalizability without relying on human annotation.", "target": "This paper introduces a new ECE framework that combines a more dedicated rule-based system, based on constituency parsing tree to discover causal patterns, with a neural model trained on the rule-annotated dataset. This enables high extraction performance and generalizability without relying on human annotation.", "example": "Convert the coordinate to text: [-3.6688 -2.3678]:"}
{"text": "Convert the coordinate to text: [-1.6828 -6.6111]: This study offers an empirical evaluation of the extent to which these results extend to science tasks, using 14 domain-specific transformer-based models, including ScholarBERT, a 770-million-parameter science-focused masked language model trained on up to 225 billion tokens.", "target": "This study offers an empirical evaluation of the extent to which these results extend to science tasks, using 14 domain-specific transformer-based models, including ScholarBERT, a 770-million-parameter science-focused masked language model trained on up to 225 billion tokens.", "example": "Convert the coordinate to text: [-1.6828 -6.6111]:"}
{"text": "Convert the coordinate to text: [ 4.2252 -1.5995]: The authors propose a new semi-supervised framework known as ProtoS2, which uses prototypical cluster separation (PCS) and prototypical-center data selection (CDS) to address these issues in SSTC.", "target": "The authors propose a new semi-supervised framework known as ProtoS2, which uses prototypical cluster separation (PCS) and prototypical-center data selection (CDS) to address these issues in SSTC.", "example": "Convert the coordinate to text: [ 4.2252 -1.5995]:"}
{"text": "Convert the coordinate to text: [2.9495 5.2693]: The paper introduces VecSim, which aggregates paths from the query node with common arrived nodes to obtain hitting probabilities, then reversely aggregates paths starting from arrived nodes for first-meeting probabilities, and excludes extra-meeting probabilities at each step. An efficient sampling-based algorithm is designed to estimate the extra-meeting probabilities by sampling paths within a specified length.", "target": "The paper introduces VecSim, which aggregates paths from the query node with common arrived nodes to obtain hitting probabilities, then reversely aggregates paths starting from arrived nodes for first-meeting probabilities, and excludes extra-meeting probabilities at each step. An efficient sampling-based algorithm is designed to estimate the extra-meeting probabilities by sampling paths within a specified length.", "example": "Convert the coordinate to text: [2.9495 5.2693]:"}
{"text": "Convert the coordinate to text: [9.7946 5.4136]: The authors introduce a new method to construct a debiased estimator that tackles the issue of non-normal asymptotic behavior in adaptive linear regression models using adaptive linear estimating equations.", "target": "The authors introduce a new method to construct a debiased estimator that tackles the issue of non-normal asymptotic behavior in adaptive linear regression models using adaptive linear estimating equations.", "example": "Convert the coordinate to text: [9.7946 5.4136]:"}
{"text": "Convert the coordinate to text: [ 5.2496 13.1499]: This paper proposes a unified framework for exploration in RL based on an option-critic architecture which learns to integrate a set of diverse exploration strategies, allowing the agent to adaptively select the most effective exploration strategy for each given task.", "target": "This paper proposes a unified framework for exploration in RL based on an option-critic architecture which learns to integrate a set of diverse exploration strategies, allowing the agent to adaptively select the most effective exploration strategy for each given task.", "example": "Convert the coordinate to text: [ 5.2496 13.1499]:"}
{"text": "Convert the coordinate to text: [ 14.8211 -15.0744]: The paper proposes a unified Neural Radiance Field (NeRF) framework that jointly performs scene decomposition and composition for modeling real-world scenes. The scene decomposition aims to learn disentangled 3D representations of objects and the background to facilitate scene editing, while scene composition models an entire scene representation for novel view synthesis.", "target": "The paper proposes a unified Neural Radiance Field (NeRF) framework that jointly performs scene decomposition and composition for modeling real-world scenes. The scene decomposition aims to learn disentangled 3D representations of objects and the background to facilitate scene editing, while scene composition models an entire scene representation for novel view synthesis.", "example": "Convert the coordinate to text: [ 14.8211 -15.0744]:"}
{"text": "Convert the coordinate to text: [12.9858 -8.0121]: The authors propose the concept of BallGAN, an approximation where the background is represented as a spherical surface, and a scene is depicted as a union of the foreground in the sphere and the thin spherical background, reducing the degree of freedom in the background field.", "target": "The authors propose the concept of BallGAN, an approximation where the background is represented as a spherical surface, and a scene is depicted as a union of the foreground in the sphere and the thin spherical background, reducing the degree of freedom in the background field.", "example": "Convert the coordinate to text: [12.9858 -8.0121]:"}
{"text": "Convert the coordinate to text: [ 8.6496 -3.327 ]: To address this, the authors propose the reformulation of discrete feature transformation as a continuous space optimization task. This is done through an embedding-optimization-reconstruction framework, designed specifically to handle data preparation, feature transformation operation sequence embedding, optimal embedding search, and transformation operation sequence reconstruction.", "target": "To address this, the authors propose the reformulation of discrete feature transformation as a continuous space optimization task. This is done through an embedding-optimization-reconstruction framework, designed specifically to handle data preparation, feature transformation operation sequence embedding, optimal embedding search, and transformation operation sequence reconstruction.", "example": "Convert the coordinate to text: [ 8.6496 -3.327 ]:"}
{"text": "Convert the coordinate to text: [10.4095 -3.1375]: The study investigates the discriminative structures in the intermediate layers of a neural network, revealing that the feature norm acts like a confidence value of a classifier, is class-agnostic, and that the conventional feature norm can fail to capture the deactivation tendency of hidden layer neurons, which can lead to misclassification.", "target": "The study investigates the discriminative structures in the intermediate layers of a neural network, revealing that the feature norm acts like a confidence value of a classifier, is class-agnostic, and that the conventional feature norm can fail to capture the deactivation tendency of hidden layer neurons, which can lead to misclassification.", "example": "Convert the coordinate to text: [10.4095 -3.1375]:"}
{"text": "Convert the coordinate to text: [  9.8714 -19.243 ]: The authors propose to leverage monocular depth priors to guide fusion in 3D scene reconstruction to improve surface prediction and deal with irrelevant, ambiguous, or occluded features. The authors also propose using variance-based and a cross-attention-based fusion modules as alternatives to average-based fusion.", "target": "The authors propose to leverage monocular depth priors to guide fusion in 3D scene reconstruction to improve surface prediction and deal with irrelevant, ambiguous, or occluded features. The authors also propose using variance-based and a cross-attention-based fusion modules as alternatives to average-based fusion.", "example": "Convert the coordinate to text: [  9.8714 -19.243 ]:"}
{"text": "Convert the coordinate to text: [11.0782 -7.796 ]: The authors propose a domain translation-based unified method for multi-weather image restoration that learns multiple weather degradations simultaneously, making it useful for real-world conditions.", "target": "The authors propose a domain translation-based unified method for multi-weather image restoration that learns multiple weather degradations simultaneously, making it useful for real-world conditions.", "example": "Convert the coordinate to text: [11.0782 -7.796 ]:"}
{"text": "Convert the coordinate to text: [9.9089 5.0019]: This study proposes a new approach for estimating the sample mean, individual treatment effects, and average treatment effect with regression adjustment in a finite population setting, using techniques from randomized numerical linear algebra. This approach only involves sampling a subset of the population for the experiment, contrary to the common practice.", "target": "This study proposes a new approach for estimating the sample mean, individual treatment effects, and average treatment effect with regression adjustment in a finite population setting, using techniques from randomized numerical linear algebra. This approach only involves sampling a subset of the population for the experiment, contrary to the common practice.", "example": "Convert the coordinate to text: [9.9089 5.0019]:"}
{"text": "Convert the coordinate to text: [-0.1418 -4.5865]: This study proposes a Scalable Dialogue State Correction (Scalable-DSC) method, along with a Structural Template Prompt (STP), capable of correcting any wrong slot values in dialogue states predicted by any DST model.", "target": "This study proposes a Scalable Dialogue State Correction (Scalable-DSC) method, along with a Structural Template Prompt (STP), capable of correcting any wrong slot values in dialogue states predicted by any DST model.", "example": "Convert the coordinate to text: [-0.1418 -4.5865]:"}
{"text": "Convert the coordinate to text: [-3.1028 -6.5704]: The authors introduce AfriSenti, a sentiment analysis benchmark that contains more than 110,000 tweets in 14 African languages from four language families, providing a high-quality annotated dataset for sentiment analysis research in African languages.", "target": "The authors introduce AfriSenti, a sentiment analysis benchmark that contains more than 110,000 tweets in 14 African languages from four language families, providing a high-quality annotated dataset for sentiment analysis research in African languages.", "example": "Convert the coordinate to text: [-3.1028 -6.5704]:"}
{"text": "Convert the coordinate to text: [-6.9133  6.9666]: The authors present an efficient semantic pipeline to study depression severity in individuals based on their social media writings by selecting test user sentences for producing semantic rankings over an index of representative training sentences corresponding to depressive symptoms and severity levels.", "target": "The authors present an efficient semantic pipeline to study depression severity in individuals based on their social media writings by selecting test user sentences for producing semantic rankings over an index of representative training sentences corresponding to depressive symptoms and severity levels.", "example": "Convert the coordinate to text: [-6.9133  6.9666]:"}
{"text": "Convert the coordinate to text: [  8.3342 -12.4004]: The authors propose a new method that uses a bottom-up approach to lane graph estimation from aerial imagery. It aggregates multiple overlapping graphs into a single consistent graph. The approach uses a graph neural network to predict the layout of lanes from any vehicle position, and aggregates these predictions into a consistent global lane graph.", "target": "The authors propose a new method that uses a bottom-up approach to lane graph estimation from aerial imagery. It aggregates multiple overlapping graphs into a single consistent graph. The approach uses a graph neural network to predict the layout of lanes from any vehicle position, and aggregates these predictions into a consistent global lane graph.", "example": "Convert the coordinate to text: [  8.3342 -12.4004]:"}
{"text": "Convert the coordinate to text: [ 0.2742 -5.0458]: A novel knowledge graph pretraining model, KGTransformer, is proposed with the capability to serve as a uniform KRF module across various KG-related tasks. KGTransformer is pretrained with three self-supervised tasks using sampled sub-graphs as input.", "target": "A novel knowledge graph pretraining model, KGTransformer, is proposed with the capability to serve as a uniform KRF module across various KG-related tasks. KGTransformer is pretrained with three self-supervised tasks using sampled sub-graphs as input.", "example": "Convert the coordinate to text: [ 0.2742 -5.0458]:"}
{"text": "Convert the coordinate to text: [-9.5519  9.303 ]: The paper explores the contextual dimensions of youth online risks through qualitative content analyses on risky media content. These findings are then used to inform semi- and self-supervised state-of-the-art vision transformers to automate the process of identifying risky images shared by youth.", "target": "The paper explores the contextual dimensions of youth online risks through qualitative content analyses on risky media content. These findings are then used to inform semi- and self-supervised state-of-the-art vision transformers to automate the process of identifying risky images shared by youth.", "example": "Convert the coordinate to text: [-9.5519  9.303 ]:"}
{"text": "Convert the coordinate to text: [-2.7615 -5.0003]: The authors investigate how well popular LLMs capture the magnitudes of numbers (e.g., that 4 < 5) from a behavioral lens, asking whether the number representations of LLMs correspond to those of human language users, who typically demonstrate the distance, size, and ratio effects.", "target": "The authors investigate how well popular LLMs capture the magnitudes of numbers (e.g., that 4 < 5) from a behavioral lens, asking whether the number representations of LLMs correspond to those of human language users, who typically demonstrate the distance, size, and ratio effects.", "example": "Convert the coordinate to text: [-2.7615 -5.0003]:"}
{"text": "Convert the coordinate to text: [-6.1007 10.2728]: This paper proposes a Schema-Guided User Satisfaction Modeling framework (SG-USM) that explicitly models the degree to which the user's preferences, as expressed in the task attributes, are fulfilled by the system in order to predict the user's level of satisfaction.", "target": "This paper proposes a Schema-Guided User Satisfaction Modeling framework (SG-USM) that explicitly models the degree to which the user's preferences, as expressed in the task attributes, are fulfilled by the system in order to predict the user's level of satisfaction.", "example": "Convert the coordinate to text: [-6.1007 10.2728]:"}
{"text": "Convert the coordinate to text: [-10.112   -1.2603]: This paper proposes a single-step phrase retrieval method for ODConvQA tasks that reduces the traditional two-step (retriever and reader) process to a single one, streamlining the answering process.", "target": "This paper proposes a single-step phrase retrieval method for ODConvQA tasks that reduces the traditional two-step (retriever and reader) process to a single one, streamlining the answering process.", "example": "Convert the coordinate to text: [-10.112   -1.2603]:"}
{"text": "Convert the coordinate to text: [  2.7602 -15.366 ]: The study introduces a pathologist-in-the-loop framework for generating clinically-plausible synthetic medical images using human feedback and a diffusion model pretrained on real images.", "target": "The study introduces a pathologist-in-the-loop framework for generating clinically-plausible synthetic medical images using human feedback and a diffusion model pretrained on real images.", "example": "Convert the coordinate to text: [  2.7602 -15.366 ]:"}
{"text": "Convert the coordinate to text: [-0.9278 -5.1316]: The authors propose a multi-task prompting method for graph models, inspired by the concept of prompt learning in NLP. They aim to bridge the gap between various graph tasks and pre-trained models using prompts that mirror NLP prompts in format.", "target": "The authors propose a multi-task prompting method for graph models, inspired by the concept of prompt learning in NLP. They aim to bridge the gap between various graph tasks and pre-trained models using prompts that mirror NLP prompts in format.", "example": "Convert the coordinate to text: [-0.9278 -5.1316]:"}
{"text": "Convert the coordinate to text: [ 0.3594 -4.4253]: This paper proposes an adversarial training-inspired two-stage debiasing model called Contrastive learning with Continuous Prompt Augmentation (CCPA) to mitigate social biases in PLMs' encoding. It includes a data augmentation method based on continuous prompt tuning and a contrastive learning method to fine-tune PLMs' parameters.", "target": "This paper proposes an adversarial training-inspired two-stage debiasing model called Contrastive learning with Continuous Prompt Augmentation (CCPA) to mitigate social biases in PLMs' encoding. It includes a data augmentation method based on continuous prompt tuning and a contrastive learning method to fine-tune PLMs' parameters.", "example": "Convert the coordinate to text: [ 0.3594 -4.4253]:"}
{"text": "Convert the coordinate to text: [-2.1722 -3.7189]: The authors introduce AutoTUS, a multi-stage self-supervised table union search framework, aiming to better capture column relationships and improve noise robustness by using iterative large language model-empowered contextualized column relation encoding, adaptive clustering, pseudo label classification, and a table noise generator.", "target": "The authors introduce AutoTUS, a multi-stage self-supervised table union search framework, aiming to better capture column relationships and improve noise robustness by using iterative large language model-empowered contextualized column relation encoding, adaptive clustering, pseudo label classification, and a table noise generator.", "example": "Convert the coordinate to text: [-2.1722 -3.7189]:"}
{"text": "Convert the coordinate to text: [-10.7758  -0.3767]: The authors develop a system for the European Space Agency designed to answer complex natural language queries and provide engineers access to information contained in a KB that models the orbital space debris environment. The system works by generating a program sketch from a natural language query, specialize the sketch into a concrete query program and then execute the program against the database.", "target": "The authors develop a system for the European Space Agency designed to answer complex natural language queries and provide engineers access to information contained in a KB that models the orbital space debris environment. The system works by generating a program sketch from a natural language query, specialize the sketch into a concrete query program and then execute the program against the database.", "example": "Convert the coordinate to text: [-10.7758  -0.3767]:"}
{"text": "Convert the coordinate to text: [-3.217  -4.5004]: This paper investigates the ability of language models to handle 1-to-N relational knowledge, including two essential skills: (i) memorizing multiple objects individually and (ii) retrieving multiple stored objects without excesses or deficiencies at once.", "target": "This paper investigates the ability of language models to handle 1-to-N relational knowledge, including two essential skills: (i) memorizing multiple objects individually and (ii) retrieving multiple stored objects without excesses or deficiencies at once.", "example": "Convert the coordinate to text: [-3.217  -4.5004]:"}
{"text": "Convert the coordinate to text: [ 0.2259 -8.9602]: The authors propose a solution called FC-CLIP, a single-stage framework by using a shared Frozen Convolutional CLIP backbone that simplifies the current two-stage pipeline. This approach maintains the ability of open-vocabulary classification and can also serve as a strong mask generator, improving the accuracy-cost trade-off.", "target": "The authors propose a solution called FC-CLIP, a single-stage framework by using a shared Frozen Convolutional CLIP backbone that simplifies the current two-stage pipeline. This approach maintains the ability of open-vocabulary classification and can also serve as a strong mask generator, improving the accuracy-cost trade-off.", "example": "Convert the coordinate to text: [ 0.2259 -8.9602]:"}
{"text": "Convert the coordinate to text: [12.4725 -9.4849]: This paper proposes that deepfake detectors encode multi-order interactions among visual concepts, and detectors with better generalization abilities tend to encode low-order interactions with fewer negative contributions. Generalized deepfake detectors usually weaken the negative contributions of low-order interactions by suppressing their strength.", "target": "This paper proposes that deepfake detectors encode multi-order interactions among visual concepts, and detectors with better generalization abilities tend to encode low-order interactions with fewer negative contributions. Generalized deepfake detectors usually weaken the negative contributions of low-order interactions by suppressing their strength.", "example": "Convert the coordinate to text: [12.4725 -9.4849]:"}
{"text": "Convert the coordinate to text: [  9.2028 -19.6267]: The authors introduce 3D distillation, a novel training framework that uses the projected depth of reconstructed reflective surfaces to generate accurate depth pseudo-labels, noting that reflective surfaces can be accurately reconstructed by aggregating the predicted depth of views that are not contaminated by strong specular reflections.", "target": "The authors introduce 3D distillation, a novel training framework that uses the projected depth of reconstructed reflective surfaces to generate accurate depth pseudo-labels, noting that reflective surfaces can be accurately reconstructed by aggregating the predicted depth of views that are not contaminated by strong specular reflections.", "example": "Convert the coordinate to text: [  9.2028 -19.6267]:"}
{"text": "Convert the coordinate to text: [  7.5887 -13.2601]: GACE is proposed as an intuitive and highly efficient method to improve the confidence estimation of black-box 3D object detectors by aggregating geometric cues of detections and their spatial relationships.", "target": "GACE is proposed as an intuitive and highly efficient method to improve the confidence estimation of black-box 3D object detectors by aggregating geometric cues of detections and their spatial relationships.", "example": "Convert the coordinate to text: [  7.5887 -13.2601]:"}
{"text": "Convert the coordinate to text: [-0.7951 -3.5153]: The authors propose Neural Tree Search (NuTrea), a tree-search based GNN model that incorporates a broader KG context. This model improves message-passing by exploring unreached subtree regions and introduces the Relation Frequency-Inverse Entity Frequency (RF-IEF) node embedding to better characterize ambiguous KG nodes.", "target": "The authors propose Neural Tree Search (NuTrea), a tree-search based GNN model that incorporates a broader KG context. This model improves message-passing by exploring unreached subtree regions and introduces the Relation Frequency-Inverse Entity Frequency (RF-IEF) node embedding to better characterize ambiguous KG nodes.", "example": "Convert the coordinate to text: [-0.7951 -3.5153]:"}
{"text": "Convert the coordinate to text: [ 6.116 14.   ]: This paper proposes UBER, an unsupervised approach which leverages diversified rewards to extract useful behaviors from offline reward-free datasets and reuses them as candidate policies to facilitate the learning of new tasks.", "target": "This paper proposes UBER, an unsupervised approach which leverages diversified rewards to extract useful behaviors from offline reward-free datasets and reuses them as candidate policies to facilitate the learning of new tasks.", "example": "Convert the coordinate to text: [ 6.116 14.   ]:"}
{"text": "Convert the coordinate to text: [ 9.685  12.1247]: The authors introduce a new generalized combinatorial bandit model, referred to as 'cascading contextual assortment bandit', and they propose two Upper Confidence Bound (UCB) bandit algorithms, UCB-CCA and UCB-CCA+, for this model.", "target": "The authors introduce a new generalized combinatorial bandit model, referred to as 'cascading contextual assortment bandit', and they propose two Upper Confidence Bound (UCB) bandit algorithms, UCB-CCA and UCB-CCA+, for this model.", "example": "Convert the coordinate to text: [ 9.685  12.1247]:"}
{"text": "Convert the coordinate to text: [7.0029 7.6636]: The authors propose enhancing the performance of private estimation by using a small amount of public data. They introduce an efficient algorithm called the Locally differentially Private Decision Tree (LPDT) for LDP regression.", "target": "The authors propose enhancing the performance of private estimation by using a small amount of public data. They introduce an efficient algorithm called the Locally differentially Private Decision Tree (LPDT) for LDP regression.", "example": "Convert the coordinate to text: [7.0029 7.6636]:"}
{"text": "Convert the coordinate to text: [7.6459 9.1116]: The authors introduce a new framework, Two-Stage Predict+Optimize, designed to better handle unknown parameters in constraints.", "target": "The authors introduce a new framework, Two-Stage Predict+Optimize, designed to better handle unknown parameters in constraints.", "example": "Convert the coordinate to text: [7.6459 9.1116]:"}
{"text": "Convert the coordinate to text: [-10.2562  11.2399]: The authors propose in5, a model designed to make human physiology more accessible for HCI design. This model has two parts: the MEECS dichotomies (move, eat, engage, cogitate, sleep) affected by parameters of quality, quantity, time, and context; and tuning, an approach to adjust the parameters of these dichotomies to optimize health, wellbeing, and performance.", "target": "The authors propose in5, a model designed to make human physiology more accessible for HCI design. This model has two parts: the MEECS dichotomies (move, eat, engage, cogitate, sleep) affected by parameters of quality, quantity, time, and context; and tuning, an approach to adjust the parameters of these dichotomies to optimize health, wellbeing, and performance.", "example": "Convert the coordinate to text: [-10.2562  11.2399]:"}
{"text": "Convert the coordinate to text: [ 14.7765 -15.0279]: The paper proposes a new representation of NeRF based on textured polygons, which permits efficient synthesis of novel images via mainstream rendering pipelines.", "target": "The paper proposes a new representation of NeRF based on textured polygons, which permits efficient synthesis of novel images via mainstream rendering pipelines.", "example": "Convert the coordinate to text: [ 14.7765 -15.0279]:"}
{"text": "Convert the coordinate to text: [ 0.6197 -1.9572]: The paper introduces ExplainableFold, an explainable AI framework for protein structure prediction that proposes a counterfactual learning framework inspired by biological principles to generate counterfactual explanations for protein structure prediction.", "target": "The paper introduces ExplainableFold, an explainable AI framework for protein structure prediction that proposes a counterfactual learning framework inspired by biological principles to generate counterfactual explanations for protein structure prediction.", "example": "Convert the coordinate to text: [ 0.6197 -1.9572]:"}
{"text": "Convert the coordinate to text: [-4.2593  3.9143]: The authors propose a framework for exploration in large-scale recommender systems that comprises of three parts: user-creator exploration, an online exploration framework, and a feed composition mechanism. This framework is designed to address the shortcomings of existing systems and can be integrated with minimal changes.", "target": "The authors propose a framework for exploration in large-scale recommender systems that comprises of three parts: user-creator exploration, an online exploration framework, and a feed composition mechanism. This framework is designed to address the shortcomings of existing systems and can be integrated with minimal changes.", "example": "Convert the coordinate to text: [-4.2593  3.9143]:"}
{"text": "Convert the coordinate to text: [-4.3865 11.9412]: This study suggests the categorization of AI roles based on computational methods to get a comprehensive understanding of the laypeople's perception of AI.", "target": "This study suggests the categorization of AI roles based on computational methods to get a comprehensive understanding of the laypeople's perception of AI.", "example": "Convert the coordinate to text: [-4.3865 11.9412]:"}
{"text": "Convert the coordinate to text: [10.8763 -4.8888]: This study proposes a generative embedding inversion attack (GEIA) capable of reconstructing the input sequences based solely on their sentence embeddings to investigate the information leakage issue more thoroughly.", "target": "This study proposes a generative embedding inversion attack (GEIA) capable of reconstructing the input sequences based solely on their sentence embeddings to investigate the information leakage issue more thoroughly.", "example": "Convert the coordinate to text: [10.8763 -4.8888]:"}
{"text": "Convert the coordinate to text: [0.3375 0.9965]: The authors investigate the inductive biases of ICL by constructing underspecified demonstrations from a range of NLP datasets and by evaluating the effect of different interventions intended to impose an inductive bias in favor of a particular feature.", "target": "The authors investigate the inductive biases of ICL by constructing underspecified demonstrations from a range of NLP datasets and by evaluating the effect of different interventions intended to impose an inductive bias in favor of a particular feature.", "example": "Convert the coordinate to text: [0.3375 0.9965]:"}
{"text": "Convert the coordinate to text: [ 0.2858 -9.1864]: The authors propose a new task of generating visual metaphors from linguistic metaphors, which they tackle through collaboration between Large Language Models (LLMs) and Diffusion Models, using the Chain-of-Thought prompting method with the GPT-3 model to generate a text version of the visual metaphor.", "target": "The authors propose a new task of generating visual metaphors from linguistic metaphors, which they tackle through collaboration between Large Language Models (LLMs) and Diffusion Models, using the Chain-of-Thought prompting method with the GPT-3 model to generate a text version of the visual metaphor.", "example": "Convert the coordinate to text: [ 0.2858 -9.1864]:"}
{"text": "Convert the coordinate to text: [-10.6523  -2.0398]: In this study, the authors propose a novel two-stage Explainable Question Answering framework, 'Reasoning over Hierarchical Question Decomposition Tree' (RoHT). They leverage question decomposition to allow for the integration of heterogeneous knowledge, by breaking down complex questions into simpler sub-questions and selecting the appropriate knowledge source for each.", "target": "In this study, the authors propose a novel two-stage Explainable Question Answering framework, 'Reasoning over Hierarchical Question Decomposition Tree' (RoHT). They leverage question decomposition to allow for the integration of heterogeneous knowledge, by breaking down complex questions into simpler sub-questions and selecting the appropriate knowledge source for each.", "example": "Convert the coordinate to text: [-10.6523  -2.0398]:"}
{"text": "Convert the coordinate to text: [-0.611   0.6963]: This study aims to uncover and categorize social biases in Text-to-SQL models, and to summarize the categories of social biases that may occur in structured data for these models.", "target": "This study aims to uncover and categorize social biases in Text-to-SQL models, and to summarize the categories of social biases that may occur in structured data for these models.", "example": "Convert the coordinate to text: [-0.611   0.6963]:"}
{"text": "Convert the coordinate to text: [-1.7762 -5.6739]: The authors propose a method to decouple document encoding from downstream tasks, by representing each document as a plug-and-play document module, or document plugin, for pre-trained models (PlugD).", "target": "The authors propose a method to decouple document encoding from downstream tasks, by representing each document as a plug-and-play document module, or document plugin, for pre-trained models (PlugD).", "example": "Convert the coordinate to text: [-1.7762 -5.6739]:"}
{"text": "Convert the coordinate to text: [-3.0601 -3.4648]: This study proposes the challenging question of evaluating the faithfulness of natural language explanations (NLEs) and introduces two tests: a counterfactual input editor and a process of reconstructing inputs from the reasons stated in the NLEs.", "target": "This study proposes the challenging question of evaluating the faithfulness of natural language explanations (NLEs) and introduces two tests: a counterfactual input editor and a process of reconstructing inputs from the reasons stated in the NLEs.", "example": "Convert the coordinate to text: [-3.0601 -3.4648]:"}
{"text": "Convert the coordinate to text: [-2.77   -7.0385]: This paper proposes a multilingual persuasion detection system that incorporates persuasion technique attributes into a sequence classification transformer model, supporting up to 100 languages through a language agnostic approach utilizing the multilingual transformer module and Google translator interface.", "target": "This paper proposes a multilingual persuasion detection system that incorporates persuasion technique attributes into a sequence classification transformer model, supporting up to 100 languages through a language agnostic approach utilizing the multilingual transformer module and Google translator interface.", "example": "Convert the coordinate to text: [-2.77   -7.0385]:"}
{"text": "Convert the coordinate to text: [-3.4174 -4.4059]: The authors propose an approach to augment the training data, using BabelNet concepts and Wikipedia redirections to automatically annotate named entities from Wikipedia articles. They build their NER systems based on the mDeBERTa pretrained language model and train it on this augmented data.", "target": "The authors propose an approach to augment the training data, using BabelNet concepts and Wikipedia redirections to automatically annotate named entities from Wikipedia articles. They build their NER systems based on the mDeBERTa pretrained language model and train it on this augmented data.", "example": "Convert the coordinate to text: [-3.4174 -4.4059]:"}
{"text": "Convert the coordinate to text: [-2.0615 -6.1284]: The authors propose an ensemble method that combines the predictions of four distinct models: Longformer, RoBERTa, GCN, and a sentences number-based model.", "target": "The authors propose an ensemble method that combines the predictions of four distinct models: Longformer, RoBERTa, GCN, and a sentences number-based model.", "example": "Convert the coordinate to text: [-2.0615 -6.1284]:"}
{"text": "Convert the coordinate to text: [ 0.4281 -3.5527]: This study applies the k-nearest neighbor language model (kNN-LM) to the masked numeral prediction (MNP) task, as it extends pre-trained neural LMs with k-nearest neighbor (kNN) searches and can utilize patterns in the datastore for prediction, potentially improving numeral prediction accuracy.", "target": "This study applies the k-nearest neighbor language model (kNN-LM) to the masked numeral prediction (MNP) task, as it extends pre-trained neural LMs with k-nearest neighbor (kNN) searches and can utilize patterns in the datastore for prediction, potentially improving numeral prediction accuracy.", "example": "Convert the coordinate to text: [ 0.4281 -3.5527]:"}
{"text": "Convert the coordinate to text: [ 2.0557 -3.5475]: The paper introduces the Coarse-to-fine Few-shot NER (C2FNER) task and proposes an effective solution for it. The key idea is to learn group-wise discriminative representations during coarse training and focus on the granularity of new classes during few-shot learning.", "target": "The paper introduces the Coarse-to-fine Few-shot NER (C2FNER) task and proposes an effective solution for it. The key idea is to learn group-wise discriminative representations during coarse training and focus on the granularity of new classes during few-shot learning.", "example": "Convert the coordinate to text: [ 2.0557 -3.5475]:"}
{"text": "Convert the coordinate to text: [ 1.4894 -4.3803]: The authors propose a new pre-training task called Structural Contrast Pretraining (SCP) to align structural words in parallel sentences. They also propose Cross-lingual Momentum Contrast (CL-MoCo) to increase the number of negative pairs by maintaining a large queue size, further enhancing model performance.", "target": "The authors propose a new pre-training task called Structural Contrast Pretraining (SCP) to align structural words in parallel sentences. They also propose Cross-lingual Momentum Contrast (CL-MoCo) to increase the number of negative pairs by maintaining a large queue size, further enhancing model performance.", "example": "Convert the coordinate to text: [ 1.4894 -4.3803]:"}
{"text": "Convert the coordinate to text: [11.9007 -8.8586]: The authors propose a novel approach called Contrastive Transfer Pattern Mining (CTPM) which mines and utilizes inherent latent transfer patterns to improve the performance of Text Style Transfer. This is the first work that introduces the concept of transfer patterns in TST.", "target": "The authors propose a novel approach called Contrastive Transfer Pattern Mining (CTPM) which mines and utilizes inherent latent transfer patterns to improve the performance of Text Style Transfer. This is the first work that introduces the concept of transfer patterns in TST.", "example": "Convert the coordinate to text: [11.9007 -8.8586]:"}
{"text": "Convert the coordinate to text: [6.7487 7.5639]: The authors propose a new approach to privacy-preservation that leverages the learning-augmented algorithms framework to effectively use external information. This approach is applied to the task of multiple quantile release.", "target": "The authors propose a new approach to privacy-preservation that leverages the learning-augmented algorithms framework to effectively use external information. This approach is applied to the task of multiple quantile release.", "example": "Convert the coordinate to text: [6.7487 7.5639]:"}
{"text": "Convert the coordinate to text: [  5.603  -12.5789]: The authors propose a Progressive Bayesian Inference (PBI) framework to boost the performance of scribble-supervised semantic segmentation, by effectively inferring the semantic distribution of unlabeled pixels and using this information to guide the optimization of the segmentation network.", "target": "The authors propose a Progressive Bayesian Inference (PBI) framework to boost the performance of scribble-supervised semantic segmentation, by effectively inferring the semantic distribution of unlabeled pixels and using this information to guide the optimization of the segmentation network.", "example": "Convert the coordinate to text: [  5.603  -12.5789]:"}
{"text": "Convert the coordinate to text: [11.9925 -2.7492]: The authors propose a two-phase method for computing a safe weight set for BNN controllers. As long as the BNN controller uses weights from this safe set, the controlled system is guaranteed to be safe.", "target": "The authors propose a two-phase method for computing a safe weight set for BNN controllers. As long as the BNN controller uses weights from this safe set, the controlled system is guaranteed to be safe.", "example": "Convert the coordinate to text: [11.9925 -2.7492]:"}
{"text": "Convert the coordinate to text: [10.7398 -6.8648]: The authors explore the possibility of defining a latent space even when the denoising process remains stochastic. This results in a latent space of much higher dimensionality than the original image.", "target": "The authors explore the possibility of defining a latent space even when the denoising process remains stochastic. This results in a latent space of much higher dimensionality than the original image.", "example": "Convert the coordinate to text: [10.7398 -6.8648]:"}
{"text": "Convert the coordinate to text: [11.7074 -3.8529]: The paper first extends the concept of marginalized loss barrier and solution interpolation to BNNs, and then proposes a matching algorithm to search for linearly connected solutions. This is done by aligning the distributions of two independent approximate Bayesian solutions with respect to permutation matrices.", "target": "The paper first extends the concept of marginalized loss barrier and solution interpolation to BNNs, and then proposes a matching algorithm to search for linearly connected solutions. This is done by aligning the distributions of two independent approximate Bayesian solutions with respect to permutation matrices.", "example": "Convert the coordinate to text: [11.7074 -3.8529]:"}
{"text": "Convert the coordinate to text: [ 9.551  -2.2939]: The authors expose how the Pearson correlation matrix of feature maps influences the convergence rate and generalization capacity of an over-parameterized neural network. Following this analysis, they present a new zero-cost proxy, named MeCo, which requires only one random piece of data for a single forward pass. They also propose an optimization approach, MeCo_opt, to enhance the performance of their method.", "target": "The authors expose how the Pearson correlation matrix of feature maps influences the convergence rate and generalization capacity of an over-parameterized neural network. Following this analysis, they present a new zero-cost proxy, named MeCo, which requires only one random piece of data for a single forward pass. They also propose an optimization approach, MeCo_opt, to enhance the performance of their method.", "example": "Convert the coordinate to text: [ 9.551  -2.2939]:"}
{"text": "Convert the coordinate to text: [8.3161 7.6165]: Authors use PAC-Bayes theory to obtain generalization bounds on both the coverage and efficiency of set-valued predictors which can be directly optimized to maximize efficiency against a desired test coverage.", "target": "Authors use PAC-Bayes theory to obtain generalization bounds on both the coverage and efficiency of set-valued predictors which can be directly optimized to maximize efficiency against a desired test coverage.", "example": "Convert the coordinate to text: [8.3161 7.6165]:"}
{"text": "Convert the coordinate to text: [ 4.2143 -1.3602]: The paper proposes a deep learning paradigm called Scale-teaching to cope with noisy labels in time series data, based on a fine-to-coarse cross-scale fusion mechanism to learn discriminative patterns by utilizing time series at different scales.", "target": "The paper proposes a deep learning paradigm called Scale-teaching to cope with noisy labels in time series data, based on a fine-to-coarse cross-scale fusion mechanism to learn discriminative patterns by utilizing time series at different scales.", "example": "Convert the coordinate to text: [ 4.2143 -1.3602]:"}
{"text": "Convert the coordinate to text: [-0.7326  0.0729]: This paper presents Disentanglement based Cognitive Diagnosis (DCD), a model that works with limited exercise labels. The DCD model uses students' response records to model student proficiency, exercise difficulty, and exercise label distribution. Additionally, it introduces a group-based disentanglement and limited-labeled alignment modules to separate the factors relevant to concepts and align them with real limited labels.", "target": "This paper presents Disentanglement based Cognitive Diagnosis (DCD), a model that works with limited exercise labels. The DCD model uses students' response records to model student proficiency, exercise difficulty, and exercise label distribution. Additionally, it introduces a group-based disentanglement and limited-labeled alignment modules to separate the factors relevant to concepts and align them with real limited labels.", "example": "Convert the coordinate to text: [-0.7326  0.0729]:"}
{"text": "Convert the coordinate to text: [13.5295 -2.2212]: The authors propose that inhibitory/negative weights are fundamental for the learning of more diverse functions in both natural and artificial intelligence systems.", "target": "The authors propose that inhibitory/negative weights are fundamental for the learning of more diverse functions in both natural and artificial intelligence systems.", "example": "Convert the coordinate to text: [13.5295 -2.2212]:"}
{"text": "Convert the coordinate to text: [9.3881 7.2618]: The authors present a concept inspired by the predictor-corrector for ODE solvers, introducing a Unified Corrector (UniC) that can amplify the accuracy of any existing DPM sampler without extra model evaluations, and a Unified Predictor (UniP). These two are combined into a unified predictor-corrector framework (UniPC) for fast DPM sampling.", "target": "The authors present a concept inspired by the predictor-corrector for ODE solvers, introducing a Unified Corrector (UniC) that can amplify the accuracy of any existing DPM sampler without extra model evaluations, and a Unified Predictor (UniP). These two are combined into a unified predictor-corrector framework (UniPC) for fast DPM sampling.", "example": "Convert the coordinate to text: [9.3881 7.2618]:"}
{"text": "Convert the coordinate to text: [-4.3379 -8.7212]: This study proposes using large amounts of target-side monolingual data to enhance ST without transcripts. A back translation algorithm for ST (BT4ST) is developed to synthesize pseudo ST data from monolingual target data by introducing self-supervised discrete units.", "target": "This study proposes using large amounts of target-side monolingual data to enhance ST without transcripts. A back translation algorithm for ST (BT4ST) is developed to synthesize pseudo ST data from monolingual target data by introducing self-supervised discrete units.", "example": "Convert the coordinate to text: [-4.3379 -8.7212]:"}
{"text": "Convert the coordinate to text: [-12.5764   2.6802]: The authors propose a Semantic Web approach for exchanging Model/Data Cards as Linked Data or knowledge graphs in a dataspace, making them machine-readable. They suggest a schema for linking Data Cards and Model Cards within a dataspace and introduce the concept of a dataspace card which can be a starting point for extracting knowledge about models and datasets in a dataspace.", "target": "The authors propose a Semantic Web approach for exchanging Model/Data Cards as Linked Data or knowledge graphs in a dataspace, making them machine-readable. They suggest a schema for linking Data Cards and Model Cards within a dataspace and introduce the concept of a dataspace card which can be a starting point for extracting knowledge about models and datasets in a dataspace.", "example": "Convert the coordinate to text: [-12.5764   2.6802]:"}
{"text": "Convert the coordinate to text: [-3.8128 -7.2271]: The authors propose a dual-alignment pre-training (DAP) framework for cross-lingual sentence embedding that incorporates both sentence-level and token-level alignment, accomplished through a novel representation translation learning (RTL) task.", "target": "The authors propose a dual-alignment pre-training (DAP) framework for cross-lingual sentence embedding that incorporates both sentence-level and token-level alignment, accomplished through a novel representation translation learning (RTL) task.", "example": "Convert the coordinate to text: [-3.8128 -7.2271]:"}
{"text": "Convert the coordinate to text: [-1.2249 -0.014 ]: In this study, the authors conduct an error analysis to understand how three commercial Machine Translation systems translate 3rd-person pronouns, specifically focusing on the translations of gendered versus gender-neutral pronouns.", "target": "In this study, the authors conduct an error analysis to understand how three commercial Machine Translation systems translate 3rd-person pronouns, specifically focusing on the translations of gendered versus gender-neutral pronouns.", "example": "Convert the coordinate to text: [-1.2249 -0.014 ]:"}
{"text": "Convert the coordinate to text: [ 0.5815 -9.5713]: The authors propose a table and image generation task to verify the retention of entity knowledge in V & L models. The task requires models to generate a table containing knowledge about an entity and its related image, and to generate an image from an entity with a caption and a table containing related knowledge.", "target": "The authors propose a table and image generation task to verify the retention of entity knowledge in V & L models. The task requires models to generate a table containing knowledge about an entity and its related image, and to generate an image from an entity with a caption and a table containing related knowledge.", "example": "Convert the coordinate to text: [ 0.5815 -9.5713]:"}
{"text": "Convert the coordinate to text: [ 4.087  -5.0708]: The study presents a novel 3D pre-training framework, 3D PGT, which pre-trains a model on 3D molecular graphs, and fine-tunes it on molecular graphs not requiring 3D structures. The authors further develop a multi-task generative pre-train framework based on bond length, bond angle, and dihedral angle, which are key geometric descriptors, and design a surrogate metric that uses total energy to search for weight distribution.", "target": "The study presents a novel 3D pre-training framework, 3D PGT, which pre-trains a model on 3D molecular graphs, and fine-tunes it on molecular graphs not requiring 3D structures. The authors further develop a multi-task generative pre-train framework based on bond length, bond angle, and dihedral angle, which are key geometric descriptors, and design a surrogate metric that uses total energy to search for weight distribution.", "example": "Convert the coordinate to text: [ 4.087  -5.0708]:"}
{"text": "Convert the coordinate to text: [-2.2736 -5.1792]: This paper addresses this gap by discussing how to adapt existing application-specific generation benchmarks to PLMs and provides an empirical study of the limitations and capabilities of PLMs in natural language generation tasks.", "target": "This paper addresses this gap by discussing how to adapt existing application-specific generation benchmarks to PLMs and provides an empirical study of the limitations and capabilities of PLMs in natural language generation tasks.", "example": "Convert the coordinate to text: [-2.2736 -5.1792]:"}
{"text": "Convert the coordinate to text: [-10.2408  -8.1417]: The authors propose a method for formulating CCG as a recursive composition in a continuous vector space, leveraging the method of holographic embeddings as a compositional operator to model explicitly the dependencies between words and phrase structures.", "target": "The authors propose a method for formulating CCG as a recursive composition in a continuous vector space, leveraging the method of holographic embeddings as a compositional operator to model explicitly the dependencies between words and phrase structures.", "example": "Convert the coordinate to text: [-10.2408  -8.1417]:"}
{"text": "Convert the coordinate to text: [-1.0933 -5.1166]: The novel method proposed in the paper is a prompt tuning approach called MixPAVE, which uses mixed prompts for few-shot attribute value extraction. MixPAVE introduces only a small amount (< 1%) of trainable parameters while keeping the existing extraction model frozen to benefit from parameter-efficient training and avoid overfitting on limited training examples.", "target": "The novel method proposed in the paper is a prompt tuning approach called MixPAVE, which uses mixed prompts for few-shot attribute value extraction. MixPAVE introduces only a small amount (< 1%) of trainable parameters while keeping the existing extraction model frozen to benefit from parameter-efficient training and avoid overfitting on limited training examples.", "example": "Convert the coordinate to text: [-1.0933 -5.1166]:"}
{"text": "Convert the coordinate to text: [3.0094 5.8117]: The paper proposes polynomial-time algorithms for finding top-K relevant walks in GNNs, aiming to decrease the computational complexity of GNN-LRP.", "target": "The paper proposes polynomial-time algorithms for finding top-K relevant walks in GNNs, aiming to decrease the computational complexity of GNN-LRP.", "example": "Convert the coordinate to text: [3.0094 5.8117]:"}
{"text": "Convert the coordinate to text: [10.7104 -1.7439]: The authors propose a new perspective on Binary Neural Networks (BNNs) training, which they regard as an equilibrium between the estimating error and the gradient stability. Within this context, they propose a power function based estimator called Rectified Straight Through Estimator (ReSTE), which provides a better balance between the estimating error and the gradient stability.", "target": "The authors propose a new perspective on Binary Neural Networks (BNNs) training, which they regard as an equilibrium between the estimating error and the gradient stability. Within this context, they propose a power function based estimator called Rectified Straight Through Estimator (ReSTE), which provides a better balance between the estimating error and the gradient stability.", "example": "Convert the coordinate to text: [10.7104 -1.7439]:"}
{"text": "Convert the coordinate to text: [0.9127 1.4509]: The authors propose a framework named Offline Imitation Learning with Counterfactual data Augmentation (OILCA) which leverages identifiable variational autoencoder to generate counterfactual samples, aiming to remove spurious features that bias the agent and hinder generalization.", "target": "The authors propose a framework named Offline Imitation Learning with Counterfactual data Augmentation (OILCA) which leverages identifiable variational autoencoder to generate counterfactual samples, aiming to remove spurious features that bias the agent and hinder generalization.", "example": "Convert the coordinate to text: [0.9127 1.4509]:"}
{"text": "Convert the coordinate to text: [13.3816  6.2568]: The authors propose SAMA, a system that combines advances in implicit differentiation algorithms and systems to increase the scalability of meta learning. SAMA is designed to support a broad range of adaptive optimizers, reduce computational burden by avoiding explicit computation of second-order gradient information, and exploit efficient distributed training methods.", "target": "The authors propose SAMA, a system that combines advances in implicit differentiation algorithms and systems to increase the scalability of meta learning. SAMA is designed to support a broad range of adaptive optimizers, reduce computational burden by avoiding explicit computation of second-order gradient information, and exploit efficient distributed training methods.", "example": "Convert the coordinate to text: [13.3816  6.2568]:"}
{"text": "Convert the coordinate to text: [  9.6382 -11.4887]: The paper presents a novel learning-based method, DMNet (Delaunay Meshing Network), for 3D shape representation that uses Delaunay triangulation for high-precision reconstruction. The model treats Delaunay triangulation as a dual graph and incorporates local geometric information from the points into the structure of the triangulation.", "target": "The paper presents a novel learning-based method, DMNet (Delaunay Meshing Network), for 3D shape representation that uses Delaunay triangulation for high-precision reconstruction. The model treats Delaunay triangulation as a dual graph and incorporates local geometric information from the points into the structure of the triangulation.", "example": "Convert the coordinate to text: [  9.6382 -11.4887]:"}
{"text": "Convert the coordinate to text: [ 11.6991 -13.3187]: The authors propose a self-supervised framework that takes a monocular video of a moving human as input and generates a 3D neural representation that can be rendered with novel poses under arbitrary lighting conditions using a decomposition of dynamic humans into neural fields and pose-driven deformation fields.", "target": "The authors propose a self-supervised framework that takes a monocular video of a moving human as input and generates a 3D neural representation that can be rendered with novel poses under arbitrary lighting conditions using a decomposition of dynamic humans into neural fields and pose-driven deformation fields.", "example": "Convert the coordinate to text: [ 11.6991 -13.3187]:"}
{"text": "Convert the coordinate to text: [-2.774  -5.4371]: This paper proposes the use of large language models (LLMs) as query rewriters, which generate informative query rewrites through well-designed instructions. The authors also introduce a 'rewrite-then-edit' process, along with the concept of distilling LLM's rewriting capabilities to smaller models for reduced rewriting latency.", "target": "This paper proposes the use of large language models (LLMs) as query rewriters, which generate informative query rewrites through well-designed instructions. The authors also introduce a 'rewrite-then-edit' process, along with the concept of distilling LLM's rewriting capabilities to smaller models for reduced rewriting latency.", "example": "Convert the coordinate to text: [-2.774  -5.4371]:"}
{"text": "Convert the coordinate to text: [-3.6231  7.1412]: The authors propose a new metric for inference efficiency, called idealized runtime, which aims to provide a level comparison as though the models were served on uniform hardware and software without performance contention. Additionally, they propose a cost model to efficiently estimate this metric for autoregressive Transformer models.", "target": "The authors propose a new metric for inference efficiency, called idealized runtime, which aims to provide a level comparison as though the models were served on uniform hardware and software without performance contention. Additionally, they propose a cost model to efficiently estimate this metric for autoregressive Transformer models.", "example": "Convert the coordinate to text: [-3.6231  7.1412]:"}
{"text": "Convert the coordinate to text: [-1.6869 -4.1708]: The researchers propose a novel multi-task information interaction framework to improve IUR. This includes context selection, edit matrix construction, and relevance merging steps to capture semantic information at multiple levels of granularity.", "target": "The researchers propose a novel multi-task information interaction framework to improve IUR. This includes context selection, edit matrix construction, and relevance merging steps to capture semantic information at multiple levels of granularity.", "example": "Convert the coordinate to text: [-1.6869 -4.1708]:"}
{"text": "Convert the coordinate to text: [  7.4809 -21.0849]: This paper introduces a new benchmark dataset for reflection removal called SIR^2+ that considers in-the-wild scenarios and diverse glass colors and shapes.", "target": "This paper introduces a new benchmark dataset for reflection removal called SIR^2+ that considers in-the-wild scenarios and diverse glass colors and shapes.", "example": "Convert the coordinate to text: [  7.4809 -21.0849]:"}
{"text": "Convert the coordinate to text: [ 2.3601 -6.7642]: The authors propose pretraining without attention, investigating routing layers based on state-space models (SSM) and model architectures based on multiplicative gating.", "target": "The authors propose pretraining without attention, investigating routing layers based on state-space models (SSM) and model architectures based on multiplicative gating.", "example": "Convert the coordinate to text: [ 2.3601 -6.7642]:"}
{"text": "Convert the coordinate to text: [-1.5846 -4.7479]: A novel approach called Knowledge Injection into Language Models (KILM) is proposed, which injects entity-related knowledge into encoder-decoder PLMs via a generative knowledge infilling objective through continued pre-training, without needing any architectural modifications or additional parameters.", "target": "A novel approach called Knowledge Injection into Language Models (KILM) is proposed, which injects entity-related knowledge into encoder-decoder PLMs via a generative knowledge infilling objective through continued pre-training, without needing any architectural modifications or additional parameters.", "example": "Convert the coordinate to text: [-1.5846 -4.7479]:"}
{"text": "Convert the coordinate to text: [7.0678 7.7294]: The authors propose studying DP machine learning algorithms as instances of noisy fixed-point iterations, which recovers popular privacy gradient-based methods and provides a principled way to design and analyze new private optimization algorithms.", "target": "The authors propose studying DP machine learning algorithms as instances of noisy fixed-point iterations, which recovers popular privacy gradient-based methods and provides a principled way to design and analyze new private optimization algorithms.", "example": "Convert the coordinate to text: [7.0678 7.7294]:"}
{"text": "Convert the coordinate to text: [-4.3766 -3.1744]: The authors organized the LegalEval shared task in SemEval 2023, which is aimed at promoting research in legal NLP. It consists of three sub-tasks: Rhetorical Roles Labeling, Legal Named Entity Recognition, and Court Judgement Prediction.", "target": "The authors organized the LegalEval shared task in SemEval 2023, which is aimed at promoting research in legal NLP. It consists of three sub-tasks: Rhetorical Roles Labeling, Legal Named Entity Recognition, and Court Judgement Prediction.", "example": "Convert the coordinate to text: [-4.3766 -3.1744]:"}
{"text": "Convert the coordinate to text: [ 3.6001 -4.0373]: The authors propose the Serial Contrastive Knowledge Distillation (SCKD) model that uses serial knowledge distillation to preserve prior knowledge from previous models and conducts contrastive learning with pseudo samples to keep representations of samples in different relations distinguishable.", "target": "The authors propose the Serial Contrastive Knowledge Distillation (SCKD) model that uses serial knowledge distillation to preserve prior knowledge from previous models and conducts contrastive learning with pseudo samples to keep representations of samples in different relations distinguishable.", "example": "Convert the coordinate to text: [ 3.6001 -4.0373]:"}
{"text": "Convert the coordinate to text: [-3.4503 -5.6114]: The paper proposes a fully unsupervised approach for text encoding, which involves training small character-based models to reconstruct large pre-trained embedding matrices.", "target": "The paper proposes a fully unsupervised approach for text encoding, which involves training small character-based models to reconstruct large pre-trained embedding matrices.", "example": "Convert the coordinate to text: [-3.4503 -5.6114]:"}
{"text": "Convert the coordinate to text: [-6.5742 -4.9907]: The paper introduces the paradigm of word sense extension (WSE) that allows words to spawn new senses toward novel context. It simulates this by partitioning a polysemous word type into two pseudo-tokens.", "target": "The paper introduces the paradigm of word sense extension (WSE) that allows words to spawn new senses toward novel context. It simulates this by partitioning a polysemous word type into two pseudo-tokens.", "example": "Convert the coordinate to text: [-6.5742 -4.9907]:"}
{"text": "Convert the coordinate to text: [ 5.2739 -4.3802]: The paper proposes an iterative framework to investigate different sparsification models to optimize graph classification performance and interpretability. A new model, Interpretable Graph Sparsification (IGS), is proposed based on the findings of this framework.", "target": "The paper proposes an iterative framework to investigate different sparsification models to optimize graph classification performance and interpretability. A new model, Interpretable Graph Sparsification (IGS), is proposed based on the findings of this framework.", "example": "Convert the coordinate to text: [ 5.2739 -4.3802]:"}
{"text": "Convert the coordinate to text: [-0.9889 -5.1074]: In response to the real-world challenges, the paper presents a parameter- and deployment-efficient prompt tuning method, Lottery Prompt Tuning (LPT), aiming to amplify the UIE system's knowledge sharing and expansion, prevent catastrophic forgetting and rapidly generalize on few-shot and unseen tasks.", "target": "In response to the real-world challenges, the paper presents a parameter- and deployment-efficient prompt tuning method, Lottery Prompt Tuning (LPT), aiming to amplify the UIE system's knowledge sharing and expansion, prevent catastrophic forgetting and rapidly generalize on few-shot and unseen tasks.", "example": "Convert the coordinate to text: [-0.9889 -5.1074]:"}
{"text": "Convert the coordinate to text: [-8.7314 -3.6007]: The authors aim to develop an online system called MetaPro Online that can process metaphoric expressions. This system is intended to be accessible even to users without a coding background, like language learners and linguists.", "target": "The authors aim to develop an online system called MetaPro Online that can process metaphoric expressions. This system is intended to be accessible even to users without a coding background, like language learners and linguists.", "example": "Convert the coordinate to text: [-8.7314 -3.6007]:"}
{"text": "Convert the coordinate to text: [16.2124  1.8022]: The authors introduce a new task paradigm that combines Classification and Discovering into a method called Open Environment Intent Prediction, designed to provide further, fine-grained discovery of OOD based on OOD Intent Classification. They propose a general scheme for this that involves performing intent detection to identify In-domain samples and then generating labels for those identified as OOD.", "target": "The authors introduce a new task paradigm that combines Classification and Discovering into a method called Open Environment Intent Prediction, designed to provide further, fine-grained discovery of OOD based on OOD Intent Classification. They propose a general scheme for this that involves performing intent detection to identify In-domain samples and then generating labels for those identified as OOD.", "example": "Convert the coordinate to text: [16.2124  1.8022]:"}
{"text": "Convert the coordinate to text: [ 6.0424 -3.5703]: The authors address these challenges by proposing a hierarchical model that integrates domain-adaptive pretraining, data augmentation, and auxiliary-task learning techniques.", "target": "The authors address these challenges by proposing a hierarchical model that integrates domain-adaptive pretraining, data augmentation, and auxiliary-task learning techniques.", "example": "Convert the coordinate to text: [ 6.0424 -3.5703]:"}
{"text": "Convert the coordinate to text: [-3.4231 -9.439 ]: The proposed solution involves a Transformer-based machine translation model and a phoneme duration predictor for automatic dubbing. The solution uses multiple target-to-source length-ratio class labels to control target lengths and employs FastSpeech2's variation predictor to ascertain phoneme durations.", "target": "The proposed solution involves a Transformer-based machine translation model and a phoneme duration predictor for automatic dubbing. The solution uses multiple target-to-source length-ratio class labels to control target lengths and employs FastSpeech2's variation predictor to ascertain phoneme durations.", "example": "Convert the coordinate to text: [-3.4231 -9.439 ]:"}
{"text": "Convert the coordinate to text: [-3.9504 -1.1803]: The authors propose a novel event-independent representation of temporal relations that is task-independent and, therefore, domain-independent. The concept is to identify homogeneous text portions from a temporal standpoint and classify the relation between each text portion and the document creation time.", "target": "The authors propose a novel event-independent representation of temporal relations that is task-independent and, therefore, domain-independent. The concept is to identify homogeneous text portions from a temporal standpoint and classify the relation between each text portion and the document creation time.", "example": "Convert the coordinate to text: [-3.9504 -1.1803]:"}
{"text": "Convert the coordinate to text: [-2.8176 -7.0723]: The authors propose PlugIn-X, a method to activate the cross-lingual transferability of multilingual Transformers without end-task data. This is done by disassembling monolingual and multilingual Transformers into sub-modules, reassembling them into the multilingual end-task model, and performing cross-lingual transfer in a plug-and-play style after representation adaptation.", "target": "The authors propose PlugIn-X, a method to activate the cross-lingual transferability of multilingual Transformers without end-task data. This is done by disassembling monolingual and multilingual Transformers into sub-modules, reassembling them into the multilingual end-task model, and performing cross-lingual transfer in a plug-and-play style after representation adaptation.", "example": "Convert the coordinate to text: [-2.8176 -7.0723]:"}
{"text": "Convert the coordinate to text: [-5.863 10.231]: The authors introduce the first multimodal dataset for modeling persuasion behaviors, captured in a multi-player social deduction game setting, including dialogue transcriptions, videos, persuasion strategy annotations, and game outcome annotations.", "target": "The authors introduce the first multimodal dataset for modeling persuasion behaviors, captured in a multi-player social deduction game setting, including dialogue transcriptions, videos, persuasion strategy annotations, and game outcome annotations.", "example": "Convert the coordinate to text: [-5.863 10.231]:"}
{"text": "Convert the coordinate to text: [-3.2711  0.9728]: The authors propose a novel framework for learning task-agnostic representations that are transferable to a wide range of sociopragmatic tasks such as emotion detection, hate speech detection, humor, and sarcasm identification.", "target": "The authors propose a novel framework for learning task-agnostic representations that are transferable to a wide range of sociopragmatic tasks such as emotion detection, hate speech detection, humor, and sarcasm identification.", "example": "Convert the coordinate to text: [-3.2711  0.9728]:"}
{"text": "Convert the coordinate to text: [-4.8179 -3.2485]: The study presents a new approach for Event Coreference Resolution (ECR) that partitions the task into two segments: a heuristic to significantly filter out a large number of non-coreferent pairs and a training methodology on a balanced set of coreferent and non-coreferent mention pairs.", "target": "The study presents a new approach for Event Coreference Resolution (ECR) that partitions the task into two segments: a heuristic to significantly filter out a large number of non-coreferent pairs and a training methodology on a balanced set of coreferent and non-coreferent mention pairs.", "example": "Convert the coordinate to text: [-4.8179 -3.2485]:"}
{"text": "Convert the coordinate to text: [-6.0589 11.1912]: The authors propose PEEP-Talk, a real-world situational dialogue-based chatbot designed for English education that can handle out-of-topic utterance by switching to a new topic or situation and provides feedback scores on conversation and grammar error correction.", "target": "The authors propose PEEP-Talk, a real-world situational dialogue-based chatbot designed for English education that can handle out-of-topic utterance by switching to a new topic or situation and provides feedback scores on conversation and grammar error correction.", "example": "Convert the coordinate to text: [-6.0589 11.1912]:"}
{"text": "Convert the coordinate to text: [  4.8195 -14.2542]: The authors propose a unified approach to the problem of joint extraction, registration and segmentation in neuroimaging data, using only a single labeled template image and a few unlabeled raw images for training.", "target": "The authors propose a unified approach to the problem of joint extraction, registration and segmentation in neuroimaging data, using only a single labeled template image and a few unlabeled raw images for training.", "example": "Convert the coordinate to text: [  4.8195 -14.2542]:"}
{"text": "Convert the coordinate to text: [-1.0967 -5.1285]: The authors propose HybridPrompt, a cloze-and-verify-style hybrid prompt framework that bridges language models and human priors in order to improve the performance of VQA tasks.", "target": "The authors propose HybridPrompt, a cloze-and-verify-style hybrid prompt framework that bridges language models and human priors in order to improve the performance of VQA tasks.", "example": "Convert the coordinate to text: [-1.0967 -5.1285]:"}
{"text": "Convert the coordinate to text: [ 9.2596 -8.1744]: The authors propose a method called Dilated Convolutional Transformer (DCT), which combines the properties of CNNs and Transformers to improve image deraining. The core of this method is the Dilformer block, which includes multi-dilconv sparse attention (MDSA) and multi-dilconv feed-forward network (MDFN) to better utilize multi-scale information for high-quality image reconstruction.", "target": "The authors propose a method called Dilated Convolutional Transformer (DCT), which combines the properties of CNNs and Transformers to improve image deraining. The core of this method is the Dilformer block, which includes multi-dilconv sparse attention (MDSA) and multi-dilconv feed-forward network (MDFN) to better utilize multi-scale information for high-quality image reconstruction.", "example": "Convert the coordinate to text: [ 9.2596 -8.1744]:"}
{"text": "Convert the coordinate to text: [ 4.6894 -4.8213]: The paper presents a novel Cross-view Topology based Consistent and Complementary information extraction framework, termed CTCC. This framework uses deep embeddings from the bipartite graph learning module for each view individually. Then CTCC constructs the cross-view topological graph based on the OT distance between the bipartite graph of each view.", "target": "The paper presents a novel Cross-view Topology based Consistent and Complementary information extraction framework, termed CTCC. This framework uses deep embeddings from the bipartite graph learning module for each view individually. Then CTCC constructs the cross-view topological graph based on the OT distance between the bipartite graph of each view.", "example": "Convert the coordinate to text: [ 4.6894 -4.8213]:"}
{"text": "Convert the coordinate to text: [ 5.953  14.0582]: The authors propose a novel method in which fully or partially resetting the parameters of deep reinforcement learning agents leads to better replay ratio scaling capabilities.", "target": "The authors propose a novel method in which fully or partially resetting the parameters of deep reinforcement learning agents leads to better replay ratio scaling capabilities.", "example": "Convert the coordinate to text: [ 5.953  14.0582]:"}
{"text": "Convert the coordinate to text: [2.6586 1.3302]: This paper attributes the instability of Influence Functions (IFs) to the differences in class distinction and proposes a solution that utilizes class information to enhance their reliability.", "target": "This paper attributes the instability of Influence Functions (IFs) to the differences in class distinction and proposes a solution that utilizes class information to enhance their reliability.", "example": "Convert the coordinate to text: [2.6586 1.3302]:"}
{"text": "Convert the coordinate to text: [-7.0882 -6.2844]: This paper is a survey on the major works undertaken in zero pronoun translation (ZPT) after the advent of neural technologies, aiming to provide an overview of the current state and future directions of ZPT.", "target": "This paper is a survey on the major works undertaken in zero pronoun translation (ZPT) after the advent of neural technologies, aiming to provide an overview of the current state and future directions of ZPT.", "example": "Convert the coordinate to text: [-7.0882 -6.2844]:"}
{"text": "Convert the coordinate to text: [2.1474 2.0446]: The authors explore the cumulative impact of numerous intersecting features on a model, and whether these spurious patterns in the data are reflected in models trained on this data. This investigation is facilitated through a new statistical method and the reweighting of training data to reduce thousands of spurious correlations.", "target": "The authors explore the cumulative impact of numerous intersecting features on a model, and whether these spurious patterns in the data are reflected in models trained on this data. This investigation is facilitated through a new statistical method and the reweighting of training data to reduce thousands of spurious correlations.", "example": "Convert the coordinate to text: [2.1474 2.0446]:"}
{"text": "Convert the coordinate to text: [-0.2655 -4.2642]: The authors propose a method to improve dataset quality for persona attribute extraction by using more reliable text-label matching criteria. They also introduce a contrastive learning- and generation-based model with a novel hard negative sampling strategy for generalized zero-shot persona attribute extraction.", "target": "The authors propose a method to improve dataset quality for persona attribute extraction by using more reliable text-label matching criteria. They also introduce a contrastive learning- and generation-based model with a novel hard negative sampling strategy for generalized zero-shot persona attribute extraction.", "example": "Convert the coordinate to text: [-0.2655 -4.2642]:"}
{"text": "Convert the coordinate to text: [-1.9684 -6.5127]: The authors explore the use of pre-trained RoBERTa models for these tasks, testing different oversampling strategies and a strategy of adding textual features from predictions obtained with related models.", "target": "The authors explore the use of pre-trained RoBERTa models for these tasks, testing different oversampling strategies and a strategy of adding textual features from predictions obtained with related models.", "example": "Convert the coordinate to text: [-1.9684 -6.5127]:"}
{"text": "Convert the coordinate to text: [-4.3439 -9.5154]: This paper introduces Matesub, a professional web-based tool developed by Translated, which combines AI technology with a What-You-See-Is-What-You-Get (WYSIWYG) editor to generate subtitles.", "target": "This paper introduces Matesub, a professional web-based tool developed by Translated, which combines AI technology with a What-You-See-Is-What-You-Get (WYSIWYG) editor to generate subtitles.", "example": "Convert the coordinate to text: [-4.3439 -9.5154]:"}
{"text": "Convert the coordinate to text: [-4.0928 -9.0978]: The paper presents the Kyoto speech-to-speech translation system for IWSLT 2023, which is a combination of a speech-to-text translation model and a text-to-speech synthesis model.", "target": "The paper presents the Kyoto speech-to-speech translation system for IWSLT 2023, which is a combination of a speech-to-text translation model and a text-to-speech synthesis model.", "example": "Convert the coordinate to text: [-4.0928 -9.0978]:"}
{"text": "Convert the coordinate to text: [-1.9934 -5.3998]: This study introduces a dataset of Socratic conversations where an instructor assists a novice programmer in debugging solutions to computational problems and uses it to benchmark the Socratic debugging abilities of GPT-based language models.", "target": "This study introduces a dataset of Socratic conversations where an instructor assists a novice programmer in debugging solutions to computational problems and uses it to benchmark the Socratic debugging abilities of GPT-based language models.", "example": "Convert the coordinate to text: [-1.9934 -5.3998]:"}
{"text": "Convert the coordinate to text: [-5.6811 -6.2898]: The authors propose ALEXSIS+ and ALEXSIS++, multilingual and monolingual datasets respectively, containing over 50,000 unique sentences retrieved from news corpora, annotated with cosine similarities to the original complex word and sentence, to generate high-quality candidate substitutions for LS.", "target": "The authors propose ALEXSIS+ and ALEXSIS++, multilingual and monolingual datasets respectively, containing over 50,000 unique sentences retrieved from news corpora, annotated with cosine similarities to the original complex word and sentence, to generate high-quality candidate substitutions for LS.", "example": "Convert the coordinate to text: [-5.6811 -6.2898]:"}
{"text": "Convert the coordinate to text: [-1.555   8.7912]: The authors developed a benchmark called SylloBase, which includes a complete taxonomy of syllogistic reasoning patterns, and contains both automatically and manually constructed samples for generation and understanding tasks.", "target": "The authors developed a benchmark called SylloBase, which includes a complete taxonomy of syllogistic reasoning patterns, and contains both automatically and manually constructed samples for generation and understanding tasks.", "example": "Convert the coordinate to text: [-1.555   8.7912]:"}
{"text": "Convert the coordinate to text: [-2.1238 -3.3456]: The authors propose a multilingual Knowledge Graph Question Answering (KGQA) technique that orders potential responses based on the distance between the question's text embeddings and the answer's graph embeddings.", "target": "The authors propose a multilingual Knowledge Graph Question Answering (KGQA) technique that orders potential responses based on the distance between the question's text embeddings and the answer's graph embeddings.", "example": "Convert the coordinate to text: [-2.1238 -3.3456]:"}
{"text": "Convert the coordinate to text: [ 2.7062 -6.6258]: The paper proposes a novel end-to-end deep neural network for stock movement prediction, called Causality-guided Multi-memory Interaction Network (CMIN). CMIN models the multi-modality between financial text data and causality-enhanced stock correlations. It also introduces a fusion mechanism to model multi-directional interactions representing interrelationships between text and stock correlations.", "target": "The paper proposes a novel end-to-end deep neural network for stock movement prediction, called Causality-guided Multi-memory Interaction Network (CMIN). CMIN models the multi-modality between financial text data and causality-enhanced stock correlations. It also introduces a fusion mechanism to model multi-directional interactions representing interrelationships between text and stock correlations.", "example": "Convert the coordinate to text: [ 2.7062 -6.6258]:"}
{"text": "Convert the coordinate to text: [-4.1095 -5.7079]: The authors propose a method called Parallel Context Windows (PCW) that carved a long context into chunks to alleviate the context window restriction for any off-the-shelf Large Language Model without requiring further training.", "target": "The authors propose a method called Parallel Context Windows (PCW) that carved a long context into chunks to alleviate the context window restriction for any off-the-shelf Large Language Model without requiring further training.", "example": "Convert the coordinate to text: [-4.1095 -5.7079]:"}
{"text": "Convert the coordinate to text: [ 9.0826 -9.138 ]: The authors propose a novel multi-scale bidirectional recurrent architecture that iteratively optimizes the coarse-to-fine scene flow estimation. The system uses a new bidirectional gated recurrent unit that progressively augments point features and optimizes scene flow at each resolution.", "target": "The authors propose a novel multi-scale bidirectional recurrent architecture that iteratively optimizes the coarse-to-fine scene flow estimation. The system uses a new bidirectional gated recurrent unit that progressively augments point features and optimizes scene flow at each resolution.", "example": "Convert the coordinate to text: [ 9.0826 -9.138 ]:"}
{"text": "Convert the coordinate to text: [ 5.0004 -5.0015]: The authors propose a generic graph-structured Gaussian process framework (GraphGP) for adaptively transferring knowledge across graphs with either homophily or heterophily assumptions, derived from a new graph structure-aware neural network.", "target": "The authors propose a generic graph-structured Gaussian process framework (GraphGP) for adaptively transferring knowledge across graphs with either homophily or heterophily assumptions, derived from a new graph structure-aware neural network.", "example": "Convert the coordinate to text: [ 5.0004 -5.0015]:"}
{"text": "Convert the coordinate to text: [ 3.5297 -2.9073]: The authors propose Task-aware Environment Modeling Pipeline with bi-level Optimization (TEMPO), a framework that introduces an additional level of optimization on top of a maximum-likelihood model, incorporating a meta weighter network that weights each training sample.", "target": "The authors propose Task-aware Environment Modeling Pipeline with bi-level Optimization (TEMPO), a framework that introduces an additional level of optimization on top of a maximum-likelihood model, incorporating a meta weighter network that weights each training sample.", "example": "Convert the coordinate to text: [ 3.5297 -2.9073]:"}
{"text": "Convert the coordinate to text: [ 7.5324 -2.1282]: To address this, the authors propose a method to identify backdoor clients by explicitly modeling the data divergence among clients in federated NLP systems. They introduce the novel Federated F-Divergence-Based Aggregation~(Fed-FA) algorithm, which uses the f-divergence indicator to detect and discard suspicious clients.", "target": "To address this, the authors propose a method to identify backdoor clients by explicitly modeling the data divergence among clients in federated NLP systems. They introduce the novel Federated F-Divergence-Based Aggregation~(Fed-FA) algorithm, which uses the f-divergence indicator to detect and discard suspicious clients.", "example": "Convert the coordinate to text: [ 7.5324 -2.1282]:"}
{"text": "Convert the coordinate to text: [  6.8383 -20.2203]: The authors found that pretraining shadow removal networks on image inpainting datasets can reduce shadow remnants drastically, and proposed shadow removal as an adaptive fusion task taking advantage of both shadow removal and image inpainting processes.", "target": "The authors found that pretraining shadow removal networks on image inpainting datasets can reduce shadow remnants drastically, and proposed shadow removal as an adaptive fusion task taking advantage of both shadow removal and image inpainting processes.", "example": "Convert the coordinate to text: [  6.8383 -20.2203]:"}
{"text": "Convert the coordinate to text: [-14.3753  15.4184]: The authors propose the OCOsenseTM smart glasses system that uses non-contact optomyographic OCOTM sensors and an IMU to recognize and monitor facial gestures and expressions. Recognized gestures and expressions are used as input to interact with the mobile device.", "target": "The authors propose the OCOsenseTM smart glasses system that uses non-contact optomyographic OCOTM sensors and an IMU to recognize and monitor facial gestures and expressions. Recognized gestures and expressions are used as input to interact with the mobile device.", "example": "Convert the coordinate to text: [-14.3753  15.4184]:"}
{"text": "Convert the coordinate to text: [-1.3256 -8.3341]: The authors link the modality gap in neural machine translation to exposure bias and propose the Cross-modal Regularization with Scheduled Sampling (Cress) method that regularizes the output predictions of ST and MT.", "target": "The authors link the modality gap in neural machine translation to exposure bias and propose the Cross-modal Regularization with Scheduled Sampling (Cress) method that regularizes the output predictions of ST and MT.", "example": "Convert the coordinate to text: [-1.3256 -8.3341]:"}
{"text": "Convert the coordinate to text: [ 2.3247 -3.734 ]: The authors propose ClusterNS (Clustering-aware Negative Sampling), a novel method that incorporates cluster information into contrastive learning for unsupervised sentence representation learning.", "target": "The authors propose ClusterNS (Clustering-aware Negative Sampling), a novel method that incorporates cluster information into contrastive learning for unsupervised sentence representation learning.", "example": "Convert the coordinate to text: [ 2.3247 -3.734 ]:"}
{"text": "Convert the coordinate to text: [-1.1569 -4.9959]: The authors propose Retrieval and Attribute-Marking enhanced Prompting (RAMP), a method that employs large multilingual language models to perform ACT in few-shot and zero-shot settings, incorporating semantic similarity retrieval and marking in-context examples with attribute annotations.", "target": "The authors propose Retrieval and Attribute-Marking enhanced Prompting (RAMP), a method that employs large multilingual language models to perform ACT in few-shot and zero-shot settings, incorporating semantic similarity retrieval and marking in-context examples with attribute annotations.", "example": "Convert the coordinate to text: [-1.1569 -4.9959]:"}
{"text": "Convert the coordinate to text: [-0.9084 -7.1099]: The authors propose to improve pre-training efficiency by initializing one model from the other. Two strategies are explored: extracting the encoder from a seq2seq model and warming up a seq2seq training by utilizing an existing encoder.", "target": "The authors propose to improve pre-training efficiency by initializing one model from the other. Two strategies are explored: extracting the encoder from a seq2seq model and warming up a seq2seq training by utilizing an existing encoder.", "example": "Convert the coordinate to text: [-0.9084 -7.1099]:"}
{"text": "Convert the coordinate to text: [ 0.4464 -9.3708]: The authors propose a reference chain-free listener model that directly addresses the game's predictive task. The model reads the entire dialogue and uses CLIPScore features to gauge the relevance of an utterance to an image.", "target": "The authors propose a reference chain-free listener model that directly addresses the game's predictive task. The model reads the entire dialogue and uses CLIPScore features to gauge the relevance of an utterance to an image.", "example": "Convert the coordinate to text: [ 0.4464 -9.3708]:"}
{"text": "Convert the coordinate to text: [-2.6188 -6.9058]: The authors propose a data augmentation approach utilising machine translation (MT) and text generation to enhance the performance of genre and persuasion techniques detection models. Specifically, synthetic texts created using the OpenAI GPT-3 Davinci language model were used for genre detection, while DeepL translator was used for text translation to augment dataset for persuasion techniques detection.", "target": "The authors propose a data augmentation approach utilising machine translation (MT) and text generation to enhance the performance of genre and persuasion techniques detection models. Specifically, synthetic texts created using the OpenAI GPT-3 Davinci language model were used for genre detection, while DeepL translator was used for text translation to augment dataset for persuasion techniques detection.", "example": "Convert the coordinate to text: [-2.6188 -6.9058]:"}
{"text": "Convert the coordinate to text: [-3.9594 -8.9963]: The authors present a system for Tunisian Arabic to English speech translation using large pre-trained machine translation (MT) models like mBART and NLLB-200 in both end-to-end (E2E) and cascaded ST systems, improved automatic speech recognition (ASR) through pseudo-labeling data augmentation and channel matching, and a combination of E2E and cascaded ST systems with Minimum Bayes-Risk decoding.", "target": "The authors present a system for Tunisian Arabic to English speech translation using large pre-trained machine translation (MT) models like mBART and NLLB-200 in both end-to-end (E2E) and cascaded ST systems, improved automatic speech recognition (ASR) through pseudo-labeling data augmentation and channel matching, and a combination of E2E and cascaded ST systems with Minimum Bayes-Risk decoding.", "example": "Convert the coordinate to text: [-3.9594 -8.9963]:"}
{"text": "Convert the coordinate to text: [-2.2487 -6.7571]: AliBERT, a new biomedical pretrained language model specifically for French, is proposed and various learning strategies are investigated. This model uses a regularized Unigram based tokenizer that has been trained for this purpose.", "target": "AliBERT, a new biomedical pretrained language model specifically for French, is proposed and various learning strategies are investigated. This model uses a regularized Unigram based tokenizer that has been trained for this purpose.", "example": "Convert the coordinate to text: [-2.2487 -6.7571]:"}
{"text": "Convert the coordinate to text: [-1.3451 -6.7003]: The authors propose SlowBERT, a new attack on input-adaptive multi-exit BERT, where the adversary modifies the input texts imperceptibly to drastically increase the average inference cost. This attack involves a new rank-and-substitute adversarial text generation algorithm that efficiently searches for a perturbation to maximize the delay in the exit time.", "target": "The authors propose SlowBERT, a new attack on input-adaptive multi-exit BERT, where the adversary modifies the input texts imperceptibly to drastically increase the average inference cost. This attack involves a new rank-and-substitute adversarial text generation algorithm that efficiently searches for a perturbation to maximize the delay in the exit time.", "example": "Convert the coordinate to text: [-1.3451 -6.7003]:"}
{"text": "Convert the coordinate to text: [-10.9748  -2.0135]: The authors propose RobustQA, a new benchmark comprising datasets from eight different domains, to facilitate the evaluation of ODQA's robustness across various domains.", "target": "The authors propose RobustQA, a new benchmark comprising datasets from eight different domains, to facilitate the evaluation of ODQA's robustness across various domains.", "example": "Convert the coordinate to text: [-10.9748  -2.0135]:"}
{"text": "Convert the coordinate to text: [-3.1987 -6.1692]: This paper presents extensive coordinated work by two research groups to run the training and testing pipeline for three neural text simplification models under varying experimental conditions to explore the variation in results.", "target": "This paper presents extensive coordinated work by two research groups to run the training and testing pipeline for three neural text simplification models under varying experimental conditions to explore the variation in results.", "example": "Convert the coordinate to text: [-3.1987 -6.1692]:"}
{"text": "Convert the coordinate to text: [ 3.6814 -3.9562]: To overcome this issue, the authors propose CUPID, a design that uses knowledge distillation in a curriculum learning setting to learn a simpler architecture that can efficiently handle real-time predictions.", "target": "To overcome this issue, the authors propose CUPID, a design that uses knowledge distillation in a curriculum learning setting to learn a simpler architecture that can efficiently handle real-time predictions.", "example": "Convert the coordinate to text: [ 3.6814 -3.9562]:"}
{"text": "Convert the coordinate to text: [13.1188 -4.8833]: This paper introduces a novel adversarial attack called ToxicTrap that creates small word-level modifications to trick state-of-the-art text classifiers into classifying toxic text samples as harmless. It uses a greedy based search strategy for quick and efficient generation of toxic adversarial examples.", "target": "This paper introduces a novel adversarial attack called ToxicTrap that creates small word-level modifications to trick state-of-the-art text classifiers into classifying toxic text samples as harmless. It uses a greedy based search strategy for quick and efficient generation of toxic adversarial examples.", "example": "Convert the coordinate to text: [13.1188 -4.8833]:"}
{"text": "Convert the coordinate to text: [-1.0857 -7.6739]: The authors propose three novel masking strategies for cross-lingual visual pre-training - more informed visual masking, more informed textual masking, and more informed visual and textual masking. These strategies focus on learning different linguistic patterns.", "target": "The authors propose three novel masking strategies for cross-lingual visual pre-training - more informed visual masking, more informed textual masking, and more informed visual and textual masking. These strategies focus on learning different linguistic patterns.", "example": "Convert the coordinate to text: [-1.0857 -7.6739]:"}
{"text": "Convert the coordinate to text: [15.5544 -0.0221]: The authors introduce a new method called self-distilled quantization (SDQ) that minimizes accumulative quantization errors to compress Transformer language models.", "target": "The authors introduce a new method called self-distilled quantization (SDQ) that minimizes accumulative quantization errors to compress Transformer language models.", "example": "Convert the coordinate to text: [15.5544 -0.0221]:"}
{"text": "Convert the coordinate to text: [-3.9364 -9.4451]: The authors train ASR models for eleven languages with limited ASR training resources using four popular ASR toolkits, aiming to find the best architecture for under-resourced languages.", "target": "The authors train ASR models for eleven languages with limited ASR training resources using four popular ASR toolkits, aiming to find the best architecture for under-resourced languages.", "example": "Convert the coordinate to text: [-3.9364 -9.4451]:"}
{"text": "Convert the coordinate to text: [-0.7822 -8.8194]: The authors propose a new research task of generating floor plan designs from natural language descriptions and present a Sequence-to-Sequence model as an initial approach.", "target": "The authors propose a new research task of generating floor plan designs from natural language descriptions and present a Sequence-to-Sequence model as an initial approach.", "example": "Convert the coordinate to text: [-0.7822 -8.8194]:"}
{"text": "Convert the coordinate to text: [-3.4337  1.445 ]: This research introduces EmoSet, a large-scale visual emotion dataset that is well balanced and annotated with rich attributes. It surpasses current datasets in scale, richness of annotations, diversity, and data balance.", "target": "This research introduces EmoSet, a large-scale visual emotion dataset that is well balanced and annotated with rich attributes. It surpasses current datasets in scale, richness of annotations, diversity, and data balance.", "example": "Convert the coordinate to text: [-3.4337  1.445 ]:"}
{"text": "Convert the coordinate to text: [ 1.8845 11.2892]: The authors perform the theoretical exploration of correcting a flawed Hierarchical Task Network (HTN) planning domain through computational complexity, a fundamental step towards offering more effective modeling assistance. In this context, a modeler provides a list of plans as solutions and a list of plans that should not be solutions.", "target": "The authors perform the theoretical exploration of correcting a flawed Hierarchical Task Network (HTN) planning domain through computational complexity, a fundamental step towards offering more effective modeling assistance. In this context, a modeler provides a list of plans as solutions and a list of plans that should not be solutions.", "example": "Convert the coordinate to text: [ 1.8845 11.2892]:"}
{"text": "Convert the coordinate to text: [ 3.6437 -6.4233]: The paper introduces Dynamic Heterogeneous Graph Attention Search (DHGAS), a method for automating the design of DHGNNs that jointly considers spatial-temporal dependencies and heterogeneous interactions in graphs.", "target": "The paper introduces Dynamic Heterogeneous Graph Attention Search (DHGAS), a method for automating the design of DHGNNs that jointly considers spatial-temporal dependencies and heterogeneous interactions in graphs.", "example": "Convert the coordinate to text: [ 3.6437 -6.4233]:"}
{"text": "Convert the coordinate to text: [10.6264 -6.2887]: The authors propose DiffAD, a method for unsupervised anomaly detection based on the latent diffusion model, inspired by its ability to generate high-quality and diverse images. They also propose noisy condition embedding and interpolated channels to address the challenges faced by the reconstruction-based models.", "target": "The authors propose DiffAD, a method for unsupervised anomaly detection based on the latent diffusion model, inspired by its ability to generate high-quality and diverse images. They also propose noisy condition embedding and interpolated channels to address the challenges faced by the reconstruction-based models.", "example": "Convert the coordinate to text: [10.6264 -6.2887]:"}
{"text": "Convert the coordinate to text: [  9.642  -11.9153]: The authors propose 3DMiner, a pipeline that uses advances in learning self-supervised image representations to cluster images with geometrically similar shapes, and then applies a progressive bundle-adjusting reconstruction method to learn a neural occupancy field representing the underlying shape.", "target": "The authors propose 3DMiner, a pipeline that uses advances in learning self-supervised image representations to cluster images with geometrically similar shapes, and then applies a progressive bundle-adjusting reconstruction method to learn a neural occupancy field representing the underlying shape.", "example": "Convert the coordinate to text: [  9.642  -11.9153]:"}
{"text": "Convert the coordinate to text: [ 2.7297 -2.8433]: A new meta-learning algorithm for continual learning (SiM4C) is proposed, which is designed to minimize forgetting and facilitate forward transfer with limited computational overhead and without introducing any new hyper-parameters.", "target": "A new meta-learning algorithm for continual learning (SiM4C) is proposed, which is designed to minimize forgetting and facilitate forward transfer with limited computational overhead and without introducing any new hyper-parameters.", "example": "Convert the coordinate to text: [ 2.7297 -2.8433]:"}
{"text": "Convert the coordinate to text: [ 0.8997 -2.2634]: The proposed framework learns molecular representations that showcase invariance and robustness against distribution shifts, with a 'first-encoding-then-separation' strategy that identifies invariant molecule features in the latent space, straying away from conventional practices.", "target": "The proposed framework learns molecular representations that showcase invariance and robustness against distribution shifts, with a 'first-encoding-then-separation' strategy that identifies invariant molecule features in the latent space, straying away from conventional practices.", "example": "Convert the coordinate to text: [ 0.8997 -2.2634]:"}
{"text": "Convert the coordinate to text: [ 7.3102 -2.2025]: The authors propose the test-time personalized federated learning (TTPFL) setting; in this, clients locally adapt a global model in an unsupervised manner without the need for labeled data during testing. They also present the adaptive test-time personalization (ATP) algorithm that adaptively learns the adaptation rates for each module in the model from distribution shifts among the source domains.", "target": "The authors propose the test-time personalized federated learning (TTPFL) setting; in this, clients locally adapt a global model in an unsupervised manner without the need for labeled data during testing. They also present the adaptive test-time personalization (ATP) algorithm that adaptively learns the adaptation rates for each module in the model from distribution shifts among the source domains.", "example": "Convert the coordinate to text: [ 7.3102 -2.2025]:"}
{"text": "Convert the coordinate to text: [ 1.9829 -3.1834]: To better utilize the available data for modeling non-compositionality, a dynamic curriculum learning framework that learns training examples from easier to more challenging ones is proposed. To mitigate the forgetting issue, a continual learning method is incorporated into the curriculum learning framework.", "target": "To better utilize the available data for modeling non-compositionality, a dynamic curriculum learning framework that learns training examples from easier to more challenging ones is proposed. To mitigate the forgetting issue, a continual learning method is incorporated into the curriculum learning framework.", "example": "Convert the coordinate to text: [ 1.9829 -3.1834]:"}
{"text": "Convert the coordinate to text: [ 4.8847 12.9996]: The authors introduce Latent Go-Explore (LGE), a simple and general approach based on the Go-Explore paradigm for reinforcement learning. But unlike Go-Explore, it uses learned latent representation and does not utilize domain knowledge or cell partitioning.", "target": "The authors introduce Latent Go-Explore (LGE), a simple and general approach based on the Go-Explore paradigm for reinforcement learning. But unlike Go-Explore, it uses learned latent representation and does not utilize domain knowledge or cell partitioning.", "example": "Convert the coordinate to text: [ 4.8847 12.9996]:"}
{"text": "Convert the coordinate to text: [  2.564  -11.8845]: The proposed key idea is to learn the artistic style directly from a single painting and guide the synthesis without providing complex textual descriptions. The authors perceive style as a learnable textual description of a painting.", "target": "The proposed key idea is to learn the artistic style directly from a single painting and guide the synthesis without providing complex textual descriptions. The authors perceive style as a learnable textual description of a painting.", "example": "Convert the coordinate to text: [  2.564  -11.8845]:"}
{"text": "Convert the coordinate to text: [ 1.9409 -4.0998]: The authors propose a Simple Self-Contrastive Learning (SSCL) method to alleviate the over-smoothing problem by sampling negatives from PLMs intermediate layers, which improves the quality of the sentence representation.", "target": "The authors propose a Simple Self-Contrastive Learning (SSCL) method to alleviate the over-smoothing problem by sampling negatives from PLMs intermediate layers, which improves the quality of the sentence representation.", "example": "Convert the coordinate to text: [ 1.9409 -4.0998]:"}
{"text": "Convert the coordinate to text: [-1.2911 -5.7371]: The authors propose Parse-Instructed Prefix (PIP), a novel adaptation of prefix-tuning to tune large pre-trained language models on syntactically controlled paraphrase generation task in a low-data setting with a significantly less training cost. PIP employs two methods to instruct a model's encoder prefix to capture syntax-related knowledge: direct initiation (PIP-Direct) and indirect optimization (PIP-Indirect).", "target": "The authors propose Parse-Instructed Prefix (PIP), a novel adaptation of prefix-tuning to tune large pre-trained language models on syntactically controlled paraphrase generation task in a low-data setting with a significantly less training cost. PIP employs two methods to instruct a model's encoder prefix to capture syntax-related knowledge: direct initiation (PIP-Direct) and indirect optimization (PIP-Indirect).", "example": "Convert the coordinate to text: [-1.2911 -5.7371]:"}
{"text": "Convert the coordinate to text: [-1.9208  8.8663]: The paper introduces FERMAT, a multi-view evaluation set for numerical reasoning in English that evaluates models on key numerical reasoning aspects such as number understanding, mathematical operations, and training dependency, rather than just reporting a single score.", "target": "The paper introduces FERMAT, a multi-view evaluation set for numerical reasoning in English that evaluates models on key numerical reasoning aspects such as number understanding, mathematical operations, and training dependency, rather than just reporting a single score.", "example": "Convert the coordinate to text: [-1.9208  8.8663]:"}
{"text": "Convert the coordinate to text: [-1.1714 -3.7866]: The authors introduce a new task called 'less likely brainstorming,' which asks a model to generate outputs that are less likely to happen yet are considered relevant by humans. They also introduce a novel, contrastive learning-based controlled text generation method to tackle this task.", "target": "The authors introduce a new task called 'less likely brainstorming,' which asks a model to generate outputs that are less likely to happen yet are considered relevant by humans. They also introduce a novel, contrastive learning-based controlled text generation method to tackle this task.", "example": "Convert the coordinate to text: [-1.1714 -3.7866]:"}
{"text": "Convert the coordinate to text: [-0.5904 -6.8379]: The authors propose a method called EEL for reranking hypotheses by using Transformers to efficiently encode lattices of generated outputs. They further complement this with a new class of token-factored rerankers (TFRs) that allow for efficient extraction of high reranker-scoring hypotheses from the lattice.", "target": "The authors propose a method called EEL for reranking hypotheses by using Transformers to efficiently encode lattices of generated outputs. They further complement this with a new class of token-factored rerankers (TFRs) that allow for efficient extraction of high reranker-scoring hypotheses from the lattice.", "example": "Convert the coordinate to text: [-0.5904 -6.8379]:"}
{"text": "Convert the coordinate to text: [ -0.2548 -10.5982]: The study introduces Encyclopedic-VQA, a large scale VQA dataset that features visual questions about detailed properties of fine-grained categories and instances, complemented by a controlled knowledge base derived from Wikipedia, marking the evidence to support each answer.", "target": "The study introduces Encyclopedic-VQA, a large scale VQA dataset that features visual questions about detailed properties of fine-grained categories and instances, complemented by a controlled knowledge base derived from Wikipedia, marking the evidence to support each answer.", "example": "Convert the coordinate to text: [ -0.2548 -10.5982]:"}
{"text": "Convert the coordinate to text: [ 0.0929 -6.3114]: The paper introduces a sentence-aware encoder for neural topic modeling, leveraging sentence embeddings as external knowledge to make full use of semantic information in input documents, and introduces a sentence-aware attention mechanism for document representation where the bag-of-words model enables the model to place focus on topic-related sentences.", "target": "The paper introduces a sentence-aware encoder for neural topic modeling, leveraging sentence embeddings as external knowledge to make full use of semantic information in input documents, and introduces a sentence-aware attention mechanism for document representation where the bag-of-words model enables the model to place focus on topic-related sentences.", "example": "Convert the coordinate to text: [ 0.0929 -6.3114]:"}
{"text": "Convert the coordinate to text: [-4.1681  0.7912]: The authors propose a sentiment-centric pipeline that combines transformer-based sentiment analysis models with statistical testing to model sentiment\u2019s rate-of-change and correspondingly segment the novel into emotionally self-contained units.", "target": "The authors propose a sentiment-centric pipeline that combines transformer-based sentiment analysis models with statistical testing to model sentiment\u2019s rate-of-change and correspondingly segment the novel into emotionally self-contained units.", "example": "Convert the coordinate to text: [-4.1681  0.7912]:"}
{"text": "Convert the coordinate to text: [-1.3798  0.1008]: The MilaNLP team proposes an ensemble modeling approach to combine different classifiers trained with domain adaptation objectives and standard fine-tuning, aiming to improve robustness and mitigate the effects of lexical overfitting in sexism detection.", "target": "The MilaNLP team proposes an ensemble modeling approach to combine different classifiers trained with domain adaptation objectives and standard fine-tuning, aiming to improve robustness and mitigate the effects of lexical overfitting in sexism detection.", "example": "Convert the coordinate to text: [-1.3798  0.1008]:"}
{"text": "Convert the coordinate to text: [-3.7974 -3.8384]: The SRCB team proposes an external knowledge-based system to address the lack of context in the MultiCoNER II shared task. This system retrieves three types of external knowledge in different ways and combines this knowledge with the original text as input for Named Entity Recognition (NER) models.", "target": "The SRCB team proposes an external knowledge-based system to address the lack of context in the MultiCoNER II shared task. This system retrieves three types of external knowledge in different ways and combines this knowledge with the original text as input for Named Entity Recognition (NER) models.", "example": "Convert the coordinate to text: [-3.7974 -3.8384]:"}
{"text": "Convert the coordinate to text: [ 9.469  -4.1907]: The authors propose a modular bias mitigation approach, consisting of stand-alone highly sparse debiasing subnetworks. Each debiasing module can be integrated into the core model on-demand at inference time.", "target": "The authors propose a modular bias mitigation approach, consisting of stand-alone highly sparse debiasing subnetworks. Each debiasing module can be integrated into the core model on-demand at inference time.", "example": "Convert the coordinate to text: [ 9.469  -4.1907]:"}
{"text": "Convert the coordinate to text: [-1.0204 -8.4618]: To address the challenges in RRS, the authors introduce a dataset, MIMIC-RRS, involving three new modalities and seven new anatomies based on the MIMIC-III and MIMIC-CXR datasets.", "target": "To address the challenges in RRS, the authors introduce a dataset, MIMIC-RRS, involving three new modalities and seven new anatomies based on the MIMIC-III and MIMIC-CXR datasets.", "example": "Convert the coordinate to text: [-1.0204 -8.4618]:"}
{"text": "Convert the coordinate to text: [ 0.2159 -7.0559]: The authors propose that the optimal transformer configuration is closely related to the training objective, introducing the 'Bamboo' configuration concept which advocates for deeper and narrower transformer configurations particularly for masked autoencoder training.", "target": "The authors propose that the optimal transformer configuration is closely related to the training objective, introducing the 'Bamboo' configuration concept which advocates for deeper and narrower transformer configurations particularly for masked autoencoder training.", "example": "Convert the coordinate to text: [ 0.2159 -7.0559]:"}
{"text": "Convert the coordinate to text: [  6.3432 -11.653 ]: The authors propose a shift from a per-pixel classification to a mask classification, and introduce the Mask2Anomaly method, which entails several technical innovations meant to aid anomaly detection in masks.", "target": "The authors propose a shift from a per-pixel classification to a mask classification, and introduce the Mask2Anomaly method, which entails several technical innovations meant to aid anomaly detection in masks.", "example": "Convert the coordinate to text: [  6.3432 -11.653 ]:"}
{"text": "Convert the coordinate to text: [ 4.4327 -5.2066]: The authors propose GgHM, a new method utilizing Graph-guided Hybrid Matching, which incorporates task-oriented feature learning guided by a graph neural network during the class prototype construction, explicitly optimizing intra- and inter-class feature correlations.", "target": "The authors propose GgHM, a new method utilizing Graph-guided Hybrid Matching, which incorporates task-oriented feature learning guided by a graph neural network during the class prototype construction, explicitly optimizing intra- and inter-class feature correlations.", "example": "Convert the coordinate to text: [ 4.4327 -5.2066]:"}
{"text": "Convert the coordinate to text: [3.3559 5.5206]: The paper proposes to address supervision starvation in LGI by restoring corrupted affinities and replenishing missed supervision. This includes identifying critical nodes (defined as $k$-hop starved nodes) and recovering their corrupted affinities, aided by a process inspired by CUR matrix decomposition.", "target": "The paper proposes to address supervision starvation in LGI by restoring corrupted affinities and replenishing missed supervision. This includes identifying critical nodes (defined as $k$-hop starved nodes) and recovering their corrupted affinities, aided by a process inspired by CUR matrix decomposition.", "example": "Convert the coordinate to text: [3.3559 5.5206]:"}
{"text": "Convert the coordinate to text: [-6.481  12.6077]: The dynamical Emotion-Semantic Correlation Model (ESCM) for empathetic dialogue generation tasks is proposed. It constructs dynamic emotion-semantic vectors through the interaction of context and emotions and uses dependency trees to demonstrate the correlations between emotions and semantics.", "target": "The dynamical Emotion-Semantic Correlation Model (ESCM) for empathetic dialogue generation tasks is proposed. It constructs dynamic emotion-semantic vectors through the interaction of context and emotions and uses dependency trees to demonstrate the correlations between emotions and semantics.", "example": "Convert the coordinate to text: [-6.481  12.6077]:"}
{"text": "Convert the coordinate to text: [-1.34   11.7202]: The authors propose a new variant of embodied task completion that predicts actions at a higher level of abstraction, termed a plan. They also propose a method to synthetically generate dialogues as an alternative to human-human dialogues in training.", "target": "The authors propose a new variant of embodied task completion that predicts actions at a higher level of abstraction, termed a plan. They also propose a method to synthetically generate dialogues as an alternative to human-human dialogues in training.", "example": "Convert the coordinate to text: [-1.34   11.7202]:"}
{"text": "Convert the coordinate to text: [ 3.3586 -3.9696]: The paper introduces a dual knowledge distillation and target-oriented vision modeling framework for the M 3 S task, which ensures that the knowledge of MMS and MXLS can be mutually transferred, and a target-oriented contrastive objective that discards unnecessary visual information.", "target": "The paper introduces a dual knowledge distillation and target-oriented vision modeling framework for the M 3 S task, which ensures that the knowledge of MMS and MXLS can be mutually transferred, and a target-oriented contrastive objective that discards unnecessary visual information.", "example": "Convert the coordinate to text: [ 3.3586 -3.9696]:"}
{"text": "Convert the coordinate to text: [-0.0985 -3.3865]: The authors propose TIGER, a TIG embedding model that can restart at any timestamp. The model divides the sequence into multiple chunks by restarting from multiple timestamps simultaneously.", "target": "The authors propose TIGER, a TIG embedding model that can restart at any timestamp. The model divides the sequence into multiple chunks by restarting from multiple timestamps simultaneously.", "example": "Convert the coordinate to text: [-0.0985 -3.3865]:"}
{"text": "Convert the coordinate to text: [-3.7472 13.9863]: The paper proposes a new AI agent aimed at generating human-like behavior in video game navigation, and a method of evaluating its performance using thousands of crowd-sourced comparisons between human navigation and AI navigation.", "target": "The paper proposes a new AI agent aimed at generating human-like behavior in video game navigation, and a method of evaluating its performance using thousands of crowd-sourced comparisons between human navigation and AI navigation.", "example": "Convert the coordinate to text: [-3.7472 13.9863]:"}
{"text": "Convert the coordinate to text: [ -1.7542 -12.5861]: The authors propose a new single-stage paradigm based on a generative retrieval model which decodes the identifiers of target candidates in one phase using Semantic IDs, unique tuples of codewords for each item generated by a hierarchical method called RQ-VAE.", "target": "The authors propose a new single-stage paradigm based on a generative retrieval model which decodes the identifiers of target candidates in one phase using Semantic IDs, unique tuples of codewords for each item generated by a hierarchical method called RQ-VAE.", "example": "Convert the coordinate to text: [ -1.7542 -12.5861]:"}
{"text": "Convert the coordinate to text: [4.2845 5.1577]: The authors propose Graph Segment Training (GST), a framework that employs a divide-and-conquer approach to facilitate large graph property prediction with a constant memory footprint.", "target": "The authors propose Graph Segment Training (GST), a framework that employs a divide-and-conquer approach to facilitate large graph property prediction with a constant memory footprint.", "example": "Convert the coordinate to text: [4.2845 5.1577]:"}
{"text": "Convert the coordinate to text: [ 9.5391 -6.5107]: The authors propose the Fourier Transformer, an approach that progressively removes redundancies in the hidden sequence using the Fast Fourier Transform (FFT) operator to perform Discrete Cosine Transformation (DCT), which significantly reduces computational costs while retaining the ability to inherit from various large pretrained models.", "target": "The authors propose the Fourier Transformer, an approach that progressively removes redundancies in the hidden sequence using the Fast Fourier Transform (FFT) operator to perform Discrete Cosine Transformation (DCT), which significantly reduces computational costs while retaining the ability to inherit from various large pretrained models.", "example": "Convert the coordinate to text: [ 9.5391 -6.5107]:"}
{"text": "Convert the coordinate to text: [-2.3571  0.4432]: The authors introduce COBRA frames, a context-aware formalism explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context. Along with this, they create COBRACORPUS, a dataset of potentially offensive statements paired with machine-generated contexts and free-text explanations of offensiveness, implied biases, speaker intents, and listener reactions.", "target": "The authors introduce COBRA frames, a context-aware formalism explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context. Along with this, they create COBRACORPUS, a dataset of potentially offensive statements paired with machine-generated contexts and free-text explanations of offensiveness, implied biases, speaker intents, and listener reactions.", "example": "Convert the coordinate to text: [-2.3571  0.4432]:"}
{"text": "Convert the coordinate to text: [-5.9262 -0.8928]: The authors present 'Echoes from Alexandria' or 'Echoes', a substantial resource for multilingual book summarization, introducing three new datasets: Echo-Wiki for multilingual book summarization, Echo-XSum for very compressive multilingual book summarization, and Echo-FairySum for extractive book summarization.", "target": "The authors present 'Echoes from Alexandria' or 'Echoes', a substantial resource for multilingual book summarization, introducing three new datasets: Echo-Wiki for multilingual book summarization, Echo-XSum for very compressive multilingual book summarization, and Echo-FairySum for extractive book summarization.", "example": "Convert the coordinate to text: [-5.9262 -0.8928]:"}
{"text": "Convert the coordinate to text: [ 7.3618 -2.2202]: The authors define a new problem space, referred to as 'federated few-shot learning', aiming to develop a model that can perform well with clients with limited data under the Federated Learning scenario. They propose a novel federated few-shot learning framework with two separately updated models and dedicated training strategies to address the challenges of global data variance among clients and local data insufficiency.", "target": "The authors define a new problem space, referred to as 'federated few-shot learning', aiming to develop a model that can perform well with clients with limited data under the Federated Learning scenario. They propose a novel federated few-shot learning framework with two separately updated models and dedicated training strategies to address the challenges of global data variance among clients and local data insufficiency.", "example": "Convert the coordinate to text: [ 7.3618 -2.2202]:"}
{"text": "Convert the coordinate to text: [-1.1128 -5.0026]: The paper proposes CSProm-KG (Conditional Soft Prompts for KGC), which maintains a balance between structural information and textual knowledge. CSProm-KG only tunes the parameters of Conditional Soft Prompts that are generated by the entities and relations representations.", "target": "The paper proposes CSProm-KG (Conditional Soft Prompts for KGC), which maintains a balance between structural information and textual knowledge. CSProm-KG only tunes the parameters of Conditional Soft Prompts that are generated by the entities and relations representations.", "example": "Convert the coordinate to text: [-1.1128 -5.0026]:"}
{"text": "Convert the coordinate to text: [-0.1775 -6.2705]: The authors propose a pre-trained personalized review summarization method which includes a personalized encoder and an interactive information selection mechanism to effectively incorporate personalized information into the salience estimation of the input reviews.", "target": "The authors propose a pre-trained personalized review summarization method which includes a personalized encoder and an interactive information selection mechanism to effectively incorporate personalized information into the salience estimation of the input reviews.", "example": "Convert the coordinate to text: [-0.1775 -6.2705]:"}
{"text": "Convert the coordinate to text: [-4.6739 -7.121 ]: The authors propose a method for rebuilding a corpus of synthetic parallel data using target sentences predicted by a GEC model to improve performance.", "target": "The authors propose a method for rebuilding a corpus of synthetic parallel data using target sentences predicted by a GEC model to improve performance.", "example": "Convert the coordinate to text: [-4.6739 -7.121 ]:"}
{"text": "Convert the coordinate to text: [-2.2586 -5.3576]: The authors propose using GPT-4 to evaluate discourse coherence in written content, with the goal of producing evaluations that not only match human expert ratings, but also provide clear rationales for these assessments.", "target": "The authors propose using GPT-4 to evaluate discourse coherence in written content, with the goal of producing evaluations that not only match human expert ratings, but also provide clear rationales for these assessments.", "example": "Convert the coordinate to text: [-2.2586 -5.3576]:"}
{"text": "Convert the coordinate to text: [ 2.1446 -9.0486]: A self-supervised learning approach called Sentiment Knowledge Enhanced Self-supervised Learning (SKESL) is proposed, aiming to capture common sentimental patterns in unlabeled videos to facilitate learning on limited labeled data.", "target": "A self-supervised learning approach called Sentiment Knowledge Enhanced Self-supervised Learning (SKESL) is proposed, aiming to capture common sentimental patterns in unlabeled videos to facilitate learning on limited labeled data.", "example": "Convert the coordinate to text: [ 2.1446 -9.0486]:"}
{"text": "Convert the coordinate to text: [ 0.3114 -8.3263]: The authors propose a flexible VLP model that incorporates cross-modal fusions into a dual-encoder architecture. This model can easily switch between fusion-based and fusion-free modes by decoupling the fusion modules.", "target": "The authors propose a flexible VLP model that incorporates cross-modal fusions into a dual-encoder architecture. This model can easily switch between fusion-based and fusion-free modes by decoupling the fusion modules.", "example": "Convert the coordinate to text: [ 0.3114 -8.3263]:"}
{"text": "Convert the coordinate to text: [-1.0463  0.3602]: To address the existing problems in AD, a novel framework called CoAD is proposed. CoAD uses several innovations like aligning sentence-level disease labels with symptom inquiry steps, expanding symptom labels for each sub-sequence of symptoms, and developing a repeated symptom input schema for effectively learning the expanded labels.", "target": "To address the existing problems in AD, a novel framework called CoAD is proposed. CoAD uses several innovations like aligning sentence-level disease labels with symptom inquiry steps, expanding symptom labels for each sub-sequence of symptoms, and developing a repeated symptom input schema for effectively learning the expanded labels.", "example": "Convert the coordinate to text: [-1.0463  0.3602]:"}
{"text": "Convert the coordinate to text: [-3.162  -4.0738]: The paper proposes MANNER, a variational memory-augmented model for few-shot NER. MANNER uses a memory module to store information from the source domain and then retrieves relevant information to augment the few-shot task in the target domain.", "target": "The paper proposes MANNER, a variational memory-augmented model for few-shot NER. MANNER uses a memory module to store information from the source domain and then retrieves relevant information to augment the few-shot task in the target domain.", "example": "Convert the coordinate to text: [-3.162  -4.0738]:"}
{"text": "Convert the coordinate to text: [ 0.6251 -4.0364]: The authors propose a new trigger localization formulation using contrastive learning to distinguish ground-truth triggers from contexts, demonstrating robustness against partial annotation noise.", "target": "The authors propose a new trigger localization formulation using contrastive learning to distinguish ground-truth triggers from contexts, demonstrating robustness against partial annotation noise.", "example": "Convert the coordinate to text: [ 0.6251 -4.0364]:"}
{"text": "Convert the coordinate to text: [10.7245 -6.3338]: This paper presents a novel denoising model that uses a generative diffusion model to detect and localize anomalies. The proposed model introduces random noise to overwhelm anomalous pixels and leverages the KL divergence of the diffusion model and features from a pre-trained feature extractor to obtain precise anomaly scores.", "target": "This paper presents a novel denoising model that uses a generative diffusion model to detect and localize anomalies. The proposed model introduces random noise to overwhelm anomalous pixels and leverages the KL divergence of the diffusion model and features from a pre-trained feature extractor to obtain precise anomaly scores.", "example": "Convert the coordinate to text: [10.7245 -6.3338]:"}
{"text": "Convert the coordinate to text: [ 5.2106 -3.5958]: This paper proposes a new way of estimating the transferability of these pre-trained models, by examining how far the 'neural-collapse' state of the models' activations on target dataset are from their state after a model is fine-tuned on the target domain.", "target": "This paper proposes a new way of estimating the transferability of these pre-trained models, by examining how far the 'neural-collapse' state of the models' activations on target dataset are from their state after a model is fine-tuned on the target domain.", "example": "Convert the coordinate to text: [ 5.2106 -3.5958]:"}
{"text": "Convert the coordinate to text: [-3.232  -6.9054]: The authors propose EMMA-X, an EM-like Multilingual pre-training Algorithm, to learn cross-lingual universals with the aid of excessive multilingual non-parallel data and an additional semantic relation prediction task.", "target": "The authors propose EMMA-X, an EM-like Multilingual pre-training Algorithm, to learn cross-lingual universals with the aid of excessive multilingual non-parallel data and an additional semantic relation prediction task.", "example": "Convert the coordinate to text: [-3.232  -6.9054]:"}
{"text": "Convert the coordinate to text: [ 9.1089 10.5745]: The authors aim to improve upon the existing work by proposing a $\\mathcal{O}(\\log n)$-regret polynomial-time online learning algorithm which guarantees that the overall connection and moving cost is capped at $\\mathcal{O}(\\log n)$ times the time-averaged connection cost of the best fixed solution.", "target": "The authors aim to improve upon the existing work by proposing a $\\mathcal{O}(\\log n)$-regret polynomial-time online learning algorithm which guarantees that the overall connection and moving cost is capped at $\\mathcal{O}(\\log n)$ times the time-averaged connection cost of the best fixed solution.", "example": "Convert the coordinate to text: [ 9.1089 10.5745]:"}
{"text": "Convert the coordinate to text: [ 1.4915 12.0536]: This paper introduces a flexible, learning-augmented algorithmic framework for energy-efficient scheduling. This framework uses both an offline and an online algorithm for handling energy-efficient scheduling.", "target": "This paper introduces a flexible, learning-augmented algorithmic framework for energy-efficient scheduling. This framework uses both an offline and an online algorithm for handling energy-efficient scheduling.", "example": "Convert the coordinate to text: [ 1.4915 12.0536]:"}
{"text": "Convert the coordinate to text: [  6.3541 -10.5573]: This work proposes test-time training strategies that are task-agnostic and ones specifically designed for VOS. They also introduce a variant based on mask cycle consistency tailored to matching-based VOS methods.", "target": "This work proposes test-time training strategies that are task-agnostic and ones specifically designed for VOS. They also introduce a variant based on mask cycle consistency tailored to matching-based VOS methods.", "example": "Convert the coordinate to text: [  6.3541 -10.5573]:"}
{"text": "Convert the coordinate to text: [ 7.825  -3.3048]: The authors argue that there exist cases with distribution shifts unobservable in the time domain while observable in the spectral domain. To address this issue, they propose a method called Spectral Invariant Learning for Dynamic Graphs under Distribution Shifts (SILD) that can handle distribution shifts on dynamic graphs by capturing and utilizing invariant and variant spectral patterns.", "target": "The authors argue that there exist cases with distribution shifts unobservable in the time domain while observable in the spectral domain. To address this issue, they propose a method called Spectral Invariant Learning for Dynamic Graphs under Distribution Shifts (SILD) that can handle distribution shifts on dynamic graphs by capturing and utilizing invariant and variant spectral patterns.", "example": "Convert the coordinate to text: [ 7.825  -3.3048]:"}
{"text": "Convert the coordinate to text: [15.4342 -0.3011]: The authors aim to understand these 'training tricks' from an optimization perspective, and propose a principled way to synthesize forward-backward quantizers with automatic theoretical guarantees, resulting in the ProxConnect++ algorithm that includes existing binarization techniques, and an enhanced binarization algorithm, BNN++.", "target": "The authors aim to understand these 'training tricks' from an optimization perspective, and propose a principled way to synthesize forward-backward quantizers with automatic theoretical guarantees, resulting in the ProxConnect++ algorithm that includes existing binarization techniques, and an enhanced binarization algorithm, BNN++.", "example": "Convert the coordinate to text: [15.4342 -0.3011]:"}
{"text": "Convert the coordinate to text: [-0.2122 -1.3996]: The authors propose the Hyper-HMM, a hybrid model that simultaneously aligns both temporal and spatial features across brains, moving beyond the constraints of existing alignment models.", "target": "The authors propose the Hyper-HMM, a hybrid model that simultaneously aligns both temporal and spatial features across brains, moving beyond the constraints of existing alignment models.", "example": "Convert the coordinate to text: [-0.2122 -1.3996]:"}
{"text": "Convert the coordinate to text: [-10.0921  -1.1962]: The authors propose the use of tags of FAQ questions, integrated into a reinforcement learning framework, to eliminate the influence of irrelevant information in the dynamic conversation context.", "target": "The authors propose the use of tags of FAQ questions, integrated into a reinforcement learning framework, to eliminate the influence of irrelevant information in the dynamic conversation context.", "example": "Convert the coordinate to text: [-10.0921  -1.1962]:"}
{"text": "Convert the coordinate to text: [ 3.8808 -3.9234]: The authors posit that the success of ensemble and knowledge distillation in deep learning can be attributed to the 'multi-view' structure of data. They suggest these independent models can be combined not only to improve test accuracy, but also distilled into a single model leveraging 'dark knowledge' hidden in the ensemble outputs. They further propose that self-distillation can be viewed as a combination of ensemble and knowledge distillation.", "target": "The authors posit that the success of ensemble and knowledge distillation in deep learning can be attributed to the 'multi-view' structure of data. They suggest these independent models can be combined not only to improve test accuracy, but also distilled into a single model leveraging 'dark knowledge' hidden in the ensemble outputs. They further propose that self-distillation can be viewed as a combination of ensemble and knowledge distillation.", "example": "Convert the coordinate to text: [ 3.8808 -3.9234]:"}
{"text": "Convert the coordinate to text: [2.3037 1.3959]: The authors introduce DIAD, a new AD framework that adapts a white-box model class, Generalized Additive Models, to detect anomalies. The framework uses partial identification objective, which can handle noisy or heterogeneous features and incorporates small amounts of labeled data to improve anomaly detection performance in semi-supervised settings.", "target": "The authors introduce DIAD, a new AD framework that adapts a white-box model class, Generalized Additive Models, to detect anomalies. The framework uses partial identification objective, which can handle noisy or heterogeneous features and incorporates small amounts of labeled data to improve anomaly detection performance in semi-supervised settings.", "example": "Convert the coordinate to text: [2.3037 1.3959]:"}
{"text": "Convert the coordinate to text: [ 5.397  -3.0771]: The authors propose a data augmentation framework that uses the knowledge from the pre-training and fine-tuning stages of PLMCs to generate pseudo data, which is then used as training data for the subsequent stage.", "target": "The authors propose a data augmentation framework that uses the knowledge from the pre-training and fine-tuning stages of PLMCs to generate pseudo data, which is then used as training data for the subsequent stage.", "example": "Convert the coordinate to text: [ 5.397  -3.0771]:"}
{"text": "Convert the coordinate to text: [3.5347 3.3845]: The authors propose a self-adaptive adjustment framework for perturbation radii that doesn't require searching, and argue both intuitively and theoretically that adaptive perturbation radii are superior in terms of accuracy and robustness.", "target": "The authors propose a self-adaptive adjustment framework for perturbation radii that doesn't require searching, and argue both intuitively and theoretically that adaptive perturbation radii are superior in terms of accuracy and robustness.", "example": "Convert the coordinate to text: [3.5347 3.3845]:"}
{"text": "Convert the coordinate to text: [ 3.4241 -2.1344]: The paper proposes two systems: a pipeline system that models the two tasks separately, and a joint system that learns the two tasks simultaneously with a shared representation and a multi-task learning approach. The authors finally combine these in an ensemble system.", "target": "The paper proposes two systems: a pipeline system that models the two tasks separately, and a joint system that learns the two tasks simultaneously with a shared representation and a multi-task learning approach. The authors finally combine these in an ensemble system.", "example": "Convert the coordinate to text: [ 3.4241 -2.1344]:"}
{"text": "Convert the coordinate to text: [-12.4833  15.7982]: The authors present InfinitePaint, a system that allows for digital painting in virtual reality using a real wet brush on paper, which gives the user the similar haptic feedback as painting with a wet brush on a physical medium.", "target": "The authors present InfinitePaint, a system that allows for digital painting in virtual reality using a real wet brush on paper, which gives the user the similar haptic feedback as painting with a wet brush on a physical medium.", "example": "Convert the coordinate to text: [-12.4833  15.7982]:"}
{"text": "Convert the coordinate to text: [-5.165  13.5834]: The authors present an experiment where every participant is paired with one human and one robot for decision-making tasks. The power balance is manipulated to create three scenarios: human as leader, robot as leader, and no-power-difference for studying the influence of the leader in decision-making situations.", "target": "The authors present an experiment where every participant is paired with one human and one robot for decision-making tasks. The power balance is manipulated to create three scenarios: human as leader, robot as leader, and no-power-difference for studying the influence of the leader in decision-making situations.", "example": "Convert the coordinate to text: [-5.165  13.5834]:"}
{"text": "Convert the coordinate to text: [-1.0364 -5.1093]: The authors propose NLGraph (Natural Language Graph), a comprehensive benchmark of graph-based problems designed in natural language, which covers eight graph reasoning tasks. They also introduce Build-a-Graph Prompting and Algorithmic Prompting, two instruction-based approaches to enhance LLMs in solving natural language graph problems.", "target": "The authors propose NLGraph (Natural Language Graph), a comprehensive benchmark of graph-based problems designed in natural language, which covers eight graph reasoning tasks. They also introduce Build-a-Graph Prompting and Algorithmic Prompting, two instruction-based approaches to enhance LLMs in solving natural language graph problems.", "example": "Convert the coordinate to text: [-1.0364 -5.1093]:"}
{"text": "Convert the coordinate to text: [-2.7022 -5.3206]: In this paper, the authors present data augmentation strategies specifically designed for keyphrase generation in purely resource-constrained domains. The proposed techniques use the full text of the articles to improve both present and absent keyphrase generation.", "target": "In this paper, the authors present data augmentation strategies specifically designed for keyphrase generation in purely resource-constrained domains. The proposed techniques use the full text of the articles to improve both present and absent keyphrase generation.", "example": "Convert the coordinate to text: [-2.7022 -5.3206]:"}
{"text": "Convert the coordinate to text: [-1.4327  0.1607]: The authors propose a system utilizing transformer-based models, data augmentation, ensemble methods and in-context learning to identify and classify sexist content at different levels of granularity.", "target": "The authors propose a system utilizing transformer-based models, data augmentation, ensemble methods and in-context learning to identify and classify sexist content at different levels of granularity.", "example": "Convert the coordinate to text: [-1.4327  0.1607]:"}
{"text": "Convert the coordinate to text: [-3.7397 -9.3045]: The authors propose an end-to-end speech translation networks for both constrained and unconstrained conditions, comprising of a conformer encoder and a transformer decoder. The proposed systems leverage Marathi Automatic Speech Recognition (ASR) data to pre-train the encoder and subsequently train the entire model on the speech translation data.", "target": "The authors propose an end-to-end speech translation networks for both constrained and unconstrained conditions, comprising of a conformer encoder and a transformer decoder. The proposed systems leverage Marathi Automatic Speech Recognition (ASR) data to pre-train the encoder and subsequently train the entire model on the speech translation data.", "example": "Convert the coordinate to text: [-3.7397 -9.3045]:"}
{"text": "Convert the coordinate to text: [-5.6359 -0.9937]: This study proposes to analyze the model intrinsic features of a summarization model by fine-tuning BART models using different objectives (negative log-likelihood, unlikelihood, and contrastive loss) and datasets (CNN/DailyMail and XSum) and studying the changes in the model predictions and intrinsic features.", "target": "This study proposes to analyze the model intrinsic features of a summarization model by fine-tuning BART models using different objectives (negative log-likelihood, unlikelihood, and contrastive loss) and datasets (CNN/DailyMail and XSum) and studying the changes in the model predictions and intrinsic features.", "example": "Convert the coordinate to text: [-5.6359 -0.9937]:"}
{"text": "Convert the coordinate to text: [12.6747 -5.007 ]: This study focuses on the robustness of visually grounded dialog models towards textual attacks, by considering how multimodal input components contribute to model robustness and by generating adversarial test examples that successfully fool the model but remain undetectable.", "target": "This study focuses on the robustness of visually grounded dialog models towards textual attacks, by considering how multimodal input components contribute to model robustness and by generating adversarial test examples that successfully fool the model but remain undetectable.", "example": "Convert the coordinate to text: [12.6747 -5.007 ]:"}
{"text": "Convert the coordinate to text: [-3.911  -6.2286]: A new approach for cross-lingual event detection has been proposed that augments representations with additional context to bridge the language gap while enhancing the contextual information needed for event detection. The method involves a retrieval model that finds relevant sentences in the target language for an input sentence to compute augmentation representations.", "target": "A new approach for cross-lingual event detection has been proposed that augments representations with additional context to bridge the language gap while enhancing the contextual information needed for event detection. The method involves a retrieval model that finds relevant sentences in the target language for an input sentence to compute augmentation representations.", "example": "Convert the coordinate to text: [-3.911  -6.2286]:"}
{"text": "Convert the coordinate to text: [-5.7586 10.4554]: The authors propose the novel paradigm of multimodal persona-based dialogue generation for comic strips, and introduce a corresponding architecture, MPDialog.", "target": "The authors propose the novel paradigm of multimodal persona-based dialogue generation for comic strips, and introduce a corresponding architecture, MPDialog.", "example": "Convert the coordinate to text: [-5.7586 10.4554]:"}
{"text": "Convert the coordinate to text: [10.7506  7.5036]: The authors propose making use of the Convex-Concave Procedure (CCCP) to bypass potentially expensive Riemannian operations, and exploit the overall g-convexity structure to provide iteration complexity results for global optimality.", "target": "The authors propose making use of the Convex-Concave Procedure (CCCP) to bypass potentially expensive Riemannian operations, and exploit the overall g-convexity structure to provide iteration complexity results for global optimality.", "example": "Convert the coordinate to text: [10.7506  7.5036]:"}
{"text": "Convert the coordinate to text: [10.1086 -3.9697]: The authors propose an end-to-end learnable framework for fairness-aware network pruning. This framework optimizes both the pruning and debiasing tasks through adversarial training against evaluation metrics for pruning accuracy and metrics like Disparate Impact (DI) and Equalized Odds (DEO) for fairness.", "target": "The authors propose an end-to-end learnable framework for fairness-aware network pruning. This framework optimizes both the pruning and debiasing tasks through adversarial training against evaluation metrics for pruning accuracy and metrics like Disparate Impact (DI) and Equalized Odds (DEO) for fairness.", "example": "Convert the coordinate to text: [10.1086 -3.9697]:"}
{"text": "Convert the coordinate to text: [  8.9259 -11.8757]: The paper proposes ProtoTransfer, a novel approach that fully exploits image representations and transfers the learned multi-modal knowledge to all point cloud features. The approach includes constructing a class-wise prototype bank from strictly-aligned fusion features and encouraging all point cloud features to learn from these prototypes.", "target": "The paper proposes ProtoTransfer, a novel approach that fully exploits image representations and transfers the learned multi-modal knowledge to all point cloud features. The approach includes constructing a class-wise prototype bank from strictly-aligned fusion features and encouraging all point cloud features to learn from these prototypes.", "example": "Convert the coordinate to text: [  8.9259 -11.8757]:"}
{"text": "Convert the coordinate to text: [ 2.8222 14.1407]: The authors bridge the gap between social welfare and computational efficiency by showing that when (approximate) full efficiency is guaranteed through a Roughgarden-style smoothness argument, Nash equilibria can be approached using a family of no-regret learning algorithms. This enables fast and decentralized computation.", "target": "The authors bridge the gap between social welfare and computational efficiency by showing that when (approximate) full efficiency is guaranteed through a Roughgarden-style smoothness argument, Nash equilibria can be approached using a family of no-regret learning algorithms. This enables fast and decentralized computation.", "example": "Convert the coordinate to text: [ 2.8222 14.1407]:"}
{"text": "Convert the coordinate to text: [3.0616 3.8517]: The paper proposes a generalization, named Clustered Compositional Explanations, which merges Compositional Explanations with clustering and a novel search heuristic to provide an approximation to a broader spectrum of the neurons' behavior.", "target": "The paper proposes a generalization, named Clustered Compositional Explanations, which merges Compositional Explanations with clustering and a novel search heuristic to provide an approximation to a broader spectrum of the neurons' behavior.", "example": "Convert the coordinate to text: [3.0616 3.8517]:"}
{"text": "Convert the coordinate to text: [ 6.6922 13.13  ]: The paper proposes that the learned policy should choose, on a per-state basis, how closely to follow the behavior policy to maximize long-term return, provided it remains within the support of the behavior policy. The authors instantiate this principle by reweighting the data distribution in conservative Q-learning (CQL) to obtain an approximate support constraint.", "target": "The paper proposes that the learned policy should choose, on a per-state basis, how closely to follow the behavior policy to maximize long-term return, provided it remains within the support of the behavior policy. The authors instantiate this principle by reweighting the data distribution in conservative Q-learning (CQL) to obtain an approximate support constraint.", "example": "Convert the coordinate to text: [ 6.6922 13.13  ]:"}
{"text": "Convert the coordinate to text: [-2.5651 -4.979 ]: The authors propose to examine the performance of LLMs on two human-oriented metrics for studying loophole behavior: evaluation (ratings of trouble, upset, and humor), and generation (coming up with new loopholes in a given context).", "target": "The authors propose to examine the performance of LLMs on two human-oriented metrics for studying loophole behavior: evaluation (ratings of trouble, upset, and humor), and generation (coming up with new loopholes in a given context).", "example": "Convert the coordinate to text: [-2.5651 -4.979 ]:"}
{"text": "Convert the coordinate to text: [-3.8284 -3.5773]: The authors introduce a novel NER approach which identifies candidate entities in the input sentence, links each candidate to an existing knowledge base, and then predicts the fine-grained category for each entity candidate.", "target": "The authors introduce a novel NER approach which identifies candidate entities in the input sentence, links each candidate to an existing knowledge base, and then predicts the fine-grained category for each entity candidate.", "example": "Convert the coordinate to text: [-3.8284 -3.5773]:"}
{"text": "Convert the coordinate to text: [-9.9627 11.2951]: This study aims to support the development and sharing of connections between personal values and self-management tasks in patients with MCC through the facilitated use of an interactive visualization system called Conversation Canvas.", "target": "This study aims to support the development and sharing of connections between personal values and self-management tasks in patients with MCC through the facilitated use of an interactive visualization system called Conversation Canvas.", "example": "Convert the coordinate to text: [-9.9627 11.2951]:"}
{"text": "Convert the coordinate to text: [-5.8258 10.1098]: The authors propose a model that conditions the end-of-turn prediction not only on conversation history but also on what the next speaker wants to say.", "target": "The authors propose a model that conditions the end-of-turn prediction not only on conversation history but also on what the next speaker wants to say.", "example": "Convert the coordinate to text: [-5.8258 10.1098]:"}
{"text": "Convert the coordinate to text: [0.0349 0.8697]: This paper tackles whether the trade-off between privacy preservation and de-biasing really holds when both are incorporated into training in text generation models.", "target": "This paper tackles whether the trade-off between privacy preservation and de-biasing really holds when both are incorporated into training in text generation models.", "example": "Convert the coordinate to text: [0.0349 0.8697]:"}
{"text": "Convert the coordinate to text: [ 8.8691 -6.2654]: The authors propose Progressive Down-Sampling (PDS), a method that gradually compresses acoustic features into coarser-grained units containing semantic information, similar to text-level representations. They also introduce a representation fusion method to mitigate information loss during high compression.", "target": "The authors propose Progressive Down-Sampling (PDS), a method that gradually compresses acoustic features into coarser-grained units containing semantic information, similar to text-level representations. They also introduce a representation fusion method to mitigate information loss during high compression.", "example": "Convert the coordinate to text: [ 8.8691 -6.2654]:"}
{"text": "Convert the coordinate to text: [5.7908 6.5351]: The authors propose ODSS, the first optimal dynamic subset sampling algorithm that has both optimal expected query time and update time, matching the lower bounds of the subset sampling problem.", "target": "The authors propose ODSS, the first optimal dynamic subset sampling algorithm that has both optimal expected query time and update time, matching the lower bounds of the subset sampling problem.", "example": "Convert the coordinate to text: [5.7908 6.5351]:"}
{"text": "Convert the coordinate to text: [5.3796 9.0165]: The authors propose a new genetic algorithm (GA) based method to modify n-best lists produced by an MT system. The method uses common GA operations on a list of hypotheses combined with a fitness function linked to an arbitrary MT metric to generate novel and diverse outputs with high metric scores.", "target": "The authors propose a new genetic algorithm (GA) based method to modify n-best lists produced by an MT system. The method uses common GA operations on a list of hypotheses combined with a fitness function linked to an arbitrary MT metric to generate novel and diverse outputs with high metric scores.", "example": "Convert the coordinate to text: [5.3796 9.0165]:"}
{"text": "Convert the coordinate to text: [ 7.8525 -7.9687]: To tackle the shortcomings of contemporary methods, this paper proposes an explicit feature interaction-aware uplift network (EFIN) that includes four customized modules. EFIN not only encodes user, contextual, and treatment features but also models user's natural response and treatment-aware interactions.", "target": "To tackle the shortcomings of contemporary methods, this paper proposes an explicit feature interaction-aware uplift network (EFIN) that includes four customized modules. EFIN not only encodes user, contextual, and treatment features but also models user's natural response and treatment-aware interactions.", "example": "Convert the coordinate to text: [ 7.8525 -7.9687]:"}
{"text": "Convert the coordinate to text: [-10.7695  -1.9758]: The authors introduce a new dialog-level annotation workflow called Dialog Quality Annotation (DQA) which involves expert annotators evaluating the quality of dialogs as a whole and labelling dialogs for attributes such as goal completion and user sentiment.", "target": "The authors introduce a new dialog-level annotation workflow called Dialog Quality Annotation (DQA) which involves expert annotators evaluating the quality of dialogs as a whole and labelling dialogs for attributes such as goal completion and user sentiment.", "example": "Convert the coordinate to text: [-10.7695  -1.9758]:"}
{"text": "Convert the coordinate to text: [-6.4512  0.1925]: The authors establish HAUSER, a holistic and automatic evaluation system for the SG task, with five distinct criteria from three perspectives and corresponding automatic metrics for each criterion.", "target": "The authors establish HAUSER, a holistic and automatic evaluation system for the SG task, with five distinct criteria from three perspectives and corresponding automatic metrics for each criterion.", "example": "Convert the coordinate to text: [-6.4512  0.1925]:"}
{"text": "Convert the coordinate to text: [-5.3399 -1.1062]: The authors present the idea of using a multi-task learning approach that integrates tasks of automated span detection, type and quality prediction in scoring argumentative essays.", "target": "The authors present the idea of using a multi-task learning approach that integrates tasks of automated span detection, type and quality prediction in scoring argumentative essays.", "example": "Convert the coordinate to text: [-5.3399 -1.1062]:"}
{"text": "Convert the coordinate to text: [ 6.3460e-03 -9.1249e+00]: The authors propose two systems, Augment-CLIP and Stable Diffusion Sampling (SD Sampling), to enhance CLIP's ability to handle compositionality and ambiguity in Visual Word Sense Disambiguation task. Augment-CLIP augments the text prompt by generating sentences that contain the context phrase with the help of large language models (LLMs) and SD Sampling uses text-to-image Stable Diffusion to generate multiple images from the given phrase.", "target": "The authors propose two systems, Augment-CLIP and Stable Diffusion Sampling (SD Sampling), to enhance CLIP's ability to handle compositionality and ambiguity in Visual Word Sense Disambiguation task. Augment-CLIP augments the text prompt by generating sentences that contain the context phrase with the help of large language models (LLMs) and SD Sampling uses text-to-image Stable Diffusion to generate multiple images from the given phrase.", "example": "Convert the coordinate to text: [ 6.3460e-03 -9.1249e+00]:"}
{"text": "Convert the coordinate to text: [-0.3539 -6.9086]: The MELODI team proposes the use of a transformer-based architecture, with optimizations including hyper-parameter search and layer freezing. They also use adapters for model fine-tuning and introduce relation mappings to manage label set explosion.", "target": "The MELODI team proposes the use of a transformer-based architecture, with optimizations including hyper-parameter search and layer freezing. They also use adapters for model fine-tuning and introduce relation mappings to manage label set explosion.", "example": "Convert the coordinate to text: [-0.3539 -6.9086]:"}
{"text": "Convert the coordinate to text: [ 5.3406 -5.3351]: This paper proposes implementing few-shot learning paradigms to address cancer mutation detection tasks, which has hitherto been unexplored. It introduces the Gaussian Distributed Prototypical Network (GDPN) framework, designed to model label dependency from training examples in the support set and approximate transition scores via a Gaussian distribution.", "target": "This paper proposes implementing few-shot learning paradigms to address cancer mutation detection tasks, which has hitherto been unexplored. It introduces the Gaussian Distributed Prototypical Network (GDPN) framework, designed to model label dependency from training examples in the support set and approximate transition scores via a Gaussian distribution.", "example": "Convert the coordinate to text: [ 5.3406 -5.3351]:"}
{"text": "Convert the coordinate to text: [-6.9333 -6.1684]: The authors propose four weak verifiers as a method of estimating dataset quality in the absence of multiple human annotators. This approach is specifically employed for the task of semantic analysis of adpositions in Gujarati, a low-resource language.", "target": "The authors propose four weak verifiers as a method of estimating dataset quality in the absence of multiple human annotators. This approach is specifically employed for the task of semantic analysis of adpositions in Gujarati, a low-resource language.", "example": "Convert the coordinate to text: [-6.9333 -6.1684]:"}
{"text": "Convert the coordinate to text: [ 0.1381 -5.1701]: The authors propose a segment-level and category-oriented network (SLCO) for KB-REC, which includes a segment-level prompt-based method for knowledge retrieval to mitigate similarity bias and a category-based grounding method to alleviate interference from irrelevant information.", "target": "The authors propose a segment-level and category-oriented network (SLCO) for KB-REC, which includes a segment-level prompt-based method for knowledge retrieval to mitigate similarity bias and a category-based grounding method to alleviate interference from irrelevant information.", "example": "Convert the coordinate to text: [ 0.1381 -5.1701]:"}
{"text": "Convert the coordinate to text: [-8.1701  6.2715]: This paper investigates the extent to which 'how-to' guides from wikiHow differ depending on the intended audience and whether these guides are subject to subtle biases.", "target": "This paper investigates the extent to which 'how-to' guides from wikiHow differ depending on the intended audience and whether these guides are subject to subtle biases.", "example": "Convert the coordinate to text: [-8.1701  6.2715]:"}
{"text": "Convert the coordinate to text: [ 3.6545 -2.6076]: This paper introduces a new gradient trade-off approach called GetMTL, designed to alleviate the task conflict problem in MTL. It aims to achieve a specific trade-off among various tasks near the main objective of multi-task text classification, thereby enhancing the performance of each task.", "target": "This paper introduces a new gradient trade-off approach called GetMTL, designed to alleviate the task conflict problem in MTL. It aims to achieve a specific trade-off among various tasks near the main objective of multi-task text classification, thereby enhancing the performance of each task.", "example": "Convert the coordinate to text: [ 3.6545 -2.6076]:"}
{"text": "Convert the coordinate to text: [8.3311 5.9923]: The authors challenge the need for i.i.d. data sampling in generating classical convergence guarantee. Instead, they propose a more generalized approach, using a mild mixing condition of the conditional distribution that is applicable in Markov chain sampling algorithms.", "target": "The authors challenge the need for i.i.d. data sampling in generating classical convergence guarantee. Instead, they propose a more generalized approach, using a mild mixing condition of the conditional distribution that is applicable in Markov chain sampling algorithms.", "example": "Convert the coordinate to text: [8.3311 5.9923]:"}
{"text": "Convert the coordinate to text: [ 2.5386 -8.9407]: The authors propose to reintroduce image features via cross-attention in HOI detectors, and design a model with enhanced predicate visual context (PViC) using improved query design, extensive exploration of keys and values, and box pair positional embeddings as spatial guidance.", "target": "The authors propose to reintroduce image features via cross-attention in HOI detectors, and design a model with enhanced predicate visual context (PViC) using improved query design, extensive exploration of keys and values, and box pair positional embeddings as spatial guidance.", "example": "Convert the coordinate to text: [ 2.5386 -8.9407]:"}
{"text": "Convert the coordinate to text: [ 4.3028 -1.3236]: The paper aims to provide deep insights on pseudo labeling (PL) in graph learning models and proposes a cautious pseudo labeling methodology. This strategy only labels the samples with the highest confidence and multi-view consistency.", "target": "The paper aims to provide deep insights on pseudo labeling (PL) in graph learning models and proposes a cautious pseudo labeling methodology. This strategy only labels the samples with the highest confidence and multi-view consistency.", "example": "Convert the coordinate to text: [ 4.3028 -1.3236]:"}
{"text": "Convert the coordinate to text: [8.3196 7.353 ]: This work uses PAC-Bayesian theory to develop statistical guarantees for VAEs, including PAC-Bayesian bound for posterior distributions conditioned on individual data samples and generalization guarantees for the VAE's reconstruction loss.", "target": "This work uses PAC-Bayesian theory to develop statistical guarantees for VAEs, including PAC-Bayesian bound for posterior distributions conditioned on individual data samples and generalization guarantees for the VAE's reconstruction loss.", "example": "Convert the coordinate to text: [8.3196 7.353 ]:"}
{"text": "Convert the coordinate to text: [ 6.2797 -2.3656]: Inspired by the strong generalization of simplex Equiangular Tight Frame (ETF) on imbalanced data, the paper proposes FedGELA, a novel approach where the classifier is globally fixed as a simplex ETF while locally adapted to the personal distributions.", "target": "Inspired by the strong generalization of simplex Equiangular Tight Frame (ETF) on imbalanced data, the paper proposes FedGELA, a novel approach where the classifier is globally fixed as a simplex ETF while locally adapted to the personal distributions.", "example": "Convert the coordinate to text: [ 6.2797 -2.3656]:"}
{"text": "Convert the coordinate to text: [-2.6328 -6.217 ]: The study evaluates the zero-shot performance of various language models on TTC23, a benchmark collection of 23 public TTC datasets and creates TTC-specialized language models by fine-tuning these LMs over a subset of the datasets.", "target": "The study evaluates the zero-shot performance of various language models on TTC23, a benchmark collection of 23 public TTC datasets and creates TTC-specialized language models by fine-tuning these LMs over a subset of the datasets.", "example": "Convert the coordinate to text: [-2.6328 -6.217 ]:"}
{"text": "Convert the coordinate to text: [9.6883 9.1685]: The authors focus on the maximization of a family of submodular functions in the presence of biases. The key premise is that constraint-based interventions do not guarantee optimal utility for this family of functions, unlike linear functions.", "target": "The authors focus on the maximization of a family of submodular functions in the presence of biases. The key premise is that constraint-based interventions do not guarantee optimal utility for this family of functions, unlike linear functions.", "example": "Convert the coordinate to text: [9.6883 9.1685]:"}
{"text": "Convert the coordinate to text: [-1.3936 -4.8228]: The authors propose a novel method of equipping PLM-based extractors with a knowledge-guided prompt as an intervention to mitigate concept bias, using the Structural Causal Model (SCM). The prompt uses the topic of a given entity from the existing knowledge in Knowledge Graphs to reduce the spurious co-occurrence correlations between entities and biased concepts.", "target": "The authors propose a novel method of equipping PLM-based extractors with a knowledge-guided prompt as an intervention to mitigate concept bias, using the Structural Causal Model (SCM). The prompt uses the topic of a given entity from the existing knowledge in Knowledge Graphs to reduce the spurious co-occurrence correlations between entities and biased concepts.", "example": "Convert the coordinate to text: [-1.3936 -4.8228]:"}
{"text": "Convert the coordinate to text: [-1.1487  0.2229]: The authors are attempting to build a data-design approach specifically to examine and address the identified gender bias in English-Twi machine translation.", "target": "The authors are attempting to build a data-design approach specifically to examine and address the identified gender bias in English-Twi machine translation.", "example": "Convert the coordinate to text: [-1.1487  0.2229]:"}
{"text": "Convert the coordinate to text: [ 4.0975 -8.2204]: The authors propose a new module termed Sub-Band based Attention (SBA), which uses either the high or middle sub-bands of the encoder features to enhance the decoder features and improve the feature discrimination. A Transformer Attended Convolution (TAC) module as the main encoder block is introduced, which enhances the CNN features with stronger long-range object contexts.", "target": "The authors propose a new module termed Sub-Band based Attention (SBA), which uses either the high or middle sub-bands of the encoder features to enhance the decoder features and improve the feature discrimination. A Transformer Attended Convolution (TAC) module as the main encoder block is introduced, which enhances the CNN features with stronger long-range object contexts.", "example": "Convert the coordinate to text: [ 4.0975 -8.2204]:"}
{"text": "Convert the coordinate to text: [-2.9118 -9.6218]: The authors undertake the first large-scale computational investigation of dogwhistles. They create a typology of dogwhistles, build a glossary of over 300 examples, analyze their usage in historical speeches, and assess how a large language model (GPT-3) performs in identifying dogwhistles and their meanings.", "target": "The authors undertake the first large-scale computational investigation of dogwhistles. They create a typology of dogwhistles, build a glossary of over 300 examples, analyze their usage in historical speeches, and assess how a large language model (GPT-3) performs in identifying dogwhistles and their meanings.", "example": "Convert the coordinate to text: [-2.9118 -9.6218]:"}
{"text": "Convert the coordinate to text: [-0.9011 -3.3984]: The authors developed 'Chain-of-Thought' prompts to facilitate ChatGPT-generated argument contexts (ACs) for predicting the quality of argument revisions.", "target": "The authors developed 'Chain-of-Thought' prompts to facilitate ChatGPT-generated argument contexts (ACs) for predicting the quality of argument revisions.", "example": "Convert the coordinate to text: [-0.9011 -3.3984]:"}
{"text": "Convert the coordinate to text: [11.8717 -0.3508]: The paper introduces a general theoretical framework, based on random matrix theory and the theory of neural tangent kernels, to study the properties of ASR-U systems.", "target": "The paper introduces a general theoretical framework, based on random matrix theory and the theory of neural tangent kernels, to study the properties of ASR-U systems.", "example": "Convert the coordinate to text: [11.8717 -0.3508]:"}
{"text": "Convert the coordinate to text: [-4.4033 -3.1945]: The paper conducts a critical evaluation of recent improvements in DocRE field, questioning their validity as many are based on untenable assumptions such as perfect localization, normalization, and typing of all named entities.", "target": "The paper conducts a critical evaluation of recent improvements in DocRE field, questioning their validity as many are based on untenable assumptions such as perfect localization, normalization, and typing of all named entities.", "example": "Convert the coordinate to text: [-4.4033 -3.1945]:"}
{"text": "Convert the coordinate to text: [ 0.3571 -4.6021]: This study explores compositional generalization for multi-attribute controllable dialogue generation, where a model can learn from seen attribute values and generalize to unseen combinations. A model called DCG is proposed, which is a prompt-based disentangled controllable dialogue generation model.", "target": "This study explores compositional generalization for multi-attribute controllable dialogue generation, where a model can learn from seen attribute values and generalize to unseen combinations. A model called DCG is proposed, which is a prompt-based disentangled controllable dialogue generation model.", "example": "Convert the coordinate to text: [ 0.3571 -4.6021]:"}
{"text": "Convert the coordinate to text: [-1.0954 -5.181 ]: AmbigPrompt is introduced as a solution which involves integrating an answering model with a prompting model iteratively. The prompting model carries out the reading process adaptively and continuously triggers the answering model to compose distinct and relevant answers.", "target": "AmbigPrompt is introduced as a solution which involves integrating an answering model with a prompting model iteratively. The prompting model carries out the reading process adaptively and continuously triggers the answering model to compose distinct and relevant answers.", "example": "Convert the coordinate to text: [-1.0954 -5.181 ]:"}
{"text": "Convert the coordinate to text: [-3.438  -6.5365]: The study introduces a solution named 'MIL-Decoding', a method that detoxifies language models at a token level by integrating the model with a multiple instance learning (MIL) network trained on a corpus with toxicity labels for each text.", "target": "The study introduces a solution named 'MIL-Decoding', a method that detoxifies language models at a token level by integrating the model with a multiple instance learning (MIL) network trained on a corpus with toxicity labels for each text.", "example": "Convert the coordinate to text: [-3.438  -6.5365]:"}
{"text": "Convert the coordinate to text: [-4.2147 -4.594 ]: The authors propose a model named R-BSL that uses Boundary Shift Loss to refine the predicted scope of negation.", "target": "The authors propose a model named R-BSL that uses Boundary Shift Loss to refine the predicted scope of negation.", "example": "Convert the coordinate to text: [-4.2147 -4.594 ]:"}
{"text": "Convert the coordinate to text: [-2.3288 -5.4082]: The team's approach to solve the NER task involves the use of transfer learning by fine-tuning pre-trained language models (PLMs) on the competition dataset, combined with injecting external knowledge.", "target": "The team's approach to solve the NER task involves the use of transfer learning by fine-tuning pre-trained language models (PLMs) on the competition dataset, combined with injecting external knowledge.", "example": "Convert the coordinate to text: [-2.3288 -5.4082]:"}
{"text": "Convert the coordinate to text: [-6.7719 -6.4253]: The authors present an approach to assessing Dutch text complexity at the sentence level and perform an interpretability analysis to explore the correlation between neural models and linguistic complexity features. Based on these insights, they also develop the first contextual lexical simplification model for Dutch.", "target": "The authors present an approach to assessing Dutch text complexity at the sentence level and perform an interpretability analysis to explore the correlation between neural models and linguistic complexity features. Based on these insights, they also develop the first contextual lexical simplification model for Dutch.", "example": "Convert the coordinate to text: [-6.7719 -6.4253]:"}
{"text": "Convert the coordinate to text: [-9.8194 -1.7163]: A new method is proposed for generating question-answer pairs for reading comprehension that takes into account their difficulty level, which is estimated using item response theory. The method focuses on providing difficulty-controllable questions appropriate for each learner\u2019s reading ability.", "target": "A new method is proposed for generating question-answer pairs for reading comprehension that takes into account their difficulty level, which is estimated using item response theory. The method focuses on providing difficulty-controllable questions appropriate for each learner\u2019s reading ability.", "example": "Convert the coordinate to text: [-9.8194 -1.7163]:"}
{"text": "Convert the coordinate to text: [-7.3918 12.1734]: This study leverages a corpus of 442 freely-told stories by Dutch children aged 4-12, recorded in their everyday classroom environments, to study language and ToM using NLP tools. The stories were labelled according to the mental depth of story characters as a proxy for the children\u2019s ToM \u2018in action\u2019.", "target": "This study leverages a corpus of 442 freely-told stories by Dutch children aged 4-12, recorded in their everyday classroom environments, to study language and ToM using NLP tools. The stories were labelled according to the mental depth of story characters as a proxy for the children\u2019s ToM \u2018in action\u2019.", "example": "Convert the coordinate to text: [-7.3918 12.1734]:"}
{"text": "Convert the coordinate to text: [ 4.3283 -0.9777]: The authors propose a class-rebalancing self-training framework to address class-level imbalanced performance in distantly-supervised named entity recognition. A class-wise flexible threshold is used for candidate selection and a hybrid pseudo label is adopted for label generation.", "target": "The authors propose a class-rebalancing self-training framework to address class-level imbalanced performance in distantly-supervised named entity recognition. A class-wise flexible threshold is used for candidate selection and a hybrid pseudo label is adopted for label generation.", "example": "Convert the coordinate to text: [ 4.3283 -0.9777]:"}
{"text": "Convert the coordinate to text: [-2.5252 -5.0988]: The authors of this tutorial aim to provide a centralized and cohesive discussion of critical considerations when choosing how to generate from a language model, covering a wide range of empirically-observed problems and their corresponding proposed algorithmic solutions.", "target": "The authors of this tutorial aim to provide a centralized and cohesive discussion of critical considerations when choosing how to generate from a language model, covering a wide range of empirically-observed problems and their corresponding proposed algorithmic solutions.", "example": "Convert the coordinate to text: [-2.5252 -5.0988]:"}
{"text": "Convert the coordinate to text: [16.2045  1.7705]: This research aims to highlight the limitations of current techniques in detecting out-of-distribution (OOD) behavior in Natural Language Processing (NLP) tasks by evaluating eight methods that are easily integrable and don't require additional OOD data or model modifications.", "target": "This research aims to highlight the limitations of current techniques in detecting out-of-distribution (OOD) behavior in Natural Language Processing (NLP) tasks by evaluating eight methods that are easily integrable and don't require additional OOD data or model modifications.", "example": "Convert the coordinate to text: [16.2045  1.7705]:"}
{"text": "Convert the coordinate to text: [-9.6503 -0.8816]: The authors introduce the first dataset (Question Intention Dataset) that includes questions with both positive/neutral and negative intentions and underlying intention categories within each group. They propose a classification method using Transformers augmented by TF-IDF-based features for classifying the main intention categories.", "target": "The authors introduce the first dataset (Question Intention Dataset) that includes questions with both positive/neutral and negative intentions and underlying intention categories within each group. They propose a classification method using Transformers augmented by TF-IDF-based features for classifying the main intention categories.", "example": "Convert the coordinate to text: [-9.6503 -0.8816]:"}
{"text": "Convert the coordinate to text: [13.1207 -6.8924]: The authors highlight the importance of controlling the generator capacity in ELECTRA-style training and propose to modularize the generator optimization, by fully decoupling the generator optimizer and the discriminator optimizer.", "target": "The authors highlight the importance of controlling the generator capacity in ELECTRA-style training and propose to modularize the generator optimization, by fully decoupling the generator optimizer and the discriminator optimizer.", "example": "Convert the coordinate to text: [13.1207 -6.8924]:"}
{"text": "Convert the coordinate to text: [ 11.9796 -12.3449]: This study defines and tackles the Cloth2Body problem aiming to generate 3D human body meshes from 2D clothing images. The authors propose an end-to-end framework that can estimate 3D body mesh parameterized by pose and shape.", "target": "This study defines and tackles the Cloth2Body problem aiming to generate 3D human body meshes from 2D clothing images. The authors propose an end-to-end framework that can estimate 3D body mesh parameterized by pose and shape.", "example": "Convert the coordinate to text: [ 11.9796 -12.3449]:"}
{"text": "Convert the coordinate to text: [2.3336 0.7327]: The authors follow a model introduced by Cai and Daskalakis to consider the case that bidders' prior distributions can be well-approximated by a topic model. They present a new approach consisting of an active learning component and a mechanism design component, in effect bridging the theory of mechanism design with the technique of Randomized Linear Algebra (RLA) for regression problems.", "target": "The authors follow a model introduced by Cai and Daskalakis to consider the case that bidders' prior distributions can be well-approximated by a topic model. They present a new approach consisting of an active learning component and a mechanism design component, in effect bridging the theory of mechanism design with the technique of Randomized Linear Algebra (RLA) for regression problems.", "example": "Convert the coordinate to text: [2.3336 0.7327]:"}
{"text": "Convert the coordinate to text: [ -1.4424 -13.2258]: The authors propose an Explicit Conditional Multimodal Variational Auto-Encoder (ECMVAE) for AVS, which models the contribution of each modality (audio and visual data) explicitly. This is achieved by factorizing the representations of each modality with a modality-shared representation and a modality-specific representation.", "target": "The authors propose an Explicit Conditional Multimodal Variational Auto-Encoder (ECMVAE) for AVS, which models the contribution of each modality (audio and visual data) explicitly. This is achieved by factorizing the representations of each modality with a modality-shared representation and a modality-specific representation.", "example": "Convert the coordinate to text: [ -1.4424 -13.2258]:"}
{"text": "Convert the coordinate to text: [ 10.3234 -16.1185]: This paper takes a new perspective for crack detection by modeling cracks as a series of sub-cracks with corresponding orientations. A new method, CrackDet, is proposed that uses a novel piecewise angle definition to alleviate the boundary discontinuity problem, and a multi-branch angle regression loss for learning the orientation and variance of the sub-cracks together.", "target": "This paper takes a new perspective for crack detection by modeling cracks as a series of sub-cracks with corresponding orientations. A new method, CrackDet, is proposed that uses a novel piecewise angle definition to alleviate the boundary discontinuity problem, and a multi-branch angle regression loss for learning the orientation and variance of the sub-cracks together.", "example": "Convert the coordinate to text: [ 10.3234 -16.1185]:"}
{"text": "Convert the coordinate to text: [ 2.3678 -4.8841]: The authors propose a hierarchical framework to learn a grand unified representation (GUR) for USL-VI-ReID that tackles hierarchical discrepancy and unifies identities across two modalities. The GUR entails a bottom-up domain learning strategy to explore the information of hierarchical domains and a cross-modality label unification module to construct a cross-modality affinity matrix for propagating labels between two modalities.", "target": "The authors propose a hierarchical framework to learn a grand unified representation (GUR) for USL-VI-ReID that tackles hierarchical discrepancy and unifies identities across two modalities. The GUR entails a bottom-up domain learning strategy to explore the information of hierarchical domains and a cross-modality label unification module to construct a cross-modality affinity matrix for propagating labels between two modalities.", "example": "Convert the coordinate to text: [ 2.3678 -4.8841]:"}
{"text": "Convert the coordinate to text: [10.3096 -3.6241]: TripLe is proposed, which partially scales the model before training while growing the remaining new parameters during training\u2014these new parameters copy the warmed-up weights with their optimizer states from existing weights. This approach also includes the serialization of model width and depth scaling, ensuring the preservation of each expansion's functionality.", "target": "TripLe is proposed, which partially scales the model before training while growing the remaining new parameters during training\u2014these new parameters copy the warmed-up weights with their optimizer states from existing weights. This approach also includes the serialization of model width and depth scaling, ensuring the preservation of each expansion's functionality.", "example": "Convert the coordinate to text: [10.3096 -3.6241]:"}
{"text": "Convert the coordinate to text: [15.6593 -0.0886]: The authors propose a zero-shot sharpness-aware quantization (ZSAQ) framework for the zero-shot quantization of various pre-trained language models which leverages SAM-SGA optimization to improve quantization accuracy and model generalization.", "target": "The authors propose a zero-shot sharpness-aware quantization (ZSAQ) framework for the zero-shot quantization of various pre-trained language models which leverages SAM-SGA optimization to improve quantization accuracy and model generalization.", "example": "Convert the coordinate to text: [15.6593 -0.0886]:"}
{"text": "Convert the coordinate to text: [ 5.5594 -2.5687]: You Only Condense Once (YOCO) is proposed to address these issues. It generates smaller condensed datasets from an initial condensed dataset through two simple pruning rules: Low LBPE Score and Balanced Construction.", "target": "You Only Condense Once (YOCO) is proposed to address these issues. It generates smaller condensed datasets from an initial condensed dataset through two simple pruning rules: Low LBPE Score and Balanced Construction.", "example": "Convert the coordinate to text: [ 5.5594 -2.5687]:"}
{"text": "Convert the coordinate to text: [ 2.5242 -8.1189]: This paper rethinks the importance of support information and proposes a new query-centric FSS model, Adversarial Mining Transformer (AMFormer), which can achieve accurate query image segmentation with only rough support guidance or even weak support labels.", "target": "This paper rethinks the importance of support information and proposes a new query-centric FSS model, Adversarial Mining Transformer (AMFormer), which can achieve accurate query image segmentation with only rough support guidance or even weak support labels.", "example": "Convert the coordinate to text: [ 2.5242 -8.1189]:"}
{"text": "Convert the coordinate to text: [ 7.0283 -4.1181]: The paper introduces a more complex scenario, Open Test-Time DG (OTDG), where both domain shift and open class may occur on unseen test data, and proposes a novel two-stage framework (Compaction and Disambiguation - CODA) to address this.", "target": "The paper introduces a more complex scenario, Open Test-Time DG (OTDG), where both domain shift and open class may occur on unseen test data, and proposes a novel two-stage framework (Compaction and Disambiguation - CODA) to address this.", "example": "Convert the coordinate to text: [ 7.0283 -4.1181]:"}
{"text": "Convert the coordinate to text: [ 13.0264 -11.6075]: The authors propose FaceComposer, a unified generative model based on the latent diffusion framework. This model, which uses face-specific conditions such as Identity Feature and Projected Normalized Coordinate Code, can perform a variety of facial content creation tasks.", "target": "The authors propose FaceComposer, a unified generative model based on the latent diffusion framework. This model, which uses face-specific conditions such as Identity Feature and Projected Normalized Coordinate Code, can perform a variety of facial content creation tasks.", "example": "Convert the coordinate to text: [ 13.0264 -11.6075]:"}
{"text": "Convert the coordinate to text: [12.032  -8.8372]: The authors introduce StyleDrop, a method that uses a text-to-image model to synthesize images that adhere to a specific style, capturing nuances such as color schemes, shading, design patterns, and global effects.", "target": "The authors introduce StyleDrop, a method that uses a text-to-image model to synthesize images that adhere to a specific style, capturing nuances such as color schemes, shading, design patterns, and global effects.", "example": "Convert the coordinate to text: [12.032  -8.8372]:"}
{"text": "Convert the coordinate to text: [-0.0421 -8.9793]: This paper proposes a Local modality-customized Value Estimation (LVE) paradigm, in contrast to the typical Global Value Estimation methods, which dynamically estimates the contribution of each modality and adjusts their importance weights. Also, a task-contextual re-fusion process is developed to achieve a task-level re-balance of estimations from both feature and value levels.", "target": "This paper proposes a Local modality-customized Value Estimation (LVE) paradigm, in contrast to the typical Global Value Estimation methods, which dynamically estimates the contribution of each modality and adjusts their importance weights. Also, a task-contextual re-fusion process is developed to achieve a task-level re-balance of estimations from both feature and value levels.", "example": "Convert the coordinate to text: [-0.0421 -8.9793]:"}
{"text": "Convert the coordinate to text: [-1.2061 -4.8927]: This study proposes a pre-training approach, ConPrompt, that leverages machine-generated data for implicit hate speech detection. ToxiGen-ConPrompt, a pre-trained language model for implicit hate speech detection, is presented, which uses example statements from the same prompt for contrastive learning.", "target": "This study proposes a pre-training approach, ConPrompt, that leverages machine-generated data for implicit hate speech detection. ToxiGen-ConPrompt, a pre-trained language model for implicit hate speech detection, is presented, which uses example statements from the same prompt for contrastive learning.", "example": "Convert the coordinate to text: [-1.2061 -4.8927]:"}
{"text": "Convert the coordinate to text: [11.9649  7.4304]: This paper formulates GDRO as a stochastic convex-concave saddle-point problem, and uses stochastic mirror descent (SMD) in the optimization process. The authors also propose a novel concept of weighted GDRO to handle scenarios where the number of samples from each distribution varies.", "target": "This paper formulates GDRO as a stochastic convex-concave saddle-point problem, and uses stochastic mirror descent (SMD) in the optimization process. The authors also propose a novel concept of weighted GDRO to handle scenarios where the number of samples from each distribution varies.", "example": "Convert the coordinate to text: [11.9649  7.4304]:"}
{"text": "Convert the coordinate to text: [-1.1434 -4.9256]: This paper reevaluates existing techniques for automated prompting across a range of downstream tasks and K-shot learning scenarios, and questions the assumption that automated prompting consistently outperforms simple manual prompts.", "target": "This paper reevaluates existing techniques for automated prompting across a range of downstream tasks and K-shot learning scenarios, and questions the assumption that automated prompting consistently outperforms simple manual prompts.", "example": "Convert the coordinate to text: [-1.1434 -4.9256]:"}
{"text": "Convert the coordinate to text: [ 3.6945 -5.4233]: The authors introduce a new challenge, 'GNN Session-based New Item Recommendation (GSNIR)', and propose a solution in the form of a dual-intent enhanced graph neural network designed to recommend new items to users.", "target": "The authors introduce a new challenge, 'GNN Session-based New Item Recommendation (GSNIR)', and propose a solution in the form of a dual-intent enhanced graph neural network designed to recommend new items to users.", "example": "Convert the coordinate to text: [ 3.6945 -5.4233]:"}
{"text": "Convert the coordinate to text: [ 3.8905 -4.032 ]: The authors propose a new unlearning framework, KGA (Knowledge Gap Alignment), that maintains distribution differences (knowledge gap), which opposes from previous works that try to recover gradients or forces models to perform close to one specific distribution.", "target": "The authors propose a new unlearning framework, KGA (Knowledge Gap Alignment), that maintains distribution differences (knowledge gap), which opposes from previous works that try to recover gradients or forces models to perform close to one specific distribution.", "example": "Convert the coordinate to text: [ 3.8905 -4.032 ]:"}
{"text": "Convert the coordinate to text: [4.1919 0.3645]: In this work, the authors propose Q-Diversity, a reformulation of the group DRO framework that can relax group identification from annotation into direct parameterization and uses a novel mixing strategy to diversify under-represented groups.", "target": "In this work, the authors propose Q-Diversity, a reformulation of the group DRO framework that can relax group identification from annotation into direct parameterization and uses a novel mixing strategy to diversify under-represented groups.", "example": "Convert the coordinate to text: [4.1919 0.3645]:"}
{"text": "Convert the coordinate to text: [-6.0431 -6.4477]: The authors introduce a parallel tense test set containing 552 French-English utterances and establish a corresponding benchmark for tense prediction accuracy.", "target": "The authors introduce a parallel tense test set containing 552 French-English utterances and establish a corresponding benchmark for tense prediction accuracy.", "example": "Convert the coordinate to text: [-6.0431 -6.4477]:"}
{"text": "Convert the coordinate to text: [-4.1237 -2.5963]: The authors propose to quantitatively measure a model's sensitivity on speaker names and evaluate known methods for reducing speaker name sensitivity, including a novel approach of their own.", "target": "The authors propose to quantitatively measure a model's sensitivity on speaker names and evaluate known methods for reducing speaker name sensitivity, including a novel approach of their own.", "example": "Convert the coordinate to text: [-4.1237 -2.5963]:"}
{"text": "Convert the coordinate to text: [ 5.6406 -4.853 ]: The authors propose a policy, GFN4Rec, a generative method that leverages the concept of flow networks to align list generation probability and its reward. It includes a log scale reward matching loss to intrinsically improve the generation diversity and an autoregressive item selection model to capture item mutual influences.", "target": "The authors propose a policy, GFN4Rec, a generative method that leverages the concept of flow networks to align list generation probability and its reward. It includes a log scale reward matching loss to intrinsically improve the generation diversity and an autoregressive item selection model to capture item mutual influences.", "example": "Convert the coordinate to text: [ 5.6406 -4.853 ]:"}
{"text": "Convert the coordinate to text: [-1.8984  2.6571]: The authors propose LLM-Blender, an ensembling framework that incorporates two modules: PairRanker and GenFuser. PairRanker employs a specialized pairwise comparison method to distinguish subtle differences between candidate outputs. GenFuser merges the top-ranked candidates, generating improved outputs.", "target": "The authors propose LLM-Blender, an ensembling framework that incorporates two modules: PairRanker and GenFuser. PairRanker employs a specialized pairwise comparison method to distinguish subtle differences between candidate outputs. GenFuser merges the top-ranked candidates, generating improved outputs.", "example": "Convert the coordinate to text: [-1.8984  2.6571]:"}
{"text": "Convert the coordinate to text: [-2.6444 -3.5842]: This paper proposes a multi-stage method called Typed Predicate-Entailment Graph Generator (TP-EGG) that generates new predicates and detects entailment relations among them, leveraging pre-trained language models and bypassing the need for specially prepared corpora.", "target": "This paper proposes a multi-stage method called Typed Predicate-Entailment Graph Generator (TP-EGG) that generates new predicates and detects entailment relations among them, leveraging pre-trained language models and bypassing the need for specially prepared corpora.", "example": "Convert the coordinate to text: [-2.6444 -3.5842]:"}
{"text": "Convert the coordinate to text: [-1.8044 -5.8777]: The authors proposed using a GPT2-based pre-trained model, fine-tuned for Subtask 2, and transformed the evidence retrieval task into a binary classification task by combining premises and statements as input.", "target": "The authors proposed using a GPT2-based pre-trained model, fine-tuned for Subtask 2, and transformed the evidence retrieval task into a binary classification task by combining premises and statements as input.", "example": "Convert the coordinate to text: [-1.8044 -5.8777]:"}
{"text": "Convert the coordinate to text: [ 1.3456 -2.5607]: The authors propose DITTO, a method for efficient and fair targeted subset selection that uses Submodular Mutual Information (SMI) functions to find representative speech samples of target accents, within a fixed budget, for effective ASR finetuning.", "target": "The authors propose DITTO, a method for efficient and fair targeted subset selection that uses Submodular Mutual Information (SMI) functions to find representative speech samples of target accents, within a fixed budget, for effective ASR finetuning.", "example": "Convert the coordinate to text: [ 1.3456 -2.5607]:"}
{"text": "Convert the coordinate to text: [ 5.0737 -5.7293]: The authors introduce PERT-GNN, a generic graph neural network framework, which predicts end-to-end latency for microservice applications by characterizing interactions or dependencies of microservices using the Program Evaluation and Review Technique (PERT). The system captures complex temporal causality of different microservice traces for more accurate latency predictions.", "target": "The authors introduce PERT-GNN, a generic graph neural network framework, which predicts end-to-end latency for microservice applications by characterizing interactions or dependencies of microservices using the Program Evaluation and Review Technique (PERT). The system captures complex temporal causality of different microservice traces for more accurate latency predictions.", "example": "Convert the coordinate to text: [ 5.0737 -5.7293]:"}
{"text": "Convert the coordinate to text: [-0.4437 -3.6772]: The authors propose a degree-free solution called Multi-Modal Knowledge Hyper Graph (MKHG) that models many-to-many relationships and diversifies sub-semantics via various hyperlinks, addressing the challenge of heterogeneous sources and modalities.", "target": "The authors propose a degree-free solution called Multi-Modal Knowledge Hyper Graph (MKHG) that models many-to-many relationships and diversifies sub-semantics via various hyperlinks, addressing the challenge of heterogeneous sources and modalities.", "example": "Convert the coordinate to text: [-0.4437 -3.6772]:"}
{"text": "Convert the coordinate to text: [8.8989 5.7068]: The paper proposes STEP, an Adam-aware recipe that learns N:M masks in two phases, tackling the issue of poorly estimated second moment in Adam states given by the masked weights. The first phase calculates a reliable variance estimate (precondition phase), and the second phase keeps the variance fixed and uses them as preconditions to learn N:M masks (mask-learning phase).", "target": "The paper proposes STEP, an Adam-aware recipe that learns N:M masks in two phases, tackling the issue of poorly estimated second moment in Adam states given by the masked weights. The first phase calculates a reliable variance estimate (precondition phase), and the second phase keeps the variance fixed and uses them as preconditions to learn N:M masks (mask-learning phase).", "example": "Convert the coordinate to text: [8.8989 5.7068]:"}
{"text": "Convert the coordinate to text: [-3.0241 -9.4202]: The study proposes a Generative Spoken Language Model (GSLM) that operates based on word-size continuous-valued audio embeddings rather than discrete units, aiming to generate diverse and expressive language output.", "target": "The study proposes a Generative Spoken Language Model (GSLM) that operates based on word-size continuous-valued audio embeddings rather than discrete units, aiming to generate diverse and expressive language output.", "example": "Convert the coordinate to text: [-3.0241 -9.4202]:"}
{"text": "Convert the coordinate to text: [9.9472 4.7725]: The study aims to analyze the biases in foundation models and proposes the method of Generalized Logit Adjustment (GLA) to address them. The GLA employs an optimization-based bias estimation approach for debiasing foundation models.", "target": "The study aims to analyze the biases in foundation models and proposes the method of Generalized Logit Adjustment (GLA) to address them. The GLA employs an optimization-based bias estimation approach for debiasing foundation models.", "example": "Convert the coordinate to text: [9.9472 4.7725]:"}
{"text": "Convert the coordinate to text: [ 6.1913 11.8006]: The authors extend the theory of MDPs by addressing an unexplored issue, i.e., the functionals of the reward that can be computed and optimized exactly within MDPs, with a particular focus on the planning problem.", "target": "The authors extend the theory of MDPs by addressing an unexplored issue, i.e., the functionals of the reward that can be computed and optimized exactly within MDPs, with a particular focus on the planning problem.", "example": "Convert the coordinate to text: [ 6.1913 11.8006]:"}
{"text": "Convert the coordinate to text: [ 5.8019 -2.1221]: The authors propose Context-Aware Automated Feature Engineering (CAAFE), a feature engineering method that leverages large language models to iteratively generate semantically meaningful features for tabular datasets based on their descriptions.", "target": "The authors propose Context-Aware Automated Feature Engineering (CAAFE), a feature engineering method that leverages large language models to iteratively generate semantically meaningful features for tabular datasets based on their descriptions.", "example": "Convert the coordinate to text: [ 5.8019 -2.1221]:"}
{"text": "Convert the coordinate to text: [11.625  -1.5025]: The authors propose to investigate a new proxy model of a standard linear network: a rank-1 linear network (each weight matrix is parameterized in rank-1 form). They present a potential function such that GD converges to its minimizer constrained by zero training error and further characterize the role of the noise introduced by SGD.", "target": "The authors propose to investigate a new proxy model of a standard linear network: a rank-1 linear network (each weight matrix is parameterized in rank-1 form). They present a potential function such that GD converges to its minimizer constrained by zero training error and further characterize the role of the noise introduced by SGD.", "example": "Convert the coordinate to text: [11.625  -1.5025]:"}
{"text": "Convert the coordinate to text: [ 10.1953 -10.5569]: This study proposes a novel solution to this challenge: a reconstruction-based method for synthetic-to-real domain adaptation. It uses geometric transformations of a base image according to predicted keypoints and applies a reconstruction loss to refine predictions.", "target": "This study proposes a novel solution to this challenge: a reconstruction-based method for synthetic-to-real domain adaptation. It uses geometric transformations of a base image according to predicted keypoints and applies a reconstruction loss to refine predictions.", "example": "Convert the coordinate to text: [ 10.1953 -10.5569]:"}
{"text": "Convert the coordinate to text: [-2.8138 -6.7713]: The team experimented with monolingual and multilingual models, the application of class weights and sample weights, and two distinct fine-tuning strategies (task-agnostic and task-dependent).", "target": "The team experimented with monolingual and multilingual models, the application of class weights and sample weights, and two distinct fine-tuning strategies (task-agnostic and task-dependent).", "example": "Convert the coordinate to text: [-2.8138 -6.7713]:"}
{"text": "Convert the coordinate to text: [-3.9693 -3.3532]: The paper discusses the results of SemEval 2023 task 7 -- Multi-Evidence Natural Language Inference for Clinical Trial Data -- which consisted of an NLI task and an evidence selection task on clinical trial data.", "target": "The paper discusses the results of SemEval 2023 task 7 -- Multi-Evidence Natural Language Inference for Clinical Trial Data -- which consisted of an NLI task and an evidence selection task on clinical trial data.", "example": "Convert the coordinate to text: [-3.9693 -3.3532]:"}
{"text": "Convert the coordinate to text: [-5.2474 -2.9615]: The authors propose a method to improve the efficiency of integrating textual commonsense descriptions into language models without modifying the model, by grouping training samples with similar commonsense descriptions into a single batch and reusing the encoded description across multiple samples.", "target": "The authors propose a method to improve the efficiency of integrating textual commonsense descriptions into language models without modifying the model, by grouping training samples with similar commonsense descriptions into a single batch and reusing the encoded description across multiple samples.", "example": "Convert the coordinate to text: [-5.2474 -2.9615]:"}
{"text": "Convert the coordinate to text: [-0.5717 -3.307 ]: The authors propose a model, MultiTool-CoT, which leverages chain-of-thought (CoT) prompting to incorporate multiple external tools during the reasoning process.", "target": "The authors propose a model, MultiTool-CoT, which leverages chain-of-thought (CoT) prompting to incorporate multiple external tools during the reasoning process.", "example": "Convert the coordinate to text: [-0.5717 -3.307 ]:"}
{"text": "Convert the coordinate to text: [-5.7637 -0.6036]: The researchers propose FERRANTI, a fine-grained evaluation framework for FEC in dialogue summarization. They also create the first manually annotated FEC dataset for dialogue summarization containing 4,000 items.", "target": "The researchers propose FERRANTI, a fine-grained evaluation framework for FEC in dialogue summarization. They also create the first manually annotated FEC dataset for dialogue summarization containing 4,000 items.", "example": "Convert the coordinate to text: [-5.7637 -0.6036]:"}
{"text": "Convert the coordinate to text: [-5.7924 -0.6961]: The paper presents GUMSum, a carefully crafted dataset of English summaries in 12 different written and spoken genres, specifically for evaluating abstractive summarization. The summaries are highly constrained with focus on substitutive potential, factuality, and faithfulness.", "target": "The paper presents GUMSum, a carefully crafted dataset of English summaries in 12 different written and spoken genres, specifically for evaluating abstractive summarization. The summaries are highly constrained with focus on substitutive potential, factuality, and faithfulness.", "example": "Convert the coordinate to text: [-5.7924 -0.6961]:"}
{"text": "Convert the coordinate to text: [-0.8521 -5.0379]: This paper presents a generative zero-shot prompt learning framework which aims for improving generalization and robustness in the cross-domain slot filling. A novel inverse prompting strategy is released to discern different slot types and avoid multiple prediction problems, along with an efficient prompt-tuning strategy aimed to provide better performance by only training fewer prompt parameters.", "target": "This paper presents a generative zero-shot prompt learning framework which aims for improving generalization and robustness in the cross-domain slot filling. A novel inverse prompting strategy is released to discern different slot types and avoid multiple prediction problems, along with an efficient prompt-tuning strategy aimed to provide better performance by only training fewer prompt parameters.", "example": "Convert the coordinate to text: [-0.8521 -5.0379]:"}
{"text": "Convert the coordinate to text: [-8.579  -6.3676]: The authors propose the use of L2-specific grammatical microsystems within an Intelligent Computer-assisted Language Learning (ICALL) system, and design new grammatico-functional measures, focusing on the IT, THIS, THAT proform microsystem. These measures consider the paradigmatic relations between words performing the same linguistic functions and their likelihood of occurrence.", "target": "The authors propose the use of L2-specific grammatical microsystems within an Intelligent Computer-assisted Language Learning (ICALL) system, and design new grammatico-functional measures, focusing on the IT, THIS, THAT proform microsystem. These measures consider the paradigmatic relations between words performing the same linguistic functions and their likelihood of occurrence.", "example": "Convert the coordinate to text: [-8.579  -6.3676]:"}
{"text": "Convert the coordinate to text: [0.5068 1.4535]: The authors proposed an approach to evaluate fine-tuned models on three benchmarks: a standard held-out test, a task-agnostic functional benchmark, and a dynamic test set, and explored the use of data cartography to identify high quality training data.", "target": "The authors proposed an approach to evaluate fine-tuned models on three benchmarks: a standard held-out test, a task-agnostic functional benchmark, and a dynamic test set, and explored the use of data cartography to identify high quality training data.", "example": "Convert the coordinate to text: [0.5068 1.4535]:"}
{"text": "Convert the coordinate to text: [ 0.1458 -9.0348]: The RCLN team focused on using the CLIP as their base model while incorporating additional information from captions generated from images and image generation from prompt text using Stable Diffusion.", "target": "The RCLN team focused on using the CLIP as their base model while incorporating additional information from captions generated from images and image generation from prompt text using Stable Diffusion.", "example": "Convert the coordinate to text: [ 0.1458 -9.0348]:"}
{"text": "Convert the coordinate to text: [-3.9856 -7.1984]: The team proposes a multilingual approach that uses machine translation of the input, followed by application of an English prediction model for framing detection in online news articles.", "target": "The team proposes a multilingual approach that uses machine translation of the input, followed by application of an English prediction model for framing detection in online news articles.", "example": "Convert the coordinate to text: [-3.9856 -7.1984]:"}
{"text": "Convert the coordinate to text: [-9.9036 -1.7731]: A composite approach is presented, involving a transformer model trained for Question-Answering, supplemented by a task-specific post-processing technique. Additionally, the authors have engineered strategies to optimize the model as per the task requirements using varied specialist models and a specifically designed post-processor. They further explored data enhancement strategies like Heuristic Labeling and Semi-Supervised Learning.", "target": "A composite approach is presented, involving a transformer model trained for Question-Answering, supplemented by a task-specific post-processing technique. Additionally, the authors have engineered strategies to optimize the model as per the task requirements using varied specialist models and a specifically designed post-processor. They further explored data enhancement strategies like Heuristic Labeling and Semi-Supervised Learning.", "example": "Convert the coordinate to text: [-9.9036 -1.7731]:"}
{"text": "Convert the coordinate to text: [-3.1952 -9.9133]: The authors aim to enhance the robustness of discrete input representations for generative spoken language modeling by defining a way to measure robustness against signal variations and introducing a method to learn robust discrete speech representation for such modeling.", "target": "The authors aim to enhance the robustness of discrete input representations for generative spoken language modeling by defining a way to measure robustness against signal variations and introducing a method to learn robust discrete speech representation for such modeling.", "example": "Convert the coordinate to text: [-3.1952 -9.9133]:"}
{"text": "Convert the coordinate to text: [-4.008  -9.0219]: The team from Johns Hopkins developed cascaded speech translation systems for both constrained and unconstrained subtracks, leveraging pre-trained models and domain-specific corpora to tailor their solution to the technical nature of ACL presentations.", "target": "The team from Johns Hopkins developed cascaded speech translation systems for both constrained and unconstrained subtracks, leveraging pre-trained models and domain-specific corpora to tailor their solution to the technical nature of ACL presentations.", "example": "Convert the coordinate to text: [-4.008  -9.0219]:"}
{"text": "Convert the coordinate to text: [-10.0397  -8.0054]: The authors propose a novel approach for EASA enhancement using combinatory categorial grammar (CCG) supertags, which carry both the syntactic and semantic information of the associated words. This method introduces a CCG supertag decoding process to learn the information carried by CCG supertags and guide the attention over the input words.", "target": "The authors propose a novel approach for EASA enhancement using combinatory categorial grammar (CCG) supertags, which carry both the syntactic and semantic information of the associated words. This method introduces a CCG supertag decoding process to learn the information carried by CCG supertags and guide the attention over the input words.", "example": "Convert the coordinate to text: [-10.0397  -8.0054]:"}
{"text": "Convert the coordinate to text: [ 0.4461 -8.9925]: The study proposes to utilize both textual and visual encoders of multi-modal pre-trained models to enhance language understanding tasks by generating an image associated with a textual prompt, thereby enriching the representation of a phrase for downstream tasks.", "target": "The study proposes to utilize both textual and visual encoders of multi-modal pre-trained models to enhance language understanding tasks by generating an image associated with a textual prompt, thereby enriching the representation of a phrase for downstream tasks.", "example": "Convert the coordinate to text: [ 0.4461 -8.9925]:"}
{"text": "Convert the coordinate to text: [-1.0563 -5.0792]: The paper proposes a novel Discriminative Soft Prompts (DSP) approach that reformulates zero-shot tasks into token discrimination tasks without having to construct verbalizers. The approach also includes a soft prompt co-reference strategy to improve inference speed.", "target": "The paper proposes a novel Discriminative Soft Prompts (DSP) approach that reformulates zero-shot tasks into token discrimination tasks without having to construct verbalizers. The approach also includes a soft prompt co-reference strategy to improve inference speed.", "example": "Convert the coordinate to text: [-1.0563 -5.0792]:"}
{"text": "Convert the coordinate to text: [-10.6792  -2.0042]: To address this, the authors present MITQA, a transformer-based TextTableQA system specifically designed to handle distant supervision along these axes, utilizing a multi-instance loss objective and careful curriculum design.", "target": "To address this, the authors present MITQA, a transformer-based TextTableQA system specifically designed to handle distant supervision along these axes, utilizing a multi-instance loss objective and careful curriculum design.", "example": "Convert the coordinate to text: [-10.6792  -2.0042]:"}
{"text": "Convert the coordinate to text: [ 3.2943 14.0499]: The paper establishes the existence of a Nash Equilibrium for any \u03bb-regularized GMFG with less strict conditions compared to previous approaches. It also introduces an efficient algorithm to learn the NE in weakly monotone GMFGs, using a novel action-value function estimation procedure during the online learning process.", "target": "The paper establishes the existence of a Nash Equilibrium for any \u03bb-regularized GMFG with less strict conditions compared to previous approaches. It also introduces an efficient algorithm to learn the NE in weakly monotone GMFGs, using a novel action-value function estimation procedure during the online learning process.", "example": "Convert the coordinate to text: [ 3.2943 14.0499]:"}
{"text": "Convert the coordinate to text: [ 6.9821 -6.6779]: The authors propose a FeedBack Loop Network (FBLNet) which aims to model the procedure of driving experience accumulation. The FBLNet generates incremental knowledge over repeated iterations which simulates the accumulation of human driving experience.", "target": "The authors propose a FeedBack Loop Network (FBLNet) which aims to model the procedure of driving experience accumulation. The FBLNet generates incremental knowledge over repeated iterations which simulates the accumulation of human driving experience.", "example": "Convert the coordinate to text: [ 6.9821 -6.6779]:"}
{"text": "Convert the coordinate to text: [-3.7962 -4.5441]: The paper proposes the idea that concepts are encoded as subspaces of a representation space in text-guided generative models, and develops a method for identifying the part of the representation corresponding to a given concept, allowing for algebraic manipulation of the representation.", "target": "The paper proposes the idea that concepts are encoded as subspaces of a representation space in text-guided generative models, and develops a method for identifying the part of the representation corresponding to a given concept, allowing for algebraic manipulation of the representation.", "example": "Convert the coordinate to text: [-3.7962 -4.5441]:"}
{"text": "Convert the coordinate to text: [ 0.7081 15.6756]: The authors propose to analyze these auctions in both offline and online settings by designing efficient bidding algorithms with low regret, and further study the possible collusion among the bidders in two main auction variants.", "target": "The authors propose to analyze these auctions in both offline and online settings by designing efficient bidding algorithms with low regret, and further study the possible collusion among the bidders in two main auction variants.", "example": "Convert the coordinate to text: [ 0.7081 15.6756]:"}
{"text": "Convert the coordinate to text: [ 7.8617 12.8325]: This study uses concepts from statistical physics to explore the typical learning curves for temporal difference learning of a value function with linear function approximators.", "target": "This study uses concepts from statistical physics to explore the typical learning curves for temporal difference learning of a value function with linear function approximators.", "example": "Convert the coordinate to text: [ 7.8617 12.8325]:"}
{"text": "Convert the coordinate to text: [-10.8577  -1.9955]: The paper focuses on the creation of a large-scale dialogue quality assessment dataset (DiQAD), designed for automatically assessing open-domain dialogue quality. The assessment criteria are established based on dimensions conforming to human judgements on dialogue qualities.", "target": "The paper focuses on the creation of a large-scale dialogue quality assessment dataset (DiQAD), designed for automatically assessing open-domain dialogue quality. The assessment criteria are established based on dimensions conforming to human judgements on dialogue qualities.", "example": "Convert the coordinate to text: [-10.8577  -1.9955]:"}
{"text": "Convert the coordinate to text: [-8.5855  8.8245]: The study aims to explore individual patterns of Bitmoji sticker usage based on dimensions of reciprocity and selectivity, the concept of network homophily among friends, and the potential impact of receiving Bitmoji stickers on future usage and overall Snapchat engagement.", "target": "The study aims to explore individual patterns of Bitmoji sticker usage based on dimensions of reciprocity and selectivity, the concept of network homophily among friends, and the potential impact of receiving Bitmoji stickers on future usage and overall Snapchat engagement.", "example": "Convert the coordinate to text: [-8.5855  8.8245]:"}
{"text": "Convert the coordinate to text: [ -0.714  -12.3642]: The authors proposes MAsked Generative Encoder (MAGE), a pioneering framework that merges state-of-the-art image generation and self-supervised representation learning. The key innovation is the application of variable masking ratios in masked image modeling pre-training to facilitate both generative training and representation learning within the same framework.", "target": "The authors proposes MAsked Generative Encoder (MAGE), a pioneering framework that merges state-of-the-art image generation and self-supervised representation learning. The key innovation is the application of variable masking ratios in masked image modeling pre-training to facilitate both generative training and representation learning within the same framework.", "example": "Convert the coordinate to text: [ -0.714  -12.3642]:"}
{"text": "Convert the coordinate to text: [-10.49    -1.8503]: The authors propose a new task, N-to-N QA extraction, where derived questions and corresponding answers might be separated across different utterances. They also introduce a suite of generative/discriminative tagging based methods with end-to-end and two-stage variants.", "target": "The authors propose a new task, N-to-N QA extraction, where derived questions and corresponding answers might be separated across different utterances. They also introduce a suite of generative/discriminative tagging based methods with end-to-end and two-stage variants.", "example": "Convert the coordinate to text: [-10.49    -1.8503]:"}
{"text": "Convert the coordinate to text: [-10.9598  11.1574]: The authors collaborated to design and deploy a technology that supports front-line staff at the largest emergency housing shelter in Calgary, Canada by creating an interface that offers a holistic understanding of client context to aid decision-making.", "target": "The authors collaborated to design and deploy a technology that supports front-line staff at the largest emergency housing shelter in Calgary, Canada by creating an interface that offers a holistic understanding of client context to aid decision-making.", "example": "Convert the coordinate to text: [-10.9598  11.1574]:"}
{"text": "Convert the coordinate to text: [7.6555 4.6241]: The paper proposes methods for deriving explicit joint distributions from MLMs, specifically focusing on distributions over two tokens, making it possible to calculate exact distributional properties.", "target": "The paper proposes methods for deriving explicit joint distributions from MLMs, specifically focusing on distributions over two tokens, making it possible to calculate exact distributional properties.", "example": "Convert the coordinate to text: [7.6555 4.6241]:"}
{"text": "Convert the coordinate to text: [-5.8325 -3.6516]: The authors propose a hybrid metric that combines functional correctness and syntactic similarity to better represent the real-world value of code generation.", "target": "The authors propose a hybrid metric that combines functional correctness and syntactic similarity to better represent the real-world value of code generation.", "example": "Convert the coordinate to text: [-5.8325 -3.6516]:"}
{"text": "Convert the coordinate to text: [-2.6568 -6.3395]: IXA introduces a sequence labeling fine-tune approach using a lightweight few-shot baseline system (10e), leveraging transfer learning from pre-trained Named Entity Recognition and cross-lingual knowledge from the LM checkpoint.", "target": "IXA introduces a sequence labeling fine-tune approach using a lightweight few-shot baseline system (10e), leveraging transfer learning from pre-trained Named Entity Recognition and cross-lingual knowledge from the LM checkpoint.", "example": "Convert the coordinate to text: [-2.6568 -6.3395]:"}
{"text": "Convert the coordinate to text: [1.3539 2.5959]: A novel Causal Interventional paradigm for MRC (CI4MRC) is proposed to deal with name bias. The authors posit that the pre-trained knowledge concerning names is indeed a confounder, as derived by analyzing the causalities among pre-trained knowledge, context representation, and answers using a Structural Causal Model (SCM).", "target": "A novel Causal Interventional paradigm for MRC (CI4MRC) is proposed to deal with name bias. The authors posit that the pre-trained knowledge concerning names is indeed a confounder, as derived by analyzing the causalities among pre-trained knowledge, context representation, and answers using a Structural Causal Model (SCM).", "example": "Convert the coordinate to text: [1.3539 2.5959]:"}
{"text": "Convert the coordinate to text: [ 3.967 -3.653]: A novel framework called Learned Exits and Comparison-based early exiting (LECO) is proposed to improve PTMs\u2019 early exiting performances. The framework includes a novel search space for intermediate exits and a differentiable neural architecture search (DNAS) to automatically design exit architectures for different intermediate layers.", "target": "A novel framework called Learned Exits and Comparison-based early exiting (LECO) is proposed to improve PTMs\u2019 early exiting performances. The framework includes a novel search space for intermediate exits and a differentiable neural architecture search (DNAS) to automatically design exit architectures for different intermediate layers.", "example": "Convert the coordinate to text: [ 3.967 -3.653]:"}
{"text": "Convert the coordinate to text: [-10.1279  -1.7835]: This study defines three types of questions (grammar, function word, and context) and proposes a method to generate distractors according to the characteristics of each question type.", "target": "This study defines three types of questions (grammar, function word, and context) and proposes a method to generate distractors according to the characteristics of each question type.", "example": "Convert the coordinate to text: [-10.1279  -1.7835]:"}
{"text": "Convert the coordinate to text: [-0.2213 -6.2566]: The authors propose to apply the Fusion-in-Decoder (FiD) approach, originally used in open-domain QA, to ICL, with the aim to improve efficiency and task performance.", "target": "The authors propose to apply the Fusion-in-Decoder (FiD) approach, originally used in open-domain QA, to ICL, with the aim to improve efficiency and task performance.", "example": "Convert the coordinate to text: [-0.2213 -6.2566]:"}
{"text": "Convert the coordinate to text: [-3.0845 -3.3807]: The authors conduct an empirical study on the 'Unlabeled Entity Problem' and propose a novel representation learning method to learn discriminating representations for the entity classes and 'O'. They also propose an entity-aware contrastive learning method that detects entity clusters within 'O' and two distance-based relabeling strategies for better learning of old classes.", "target": "The authors conduct an empirical study on the 'Unlabeled Entity Problem' and propose a novel representation learning method to learn discriminating representations for the entity classes and 'O'. They also propose an entity-aware contrastive learning method that detects entity clusters within 'O' and two distance-based relabeling strategies for better learning of old classes.", "example": "Convert the coordinate to text: [-3.0845 -3.3807]:"}
{"text": "Convert the coordinate to text: [-3.0089 -3.3812]: The authors introduce Code4Struct, a method that leverages text-to-structure translation capability of LLMs to tackle structured prediction tasks. Particularly, they formulate Event Argument Extraction (EAE) as converting text into event-argument structures that can be represented as a class object using code.", "target": "The authors introduce Code4Struct, a method that leverages text-to-structure translation capability of LLMs to tackle structured prediction tasks. Particularly, they formulate Event Argument Extraction (EAE) as converting text into event-argument structures that can be represented as a class object using code.", "example": "Convert the coordinate to text: [-3.0089 -3.3812]:"}
{"text": "Convert the coordinate to text: [  0.3186 -15.2588]: The study introduces a new attention readout for a convolutional data-driven core for neurons in macaque V4 and proposes a diffusion-based method for generating MEIs via Energy Guidance (EGG), which aims to resolve the problems of synthesizing MEIs through traditional gradient ascent.", "target": "The study introduces a new attention readout for a convolutional data-driven core for neurons in macaque V4 and proposes a diffusion-based method for generating MEIs via Energy Guidance (EGG), which aims to resolve the problems of synthesizing MEIs through traditional gradient ascent.", "example": "Convert the coordinate to text: [  0.3186 -15.2588]:"}
{"text": "Convert the coordinate to text: [-2.8851 14.8998]: This paper proposes a new approach called GridMM for structuring a previously visited environment. Rather than using the methods mentioned earlier, GridMM creates a top-down, egocentric, dynamically growing grid map of the observed environment where historical data is projected from a global perspective.", "target": "This paper proposes a new approach called GridMM for structuring a previously visited environment. Rather than using the methods mentioned earlier, GridMM creates a top-down, egocentric, dynamically growing grid map of the observed environment where historical data is projected from a global perspective.", "example": "Convert the coordinate to text: [-2.8851 14.8998]:"}
{"text": "Convert the coordinate to text: [10.4544  7.4813]: To fill the study gap, the authors introduce an optimality criterion for the tightness of approximation which enables the development of optimal bounds for any function convex in the region of interest, and propose a sampling-based technique (SOL) for more general Lipshitz-continuous functions.", "target": "To fill the study gap, the authors introduce an optimality criterion for the tightness of approximation which enables the development of optimal bounds for any function convex in the region of interest, and propose a sampling-based technique (SOL) for more general Lipshitz-continuous functions.", "example": "Convert the coordinate to text: [10.4544  7.4813]:"}
{"text": "Convert the coordinate to text: [-5.8288 -0.5959]: The authors propose an adaptive model, GEMINI, that integrates a sentence rewriter and a generator to mimic human summary writing techniques. GEMINI can adaptively choose to rewrite a specific document sentence or generate a summary sentence from scratch.", "target": "The authors propose an adaptive model, GEMINI, that integrates a sentence rewriter and a generator to mimic human summary writing techniques. GEMINI can adaptively choose to rewrite a specific document sentence or generate a summary sentence from scratch.", "example": "Convert the coordinate to text: [-5.8288 -0.5959]:"}
{"text": "Convert the coordinate to text: [-4.6363 -1.1336]: The authors propose a simple yet effective solution, Syntax-Integrated RoBERTa for ABSC (SIR-ABSC), which incorporates syntax directly into the language model by using a novel aggregator token.", "target": "The authors propose a simple yet effective solution, Syntax-Integrated RoBERTa for ABSC (SIR-ABSC), which incorporates syntax directly into the language model by using a novel aggregator token.", "example": "Convert the coordinate to text: [-4.6363 -1.1336]:"}
{"text": "Convert the coordinate to text: [-9.4239  6.774 ]: PostGuard, a secure email encryption solution is proposed. Its uniqueness lies in combining identity-based encryption with a digital identity wallet, which allows senders to specify recipients' attributes for email decryption, reducing decryption process to authentication.", "target": "PostGuard, a secure email encryption solution is proposed. Its uniqueness lies in combining identity-based encryption with a digital identity wallet, which allows senders to specify recipients' attributes for email decryption, reducing decryption process to authentication.", "example": "Convert the coordinate to text: [-9.4239  6.774 ]:"}
{"text": "Convert the coordinate to text: [-2.9925 -3.5669]: The authors argue for different strategies to handle the two types of noise in Distantly-Supervised Named Entity Recognition, and propose the SANTA model, which uses Memory-smoothed Focal Loss and Entity-aware KNN to handle inaccurate annotation and Boundary Mixup to handle incomplete annotation.", "target": "The authors argue for different strategies to handle the two types of noise in Distantly-Supervised Named Entity Recognition, and propose the SANTA model, which uses Memory-smoothed Focal Loss and Entity-aware KNN to handle inaccurate annotation and Boundary Mixup to handle incomplete annotation.", "example": "Convert the coordinate to text: [-2.9925 -3.5669]:"}
{"text": "Convert the coordinate to text: [ 0.5897 -7.9785]: The authors propose a new task, MEMEX - given a meme and a related document, the goal is to mine the context that succinctly explains the background of the meme. To facilitate this task, the authors propose MIME (MultImodal Meme Explainer), a multimodal neural framework that uses common sense enriched meme representation and a layered approach to capture the cross-modal semantic dependencies between the meme and the context.", "target": "The authors propose a new task, MEMEX - given a meme and a related document, the goal is to mine the context that succinctly explains the background of the meme. To facilitate this task, the authors propose MIME (MultImodal Meme Explainer), a multimodal neural framework that uses common sense enriched meme representation and a layered approach to capture the cross-modal semantic dependencies between the meme and the context.", "example": "Convert the coordinate to text: [ 0.5897 -7.9785]:"}
{"text": "Convert the coordinate to text: [12.4495  3.0008]: The authors propose the usage of banded matrix mechanisms with MF to absorb prior state-of-the-art algorithms in both federated and centralized training settings, thus addressing the issue of poor performance and applicability in some scenarios.", "target": "The authors propose the usage of banded matrix mechanisms with MF to absorb prior state-of-the-art algorithms in both federated and centralized training settings, thus addressing the issue of poor performance and applicability in some scenarios.", "example": "Convert the coordinate to text: [12.4495  3.0008]:"}
{"text": "Convert the coordinate to text: [-1.3936  0.1195]: The authors developed a novel neural framework for sexism detection and misogyny which combines text representations from pre-trained language models like Bidirectional Encoder Representations from Transformers (BERT), BiLSTM architectures, and data augmentation techniques.", "target": "The authors developed a novel neural framework for sexism detection and misogyny which combines text representations from pre-trained language models like Bidirectional Encoder Representations from Transformers (BERT), BiLSTM architectures, and data augmentation techniques.", "example": "Convert the coordinate to text: [-1.3936  0.1195]:"}
{"text": "Convert the coordinate to text: [-7.336  -6.3481]: This study proposes a dynamic model that tracks accumulation of lexical experience as one reads through a book in order to explain the variance in measurements of children's fluency.", "target": "This study proposes a dynamic model that tracks accumulation of lexical experience as one reads through a book in order to explain the variance in measurements of children's fluency.", "example": "Convert the coordinate to text: [-7.336  -6.3481]:"}
{"text": "Convert the coordinate to text: [10.0692 -3.9515]: This study investigates structured pruning of generative PLMs, which involves hidden dimensions shared by various modules like embedding layer and layer normalization. To identify redundant network structures, learnable masks are assigned over compressible components, followed by sparse training, leading to variable sizes of PLMs which could be fine-tuned for specific tasks.", "target": "This study investigates structured pruning of generative PLMs, which involves hidden dimensions shared by various modules like embedding layer and layer normalization. To identify redundant network structures, learnable masks are assigned over compressible components, followed by sparse training, leading to variable sizes of PLMs which could be fine-tuned for specific tasks.", "example": "Convert the coordinate to text: [10.0692 -3.9515]:"}
{"text": "Convert the coordinate to text: [-2.442  -5.3627]: The authors conduct edge and minimal description length (MDL) probing experiments on three pre-trained language models (PLMs) to scrutinize the encoding of hyperbolic information in these models.", "target": "The authors conduct edge and minimal description length (MDL) probing experiments on three pre-trained language models (PLMs) to scrutinize the encoding of hyperbolic information in these models.", "example": "Convert the coordinate to text: [-2.442  -5.3627]:"}
{"text": "Convert the coordinate to text: [  7.9978 -10.7312]: The authors propose a novel self-supervised learning framework, named Alice, which aims to model anatomical invariance and enable semantic alignment through a combination of discriminative and generative objectives.", "target": "The authors propose a novel self-supervised learning framework, named Alice, which aims to model anatomical invariance and enable semantic alignment through a combination of discriminative and generative objectives.", "example": "Convert the coordinate to text: [  7.9978 -10.7312]:"}
{"text": "Convert the coordinate to text: [ 0.4664 -9.1441]: ViPE is introduced as a robust and lightweight series of language models, trained on a large set of lyrics with noisy visual descriptions that represent their implicit meaning. These synthetic visual descriptions are generated by GPT3.5, without relying on human annotations or images.", "target": "ViPE is introduced as a robust and lightweight series of language models, trained on a large set of lyrics with noisy visual descriptions that represent their implicit meaning. These synthetic visual descriptions are generated by GPT3.5, without relying on human annotations or images.", "example": "Convert the coordinate to text: [ 0.4664 -9.1441]:"}
{"text": "Convert the coordinate to text: [-2.8766 -5.0079]: The authors propose measuring the alignment of large language models (LLMs) with human intuitive theories by comparing their respective causal and moral judgements using a dataset of stories from cognitive science research papers.", "target": "The authors propose measuring the alignment of large language models (LLMs) with human intuitive theories by comparing their respective causal and moral judgements using a dataset of stories from cognitive science research papers.", "example": "Convert the coordinate to text: [-2.8766 -5.0079]:"}
{"text": "Convert the coordinate to text: [ 11.5863 -16.1595]: The paper proposes EgoDistill, a distillation-based approach that reconstructs heavy egocentric video clip features by combining the semantics from a sparse set of video frames with head motion data from lightweight IMU readings.", "target": "The paper proposes EgoDistill, a distillation-based approach that reconstructs heavy egocentric video clip features by combining the semantics from a sparse set of video frames with head motion data from lightweight IMU readings.", "example": "Convert the coordinate to text: [ 11.5863 -16.1595]:"}
{"text": "Convert the coordinate to text: [ 14.3211 -14.9949]: This paper identifies the complexities of synchronizing camera poses with GeNeRFs, then proposes DBARF, a solution that bundle adjusts camera poses using a cost feature map as an implicit cost function and can be jointly trained with GeNeRFs in a self-supervised manner.", "target": "This paper identifies the complexities of synchronizing camera poses with GeNeRFs, then proposes DBARF, a solution that bundle adjusts camera poses using a cost feature map as an implicit cost function and can be jointly trained with GeNeRFs in a self-supervised manner.", "example": "Convert the coordinate to text: [ 14.3211 -14.9949]:"}
{"text": "Convert the coordinate to text: [-0.5195 -6.8413]: The authors propose to solve these tasks as a classification problem by fine-tuning transformer-based architecture, by testing variations such as the combination of multiple transformers, using domain adaptive pretraining on unlabelled datasets, joint learning, and taking different layers of transformers as input to a classification head.", "target": "The authors propose to solve these tasks as a classification problem by fine-tuning transformer-based architecture, by testing variations such as the combination of multiple transformers, using domain adaptive pretraining on unlabelled datasets, joint learning, and taking different layers of transformers as input to a classification head.", "example": "Convert the coordinate to text: [-0.5195 -6.8413]:"}
{"text": "Convert the coordinate to text: [  8.1139 -20.323 ]: The paper introduces a robust object reconstruction pipeline, combining neural based object reconstruction and physics-based inverse rendering (PBIR). The pipeline leverages a neural stage to produce high-quality but potentially imperfect predictions of object shape, reflectance, and illumination, and then refines these initial results using PBIR to obtain the final high-quality reconstruction.", "target": "The paper introduces a robust object reconstruction pipeline, combining neural based object reconstruction and physics-based inverse rendering (PBIR). The pipeline leverages a neural stage to produce high-quality but potentially imperfect predictions of object shape, reflectance, and illumination, and then refines these initial results using PBIR to obtain the final high-quality reconstruction.", "example": "Convert the coordinate to text: [  8.1139 -20.323 ]:"}
{"text": "Convert the coordinate to text: [-0.3575 -0.4504]: This paper introduces logical summary Markov models, a family of models for event sequences that provide interpretable predictions through logical rules that relate historical predicates to the probability of observing an event type at any position in the sequence.", "target": "This paper introduces logical summary Markov models, a family of models for event sequences that provide interpretable predictions through logical rules that relate historical predicates to the probability of observing an event type at any position in the sequence.", "example": "Convert the coordinate to text: [-0.3575 -0.4504]:"}
{"text": "Convert the coordinate to text: [ 5.4412 -6.5237]: The authors propose a novel model, Spatio-Temporal Graph Neural Processes (STGNP), a neural latent variable model, to address the shortcomings of existing methods. The model includes Graph Bayesian Aggregation (GBA), a Bayesian graph aggregator, to consider uncertainties in context data and graph structure.", "target": "The authors propose a novel model, Spatio-Temporal Graph Neural Processes (STGNP), a neural latent variable model, to address the shortcomings of existing methods. The model includes Graph Bayesian Aggregation (GBA), a Bayesian graph aggregator, to consider uncertainties in context data and graph structure.", "example": "Convert the coordinate to text: [ 5.4412 -6.5237]:"}
{"text": "Convert the coordinate to text: [-1.2097 -7.6078]: The paper introduces a hypothesis and methodology: transfer the in-context learning ability from the language domain to VL domain. This is achieved by first meta-training a language model on NLP tasks, and then transferring this model to perform VL tasks by attaching a visual encoder.", "target": "The paper introduces a hypothesis and methodology: transfer the in-context learning ability from the language domain to VL domain. This is achieved by first meta-training a language model on NLP tasks, and then transferring this model to perform VL tasks by attaching a visual encoder.", "example": "Convert the coordinate to text: [-1.2097 -7.6078]:"}
{"text": "Convert the coordinate to text: [ 4.6728 -4.207 ]: The authors propose a novel clustering-based framework called CARL-G for graph representation learning. CARL-G uses a loss inspired by Cluster Validation Indices (CVIs), measures of cluster quality that do not require ground truth labels.", "target": "The authors propose a novel clustering-based framework called CARL-G for graph representation learning. CARL-G uses a loss inspired by Cluster Validation Indices (CVIs), measures of cluster quality that do not require ground truth labels.", "example": "Convert the coordinate to text: [ 4.6728 -4.207 ]:"}
{"text": "Convert the coordinate to text: [ 4.2445 13.1532]: The authors introduce a method for skill disentanglement in imitation learning from sub-optimal demonstrations, functioning on both small clean demonstration sets and large noisy sets. The method operates at the sub-demonstration level, encoding action primitives of varying quality into different skills.", "target": "The authors introduce a method for skill disentanglement in imitation learning from sub-optimal demonstrations, functioning on both small clean demonstration sets and large noisy sets. The method operates at the sub-demonstration level, encoding action primitives of varying quality into different skills.", "example": "Convert the coordinate to text: [ 4.2445 13.1532]:"}
{"text": "Convert the coordinate to text: [18.5303 -3.1853]: The authors propose a new approach for creating spoilers for potential clickbait posts through a system that employs hierarchical encoding with count and document length feature-based modelling for spoiler type classification. Combining multiple ranking with reciprocal rank fusion for passage spoiler retrieval and a question-answering approach for phrase spoiler retrieval is also suggested.", "target": "The authors propose a new approach for creating spoilers for potential clickbait posts through a system that employs hierarchical encoding with count and document length feature-based modelling for spoiler type classification. Combining multiple ranking with reciprocal rank fusion for passage spoiler retrieval and a question-answering approach for phrase spoiler retrieval is also suggested.", "example": "Convert the coordinate to text: [18.5303 -3.1853]:"}
{"text": "Convert the coordinate to text: [-0.7267  0.5929]: The study examines the existence and extent of social biases in biomedical masked language models; additionally, it seeks to bring awareness to the potential repercussions of such biases.", "target": "The study examines the existence and extent of social biases in biomedical masked language models; additionally, it seeks to bring awareness to the potential repercussions of such biases.", "example": "Convert the coordinate to text: [-0.7267  0.5929]:"}
{"text": "Convert the coordinate to text: [-4.8860e-03 -5.0509e+00]: The authors propose a novel domain attention module that uses distributional signatures to effectively construct a multi-domain dialogue system with limited data. They also introduce the concept of an adjacent n-gram pattern to discover potential patterns for dialogue entities.", "target": "The authors propose a novel domain attention module that uses distributional signatures to effectively construct a multi-domain dialogue system with limited data. They also introduce the concept of an adjacent n-gram pattern to discover potential patterns for dialogue entities.", "example": "Convert the coordinate to text: [-4.8860e-03 -5.0509e+00]:"}
{"text": "Convert the coordinate to text: [-5.7137 -0.5761]: The authors propose a multi-document hybrid summarization approach which generates a human-readable summary and extracts corresponding key evidences from multi-doc inputs. They devise a salient representation learning method to induce latent salient features for joint evidence extraction and summary generation.", "target": "The authors propose a multi-document hybrid summarization approach which generates a human-readable summary and extracts corresponding key evidences from multi-doc inputs. They devise a salient representation learning method to induce latent salient features for joint evidence extraction and summary generation.", "example": "Convert the coordinate to text: [-5.7137 -0.5761]:"}
{"text": "Convert the coordinate to text: [-1.739  -5.8906]: The authors propose a multi-intent text revision system that does not require explicit intent annotation, leveraging prefix-tuning, a method that first identifies prefixes for each edit intent, and then training a prefix transfer module to selectively apply the knowledge from these prefixes based on the input text.", "target": "The authors propose a multi-intent text revision system that does not require explicit intent annotation, leveraging prefix-tuning, a method that first identifies prefixes for each edit intent, and then training a prefix transfer module to selectively apply the knowledge from these prefixes based on the input text.", "example": "Convert the coordinate to text: [-1.739  -5.8906]:"}
{"text": "Convert the coordinate to text: [-2.9398 -5.0036]: The authors introduce a benchmark and suite of analyses (referred to as 'OUR' model) for evaluating the reasoning skills of language models, offering a test bed to assess any language model on fine-grained reasoning skills.", "target": "The authors introduce a benchmark and suite of analyses (referred to as 'OUR' model) for evaluating the reasoning skills of language models, offering a test bed to assess any language model on fine-grained reasoning skills.", "example": "Convert the coordinate to text: [-2.9398 -5.0036]:"}
{"text": "Convert the coordinate to text: [ 6.7403 -9.0081]: The authors propose a two-stage end-to-end neural network framework that explicitly models the joint-level features and utilizes them as spatiotemporal tokens for alternating spatial and temporal transformer blocks, which offers a potential solution to improve 3D full-body avatars tracking.", "target": "The authors propose a two-stage end-to-end neural network framework that explicitly models the joint-level features and utilizes them as spatiotemporal tokens for alternating spatial and temporal transformer blocks, which offers a potential solution to improve 3D full-body avatars tracking.", "example": "Convert the coordinate to text: [ 6.7403 -9.0081]:"}
{"text": "Convert the coordinate to text: [4.2904 6.8996]: This paper introduces a GNN framework for solving the MIS problem by developing a dynamic programming-like recursive algorithm that constructs two smaller sub-graphs, predicts which one will have a larger maximum independent set, and uses this prediction in subsequent recursive calls.", "target": "This paper introduces a GNN framework for solving the MIS problem by developing a dynamic programming-like recursive algorithm that constructs two smaller sub-graphs, predicts which one will have a larger maximum independent set, and uses this prediction in subsequent recursive calls.", "example": "Convert the coordinate to text: [4.2904 6.8996]:"}
{"text": "Convert the coordinate to text: [-5.0915 -6.4564]: The authors build an 11B parameter paraphrase generation model (DIPPER) designed to paraphrase paragraphs, condition on surrounding context, and control lexical diversity and content reordering. They also introduce a defense mechanism that increases the robustness of AI-generated text detection to paraphrase attacks by retrieving semantically-similar generations from a database.", "target": "The authors build an 11B parameter paraphrase generation model (DIPPER) designed to paraphrase paragraphs, condition on surrounding context, and control lexical diversity and content reordering. They also introduce a defense mechanism that increases the robustness of AI-generated text detection to paraphrase attacks by retrieving semantically-similar generations from a database.", "example": "Convert the coordinate to text: [-5.0915 -6.4564]:"}
{"text": "Convert the coordinate to text: [ 5.7376 13.9429]: The authors propose a theoretical underpinning of how learning a model can lead to higher efficiency. They also illustrate how a neural network function approximation can show similar improvements, and they provide experiments to prove benefit of model-based learning for online RL in environments with factored structure.", "target": "The authors propose a theoretical underpinning of how learning a model can lead to higher efficiency. They also illustrate how a neural network function approximation can show similar improvements, and they provide experiments to prove benefit of model-based learning for online RL in environments with factored structure.", "example": "Convert the coordinate to text: [ 5.7376 13.9429]:"}
{"text": "Convert the coordinate to text: [-6.607  12.4027]: The paper introduces TransESC, taking into account turn-level state transitions of ESC from three perspectives, including semantics transition, strategy transition, and emotion transition, aiming to facilitate more natural and smooth conversations.", "target": "The paper introduces TransESC, taking into account turn-level state transitions of ESC from three perspectives, including semantics transition, strategy transition, and emotion transition, aiming to facilitate more natural and smooth conversations.", "example": "Convert the coordinate to text: [-6.607  12.4027]:"}
{"text": "Convert the coordinate to text: [-7.1664 -5.5847]: To understand these variations in conceptualization across languages, the authors propose the Conceptualizer, an approach that creates a bipartite directed alignment graph between source language concepts and sets of target language strings.", "target": "To understand these variations in conceptualization across languages, the authors propose the Conceptualizer, an approach that creates a bipartite directed alignment graph between source language concepts and sets of target language strings.", "example": "Convert the coordinate to text: [-7.1664 -5.5847]:"}
{"text": "Convert the coordinate to text: [13.0612 -4.5761]: This study suggests modeling adversarial attack on PLMs as a sequential decision-making problem where the whole attack process is sequential with two decision problems: word finder and word substitution. It proposes a reinforcement learning approach named SDM-Attack to generate adversaries.", "target": "This study suggests modeling adversarial attack on PLMs as a sequential decision-making problem where the whole attack process is sequential with two decision problems: word finder and word substitution. It proposes a reinforcement learning approach named SDM-Attack to generate adversaries.", "example": "Convert the coordinate to text: [13.0612 -4.5761]:"}
{"text": "Convert the coordinate to text: [ 0.7286 -9.753 ]: The paper proposes the establishment of connections between multi-modality video tracks, including Vision, Audio, Subtitles, and Text, through an automatically generated large-scale omni-modality video caption dataset called VAST-27M. They also propose an omni-modality video-text foundational model named VAST that can process these modalities.", "target": "The paper proposes the establishment of connections between multi-modality video tracks, including Vision, Audio, Subtitles, and Text, through an automatically generated large-scale omni-modality video caption dataset called VAST-27M. They also propose an omni-modality video-text foundational model named VAST that can process these modalities.", "example": "Convert the coordinate to text: [ 0.7286 -9.753 ]:"}
{"text": "Convert the coordinate to text: [-3.1629 -6.7442]: The authors introduce multilingual pre-trained language-meaning models based on Discourse Representation Structures (DRSs) and design a new strategy to reduce the gap between the pre-training and fine-tuning objectives.", "target": "The authors introduce multilingual pre-trained language-meaning models based on Discourse Representation Structures (DRSs) and design a new strategy to reduce the gap between the pre-training and fine-tuning objectives.", "example": "Convert the coordinate to text: [-3.1629 -6.7442]:"}
{"text": "Convert the coordinate to text: [ 5.0856 -3.215 ]: The paper introduces two improvements to current MoE approaches. First, it proposes a new sparse gate, COMET, that relies on a novel tree-based mechanism. Second, it proposes a permutation-based local search method to address the challenges related to the combinatorial nature of sparse expert selection.", "target": "The paper introduces two improvements to current MoE approaches. First, it proposes a new sparse gate, COMET, that relies on a novel tree-based mechanism. Second, it proposes a permutation-based local search method to address the challenges related to the combinatorial nature of sparse expert selection.", "example": "Convert the coordinate to text: [ 5.0856 -3.215 ]:"}
{"text": "Convert the coordinate to text: [-3.6092 -3.7967]: The authors propose a fine-grained semantic matching method for zero-shot relation extraction that decomposes sentence-level similarity score into entity and context matching scores.", "target": "The authors propose a fine-grained semantic matching method for zero-shot relation extraction that decomposes sentence-level similarity score into entity and context matching scores.", "example": "Convert the coordinate to text: [-3.6092 -3.7967]:"}
{"text": "Convert the coordinate to text: [ 3.3838 -8.1102]: The authors argue that the attention mechanism is responsible for the stated issues, and propose a constrained attention variant that focuses the attention on the most relevant parts of the sequence, while simultaneously reducing the memory consumption.", "target": "The authors argue that the attention mechanism is responsible for the stated issues, and propose a constrained attention variant that focuses the attention on the most relevant parts of the sequence, while simultaneously reducing the memory consumption.", "example": "Convert the coordinate to text: [ 3.3838 -8.1102]:"}
{"text": "Convert the coordinate to text: [ 5.1135 -0.6042]: The authors propose GraphSHA, a general framework designed to deal with class imbalance by Synthesizing HArder minor samples. A new module called SemiMixup is also introduced to avoid the violation of the subspaces of neighbor classes by the enlarged minor boundary.", "target": "The authors propose GraphSHA, a general framework designed to deal with class imbalance by Synthesizing HArder minor samples. A new module called SemiMixup is also introduced to avoid the violation of the subspaces of neighbor classes by the enlarged minor boundary.", "example": "Convert the coordinate to text: [ 5.1135 -0.6042]:"}
{"text": "Convert the coordinate to text: [-5.8654 -5.923 ]: The paper presents TBO, a new dataset for Target-based Offensive language identification. TBO bridges the gap between post-level and token-level annotation datasets by introducing a single comprehensive unified annotation taxonomy.", "target": "The paper presents TBO, a new dataset for Target-based Offensive language identification. TBO bridges the gap between post-level and token-level annotation datasets by introducing a single comprehensive unified annotation taxonomy.", "example": "Convert the coordinate to text: [-5.8654 -5.923 ]:"}
{"text": "Convert the coordinate to text: [-1.8058 -6.5814]: The authors propose an approach based on RoBERTa transformer-based language models that investigates both single-task and multi-task learning. Further, they improve results by further pre-training RoBERTa on unlabeled data and performing semi-supervised learning on a small sample of the unlabeled data using minimum class-confusion loss.", "target": "The authors propose an approach based on RoBERTa transformer-based language models that investigates both single-task and multi-task learning. Further, they improve results by further pre-training RoBERTa on unlabeled data and performing semi-supervised learning on a small sample of the unlabeled data using minimum class-confusion loss.", "example": "Convert the coordinate to text: [-1.8058 -6.5814]:"}
{"text": "Convert the coordinate to text: [-4.4764 -3.4828]: The authors propose an ensemble method that integrates multiple pre-trained language models to improve entity recognition in legal text.", "target": "The authors propose an ensemble method that integrates multiple pre-trained language models to improve entity recognition in legal text.", "example": "Convert the coordinate to text: [-4.4764 -3.4828]:"}
{"text": "Convert the coordinate to text: [-0.7597 -6.8806]: The paper proposes a method for improving the interpretability of a Longformer Automatic Essay Scoring (AES) system by aligning the functional components derived from the activations of transformer models with human-understandable feature groups.", "target": "The paper proposes a method for improving the interpretability of a Longformer Automatic Essay Scoring (AES) system by aligning the functional components derived from the activations of transformer models with human-understandable feature groups.", "example": "Convert the coordinate to text: [-0.7597 -6.8806]:"}
{"text": "Convert the coordinate to text: [-4.2737  0.4196]: This paper examines the use of tokens identified as salient by LIME and a gradient-based method by a BERT BASE model in aspect-based sentiment analysis and the effectiveness of these methods in generating successful rationales.", "target": "This paper examines the use of tokens identified as salient by LIME and a gradient-based method by a BERT BASE model in aspect-based sentiment analysis and the effectiveness of these methods in generating successful rationales.", "example": "Convert the coordinate to text: [-4.2737  0.4196]:"}
{"text": "Convert the coordinate to text: [-0.6258 -4.3775]: The authors propose a synthetic data generation framework (SynDG) for grounded dialogues, utilizing large pre-trained language models and freely available knowledge data. The generation process of SynDG is designed to consider dialogue flow and coherence.", "target": "The authors propose a synthetic data generation framework (SynDG) for grounded dialogues, utilizing large pre-trained language models and freely available knowledge data. The generation process of SynDG is designed to consider dialogue flow and coherence.", "example": "Convert the coordinate to text: [-0.6258 -4.3775]:"}
{"text": "Convert the coordinate to text: [  2.3551 -11.7015]: The authors propose a two-stage approach, named parse-then-place, that introduces an intermediate representation (IR) between text and layout to represent diverse layout constraints and decomposes Text-to-Layout into two stages i.e., parse stage and a place stage. They use a Transformer-based layout generation model to model combined and incomplete constraints and represent constraints and layouts as sequences.", "target": "The authors propose a two-stage approach, named parse-then-place, that introduces an intermediate representation (IR) between text and layout to represent diverse layout constraints and decomposes Text-to-Layout into two stages i.e., parse stage and a place stage. They use a Transformer-based layout generation model to model combined and incomplete constraints and represent constraints and layouts as sequences.", "example": "Convert the coordinate to text: [  2.3551 -11.7015]:"}
{"text": "Convert the coordinate to text: [ 7.0995 -4.179 ]: The authors propose Source-Only Deployment Authorization (SDPA) and Target-Combined Deployment Authorization (TPDA). They introduce a new method, Domain-Specified Optimization (DSO) for SDPA and a simplification of DSO, called Target-Dependent Domain-Specified Optimization (TDSO) for TPDA.", "target": "The authors propose Source-Only Deployment Authorization (SDPA) and Target-Combined Deployment Authorization (TPDA). They introduce a new method, Domain-Specified Optimization (DSO) for SDPA and a simplification of DSO, called Target-Dependent Domain-Specified Optimization (TDSO) for TPDA.", "example": "Convert the coordinate to text: [ 7.0995 -4.179 ]:"}
{"text": "Convert the coordinate to text: [11.6618 -2.2221]: This study extends the residual neural network (ResNet), originally used to address the vanishing gradient problem, to general Riemannian manifolds in a geometrically principled way. The resultant model is called a Riemannian ResNet.", "target": "This study extends the residual neural network (ResNet), originally used to address the vanishing gradient problem, to general Riemannian manifolds in a geometrically principled way. The resultant model is called a Riemannian ResNet.", "example": "Convert the coordinate to text: [11.6618 -2.2221]:"}
{"text": "Convert the coordinate to text: [ 4.9323 -4.9539]: The authors propose a novel Curriculum Learning strategy for GNNs that gradually incorporates more edges into training based on their difficulty, from easy to hard. The difficulty is measured by how well the edges are expected given the current model training status.", "target": "The authors propose a novel Curriculum Learning strategy for GNNs that gradually incorporates more edges into training based on their difficulty, from easy to hard. The difficulty is measured by how well the edges are expected given the current model training status.", "example": "Convert the coordinate to text: [ 4.9323 -4.9539]:"}
{"text": "Convert the coordinate to text: [1.8482 2.956 ]: This paper explores the potential of interventional data in causal representation learning, hypothesizing that it carries geometric signatures of latent factors support.", "target": "This paper explores the potential of interventional data in causal representation learning, hypothesizing that it carries geometric signatures of latent factors support.", "example": "Convert the coordinate to text: [1.8482 2.956 ]:"}
{"text": "Convert the coordinate to text: [12.4017 -5.4013]: The authors propose an approach to immunize images so as to make them resistant to manipulation by diffusion models. This is achieved by injecting imperceptible adversarial perturbations designed to disrupt the operation of the targeted models, leading them to generate unrealistic images.", "target": "The authors propose an approach to immunize images so as to make them resistant to manipulation by diffusion models. This is achieved by injecting imperceptible adversarial perturbations designed to disrupt the operation of the targeted models, leading them to generate unrealistic images.", "example": "Convert the coordinate to text: [12.4017 -5.4013]:"}
{"text": "Convert the coordinate to text: [-10.8746  13.3984]: This research explores a new approach to augmentative and alternative communication (AAC) device design that directly addresses the tension between visibility and stigma.", "target": "This research explores a new approach to augmentative and alternative communication (AAC) device design that directly addresses the tension between visibility and stigma.", "example": "Convert the coordinate to text: [-10.8746  13.3984]:"}
{"text": "Convert the coordinate to text: [-5.4829 13.967 ]: The authors propose the need to investigate human perceptions of the danger level of objects involved in human-robot interactions. To aid these investigations, the authors created a database of kitchen objects.", "target": "The authors propose the need to investigate human perceptions of the danger level of objects involved in human-robot interactions. To aid these investigations, the authors created a database of kitchen objects.", "example": "Convert the coordinate to text: [-5.4829 13.967 ]:"}
{"text": "Convert the coordinate to text: [-2.5678 -7.2003]: The authors propose a target-side augmentation method that uses a data augmentation (DA) model to generate various potential translations for each source document to address the data sparsity in document-level machine translation.", "target": "The authors propose a target-side augmentation method that uses a data augmentation (DA) model to generate various potential translations for each source document to address the data sparsity in document-level machine translation.", "example": "Convert the coordinate to text: [-2.5678 -7.2003]:"}
{"text": "Convert the coordinate to text: [-1.7086 -4.5323]: This work proposes a more generalized active retrieval augmented generation methodology, specifically, Forward-Looking Active REtrieval augmented generation (FLARE). FLARE uses an anticipated prediction of the upcoming sentence as a query, retrieves relevant documents, and regenerates the sentence if it contains low-confidence tokens.", "target": "This work proposes a more generalized active retrieval augmented generation methodology, specifically, Forward-Looking Active REtrieval augmented generation (FLARE). FLARE uses an anticipated prediction of the upcoming sentence as a query, retrieves relevant documents, and regenerates the sentence if it contains low-confidence tokens.", "example": "Convert the coordinate to text: [-1.7086 -4.5323]:"}
{"text": "Convert the coordinate to text: [3.4438 5.0311]: The authors propose model-agnostic data subsampling methods that explore the topology of the user-item graph to estimate data importance, allowing for effective subsampling without reliance on a pre-trained model.", "target": "The authors propose model-agnostic data subsampling methods that explore the topology of the user-item graph to estimate data importance, allowing for effective subsampling without reliance on a pre-trained model.", "example": "Convert the coordinate to text: [3.4438 5.0311]:"}
{"text": "Convert the coordinate to text: [ 6.7429 -5.3477]: The authors propose PROPETL, a novel method that enables efficient sharing of a single parameter-efficient transfer learning (PETL) module, called a prototype network, across layers and tasks. This method also involves learning binary masks to select different sub-networks from the shared prototype network and applying them as PETL modules into different layers.", "target": "The authors propose PROPETL, a novel method that enables efficient sharing of a single parameter-efficient transfer learning (PETL) module, called a prototype network, across layers and tasks. This method also involves learning binary masks to select different sub-networks from the shared prototype network and applying them as PETL modules into different layers.", "example": "Convert the coordinate to text: [ 6.7429 -5.3477]:"}
{"text": "Convert the coordinate to text: [-4.424  -1.7138]: This paper presents a new corpus annotated for biographical event detection. This corpus is compared with five existing corpora to train a model specifically for the biographical event detection task.", "target": "This paper presents a new corpus annotated for biographical event detection. This corpus is compared with five existing corpora to train a model specifically for the biographical event detection task.", "example": "Convert the coordinate to text: [-4.424  -1.7138]:"}
{"text": "Convert the coordinate to text: [-2.1168 -4.7268]: The paper proposes an unsupervised seq2seq model for open-domain keyphrase generation, composed of two modules: a 'phraseness' module for generating phrases, and an 'informativeness' module to guide generation towards core concepts of the text.", "target": "The paper proposes an unsupervised seq2seq model for open-domain keyphrase generation, composed of two modules: a 'phraseness' module for generating phrases, and an 'informativeness' module to guide generation towards core concepts of the text.", "example": "Convert the coordinate to text: [-2.1168 -4.7268]:"}
{"text": "Convert the coordinate to text: [-5.0122 -6.8245]: The authors propose a method of reducing dataset creation costs for new languages through manual editing of automatically translated data, leading to the creation of a new multilingual benchmark called X-RiSAWOZ. They also develop a toolset to speed up the post-editing of a new language dataset after translation.", "target": "The authors propose a method of reducing dataset creation costs for new languages through manual editing of automatically translated data, leading to the creation of a new multilingual benchmark called X-RiSAWOZ. They also develop a toolset to speed up the post-editing of a new language dataset after translation.", "example": "Convert the coordinate to text: [-5.0122 -6.8245]:"}
{"text": "Convert the coordinate to text: [-7.7775 -0.1445]: The team from ITTC approaches the problem of evidence retrieval as a document retrieval and sentence similarity task.", "target": "The team from ITTC approaches the problem of evidence retrieval as a document retrieval and sentence similarity task.", "example": "Convert the coordinate to text: [-7.7775 -0.1445]:"}
{"text": "Convert the coordinate to text: [ 0.5099 -3.2324]: The authors propose a Knowledge-enabled Hierarchical Text Classification model (K-HTC) that incorporates knowledge graphs into HTC to overcome the limitation of lack of domain knowledge. This knowledge integration occurs both within text representation and the hierarchical label learning process.", "target": "The authors propose a Knowledge-enabled Hierarchical Text Classification model (K-HTC) that incorporates knowledge graphs into HTC to overcome the limitation of lack of domain knowledge. This knowledge integration occurs both within text representation and the hierarchical label learning process.", "example": "Convert the coordinate to text: [ 0.5099 -3.2324]:"}
{"text": "Convert the coordinate to text: [ 4.8275 -4.8264]: This study proposes a competence-based curriculum learning approach for graph neural networks that incorporates different criteria of graph complexity as indications of difficulty during training. Additionally, a scheduling scheme is used to account for sample difficulty and model competence during training.", "target": "This study proposes a competence-based curriculum learning approach for graph neural networks that incorporates different criteria of graph complexity as indications of difficulty during training. Additionally, a scheduling scheme is used to account for sample difficulty and model competence during training.", "example": "Convert the coordinate to text: [ 4.8275 -4.8264]:"}
{"text": "Convert the coordinate to text: [ 9.4742 11.942 ]: This study reveals contrasting results that collaboration is not beneficial when the machines have access to first-order gradient information at the queried points. Additionally, it delves into the challenging setting of federated online optimization with bandit (zeroth-order) feedback.", "target": "This study reveals contrasting results that collaboration is not beneficial when the machines have access to first-order gradient information at the queried points. Additionally, it delves into the challenging setting of federated online optimization with bandit (zeroth-order) feedback.", "example": "Convert the coordinate to text: [ 9.4742 11.942 ]:"}
{"text": "Convert the coordinate to text: [ 5.3804 -8.8308]: The authors propose to perceive diverse spatial-temporal cues in videos to discover potential domain-invariant cues. They introduce a model named Spatial-Temporal Diversification Network (STDN) which enhances the diversity through both space and time dimensions of video data.", "target": "The authors propose to perceive diverse spatial-temporal cues in videos to discover potential domain-invariant cues. They introduce a model named Spatial-Temporal Diversification Network (STDN) which enhances the diversity through both space and time dimensions of video data.", "example": "Convert the coordinate to text: [ 5.3804 -8.8308]:"}
{"text": "Convert the coordinate to text: [ 1.4716 -3.3355]: The study introduces a method to improve the compositional generalization of deep networks by using iterated learning on models with simplicial embeddings to discretize representations, a concept inspired by the 'iterated learning' process observed in human learning and an analysis of compositionality based on Kolmogorov complexity.", "target": "The study introduces a method to improve the compositional generalization of deep networks by using iterated learning on models with simplicial embeddings to discretize representations, a concept inspired by the 'iterated learning' process observed in human learning and an analysis of compositionality based on Kolmogorov complexity.", "example": "Convert the coordinate to text: [ 1.4716 -3.3355]:"}
{"text": "Convert the coordinate to text: [-4.743  -5.3303]: The authors propose a new task, multilingual entailment graph enhancement, which utilizes the entailment information from one EG to enhance another EG in a different language. The goal is to create an enhanced EG containing richer and more accurate entailment information.", "target": "The authors propose a new task, multilingual entailment graph enhancement, which utilizes the entailment information from one EG to enhance another EG in a different language. The goal is to create an enhanced EG containing richer and more accurate entailment information.", "example": "Convert the coordinate to text: [-4.743  -5.3303]:"}
{"text": "Convert the coordinate to text: [-0.863  -4.1464]: The authors argue that it's more effective to predict the paths inside the hierarchical tree (representing different discourse relations) rather than flat labels or connectives. Hence, they propose a new prompt-based path prediction method to utilize interactive information and intrinsic senses among the hierarchy in IDRR.", "target": "The authors argue that it's more effective to predict the paths inside the hierarchical tree (representing different discourse relations) rather than flat labels or connectives. Hence, they propose a new prompt-based path prediction method to utilize interactive information and intrinsic senses among the hierarchy in IDRR.", "example": "Convert the coordinate to text: [-0.863  -4.1464]:"}
{"text": "Convert the coordinate to text: [-4.3923 -8.1925]: The authors present a hyperparameter optimization toolkit for neural machine translation (NMT) implemented as a wrapper on top of the open-source Sockeye NMT software.", "target": "The authors present a hyperparameter optimization toolkit for neural machine translation (NMT) implemented as a wrapper on top of the open-source Sockeye NMT software.", "example": "Convert the coordinate to text: [-4.3923 -8.1925]:"}
{"text": "Convert the coordinate to text: [-6.5659 -1.8181]: This paper investigates the impact of the quality of the alignments, which can be automatic, manual, or a mix, on the performance of two information extraction tasks.", "target": "This paper investigates the impact of the quality of the alignments, which can be automatic, manual, or a mix, on the performance of two information extraction tasks.", "example": "Convert the coordinate to text: [-6.5659 -1.8181]:"}
{"text": "Convert the coordinate to text: [ 8.6289 11.0603]: This paper proposes a novel approach called General RL Optimizers Obtained Via Environment Design (GROOVE), which automatically generates curricula to maximize the regret of a meta-learned optimizer, and introduces a new concept of algorithmic regret (AR).", "target": "This paper proposes a novel approach called General RL Optimizers Obtained Via Environment Design (GROOVE), which automatically generates curricula to maximize the regret of a meta-learned optimizer, and introduces a new concept of algorithmic regret (AR).", "example": "Convert the coordinate to text: [ 8.6289 11.0603]:"}
{"text": "Convert the coordinate to text: [9.9371 5.7714]: The study introduces a new concept - hierarchical randomized smoothing - which partially smooths objects by adding random noise only on a randomly selected subset of their entities, providing a more targeted approach compared to existing methods and thus obtaining stronger robustness guarantees.", "target": "The study introduces a new concept - hierarchical randomized smoothing - which partially smooths objects by adding random noise only on a randomly selected subset of their entities, providing a more targeted approach compared to existing methods and thus obtaining stronger robustness guarantees.", "example": "Convert the coordinate to text: [9.9371 5.7714]:"}
