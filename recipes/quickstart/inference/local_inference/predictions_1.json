{"input":"[-1.8679 -6.7739] The authors propose SpellBERT, a pretrained model for CSC that includes graph-based extra features and does not rely on a predefined confusion set. This model uses a graph neural network to introduce radical and pinyin information as visual and phonetic features and a masked language model for pre-training. | [-1.8496 -6.8381] The authors propose to use entmax-based models to solve the 'cat got your tongue' problem in sequence-to-sequence models and apply label smoothing with Fenchel-Young losses. | [-1.8093 -6.862 ] The authors propose a novel pre-training method called MPNet that seeks to inherit the advantages of both BERT and XLNet while avoiding their limitations. Contrary to BERT, MPNet leverages the dependency among predicted tokens through permuted language modeling, and against XLNet, it reduces the position discrepancy by taking auxiliary position information as input to view a full sentence. | Convert the coordinate to text: [-1.8337 -6.7963]:","generate_predictions":" This paper proposes a method for using pre-trained language models for semantic retrieval in open and restricted domains without any task-specific pre-training. The method involves creating an information retrieval dataset by combining the relevant data from the semantic search and the data from a large general purpose corpus.","labels":"The authors propose a system that uses a multi-label contrastive loss for fine-tuning large pre-trained language models in a multi-lingual setting for Framing Detection."}
{"input":"[ 4.6956 -1.4301] A new strategy is proposed that applies a smooth transition and interplay between filtering and relabelling noisy data as a dynamic curriculum, starting with clean data and gradually moving to noisy-labeled data with pseudo labels produced by a time-ensemble of the model and data augmentations. | [ 4.7182 -1.4342] To mitigate the issue of noisy labels, the paper proposes Soft Label Smoothing (SLS) and the Smooth Operator Framework for Teaching (SOFT). SLS assigns probabilities to multiple high-confidence classes based on the corresponding confidence while allocating a fixed lower probability to low-confidence classes. | [ 4.7284 -1.408 ] The authors propose a MUlti-Classifier (MUC) incremental learning paradigm, introducing an ensemble of auxiliary classifiers to estimate more effective regularization constraints. The paradigm is hoped to regularize the network parameters or activations when learning the next task. | Convert the coordinate to text: [ 4.6963 -1.4735]:","generate_predictions":" The authors propose label smoothing and data augmentation to the MIM model, including a novel approach called 'auxiliary smoothing', which uses the MIM model's posterior as a prior for an auxiliary image classifier to stabilize training for deeper or higher-resolution models.","labels":"The authors propose Rank-N-Contrast (RNC), a framework that learns continuous representations for regression by contrasting samples against each other based on their rankings in the target space."}
{"input":"[13.7942 -0.0261] The authors illustrate that changing the numerical solver associated with a trained Neural ODE model may result in a performance loss, invalidating the concept of the model being a flow generated from an ODE. A critical step size for solver is found beyond which training yields a valid ODE vector field. | [13.8198 -0.0357] The authors elaborate on Second Order Neural ODEs (SONODEs) and Augmented NODEs (ANODEs), providing a methodology on how the adjoint sensitivity method can be extended to SONODEs, and proving that a first order optimization method is computationally more efficient. | [13.8008 -0.0485] The authors propose Spatial-Temporal Graph Ordinary Differential Equation Networks (STGODE) which captures spatial-temporal dynamics through a tensor-based ordinary differential equation (ODE), allowing for deeper network construction and synchronous use of spatial-temporal features. The model also considers semantical adjacency matrix in their framework to provide a more comprehensive understanding of the network. | Convert the coordinate to text: [13.8038 -0.0195]:","generate_predictions":" The authors propose the Temporal Graph Neural Ordinary Differential Equation (TGNODE), a new framework that generalizes graph neural ordinary differential equations and can handle both continuous and discrete changes in events. This is achieved through the design of an embedded temporal layer to learn temporal dynamics and an operator layer to learn node-wise dynamics.","labels":"The authors propose a model, Context-attended Graph ODE (CARE), to handle time-varying dynamic systems. CARE uses a context variable to model time-varying environment and constructs an encoder to initialize this context variable from historical trajectories."}
{"input":"[ 5.6434 -4.91  ] The paper presents an innovative way to acquire limits on the separation power of GNNs in terms of the Weisfeiler-Leman (WL) tests. The idea is to view GNNs as expressions in a procedural tensor language that describes GNN layer computations. | [ 5.6896 -4.8078] The authors present two key innovations: they first argue that k-order networks can be more expressive than 1-WL tested networks and can distinguish between non-isomorphic graphs as good as the k-WL tests. They then suggest a reduced 2-order network containing just scaled identity operator, augmented with a single quadratic operation (matrix multiplication), to create a simpler and scalable model with 3-WL expressiveness. | [ 5.6921 -4.9179] A novel graph indexing and searching algorithm is proposed, using the property that Mobius transformation introduces an isomorphism between a subgraph of l^2-Delaunay graph and Delaunay graph for inner product. | Convert the coordinate to text: [ 5.6406 -4.853 ]:","generate_predictions":" This paper proposes a GNN learning framework that incorporates subgraph-level patterns and node features into training to obtain highly discriminative node representations, overcoming the limitations of existing methods.","labels":"The authors propose a policy, GFN4Rec, a generative method that leverages the concept of flow networks to align list generation probability and its reward. It includes a log scale reward matching loss to intrinsically improve the generation diversity and an autoregressive item selection model to capture item mutual influences."}
{"input":"[ 5.638 13.786] The paper presents an off-policy, interactive RL algorithm that learns a reward model by actively querying a teacher's preferences between two clips of behavior and use it to train an agent. It relabels all the agent's past experience when its reward model changes. | [ 5.6615 13.7966] An algorithm called Reward Query Synthesis via Trajectory Optimization (ReQueST) is proposed that safely and interactively learns a model of the user's reward function. It synthesizes hypothetical behaviors, has the user label the behaviors with rewards, and trains a neural network to predict the rewards\u2014all without interacting with the environment. | [ 5.677  13.7381] The study proposes to understand how reward hacking arises by constructing four RL environments with misspecified rewards and investigating it as a function of agent capabilities such as model capacity, action space resolution, observation space noise, and training time. | Convert the coordinate to text: [ 5.6371 13.7621]:","generate_predictions":" The study proposes the use of reward shaping in deep reinforcement learning from raw pixels, using two methods based on intrinsic motivation measures in the form of curiosity or novelty, along with reward scaling, to enhance learning performance.","labels":"The authors propose a novel approach for curriculum RL named 'Diversify for Disagreement & Conquer (D2C)' that requires only a few examples of desired outcomes and can function in any environment."}
{"input":"[ 10.4967 -18.8439] The present study introduces the concept of distorted reconstruction from two views, which differs from traditional approaches by not satisfying the epipolar constraint, and can be computed using point correspondences and a potentially inexact estimate of the stereo configuration. | [ 10.6731 -18.8723] The authors propose a method to recover the poses of the reference plane directly from its reflections on the specular surface by establishing reflection correspondences on the reference plane in three distinct poses. | Convert the coordinate to text: [ 10.5434 -18.8509]:","generate_predictions":" To overcome the issue of high-dimensional space search in multi-camera calibration, this study proposes a strategy of generating hypotheses in a low-dimensional space where all unknowns can be expressed linearly.","labels":"Dynamo-Depth is introduced as an approach that disambiguates dynamical motion in a scene by jointly learning monocular depth, 3D independent flow field, and motion segmentation from unlabeled monocular videos."}
{"input":"[-2.6332  0.0939] This study introduces Task Adaptive Pretraining (TAPT) for Transformer-based architectures, aiming to improve the coarse binary classification of Hindi Tweets into 'Hostile' or 'Not', and multi-label classification of Tweets into 'hate', 'fake', 'offensive', and 'defamation'. | [-2.625   0.1932] The authors propose a new challenging NLP task of detecting political bias in Hindi news articles and present a transformer-based transfer learning method to fine-tune pre-trained networks for bias detection. | Convert the coordinate to text: [-2.6458  0.0878]:","generate_predictions":" The study proposes Pretrained Transformers for Text Ranking (PTTR), a training framework for learning a shared model on multiple ranking tasks to capture task-agnostic knowledge, and a unified reranking model for applying this knowledge to existing first-stage ranked candidates.","labels":"The authors propose a fine-tuned transformer-based model for problematic webpage classification and a novel webpage data collection strategy leveraging short-text hate speech datasets. They also introduce a custom GPT-4 few-shot prompt annotation scheme for webpage annotation."}
{"input":"[ 0.2392 -9.2971] The authors propose a new task, unsupervised vision-language (VL) grammar induction, and a novel method, CLIORA, which simultaneously extracts a shared vision-language constituency tree structure grounded in both image and language modalities. | [ 0.3308 -9.313 ] The authors propose a multi-granularity retrieval system to address these challenges, which comprises of three modules - a language parsing module to extract fine-grained attributes from language descriptions, a language-augmented multi-query vehicle track retrieval module to fuse information from multiple imperfect queries, and a target vehicle attributes enhancement module to fuse static and dynamic properties of the target vehicle. | [ 0.2928 -9.3361] The authors argue that language features deserve more attention in vision-language tasks, proving this through experiments which compare different word embeddings, language models, and embedding augmentation steps on five common VL tasks. They also propose a new Graph Oriented Vision-Language Embedding (GrOVLE), derived from Word2Vec using WordNet and a unique visual-language graph based on Visual Genome. | Convert the coordinate to text: [ 0.2766 -9.259 ]:","generate_predictions":" This paper proposes a novel Vision-Language-Object Graph (VL-Object Graph) that consists of the image, the input text, and the ground-truth or detected objects which captures the multi-modal entity co-occurrence, enabling the training of object classifiers using zero visual supervision.","labels":"To address the issue of semantic misalignment, a new framework named Concept Curation (CoCu) is introduced. This uses CLIP to compensate for missing semantics in image-text pairs by maintaining a concept archive with potential visually-matched concepts."}
{"input":"[13.4506 -4.7345] A stronger weight-poisoning attack method is proposed. This method introduces a layerwise weight poisoning strategy to plant deeper undetectable backdoors with a combinatorial trigger. | [13.4317 -4.752 ] The paper proposes a novel approach, TDSSA (Truth Discovery against Strategic Sybil Attack), to defend against strategic Sybil attacks that attempt to evade traditional detection methods. | [13.4117 -4.7155] The authors develop a new data poisoning attack that allows an adversary to control model predictions whenever a desired trigger phrase is present in the input. | Convert the coordinate to text: [13.4297 -4.7303]:","generate_predictions":" This study explores the relationship between backdoor attack and poisoning attack in deep neural networks, observing both adversarial strategies can significantly enhance each other. Additionally, the authors propose a more efficient and scalable algorithm for generating multi-poison-labels using the gradient of the deep neural network.","labels":"This paper introduces a robust and stealthy backdoor attack design: BITE. BITE poisons training data to establish strong correlations between a target label and certain 'trigger words' by naturally and iteratively injecting them into target-label instances."}
{"input":"[ 0.7978 -3.7405] This study explores the potential benefits of using semantic information of labels to guide the classification task in item categorization systems within e-commerce, and proposes the use of a hyperbolic space to embed product labels organized hierarchically. | [ 0.6607 -3.7885] The paper introduces self-training to SRL, utilizing abundant unlabeled tweets to lessen the dependency on annotated tweets. The authors present a novel tweet selection strategy that ensures selected tweets are both correct and informative. | Convert the coordinate to text: [ 0.7344 -3.773 ]:","generate_predictions":" Motivated to improve the precision without sacrificing recall or requiring human-annotated labels, the authors propose a data programming solution for tweet selection with the help of weakly-supervised programming rules for automated annotation.","labels":"The paper characterizes two ways in which ICL leverages demonstrations, namely: Task Recognition (TR) which measures the extent that LLMs can recognize a task through demonstrations and apply their pre-trained priors; and Task Learning (TL), which is the ability to capture new input-label mappings that were not seen in pre-training."}
{"input":"[-1.2245 -4.1524] The authors introduce a light hybrid retriever, which leverages an indexing-efficient dense retriever (i.e., DrBoost) and a lighter dense retriever (LITE) jointly trained on contrastive learning and knowledge distillation from DrBoost. This allows for a reduction in the indexing memory of hybrid retrievers without losing performance. | [-1.1857 -4.1053] The authors propose an entity guided question generation model that addresses these shortcomings by simultaneously capturing both the structural and sequence information in the context using a Graph Convolutional Network and a Bidirectional Long Short Term Memory Network. | [-1.1851 -4.0819] The authors propose a retrieval augmented framework, which retrieves relevant code or summaries from a retrieval database and provides them as a supplement to code generation or summarization models. | Convert the coordinate to text: [-1.2103 -4.1702]:","generate_predictions":" This study introduces a dense retrieval-based knowledge retrieval method enhanced with relation-aware representation, a cross-encoder-based passage re-ranker trained on contrastive learning, and an efficient pipeline of combining dense retrieval and cross-encoding at inference.","labels":"The authors propose an efficient algorithm for latent variable modeling to leverage large amounts of dialogue data, avoiding the need for intermediate labels. This is achieved by adapting a query generator with an off-the-shelf knowledge retriever and simultaneously training the query and response generators over the query's latent variable."}
{"input":"[2.3437 0.673 ] The authors propose a novel theoretical framework that assumes a teaching goal of minimizing the learner's expected generalization error at each iteration, and provides a theoretical justification for curriculum learning. | [2.3478 0.7919] To address this, the authors propose Data-IQ, a framework for systematically stratifying data examples into specific outcome-related subgroups (Easy, Ambiguous, Hard) based on their predictive confidence and aleatoric (data) uncertainty during training. | [2.2921 0.6725] The authors aim to determine the most important hyperparameters and their typically good values for given algorithms, using a meta-learning framework across many datasets. | Convert the coordinate to text: [2.3336 0.7327]:","generate_predictions":" The authors propose a framework to optimize these two decisions jointly for selecting and training samples.","labels":"The authors follow a model introduced by Cai and Daskalakis to consider the case that bidders' prior distributions can be well-approximated by a topic model. They present a new approach consisting of an active learning component and a mechanism design component, in effect bridging the theory of mechanism design with the technique of Randomized Linear Algebra (RLA) for regression problems."}
{"input":"[ 1.5767 13.4959] The authors adapt three metamodels of bounded rational behavior, two based on Quantal level-k and one based on Nash equilibrium with quantal errors, to create game theoretic models of driving behavior within the context of hierarchical games, a framework used in multi-agent motion planning. | [ 1.6342 13.4793] The authors suggest an alternative approach to academic recruitment where they make a single batch of offers rather than sequential ones, treat the target number of positions as a soft constraint, and seek to maximize the overall expected value associated with candidates who accept, minus an expected penalty for deviating from the target. | [ 1.5696 13.5214] The authors present a simple model of a game where each strategy has additional costs (computational or otherwise), studying the strategic aspects of bounded rational behavior. | Convert the coordinate to text: [ 1.6075 13.5053]:","generate_predictions":" The authors propose a new framework that models agent interactions across multiple games to improve cooperation among agents with varied objectives.","labels":"The authors introduce a soft quota setting in which every post is associated with two values \u2014 a lower and upper target which denote a range for the intended number of applicants in any assignment. They allow the number of applicants assigned to fall outside this range, creating assignments with deviation."}
{"input":"[1.3273 2.4041] The authors present GenASAP, a generative model for a developed custom DNA microarray platform to survey AS levels on a large scale. | [1.3473 2.4692] The paper proposes a novel framework known as Causal Intervention by Semantic Smoothing (CISS) that aims for robustness against natural language attacks. Instead of just fitting observational data, CISS learns causal effects by smoothing in the latent semantic space to make robust predictions. | [1.3746 2.4349] The authors introduce a deep generative model-based framework, Credence, to validate causal inference methods. It generates synthetic data that closely mirror empirical distribution of the observed sample, and lets the user specify ground truth for the form and magnitude of causal effects and confounding bias. | Convert the coordinate to text: [1.3245 2.4293]:","generate_predictions":" The paper introduces the idea of a causal explanation loss, termed as CausalExplain (CE). It uses an auxiliary loss to encourage the training process to avoid shortcut features and find explainable features of the visual evidence associated with the cause or effect.","labels":"The authors theoretically clarified the relationship between SRS predictions and instance reliability and proposed two error-bounded strategies to rectify unreliable targets and input."}
{"input":"[-2.5714 -7.4227] Grounding on the connection between a pre-trained masked language model (MLM) and non-autoregressive generation on machine translation, the authors present XLM-D, a model that transforms an existing cross-lingual pre-training model into a non-autoregressive translation (NAT) model with a lightweight decorator. | [-2.5321 -7.4235] The paper introduces an empirical study of a character-level deep recurrent neural network (Char-RNN) specifically designed for Chinese text classification, that uses character-level features as input features. | Convert the coordinate to text: [-2.617  -7.4761]:","generate_predictions":" The authors propose a unified cross-lingual generative approach for text summarization and simplification by injecting target language and task-specific knowledge into the cross-lingual MLMs via lightweight training.","labels":"The authors propose a system consisting of a pretrained multilingual masked language model as a text encoder and a neural network as a regression model. An innovative feature is the incorporation of data augmentation via neural machine translation models to improve performance under low-resource scenarios."}
{"input":"[-2.1381 -5.3013] The paper presents ELLE, a solution for efficient lifelong pre-training for emerging data. It includes function preserved model expansion, which expands the existing PLM's width and depth for better efficiency, and pre-trained domain prompts to stimulate the proper knowledge for downstream tasks. | [-2.1822 -5.3233] The authors introduce TempLM, a system designed to distill PLMs into template-based generators to balance both faithfulness and fluency. | [-2.1849 -5.3521] This study inquires whether GPT-3 can be deployed as an effective data annotator for NLP tasks, potentially automating a human-involved process. | Convert the coordinate to text: [-2.1348 -5.3293]:","generate_predictions":" The authors present a novel strategy, MetaL, which leverages parameter-efficient language model adaptation to learn domain-specific language models for few-shot learning. This approach combines the MetaPrompt method and the knowledge distillation objective for fast and accurate learning.","labels":"The authors propose Gradient Ascent Post-training (GAP), a technique of updating pretrained language models with a few steps of gradient ascent on random, unlabeled text corpora to enhance their zero-shot generalization capabilities."}
{"input":"[12.4465  1.4814] The authors propose an improved method known as frequency domain BSS where, through the properties of linear addition and phase loss of spectrum analysis, the engineering signals are first transformed to the frequency domain, and then the spectra are processed by ICA. | [12.4595  1.4523] The authors propose a general Bayesian framework for performing ICA, which leverages ensemble learning and linear response theory from statistical physics. It can be applied to discrete and continuous sources, and also offers a way to generate new ICA algorithms without explicit prior distribution of sources. | [12.4052  1.4874] The authors pursue an alternative approach towards the identifiability of nonlinear ICA, using only assumptions on the mixing process, such as Structural Sparsity. | Convert the coordinate to text: [12.4251  1.4577]:","generate_predictions":" This work extends a nonlinear independent component analysis (ICA) framework to jointly learn features and latent representations of time series. Its core assumption is that the high-dimensional time series admits a low-dimensional latent representation via nonlinear dynamics.","labels":"The authors propose an intermediate problem termed Causal Component Analysis (CauCA), generalizing ICA by modeling causal dependence among the latent components and presenting as a special case of CRL. This offers a focus on learning the unmixing function and the causal mechanisms."}
{"input":"[ 4.9467 -2.3852] To judge the quality of graphs and develop performance-safe GSSL methods, the authors propose a large margin separation method called LEAD for safe GSSL. The idea is that high-quality graphs should give predictive results on unlabeled data with a large margin separation, and these should be exploited while keeping the riskier small-margin graphs rarely exploited. | [ 4.9044 -2.398 ] This paper presents a Label Distribution Learning (LDL) approach to acne image analysis that considers the ambiguous information among acne severity. The authors propose a unified framework for joint acne image grading and counting, optimized by multi-task learning loss. | [ 4.9716 -2.4259] The authors propose a novel algorithm called UncertaintyAware Self-Distillation (UASD) to address the under-studied problem in SSL where there's a class distribution mismatch between labelled and unlabeled data. UASD can produce soft targets that prevent severe error propagation and enable efficient learning from unlabelled data that includes out-of-distribution samples. | Convert the coordinate to text: [ 4.926  -2.3865]:","generate_predictions":" The authors propose a new method called Coarse-to-Fine Dual Branch Networks with Soft Distillation (C2F-SDN), which adopts a teacher-student architecture to learn robust semantic representations for both clean and noisy data for open-set recognition.","labels":"The authors propose a novel SSL setting where unlabeled samples come from a mixed distribution that differs from the feature distribution of labeled samples, and present a solution \u2014 Self-Supervised Feature Adaptation (SSFA), a framework that adapts the feature extractor of the model to better suit the distribution of unlabeled data."}
{"input":"[ 0.2392 -9.2971] The authors propose a new task, unsupervised vision-language (VL) grammar induction, and a novel method, CLIORA, which simultaneously extracts a shared vision-language constituency tree structure grounded in both image and language modalities. | [ 0.2731 -9.359 ] The authors investigate the out-of-distribution performance of end-to-end and neuro-symbolic systems in vision-and-language reasoning tasks using four types of generalization tests including a novel segment-combine test for multi-image queries. | Convert the coordinate to text: [ 0.1561 -9.3428]:","generate_predictions":" The authors propose a modular approach to VQA that allows for the manipulation, insertion and deletion of information within a model, using an attention and graph-based architecture.","labels":"The authors propose a solution which first extends the textual context using word definitions contained in WordNet and in Open English WordNet. Second, it uses the CLIP model to select the most suitable image with the extended word context and additional information obtained from the BEiT image classification model."}
{"input":"[-0.0681 -9.1879] The authors study ambiguities in text-to-image generative models and propose a framework to handle these ambiguities by soliciting clarifications from the user. | [-0.048  -9.1743] To analyze the openness of CLIP-like models, the authors introduce the concept of 'extensibility', which measures the model's ability to handle new visual concepts through vocabulary expansions. | [-0.1802 -9.1464] The authors conduct a study to understand and provide guidelines for what prompt keywords and model hyperparameters can help produce coherent outputs with text-to-image generative models. | Convert the coordinate to text: [-0.107  -9.1283]:","generate_predictions":" The authors conducted an extensive study of this invariance in CLIP and found a clear correlation between invariance to transformations in the image domain and textual mentions in the CLIP training dataset.","labels":"The study proposes to better understand and quantify progress in the direction of fine-grained vision-and-language understanding, by investigating four competitive V&L models on four fine-grained benchmarks."}
{"input":"[-3.2316 -5.4742] The authors propose the first unified benchmark named GLUE-X for evaluating OOD robustness in NLP models, intending to provide insights on how to measure and improve the robustness of a model. | [-3.1683 -5.4836] This study reveals that the success of privacy attacks on language models is largely attributed to the duplication in commonly-used, web-scraped training data sets. | Convert the coordinate to text: [-3.2245 -5.4291]:","generate_predictions":" The authors propose a unified testbed to measure the compositional generalization of sequence-to-sequence models across four aspects: domain, topic, length and intent.","labels":"This work investigates the distractibility of large language models, that is, how model problem-solving accuracy can be affected by irrelevant context. Additionally, the authors introduce the Grade-School Math with Irrelevant Context (GSM-IC), a dataset designed to measure this distractibility"}
{"input":"[-13.2887   5.3067] The authors aim to investigate the feasibility of enabling web application development by nonprogrammers and targeting a specific subset of web applications, i.e., web-based data collection, storage, and retrieval applications. | [-13.249    5.2855] The paper presents a novel method to compile the most preferred environments in order to mitigate the issue of large space requirements induced by the existing compilation-based solutions. | [-13.3391   5.3072] The paper aims to identify the benefits that could be gained through the provision of mechanisms for extending W3 clients and examine how additional software components may be realized. | Convert the coordinate to text: [-13.2631   5.3297]:","generate_predictions":" The paper proposes an object-based software system developed for automatic information management and maintenance in the process of construction building. It offers a general, flexible, comprehensive management system for use in different domains of construction and manufacturing industries.","labels":"The paper proposes a new approach to measure potential performance gains of upgraded Python web applications, using an interactive service that assists developers with optimizing their Python code through changes to the system infrastructure."}
{"input":"[-0.7108  0.1731] The authors propose a Neural Cognitive Diagnosis (NeuralCD) framework that uses neural networks to learn complex exercise interactions, thus providing more precise and interpretable diagnosis results. | [-0.8386  0.1529] The paper introduces a neural network-based approach, Learning Similarity Metrics (LSiM), that leverages a Siamese network architecture to calculate a robust and generalizing metric for comparison of numerical simulation field data. | Convert the coordinate to text: [-0.7326  0.0729]:","generate_predictions":" The authors propose a new framework, namely, the Neural Information Router (NeIR), which utilizes neural network to learn the content interaction among all the exercises, aiming to address several issues with previous models.","labels":"This paper presents Disentanglement based Cognitive Diagnosis (DCD), a model that works with limited exercise labels. The DCD model uses students' response records to model student proficiency, exercise difficulty, and exercise label distribution. Additionally, it introduces a group-based disentanglement and limited-labeled alignment modules to separate the factors relevant to concepts and align them with real limited labels."}
{"input":"[-2.9813 -2.5026] The authors propose GERE, a system that retrieves evidences in a generative fashion. Instead of the classical index-retrieve-rank approach, GERE generates document titles and evidence sentence identifiers to be used in fact verification. | [-2.992  -2.5288] The authors present a method that identifies and activates expert units within TLMs during inference to control the concepts in the generated output. The method can make fine-grained adjustments and can be used to correct gender bias in text generation. | [-3.0265 -2.4476] This work introduces a new method to bridge the gaps between multiple knowledge bases by producing new assertions using graph similarity computed with principal component analysis to draw analogies across various knowledge bases. | Convert the coordinate to text: [-2.941 -2.462]:","generate_predictions":" The authors propose a new model that integrates a commonsense reasoner into a language model to predict rationales for the predicted outcomes.","labels":"The study puts forth a new setting, actively supervised clustering for OpenRE, where clustering learning and relation labeling are alternately performed. This provides necessary clustering guidance without a significant increase in human effort. A key component of this setting involves choosing which instances to label, for which the authors develop a new strategy suitable for dynamically discovering clusters of unknown relations."}
{"input":"[-8.4974 -3.7874] The authors designed and implemented Termino, a comprehensive terminological resource for text processing that can store terminological information in a flexible, extensible relational database and execute term lookups using finite-state machines compiled from this database. | [-8.4218 -3.735 ] The paper proposes a methodology to reuse semantic structures while switching between several representation languages. In the process, the authors present a concept of semantic patterns to communicate knowledge at a certain level of representation. | [-8.4184 -3.7818] The paper proposes an innovative solution that uses a combination of lexical approaches and language games to reduce the complexity of the semantic problem by shifting from the ontology level to the simpler lexicon level and avoids the use of a centralized third party mediator. | Convert the coordinate to text: [-8.4793 -3.7511]:","generate_predictions":" A new method for ontology learning is proposed in this thesis. This method involves starting with a base resource, then utilizing the output of other ontology learning methods as evidence, to extract information for ontology engineering.","labels":"Cornet is introduced, a system that automatically learns conditional formatting rules from user examples, efficiently eliminating the need for manual rule writing."}
{"input":"[ 3.5743 -3.9742] The authors propose a Self-supervised teaching assistant (SSTA) concept for improving transformers' performance that includes a head-level knowledge distillation method. This method mimics the attention distribution of the most important head of the supervised teacher and self-supervised teaching assistant to focus the student on the token relationships deemed by the teacher and teacher assistant. | [ 3.6242 -3.9438] This paper proposes the local correlation exploration framework for knowledge distillation. It includes modeling three kinds of local knowledge: intra-instance local relationship, inter-instance relationship on the same local position, and the inter-instance relationship across different local positions. Furthermore, a novel class-aware attention module is proposed to concentrate on informative local regions of the teacher\u2019s feature maps. | [ 3.6244 -3.942 ] The paper presents a new CLIR model trained using multi-stage knowledge distillation (KD). The model uses a teacher-student setup where the teacher is a traditional pipeline system while the student is capable of executing a single CLIR operation. | Convert the coordinate to text: [ 3.5608 -3.9359]:","generate_predictions":" The authors propose a novel multi-teacher knowledge distillation framework for natural language understanding tasks.","labels":"The paper introduces Symbolic Chain-of-Thought Distillation (SCoTD), a method to train a smaller student model on rationalizations sampled from a significantly larger teacher model, demonstrating that even smaller models can benefit from chain-of-thought prompting."}
{"input":"[-2.6697 -2.4771] The authors propose NESL (the Neuro-Episodic Schema Learner), which combines large language models and FrameNet parsing with a logical representation of language and a bootstrapping set of behavioral schemas, to learn event schemas from a continuous feed of 'situation samples' drawn from a pre-trained language model. | [-2.6684 -2.4174] The authors propose an entity class-dependent discriminative mixture model which introduces a latent entity class layer to model the correlations between entities and latent entity classes. This model can better adapt to different types of entities. | [-2.551  -2.4728] The authors propose a new method involving a latent variable model with a flexible distribution to more accurately represent the relations between entity pairs. This method also offers a unified architecture for both mention-level and pair-level relation extraction. | Convert the coordinate to text: [-2.6293 -2.4542]:","generate_predictions":"The authors present a generic approach for event-centric hypergraph construction, focusing on the importance of capturing and modeling the structural relationship of all events and entity instances in a document. They introduce a novel hyperedge construction method that automatically captures event-event, entity-entity, and event-entity pair relations, and use a transformer-based joint learning framework to model this relationship.","labels":"The authors introduce a new dataset called DMASTE, which is manually annotated to fit real-world scenarios by providing more diverse and realistic reviews, including various lengths, diverse expressions, more aspect types, and more domains."}
{"input":"[  9.9086 -21.1698] The authors introudced an all-digital temporal compressive video camera. This camera adopts custom subsampling modes to achieve spatio-temporal multiplexing, re-establishing high-speed, full-resolution video by solving an undetermined system of equations using a sparse regularization framework. | [  9.8683 -21.1254] The authors propose coded sampling which not only allows N times temporal superresolution using N cameras but also lets in approximately N\/2 times more light compared to an equivalent high speed camera. They further introduce a new class of invertible codes that allow continuous blur in captured frames. | [  9.906  -21.2193] The authors propose Clairbuoyance, a system that provides feedback about the swimmer's orientation through lights mounted on swimming goggles, in two versions: Discrete signals relative to a chosen direction, and continuous signals providing a sense of absolute direction. | Convert the coordinate to text: [  9.8885 -21.1513]:","generate_predictions":" The authors propose an approach for reconstructing videos from non-uniformly sampled, multi-camera data using a joint temporal and spatial regularization framework that enforces video consistency across camera views subject to constraints from temporal and spatial models.","labels":"The authors propose a low-light video enhancement method using hybrid inputs of events and frames, leveraging the high temporal resolution of event cameras to improve video quality in low-light conditions."}
{"input":"[8.4157 0.3889] A broad family of metric spaces that quantify representational dissimilarity is defined in this study. This involves modifying existing representational similarity measures, formulating a novel metric for convolutional layers, and identifying approximate Euclidean embeddings that can be incorporated into any off-the-shelf machine learning method. | [8.3503 0.3993] The study develops new methods for identifying representative images for a class in non-metric spaces that are more suitable than the existing condensing techniques, emphasizing that atypical points may be more important in describing classes and that the distance between two images is not a good measure of representation in non-metric spaces. | [8.3431 0.3019] This paper extends the idea of special function approximation to a class of functions, namely the discriminant functions that arise in optimal Bayesian classification of Gaussian Mixture Models (GMMs) in high dimensional spaces. They propose efficient approximation through deep neural networks. | Convert the coordinate to text: [8.3808 0.359 ]:","generate_predictions":" The authors propose a novel approach to represent a set, known as the Fisher-BRNN, by constructing a family of bidirectional RNNs. Each of these RNNs is trained to maximize the Fisher kernel and captures unique aspects of the training set.","labels":"The authors introduce a linear classification model, QLDS, where the low density separation assumption is implemented via quadratic margin maximization, establishing a bridge between supervised and unsupervised learning methods."}
{"input":"[ 2.4073 15.8029] The authors propose to study the computational complexity of two problems: deciding if there is a set of nominees that allows a candidate from a given party to win the final election, and determining if a candidate from a specific party always wins, regardless of the nominees. | [ 2.4038 15.8076] The authors investigate how well certain election rules (specifically, positional scoring rules and the Minimax rule) can be approximated from partial preferences collected through either a randomized procedure (where each voter ranks a random subset of candidates) or a deterministic procedure (where each voter provides a ranking of her top candidates). | [ 2.4233 15.7984] The authors suggest measuring the proximity of a given preference profile to a nicely structured preference profile by counting the number of voters or alternatives that need to be removed to reach a nicely structured profile. | Convert the coordinate to text: [ 2.409  15.7979]:","generate_predictions":" This work delves into the computational complexity of various parameterizations for different voting rules, such as the number of candidates, the size of the domain of the profile, and the number of pivotal voters, specifically in relation to the number of voters with a fixed number of approval votes.","labels":"This paper studies different proportionality axioms in relation to large classes of approval-based satisfaction functions, while considering how outcomes could be proportional with respect to more than one satisfaction function."}
